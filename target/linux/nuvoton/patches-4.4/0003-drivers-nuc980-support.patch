diff -uprN linux-4.4.194/drivers/base/Kconfig NUC980-linux-4.4.194/drivers/base/Kconfig
--- linux-4.4.194/drivers/base/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/base/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -327,4 +327,29 @@ config CMA_ALIGNMENT
 
 endif
 
+config FMI_NUC980
+	tristate "Nuvoton NUC980 FMI function selection"
+	depends on ARCH_NUC980
+	help
+	  Switch FMI function to support SD0 or MTD NAND function.
+
+choice
+	prompt "Select FMI device to support"
+	default NUC980_FMI_MTD_NAND
+	depends on FMI_NUC980
+	help
+	  Select FMI device to support, such as SD card or NAND Flash device.
+
+	config NUC980_FMI_MTD_NAND
+		bool "Support MTD NAND Flash"
+        select MTD
+        select MTD_NAND
+        select MTD_NAND_NUC980
+
+	config NUC980_FMI_SD0
+		bool "Support SD0 Device"
+        select MMC
+        select MMC_NUC980_FMI
+endchoice
+
 endmenu
diff -uprN linux-4.4.194/drivers/char/hw_random/Kconfig NUC980-linux-4.4.194/drivers/char/hw_random/Kconfig
--- linux-4.4.194/drivers/char/hw_random/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/char/hw_random/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -333,6 +333,17 @@ config HW_RANDOM_TPM
 
 	  If unsure, say Y.
 
+config HW_RANDOM_NUVOTON
+	tristate "Nuvoton HW Random Number Generator support"
+	depends on HW_RANDOM && CRYPTO_DEV_NUC980
+	default HW_RANDOM
+	---help---
+	  This driver provides kernel-side support for the Random Number
+	  Generator in the Trusted Platform Module
+
+	  To compile this driver as a module, choose M here: the
+	  module will be called nuvoton-rng.
+
 config HW_RANDOM_MSM
 	tristate "Qualcomm SoCs Random Number Generator support"
 	depends on HW_RANDOM && ARCH_QCOM
diff -uprN linux-4.4.194/drivers/char/hw_random/Makefile NUC980-linux-4.4.194/drivers/char/hw_random/Makefile
--- linux-4.4.194/drivers/char/hw_random/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/char/hw_random/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -28,6 +28,7 @@ obj-$(CONFIG_HW_RANDOM_POWERNV) += power
 obj-$(CONFIG_HW_RANDOM_EXYNOS)	+= exynos-rng.o
 obj-$(CONFIG_HW_RANDOM_TPM) += tpm-rng.o
 obj-$(CONFIG_HW_RANDOM_BCM2835) += bcm2835-rng.o
+obj-$(CONFIG_HW_RANDOM_NUVOTON) += nuvoton-rng.o
 obj-$(CONFIG_HW_RANDOM_IPROC_RNG200) += iproc-rng200.o
 obj-$(CONFIG_HW_RANDOM_MSM) += msm-rng.o
 obj-$(CONFIG_HW_RANDOM_ST) += st-rng.o
diff -uprN linux-4.4.194/drivers/char/hw_random/nuvoton-rng.c NUC980-linux-4.4.194/drivers/char/hw_random/nuvoton-rng.c
--- linux-4.4.194/drivers/char/hw_random/nuvoton-rng.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/char/hw_random/nuvoton-rng.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,133 @@
+/*
+ * Copyright (c) 2018-2020 Nuvoton Technology Corporation, Y.C. Huang
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/hw_random.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+
+#include <mach/map.h>
+#include <mach/regs-crypto.h>
+
+
+volatile struct nuc980_crypto_regs  *regs;
+
+
+struct device *rng_dev;
+
+static int  is_first_read = 1;
+static int  rng_data_cnt = 0;
+
+static int nuvoton_rng_init(struct hwrng *rng)
+{
+	/* Dummy function. Clock should be enabled by Nuvoton crypto driver. */
+	return 0;
+}
+
+static void nuvoton_rng_cleanup(struct hwrng *rng)
+{
+	/* Dummy function. Nothing need to be cleanup. */
+}
+
+static int nuvoton_rng_read(struct hwrng *rng, u32 *data)
+{
+	volatile int   i;
+
+	if (is_first_read || (rng_data_cnt >= 0x4000000))
+	{
+		/* If it's the first time called for PRNG or accumulated 4G bits, we have to re-seed
+		   the PRNG. Use the current jiffies to be the random seed. */
+		is_first_read = 0;
+		rng_data_cnt = 0;
+		regs->CRPT_PRNG_SEED = jiffies;
+		regs->CRPT_PRNG_CTL = PRNG_KEYSZ_64 | SEEDRLD | PRNG_START;   /* generate 64-bits random data with re-seed */
+	}
+	else
+	{
+		regs->CRPT_PRNG_CTL = PRNG_KEYSZ_64 | PRNG_START; /* generate the next 64-bits data of random sequence */
+	}
+
+	/* Wait for PRNG data available.
+	   This loop is much longer than the random number generation time. */
+	for (i = 0; i < 10000; i++)
+	{
+		if (!(regs->CRPT_PRNG_CTL & PRNG_BUSY))
+		    break;
+	}
+
+	if (regs->CRPT_PRNG_CTL & PRNG_BUSY)
+	{
+		dev_err(rng_dev, "PRNG h/w busy!\n");
+		return 0;       // no data
+	}
+
+	//printk("RNG: 0x%x\n", regs->CRPT_PRNG_KEY[0]);
+
+	*data = regs->CRPT_PRNG_KEY[0];    /* retrieve 32-bits data */
+	rng_data_cnt ++;
+
+	return 4;
+}
+
+static struct hwrng nuvoton_rng = {
+	.name		= "nuvoton-rng",
+	.init       = nuvoton_rng_init,
+	.cleanup    = nuvoton_rng_cleanup,
+	.data_read  = nuvoton_rng_read,
+};
+
+static int nuvoton_rng_probe(struct platform_device *pdev)
+{
+	int ret;
+	
+	regs = (volatile struct nuc980_crypto_regs *)NUC980_VA_CRYPTO;
+
+	ret = hwrng_register(&nuvoton_rng);
+	if (ret)
+		return ret;
+
+	rng_dev = &pdev->dev;
+	dev_info(&pdev->dev, "nuvoton PRNG active\n");
+
+	return 0;
+}
+
+static int nuvoton_rng_remove(struct platform_device *pdev)
+{
+	hwrng_unregister(&nuvoton_rng);
+	return 0;
+}
+
+static const struct of_device_id nuvoton_rng_of_match[] =
+{
+    { .compatible = "nuvoton,nuvoton-rng" },
+    {},
+};
+MODULE_DEVICE_TABLE(of, nuvoton_rng_of_match);
+
+
+static struct platform_driver nuvoton_rng_driver = {
+	.probe		= nuvoton_rng_probe,
+	.remove		= nuvoton_rng_remove,
+	.driver		= {
+		.name	= "nuvoton-rng",
+		.owner	= THIS_MODULE,
+        .of_match_table = of_match_ptr(nuvoton_rng_of_match),
+	},
+};
+
+module_platform_driver(nuvoton_rng_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Nuvoton Technology Corporation");
+MODULE_DESCRIPTION("Nuvoton NUC980 PRNG driver");
diff -uprN linux-4.4.194/drivers/clk/Kconfig NUC980-linux-4.4.194/drivers/clk/Kconfig
--- linux-4.4.194/drivers/clk/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/clk/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -191,10 +191,8 @@ config COMMON_CLK_CDCE706
 source "drivers/clk/bcm/Kconfig"
 source "drivers/clk/hisilicon/Kconfig"
 source "drivers/clk/qcom/Kconfig"
-
 endmenu
 
 source "drivers/clk/mvebu/Kconfig"
-
 source "drivers/clk/samsung/Kconfig"
 source "drivers/clk/tegra/Kconfig"
diff -uprN linux-4.4.194/drivers/clk/Makefile NUC980-linux-4.4.194/drivers/clk/Makefile
--- linux-4.4.194/drivers/clk/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/clk/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -84,3 +84,4 @@ endif
 obj-$(CONFIG_ARCH_ZX)			+= zte/
 obj-$(CONFIG_ARCH_ZYNQ)			+= zynq/
 obj-$(CONFIG_H8300)		+= h8300/
+obj-$(CONFIG_ARCH_NUC980)               += nuvoton/
diff -uprN linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-apll.c NUC980-linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-apll.c
--- linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-apll.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-apll.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,169 @@
+/*
+ * linux/arch/arm/mach-nuc980/clk-apll.c
+ *
+ * Copyright (c) 2017 Nuvoton Technology Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ */
+
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+#include <linux/kernel.h>
+#include <linux/err.h>
+
+#include "clk-nuc980.h"
+
+struct clk_apll {
+	struct clk_hw hw;
+	void __iomem *base;
+};
+
+#define to_clk_apll(clk) (container_of(clk, struct clk_apll, clk))
+static int clk_apll_set_rate(struct clk_hw *hw, unsigned long rate,
+			     unsigned long parent_rate)
+{
+
+	struct clk_apll *pll = to_clk_apll(hw);
+	u32 reg;
+	reg = readl(pll->base) & ~0x0FFFFFFF;
+
+	switch (rate) {
+
+	case 98000000:		/* usbh */
+		reg |= 0x8027;
+		break;
+	case 98400000:		/* i2s */
+		reg |= 0x8028;
+		break;
+	case 169500000:		/* i2s */
+		reg |= 0x21f0;
+		break;
+	case 264000000:		/* system default, 264MHz */
+		reg |= 0x15;
+		break;
+	case 300000000:
+		reg |= 0x18;
+		break;
+	default:
+		reg |= 0x15;
+		break;
+	}
+
+	writel(reg, pll->base);
+
+	return 0;
+}
+
+static unsigned long clk_apll_recalc_rate(struct clk_hw *hw,
+					  unsigned long parent_rate)
+{
+
+	struct clk_apll *pll = to_clk_apll(hw);
+	long long ll;
+	u32 reg = readl(pll->base) & 0x0FFFFFFF;
+
+	if (parent_rate != 12000000)
+		return 0;
+
+	switch (reg) {
+	case 0x15:
+		ll = 264000000;	/* system default, 264MHz */
+		break;
+	case 0x18:
+		ll = 300000000;
+		break;
+	case 0x8027:
+		ll = 98000000;	/* usbh */
+		break;
+	case 0x8028:
+		ll = 98400000;	/* i2s */
+		break;
+	case 0x21f0:
+		ll = 169500000;	/* i2s */
+		break;
+	default:
+		ll = 264000000;
+		break;
+	}
+
+	return ll;
+}
+
+static long clk_apll_round_rate(struct clk_hw *hw, unsigned long rate,
+				unsigned long *prate)
+{
+
+	return rate;
+}
+
+static int clk_apll_enable(struct clk_hw *hw)
+{
+
+	struct clk_apll *pll = to_clk_apll(hw);
+	u32 val;
+
+	val = readl(pll->base);
+	val &= ~0x10000000;	/* PD = 0, power down mode disable */
+	val |= 0x40000000;	/* RESETN = 1 */
+	writel(val, pll->base);
+
+	return 0;
+}
+
+static void clk_apll_disable(struct clk_hw *hw)
+{
+
+	struct clk_apll *pll = to_clk_apll(hw);
+	u32 val;
+
+	val = readl(pll->base);
+	val |= 0x10000000;	/* PD = 1, power down mode enable */
+	val &= ~0x40000000;	/* RESETN = 1 */
+	writel(val, pll->base);
+}
+
+static struct clk_ops clk_apll_ops = {
+	.recalc_rate = clk_apll_recalc_rate,
+	.enable = clk_apll_enable,
+	.disable = clk_apll_disable,
+	.set_rate = clk_apll_set_rate,
+	.round_rate = clk_apll_round_rate,
+};
+
+struct clk *nuc980_clk_apll(const char *name, const char *parent,
+			    void __iomem *base)
+{
+
+	struct clk_apll *pll;
+	struct clk *clk;
+	struct clk_init_data init;
+
+	pll = kmalloc(sizeof(*pll), GFP_KERNEL);
+
+	if (!pll)
+		return ERR_PTR(-ENOMEM);
+
+	pll->base = base;
+	init.name = name;
+	init.ops = &clk_apll_ops;
+	init.flags = 0;
+	init.parent_names = &parent;
+	init.num_parents = 1;
+	pll->hw.init = &init;
+	clk = clk_register(NULL, &pll->hw);
+
+	if (IS_ERR(clk))
+		kfree(pll);
+
+	return clk;
+}
diff -uprN linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-ccf.c NUC980-linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-ccf.c
--- linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-ccf.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-ccf.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,634 @@
+/*
+ * linux/arch/arm/mach-nuc980/clk-ccf.c
+ *
+ * Copyright (c) 2017 Nuvoton Technology Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/clk.h>
+#include <linux/io.h>
+#include <linux/clkdev.h>
+#include <linux/err.h>
+#include <mach/hardware.h>
+#include <mach/regs-clock.h>
+#include <linux/spinlock.h>
+
+#include "clk-nuc980.h"
+
+DEFINE_SPINLOCK(nuc980_lock);
+
+static const char *sys_sel_clks[] = { "xin", "dummy", "apll", "upll", };
+static const char *audio_sel_clks[] = { "xin", "dummy", "apll", "upll", };
+static const char *usb_sel_clks[] = { "dummy", "dummy", "usbphy0_div", "usbphy1_div", };
+static const char *qspi0_sel_clks[] = { "xin", "pclk0_div", "apll", "upll", };
+static const char *spi0_sel_clks[] = { "xin", "pclk1_div", "apll", "upll", };
+static const char *spi1_sel_clks[] = { "xin", "pclk0_div", "apll", "upll", };
+static const char *cap0_sel_clks[] = { "xin", "dummy", "cap0_aplldiv", "cap0_uplldiv", };
+static const char *cap1_sel_clks[] = { "xin", "dummy", "cap1_aplldiv", "cap1_uplldiv", };
+static const char *uart0_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *uart1_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *uart2_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *uart3_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *uart4_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *uart5_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *uart6_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *uart7_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *uart8_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *uart9_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+static const char *adc_sel_clks[] = { "xin", "dummy", "apll", "upll", };
+static const char *wwdt_sel_clks[] = { "xin", "xin512_div", "pclk24096_div", "xin32k", };
+static const char *timer0_sel_clks[] = { "xin", "pclk0_div", "pclk4096_div", "xin32k", };
+static const char *timer1_sel_clks[] = { "xin", "pclk0_div", "pclk4096_div", "xin32k", };
+static const char *timer2_sel_clks[] = { "xin", "pclk1_div", "pclk4096_div", "xin32k", };
+static const char *timer3_sel_clks[] = { "xin", "pclk1_div", "pclk4096_div", "xin32k", };
+static const char *timer4_sel_clks[] = { "xin", "pclk0_div", "pclk4096_div", "xin32k", };
+static const char *timer5_sel_clks[] = { "xin", "pclk0_div", "pclk4096_div", "xin32k", };
+static const char *sdh0_sel_clks[] = { "xin", "dummy", "apll", "upll", };
+static const char *sdh1_sel_clks[] = { "xin", "dummy", "apll", "upll", };
+static const char *cko_sel_clks[] = { "xin", "xin32k", "apll", "upll", };
+//static const char *gpio_sel_clks[] = { "xin", "xin32k" };	// -- TODO
+
+enum nuc980_clks {
+	// source
+	xin, xin32k, apll, upll, usbphy0, usbphy1, xin512_div,
+	sys_mux, sys_div, ddr_gate, cpu_div, cpu_gate,
+	hclk1_div, hclk1_gate, pdma0_gate, pdma1_gate, tic_gate, ebi_gate, gpio_gate,
+
+	hclk_div, hclk_gate, dram_gate, sram_gate,
+
+	emac1_gate, emac1_eclk_div, emac1_eclk_gate, usbh_gate, usbd_gate,
+	fmi_gate, nand_gate, crypto_gate, sdh0_gate, cap1_gate,
+
+	emac0_gate, emac0_eclk_div, emac0_eclk_gate, sdh1_gate, audio_gate, cap0_gate, sensor_gate,
+
+	// eclk
+	audio_eclk_mux, audio_eclk_div, audio_eclk_gate,
+	usb_eclk_mux,/* usb_eclk_div,*/usbphy0_div, usbphy1_div, usb_eclk_gate,
+	qspi0_eclk_mux, qspi0_eclk_gate,
+	spi0_eclk_mux, spi0_eclk_gate,
+	spi1_eclk_mux, spi1_eclk_gate,
+	cap1_aplldiv, cap1_uplldiv, cap1_eclk_mux, cap1_eclk_div, cap1_eclk_gate,
+	cap0_aplldiv, cap0_uplldiv, cap0_eclk_mux, cap0_eclk_div, cap0_eclk_gate,
+	uart0_eclk_mux, uart0_eclk_div, uart0_eclk_gate,
+	uart1_eclk_mux, uart1_eclk_div, uart1_eclk_gate,
+	uart2_eclk_mux, uart2_eclk_div, uart2_eclk_gate,
+	uart3_eclk_mux, uart3_eclk_div, uart3_eclk_gate,
+	uart4_eclk_mux, uart4_eclk_div, uart4_eclk_gate,
+	uart5_eclk_mux, uart5_eclk_div, uart5_eclk_gate,
+	uart6_eclk_mux, uart6_eclk_div, uart6_eclk_gate,
+	uart7_eclk_mux, uart7_eclk_div, uart7_eclk_gate,
+	uart8_eclk_mux, uart8_eclk_div, uart8_eclk_gate,
+	uart9_eclk_mux, uart9_eclk_div, uart9_eclk_gate,
+	smc0_eclk_div, smc0_eclk_gate,
+	smc1_eclk_div, smc1_eclk_gate,
+	adc_eclk_mux, adc_eclk_div, adc_eclk_gate,
+	wwdt_eclk_mux, wwdt_eclk_gate,
+	wdt_eclk_mux, wdt_eclk_gate,
+	timer0_eclk_mux, timer0_eclk_gate,
+	timer1_eclk_mux, timer1_eclk_gate,
+	timer2_eclk_mux, timer2_eclk_gate,
+	timer3_eclk_mux, timer3_eclk_gate,
+	timer4_eclk_mux, timer4_eclk_gate,
+	timer5_eclk_mux, timer5_eclk_gate,
+	sdh0_eclk_mux, sdh0_eclk_div, sdh0_eclk_gate,
+	sdh1_eclk_mux, sdh1_eclk_div, sdh1_eclk_gate,
+	cko_eclk_mux, cko_eclk_div, cko_eclk_gate,
+
+	// pclk
+	pclk0_div, pclk0_gate, pclk4096_div,
+	i2c0_gate, i2c2_gate,
+	qspi0_gate, spi1_gate,
+	timer0_gate, timer1_gate, timer4_gate, timer5_gate,
+	uart0_gate, uart2_gate, uart4_gate,	uart6_gate, uart8_gate,
+
+	pclk1_div, pclk1_gate,
+	i2c1_gate, i2c3_gate,
+	spi0_gate,
+	timer2_gate, timer3_gate,
+	uart1_gate, uart3_gate, uart5_gate, uart7_gate, uart9_gate,
+	adc_gate,
+
+	pclk2_div, pclk2_gate, pclk24096_div,
+	rtc_gate,
+	wdt_gate,
+	wwdt_gate,
+	can0_gate, can1_gate, can2_gate, can3_gate,
+	smc0_gate, smc1_gate,
+	pwm0_gate, pwm1_gate,
+
+	clk_max
+};
+
+static struct clk *clk[clk_max];
+
+int __init nuc980_init_clocks(void)
+{
+	int i;
+
+	// source
+	clk[xin] = nuc980_clk_fixed("xin", 12000000);
+	clk[xin32k] = nuc980_clk_fixed("xin32k", 32768);
+	clk[apll] = nuc980_clk_apll("apll", "xin", REG_CLK_APLLCON);
+	clk[upll] = nuc980_clk_upll("upll", "xin", REG_CLK_UPLLCON);
+	// for FPGA
+	//clk[apll] = nuc980_clk_fixed("apll", 12000000);
+	//clk[upll] = nuc980_clk_fixed("upll", 12000000);
+
+	clk[usbphy0] = nuc980_clk_fixed("usbphy0", 480000000);
+	clk[usbphy1] = nuc980_clk_fixed("usbphy1", 480000000);
+
+	clk[xin512_div] = nuc980_clk_fixed_factor("xin512_div", "xin", 1, 512);	//  xin/512
+
+	clk[sys_mux] = nuc980_clk_mux("sys_mux", REG_CLK_DIV0, 3, 2, sys_sel_clks, ARRAY_SIZE(sys_sel_clks));
+	clk[sys_div] = nuc980_clk_divider("sys_div", "sys_mux", REG_CLK_DIV0, 8, 1);
+	clk[ddr_gate] = nuc980_clk_gate("ddr_gate", "sys_div", REG_CLK_HCLKEN, 10);
+
+	// CPU
+	clk[cpu_div] = nuc980_clk_divider("cpu_div", "sys_div", REG_CLK_DIV0, 16, 1);
+	clk[cpu_gate] = nuc980_clk_gate("cpu_gate", "cpu_div", REG_CLK_HCLKEN, 0);
+
+	// HCLK1 & PCLK1
+	clk[hclk1_div]  = nuc980_clk_fixed_factor("hclk1_div", "sys_div", 1, 2); //  /2
+	clk[hclk1_gate] = nuc980_clk_gate("hclk1_gate", "hclk1_div", REG_CLK_HCLKEN, 2);
+	clk[pdma0_gate] = nuc980_clk_gate("pdma0_hclk_gate", "hclk1_div", REG_CLK_HCLKEN, 12);
+	clk[pdma1_gate] = nuc980_clk_gate("pdma1_hclk_gate", "hclk1_div", REG_CLK_HCLKEN, 13);
+	clk[tic_gate] = nuc980_clk_gate("tic_hclk_gate", "hclk1_div", REG_CLK_HCLKEN, 7);
+	clk[ebi_gate] = nuc980_clk_gate("ebi_hclk_gate", "hclk1_div", REG_CLK_HCLKEN, 9);
+	clk[gpio_gate] = nuc980_clk_gate("gpio_hclk_gate", "hclk1_div", REG_CLK_HCLKEN, 11);
+	// clk[gpio_eclk_mux] = nuc980_clk_mux("gpio_eclk_mux", REG_CLK_DIV7, 7, 1, gpio_sel_clks, ARRAY_SIZE(gpio_sel_clks));
+	// clk[gpio_eclk_div] = nuc980_clk_divider("gpio_eclk_div", "gpio_eclk_mux", REG_CLK_DIV7, 0, 7);
+	// clk[gpio_eclk_gate] = nuc980_clk_gate("gpio_eclk_gate", "gpio_eclk_div", REG_CLK_HCLKEN, 11);
+
+	// HCLK & HCLK234
+	clk[hclk_div] = nuc980_clk_fixed_factor("hclk_div", "sys_div", 1, 2); //  /2
+	clk[hclk_gate] = nuc980_clk_gate("hclk_gate", "hclk_div", REG_CLK_HCLKEN, 1);
+	clk[dram_gate] = nuc980_clk_gate("dram_gate", "hclk_div", REG_CLK_HCLKEN, 10);
+	clk[sram_gate] = nuc980_clk_gate("sram_gate", "hclk_gate", REG_CLK_HCLKEN, 8);
+
+	// HCLK3
+	clk[emac1_gate] = nuc980_clk_gate("emac1_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 17);
+	clk[emac1_eclk_div] = nuc980_clk_divider("emac1_eclk_div", "hclk_div", REG_CLK_DIV8, 0, 8);
+	clk[emac1_eclk_gate] = nuc980_clk_gate("emac1_eclk_gate", "emac1_eclk_div", REG_CLK_HCLKEN, 17);
+	clk[usbh_gate] = nuc980_clk_gate("usbh_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 18);
+	clk[usbd_gate] = nuc980_clk_gate("usbd_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 19);
+	clk[fmi_gate] = nuc980_clk_gate("fmi_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 20);
+	clk[nand_gate] = nuc980_clk_gate("nand_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 21);
+	clk[crypto_gate] = nuc980_clk_gate("crypto_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 23);
+	clk[sdh0_gate] = nuc980_clk_gate("sdh0_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 22);
+	clk[cap1_gate] = nuc980_clk_gate("cap1_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 31);
+
+	// HCLK4
+	clk[emac0_gate] = nuc980_clk_gate("emac0_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 16);
+	clk[emac0_eclk_div] = nuc980_clk_divider("emac0_eclk_div", "hclk_div", REG_CLK_DIV8, 0, 8);
+	clk[emac0_eclk_gate] = nuc980_clk_gate("emac0_eclk_gate", "emac0_eclk_div", REG_CLK_HCLKEN, 16);
+	clk[sdh1_gate] = nuc980_clk_gate("sdh1_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 30);
+	clk[audio_gate] = nuc980_clk_gate("audio_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 24);
+	clk[cap0_gate] = nuc980_clk_gate("cap0_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 26);
+	clk[sensor_gate] = nuc980_clk_gate("sensor_hclk_gate", "hclk_div", REG_CLK_HCLKEN, 27); // ?? block diagram
+
+	// ECLK
+	// -AUDIO
+	clk[audio_eclk_mux] = nuc980_clk_mux("audio_eclk_mux", REG_CLK_DIV1, 19, 2, audio_sel_clks, ARRAY_SIZE(audio_sel_clks));
+	clk[audio_eclk_div] = nuc980_clk_divider("audio_eclk_div", "audio_eclk_mux", REG_CLK_DIV1, 24, 8);
+	clk[audio_eclk_gate] = nuc980_clk_gate("audio_eclk_gate", "audio_eclk_div", REG_CLK_HCLKEN, 24);
+
+	// -USB
+	clk[usb_eclk_mux] = nuc980_clk_mux("usb_eclk_mux", REG_CLK_DIV2, 3, 2, usb_sel_clks, ARRAY_SIZE(usb_sel_clks));
+	clk[usbphy0_div] = nuc980_clk_fixed_factor("usbphy0_div", "usbphy0", 1, 10);	//  usbphy0/10 = 48Hz
+	clk[usbphy1_div] = nuc980_clk_fixed_factor("usbphy1_div", "usbphy1", 1, 10);	//  usbphy1/10 = 48Hz
+	clk[usb_eclk_gate] = nuc980_clk_gate("usb_eclk_gate", "usbphy0_div", REG_CLK_HCLKEN, 18);
+
+	// -QSPI0
+	clk[qspi0_eclk_mux] = nuc980_clk_mux("qspi0_eclk_mux", REG_CLK_DIV2, 8, 2, qspi0_sel_clks, ARRAY_SIZE(qspi0_sel_clks));
+	clk[qspi0_eclk_gate] = nuc980_clk_gate("qspi0_eclk_gate", "qspi0_eclk_mux", REG_CLK_PCLKEN1, 4);
+
+	// -SPI0
+	clk[spi0_eclk_mux] = nuc980_clk_mux("spi0_eclk_mux", REG_CLK_DIV2, 10, 2, spi0_sel_clks, ARRAY_SIZE(spi0_sel_clks));
+	clk[spi0_eclk_gate] = nuc980_clk_gate("spi0_eclk_gate", "spi0_eclk_mux", REG_CLK_PCLKEN1, 5);
+
+	// -SPI1
+	clk[spi1_eclk_mux] = nuc980_clk_mux("spi1_eclk_mux", REG_CLK_DIV2, 12, 2, spi1_sel_clks, ARRAY_SIZE(spi1_sel_clks));
+	clk[spi1_eclk_gate] = nuc980_clk_gate("spi1_eclk_gate", "spi1_eclk_mux", REG_CLK_PCLKEN1, 6);
+
+	// -CAP1
+	clk[cap1_aplldiv] = nuc980_clk_divider("cap1_aplldiv", "apll", REG_CLK_DIV2, 16, 3);
+	clk[cap1_uplldiv] = nuc980_clk_divider("cap1_uplldiv", "upll", REG_CLK_DIV2, 16, 3);
+	clk[cap1_eclk_mux] = nuc980_clk_mux("cap1_eclk_mux", REG_CLK_DIV2, 19, 2, cap1_sel_clks, ARRAY_SIZE(cap1_sel_clks));
+	clk[cap1_eclk_div] = nuc980_clk_divider("cap1_eclk_div", "cap1_eclk_mux", REG_CLK_DIV2, 24, 4);
+	clk[cap1_eclk_gate] = nuc980_clk_gate("cap1_eclk_gate", "cap1_eclk_div", REG_CLK_HCLKEN, 31);
+
+	// -CAP0
+	clk[cap0_aplldiv] = nuc980_clk_divider("cap0_aplldiv", "apll", REG_CLK_DIV3, 16, 3);
+	clk[cap0_uplldiv] = nuc980_clk_divider("cap0_uplldiv", "upll", REG_CLK_DIV3, 16, 3);
+	clk[cap0_eclk_mux] = nuc980_clk_mux("cap0_eclk_mux", REG_CLK_DIV3, 19, 2, cap0_sel_clks, ARRAY_SIZE(cap0_sel_clks));
+	clk[cap0_eclk_div] = nuc980_clk_divider("cap0_eclk_div", "cap0_eclk_mux", REG_CLK_DIV3, 24, 4);
+	clk[cap0_eclk_gate] = nuc980_clk_gate("cap0_eclk_gate", "cap0_eclk_div", REG_CLK_HCLKEN, 26);
+
+	// -UART0
+	clk[uart0_eclk_mux] = nuc980_clk_mux("uart0_eclk_mux", REG_CLK_DIV4, 3, 2, uart0_sel_clks, ARRAY_SIZE(uart0_sel_clks));
+	clk[uart0_eclk_div] = nuc980_clk_divider("uart0_eclk_div", "uart0_eclk_mux", REG_CLK_DIV4, 5, 3);
+	clk[uart0_eclk_gate] = nuc980_clk_gate("uart0_eclk_gate", "uart0_eclk_div", REG_CLK_PCLKEN0, 16);
+
+	// -UART1
+	clk[uart1_eclk_mux] = nuc980_clk_mux("uart1_eclk_mux", REG_CLK_DIV4, 11, 2, uart1_sel_clks, ARRAY_SIZE(uart1_sel_clks));
+	clk[uart1_eclk_div] = nuc980_clk_divider("uart1_eclk_div", "uart1_eclk_mux", REG_CLK_DIV4, 13, 3);
+	clk[uart1_eclk_gate] = nuc980_clk_gate("uart1_eclk_gate", "uart1_eclk_div", REG_CLK_PCLKEN0, 17);
+
+	// -UART2
+	clk[uart2_eclk_mux] = nuc980_clk_mux("uart2_eclk_mux", REG_CLK_DIV4, 19, 2, uart2_sel_clks, ARRAY_SIZE(uart2_sel_clks));
+	clk[uart2_eclk_div] = nuc980_clk_divider("uart2_eclk_div", "uart2_eclk_mux", REG_CLK_DIV4, 21, 3);
+	clk[uart2_eclk_gate] = nuc980_clk_gate("uart2_eclk_gate", "uart2_eclk_div", REG_CLK_PCLKEN0, 18);
+
+	// -UART3
+	clk[uart3_eclk_mux] = nuc980_clk_mux("uart3_eclk_mux", REG_CLK_DIV4, 27, 2, uart3_sel_clks, ARRAY_SIZE(uart3_sel_clks));
+	clk[uart3_eclk_div] = nuc980_clk_divider("uart3_eclk_div", "uart3_eclk_mux", REG_CLK_DIV4, 29, 3);
+	clk[uart3_eclk_gate] = nuc980_clk_gate("uart3_eclk_gate", "uart3_eclk_div", REG_CLK_PCLKEN0, 19);
+
+	// -UART4
+	clk[uart4_eclk_mux] = nuc980_clk_mux("uart4_eclk_mux", REG_CLK_DIV5, 3, 2, uart4_sel_clks, ARRAY_SIZE(uart4_sel_clks));
+	clk[uart4_eclk_div] = nuc980_clk_divider("uart4_eclk_div", "uart4_eclk_mux", REG_CLK_DIV5, 5, 3);
+	clk[uart4_eclk_gate] = nuc980_clk_gate("uart4_eclk_gate", "uart4_eclk_div", REG_CLK_PCLKEN0, 20);
+
+	// -UART5
+	clk[uart5_eclk_mux] = nuc980_clk_mux("uart5_eclk_mux", REG_CLK_DIV5, 11, 2, uart5_sel_clks, ARRAY_SIZE(uart5_sel_clks));
+	clk[uart5_eclk_div] = nuc980_clk_divider("uart5_eclk_div", "uart5_eclk_mux", REG_CLK_DIV5, 13, 3);
+	clk[uart5_eclk_gate] = nuc980_clk_gate("uart5_eclk_gate", "uart5_eclk_div", REG_CLK_PCLKEN0, 21);
+
+	// -UART6
+	clk[uart6_eclk_mux] = nuc980_clk_mux("uart6_eclk_mux", REG_CLK_DIV5, 19, 2, uart6_sel_clks, ARRAY_SIZE(uart6_sel_clks));
+	clk[uart6_eclk_div] = nuc980_clk_divider("uart6_eclk_div", "uart6_eclk_mux", REG_CLK_DIV5, 21, 3);
+	clk[uart6_eclk_gate] = nuc980_clk_gate("uart6_eclk_gate", "uart6_eclk_div", REG_CLK_PCLKEN0, 22);
+
+	// -UART7
+	clk[uart7_eclk_mux] = nuc980_clk_mux("uart7_eclk_mux", REG_CLK_DIV5, 27, 2, uart7_sel_clks, ARRAY_SIZE(uart7_sel_clks));
+	clk[uart7_eclk_div] = nuc980_clk_divider("uart7_eclk_div", "uart7_eclk_mux", REG_CLK_DIV5, 29, 3);
+	clk[uart7_eclk_gate] = nuc980_clk_gate("uart7_eclk_gate", "uart7_eclk_div", REG_CLK_PCLKEN0, 23);
+
+	// -UART8
+	clk[uart8_eclk_mux] = nuc980_clk_mux("uart8_eclk_mux", REG_CLK_DIV6, 3, 2, uart8_sel_clks, ARRAY_SIZE(uart8_sel_clks));
+	clk[uart8_eclk_div] = nuc980_clk_divider("uart8_eclk_div", "uart8_eclk_mux", REG_CLK_DIV6, 5, 3);
+	clk[uart8_eclk_gate] = nuc980_clk_gate("uart8_eclk_gate", "uart8_eclk_div", REG_CLK_PCLKEN0, 24);
+
+	// -UART9
+	clk[uart9_eclk_mux] = nuc980_clk_mux("uart9_eclk_mux", REG_CLK_DIV6, 11, 2, uart9_sel_clks, ARRAY_SIZE(uart9_sel_clks));
+	clk[uart9_eclk_div] = nuc980_clk_divider("uart9_eclk_div", "uart9_eclk_mux", REG_CLK_DIV6, 13, 3);
+	clk[uart9_eclk_gate] = nuc980_clk_gate("uart9_eclk_gate", "uart9_eclk_div", REG_CLK_PCLKEN0, 25);
+
+	// -SMARTCARD
+	clk[smc0_eclk_div] = nuc980_clk_divider("smc0_eclk_div", "xin", REG_CLK_DIV6, 24, 4);
+	clk[smc0_eclk_gate] = nuc980_clk_gate("smc0_eclk_gate", "smc0_eclk_div", REG_CLK_PCLKEN1, 12);
+
+	clk[smc1_eclk_div] = nuc980_clk_divider("smc1_eclk_div", "xin", REG_CLK_DIV6, 28, 4);
+	clk[smc1_eclk_gate] = nuc980_clk_gate("smc1_eclk_gate", "smc1_eclk_div", REG_CLK_PCLKEN1, 13);
+
+	// -ADC
+	clk[adc_eclk_mux] = nuc980_clk_mux("adc_eclk_mux", REG_CLK_DIV7, 19, 2, adc_sel_clks, ARRAY_SIZE(adc_sel_clks));
+	clk[adc_eclk_div] = nuc980_clk_divider("adc_eclk_div", "adc_eclk_mux", REG_CLK_DIV7, 24, 8);
+	clk[adc_eclk_gate] = nuc980_clk_gate("adc_eclk_gate", "adc_eclk_div", REG_CLK_PCLKEN1, 24);
+
+	// -WWDT
+	clk[wwdt_eclk_mux] = nuc980_clk_mux("wwdt_eclk_mux", REG_CLK_DIV8, 10, 2, wwdt_sel_clks, ARRAY_SIZE(wwdt_sel_clks));
+	clk[wwdt_eclk_gate] = nuc980_clk_gate("wwdt_eclk_gate", "wwdt_eclk_mux", REG_CLK_PCLKEN0, 1);
+
+	// -WDT
+	clk[wdt_eclk_mux] = nuc980_clk_mux("wdt_eclk_mux", REG_CLK_DIV8, 8, 2, wwdt_sel_clks, ARRAY_SIZE(wwdt_sel_clks));
+	clk[wdt_eclk_gate] = nuc980_clk_gate("wdt_eclk_gate", "wdt_eclk_mux", REG_CLK_PCLKEN0, 0);
+
+	// -timer0
+	clk[timer0_eclk_mux] = nuc980_clk_mux("timer0_eclk_mux", REG_CLK_DIV8, 16, 2, timer0_sel_clks, ARRAY_SIZE(timer0_sel_clks));
+	clk[timer0_eclk_gate] = nuc980_clk_gate("timer0_eclk_gate", "timer0_eclk_mux", REG_CLK_PCLKEN0, 8);
+
+	// -timer1
+	clk[timer1_eclk_mux] = nuc980_clk_mux("timer1_eclk_mux", REG_CLK_DIV8, 18, 2, timer1_sel_clks, ARRAY_SIZE(timer1_sel_clks));
+	clk[timer1_eclk_gate] = nuc980_clk_gate("timer1_eclk_gate", "timer1_eclk_mux", REG_CLK_PCLKEN0, 9);
+
+	// -timer2
+	clk[timer2_eclk_mux] = nuc980_clk_mux("timer2_eclk_mux", REG_CLK_DIV8, 20, 2, timer2_sel_clks, ARRAY_SIZE(timer2_sel_clks));
+	clk[timer2_eclk_gate] = nuc980_clk_gate("timer2_eclk_gate", "timer2_eclk_mux", REG_CLK_PCLKEN0, 10);
+
+	// -timer3
+	clk[timer3_eclk_mux] = nuc980_clk_mux("timer3_eclk_mux", REG_CLK_DIV8, 22, 2, timer3_sel_clks, ARRAY_SIZE(timer3_sel_clks));
+	clk[timer3_eclk_gate] = nuc980_clk_gate("timer3_eclk_gate", "timer3_eclk_mux", REG_CLK_PCLKEN0, 11);
+
+	// -timer4
+	clk[timer4_eclk_mux] = nuc980_clk_mux("timer4_eclk_mux", REG_CLK_DIV8, 24, 2, timer4_sel_clks, ARRAY_SIZE(timer4_sel_clks));
+	clk[timer4_eclk_gate] = nuc980_clk_gate("timer4_eclk_gate", "timer4_eclk_mux", REG_CLK_PCLKEN0, 12);
+
+	// -timer5
+	clk[timer5_eclk_mux] = nuc980_clk_mux("timer5_eclk_mux", REG_CLK_DIV8, 26, 2, timer5_sel_clks, ARRAY_SIZE(timer5_sel_clks));
+	clk[timer5_eclk_gate] = nuc980_clk_gate("timer5_eclk_gate", "timer5_eclk_mux", REG_CLK_PCLKEN0, 13);
+
+	// -SDH0
+	clk[sdh0_eclk_mux] = nuc980_clk_mux("sdh0_eclk_mux", REG_CLK_DIV3, 3, 2, sdh0_sel_clks, ARRAY_SIZE(sdh0_sel_clks));
+	clk[sdh0_eclk_div] = nuc980_clk_divider("sdh0_eclk_div", "sdh0_eclk_mux", REG_CLK_DIV3, 8, 8);
+	clk[sdh0_eclk_gate] = nuc980_clk_gate("sdh0_eclk_gate", "sdh0_eclk_div", REG_CLK_HCLKEN, 22);
+
+	// -SDH1
+	clk[sdh1_eclk_mux] = nuc980_clk_mux("sdh1_eclk_mux", REG_CLK_DIV9, 3, 2, sdh1_sel_clks, ARRAY_SIZE(sdh1_sel_clks));
+	clk[sdh1_eclk_div] = nuc980_clk_divider("sdh1_eclk_div", "sdh1_eclk_mux", REG_CLK_DIV9, 8, 8);
+	clk[sdh1_eclk_gate] = nuc980_clk_gate("sdh1_eclk_gate", "sdh1_eclk_div", REG_CLK_HCLKEN, 30);
+
+	clk[cko_eclk_mux] = nuc980_clk_mux("cko_eclk_mux", REG_CLK_DIV9, 19, 2, cko_sel_clks, ARRAY_SIZE(cko_sel_clks));
+	clk[cko_eclk_div] = nuc980_clk_divider("cko_eclk_div", "cko_eclk_mux", REG_CLK_DIV9, 24, 8);
+	clk[cko_eclk_gate] = nuc980_clk_gate("cko_eclk_gate", "cko_eclk_div", REG_CLK_HCLKEN, 15);
+
+	// -GPIO
+	// clk[gpio_eclk_mux] = nuc980_clk_mux("gpio_eclk_mux", REG_CLK_DIV7, 7, 1, gpio_sel_clks, ARRAY_SIZE(gpio_sel_clks));
+	// clk[gpio_eclk_div] = nuc980_clk_divider("gpio_eclk_div", "gpio_eclk_mux", REG_CLK_DIV7, 0, 7);
+	// clk[gpio_eclk_gate] = nuc980_clk_gate("gpio_eclk_gate", "gpio_eclk_div", REG_CLK_PCLKEN0, 3);
+
+	// PCLK0
+	clk[pclk0_div] = nuc980_clk_fixed_factor("pclk0_div", "hclk1_div", 1, 1);
+	clk[pclk0_gate] = nuc980_clk_gate("pclk0_gate", "pclk0_div", REG_CLK_HCLKEN, 5);
+	clk[pclk4096_div] = nuc980_clk_fixed_factor("pclk4096_div", "hclk1_div", 1, 4096);	//  pclk/4096
+	clk[i2c0_gate] = nuc980_clk_gate("i2c0_gate", "pclk0_div", REG_CLK_PCLKEN1, 0);
+	clk[i2c2_gate] = nuc980_clk_gate("i2c2_gate", "pclk0_div", REG_CLK_PCLKEN1, 2);
+	clk[qspi0_gate] = nuc980_clk_gate("qspi0_gate", "pclk0_div", REG_CLK_PCLKEN1, 4);
+	clk[spi1_gate] = nuc980_clk_gate("spi1_gate", "pclk0_div", REG_CLK_PCLKEN1, 6);
+	clk[timer0_gate] = nuc980_clk_gate("timer0_gate", "pclk0_div", REG_CLK_PCLKEN0, 8);
+	clk[timer1_gate] = nuc980_clk_gate("timer1_gate", "pclk0_div", REG_CLK_PCLKEN0, 9);
+	clk[timer4_gate] = nuc980_clk_gate("timer4_gate", "xin", REG_CLK_PCLKEN0, 12);
+	clk[timer5_gate] = nuc980_clk_gate("timer5_gate", "xin", REG_CLK_PCLKEN0, 13);
+	clk[uart0_gate] = nuc980_clk_gate("uart0_gate", "pclk0_div", REG_CLK_PCLKEN0, 16);
+	clk[uart2_gate] = nuc980_clk_gate("uart2_gate", "pclk0_div", REG_CLK_PCLKEN0, 18);
+	clk[uart4_gate] = nuc980_clk_gate("uart4_gate", "pclk0_div", REG_CLK_PCLKEN0, 20);
+	clk[uart6_gate] = nuc980_clk_gate("uart6_gate", "pclk0_div", REG_CLK_PCLKEN0, 22);
+	clk[uart8_gate] = nuc980_clk_gate("uart8_gate", "pclk0_div", REG_CLK_PCLKEN0, 24);
+
+	clk[pclk1_div] = nuc980_clk_fixed_factor("pclk1_div", "hclk1_div", 1, 1);
+	clk[pclk1_gate] = nuc980_clk_gate("pclk1_gate", "pclk1_div", REG_CLK_HCLKEN, 6);
+	clk[i2c1_gate] = nuc980_clk_gate("i2c1_gate", "pclk1_div", REG_CLK_PCLKEN1, 1);
+	clk[i2c3_gate] = nuc980_clk_gate("i2c3_gate", "pclk1_div", REG_CLK_PCLKEN1, 3);
+	clk[spi0_gate] = nuc980_clk_gate("spi0_gate", "pclk1_div", REG_CLK_PCLKEN1, 5);
+	clk[timer2_gate] = nuc980_clk_gate("timer2_gate", "pclk1_div", REG_CLK_PCLKEN0, 10);
+	clk[timer3_gate] = nuc980_clk_gate("timer3_gate", "pclk1_div", REG_CLK_PCLKEN0, 11);
+	clk[uart1_gate] = nuc980_clk_gate("uart1_gate", "pclk1_div", REG_CLK_PCLKEN0, 17);
+	clk[uart3_gate] = nuc980_clk_gate("uart3_gate", "pclk1_div", REG_CLK_PCLKEN0, 19);
+	clk[uart5_gate] = nuc980_clk_gate("uart5_gate", "pclk1_div", REG_CLK_PCLKEN0, 21);
+	clk[uart7_gate] = nuc980_clk_gate("uart7_gate", "pclk1_div", REG_CLK_PCLKEN0, 23);
+	clk[uart9_gate] = nuc980_clk_gate("uart9_gate", "pclk1_div", REG_CLK_PCLKEN0, 25);
+	clk[adc_gate] = nuc980_clk_gate("adc_gate", "pclk1_div", REG_CLK_PCLKEN1, 24);
+
+	// PCLK2
+	clk[pclk2_div] = nuc980_clk_fixed_factor("pclk2_div", "hclk1_div", 1, 2);
+	clk[pclk2_gate] = nuc980_clk_gate("pclk2_gate", "pclk2_div", REG_CLK_HCLKEN, 14);
+	clk[pclk24096_div] = nuc980_clk_fixed_factor("pclk24096_div", "pclk2_div", 1, 4096);	//  pclk2/4096
+	clk[rtc_gate] = nuc980_clk_gate("rtc_gate", "pclk2_div", REG_CLK_PCLKEN0, 2);
+	clk[wdt_gate] = nuc980_clk_gate("wdt_gate", "pclk2_div", REG_CLK_PCLKEN0, 0);
+	clk[wwdt_gate] = nuc980_clk_gate("wwdt_gate", "pclk2_div", REG_CLK_PCLKEN0, 1);
+	clk[can0_gate] = nuc980_clk_gate("can0_gate", "pclk2_div", REG_CLK_PCLKEN1, 8);
+	clk[can1_gate] = nuc980_clk_gate("can1_gate", "pclk2_div", REG_CLK_PCLKEN1, 9);
+	clk[can2_gate] = nuc980_clk_gate("can2_gate", "pclk2_div", REG_CLK_PCLKEN1, 10);
+	clk[can3_gate] = nuc980_clk_gate("can3_gate", "pclk2_div", REG_CLK_PCLKEN1, 11);
+	clk[smc0_gate] = nuc980_clk_gate("smc0_gate", "pclk2_div", REG_CLK_PCLKEN1, 12);
+	clk[smc1_gate] = nuc980_clk_gate("smc1_gate", "pclk2_div", REG_CLK_PCLKEN1, 13);
+	clk[pwm0_gate] = nuc980_clk_gate("pwm0_gate", "pclk2_div", REG_CLK_PCLKEN1, 26);
+	clk[pwm1_gate] = nuc980_clk_gate("pwm1_gate", "pclk2_div", REG_CLK_PCLKEN1, 27);
+
+	for (i = 0; i < ARRAY_SIZE(clk); i++)
+		if (IS_ERR(clk[i]))
+			pr_err("nuc980 clk %d: register failed with %ld\n", i, PTR_ERR(clk[i]));
+
+	clk_register_clkdev(clk[xin], "xin", NULL);
+	clk_register_clkdev(clk[xin32k], "xin32k", NULL);
+	clk_register_clkdev(clk[apll], "apll", NULL);
+	clk_register_clkdev(clk[upll], "upll", NULL);
+
+	clk_register_clkdev(clk[usbphy0], "usbphy0", NULL);
+	clk_register_clkdev(clk[usbphy1], "usbphy1", NULL);
+
+	clk_register_clkdev(clk[xin512_div], "xin512_div", NULL);
+
+	// SYS
+	clk_register_clkdev(clk[sys_mux], "sysmux", NULL);
+	clk_register_clkdev(clk[sys_div], "sysdiv", NULL);
+
+	clk_register_clkdev(clk[ddr_gate], "ddr_hclk", NULL);
+
+	// CPU
+	clk_register_clkdev(clk[cpu_div], "cpudiv", NULL);
+	clk_register_clkdev(clk[cpu_gate], "cpu", NULL);
+
+	// HCLK1
+	clk_register_clkdev(clk[hclk1_div], "hclk1div", NULL);
+	clk_register_clkdev(clk[hclk1_gate], "hclk1", NULL);
+	clk_register_clkdev(clk[pdma0_gate], "pdma0_hclk", NULL);
+	clk_register_clkdev(clk[pdma1_gate], "pdma1_hclk", NULL);
+	clk_register_clkdev(clk[tic_gate], "tic_hclk", NULL);
+	clk_register_clkdev(clk[ebi_gate], "ebi_hclk", NULL);
+	clk_register_clkdev(clk[gpio_gate], "gpio_hclk", NULL);
+
+	// HCLK234
+	clk_register_clkdev(clk[hclk_div], "hclkdiv", NULL);
+	clk_register_clkdev(clk[hclk_gate], "hclk", NULL);
+	clk_register_clkdev(clk[dram_gate], "dram", NULL);
+	clk_register_clkdev(clk[sram_gate], "sram", NULL);
+
+	//HCLK3
+	clk_register_clkdev(clk[emac1_gate], "emac1_hclk", NULL);
+	clk_register_clkdev(clk[emac1_eclk_div], "emac1_eclk_div", NULL);
+	clk_register_clkdev(clk[emac1_eclk_gate], "emac1_eclk", NULL);
+	clk_register_clkdev(clk[usbh_gate], "usbh_hclk", NULL);
+	clk_register_clkdev(clk[usbd_gate], "usbd_hclk", NULL);
+	clk_register_clkdev(clk[fmi_gate], "fmi_hclk", NULL);
+	clk_register_clkdev(clk[nand_gate], "nand_hclk", NULL);
+	clk_register_clkdev(clk[sdh0_gate], "sdh0_hclk", NULL);
+	clk_register_clkdev(clk[crypto_gate], "crypto_hclk", NULL);
+	clk_register_clkdev(clk[cap1_gate], "cap1_hclk", NULL);
+
+	//HCLK4
+	clk_register_clkdev(clk[emac0_gate], "emac0_hclk", NULL);
+	clk_register_clkdev(clk[emac0_eclk_div], "emac0_eclk_div", NULL);
+	clk_register_clkdev(clk[emac0_eclk_gate], "emac0_eclk", NULL);
+	clk_register_clkdev(clk[sdh1_gate], "sdh1_hclk", NULL);
+	clk_register_clkdev(clk[audio_gate], "audio_hclk", NULL);
+	clk_register_clkdev(clk[cap0_gate], "cap0_hclk", NULL);
+	clk_register_clkdev(clk[sensor_gate], "sensor_hclk", NULL);
+
+	// ECLK
+	clk_register_clkdev(clk[audio_eclk_mux], "audio_eclk_mux", NULL);
+	clk_register_clkdev(clk[audio_eclk_div], "audio_eclk_div", NULL);
+	clk_register_clkdev(clk[audio_eclk_gate], "audio_eclk", NULL);
+
+	clk_register_clkdev(clk[usb_eclk_mux], "usb_eclk_mux", NULL);
+	clk_register_clkdev(clk[usbphy0_div], "usbphy0_div", NULL);
+	clk_register_clkdev(clk[usbphy1_div], "usbphy1_div", NULL);
+	clk_register_clkdev(clk[usb_eclk_gate], "usb_eclk", NULL);
+
+	clk_register_clkdev(clk[qspi0_eclk_mux], "qspi0_eclk_mux", NULL);
+	clk_register_clkdev(clk[qspi0_eclk_gate], "qspi0_eclk", NULL);
+
+	clk_register_clkdev(clk[spi0_eclk_mux], "spi0_eclk_mux", NULL);
+	clk_register_clkdev(clk[spi0_eclk_gate], "spi0_eclk", NULL);
+
+	clk_register_clkdev(clk[spi1_eclk_mux], "spi1_eclk_mux", NULL);
+	clk_register_clkdev(clk[spi1_eclk_gate], "spi1_eclk", NULL);
+
+	clk_register_clkdev(clk[cap1_aplldiv], "cap1_aplldiv", NULL);
+	clk_register_clkdev(clk[cap1_uplldiv], "cap1_uplldiv", NULL);
+	clk_register_clkdev(clk[cap1_eclk_mux], "cap1_eclk_mux", NULL);
+	clk_register_clkdev(clk[cap1_eclk_div], "cap1_eclk_div", NULL);
+	clk_register_clkdev(clk[cap1_eclk_gate], "cap1_eclk", NULL);
+
+	clk_register_clkdev(clk[cap0_aplldiv], "cap0_aplldiv", NULL);
+	clk_register_clkdev(clk[cap0_uplldiv], "cap0_uplldiv", NULL);
+	clk_register_clkdev(clk[cap0_eclk_mux], "cap0_eclk_mux", NULL);
+	clk_register_clkdev(clk[cap0_eclk_div], "cap0_eclk_div", NULL);
+	clk_register_clkdev(clk[cap0_eclk_gate], "cap0_eclk", NULL);
+
+	clk_register_clkdev(clk[uart0_eclk_mux], "uart0_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart0_eclk_div], "uart0_eclk_div", NULL);
+	clk_register_clkdev(clk[uart0_eclk_gate], "uart0_eclk", NULL);
+
+	clk_register_clkdev(clk[uart1_eclk_mux], "uart1_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart1_eclk_div], "uart1_eclk_div", NULL);
+	clk_register_clkdev(clk[uart1_eclk_gate], "uart1_eclk", NULL);
+
+	clk_register_clkdev(clk[uart2_eclk_mux], "uart2_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart2_eclk_div], "uart2_eclk_div", NULL);
+	clk_register_clkdev(clk[uart2_eclk_gate], "uart2_eclk", NULL);
+
+	clk_register_clkdev(clk[uart3_eclk_mux], "uart3_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart3_eclk_div], "uart3_eclk_div", NULL);
+	clk_register_clkdev(clk[uart3_eclk_gate], "uart3_eclk", NULL);
+
+	clk_register_clkdev(clk[uart4_eclk_mux], "uart4_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart4_eclk_div], "uart4_eclk_div", NULL);
+	clk_register_clkdev(clk[uart4_eclk_gate], "uart4_eclk", NULL);
+
+	clk_register_clkdev(clk[uart5_eclk_mux], "uart5_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart5_eclk_div], "uart5_eclk_div", NULL);
+	clk_register_clkdev(clk[uart5_eclk_gate], "uart5_eclk", NULL);
+
+	clk_register_clkdev(clk[uart6_eclk_mux], "uart6_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart6_eclk_div], "uart6_eclk_div", NULL);
+	clk_register_clkdev(clk[uart6_eclk_gate], "uart6_eclk", NULL);
+
+	clk_register_clkdev(clk[uart7_eclk_mux], "uart7_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart7_eclk_div], "uart7_eclk_div", NULL);
+	clk_register_clkdev(clk[uart7_eclk_gate], "uart7_eclk", NULL);
+
+	clk_register_clkdev(clk[uart8_eclk_mux], "uart8_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart8_eclk_div], "uart8_eclk_div", NULL);
+	clk_register_clkdev(clk[uart8_eclk_gate], "uart8_eclk", NULL);
+
+	clk_register_clkdev(clk[uart9_eclk_mux], "uart9_eclk_mux", NULL);
+	clk_register_clkdev(clk[uart9_eclk_div], "uart9_eclk_div", NULL);
+	clk_register_clkdev(clk[uart9_eclk_gate], "uart9_eclk", NULL);
+
+	clk_register_clkdev(clk[smc0_eclk_div], "smc0_eclk_div", NULL);
+	clk_register_clkdev(clk[smc0_eclk_gate], "smc0_eclk", NULL);
+	clk_register_clkdev(clk[smc1_eclk_div], "smc1_eclk_div", NULL);
+	clk_register_clkdev(clk[smc1_eclk_gate], "smc1_eclk", NULL);
+
+	clk_register_clkdev(clk[adc_eclk_mux], "adc_eclk_mux", NULL);
+	clk_register_clkdev(clk[adc_eclk_div], "adc_eclk_div", NULL);
+	clk_register_clkdev(clk[adc_eclk_gate], "adc_eclk", NULL);
+
+	clk_register_clkdev(clk[wwdt_eclk_mux], "wwdt_eclk_mux", NULL);
+	clk_register_clkdev(clk[wwdt_eclk_gate], "wwdt_eclk", NULL);
+	clk_register_clkdev(clk[wdt_eclk_mux], "wdt_eclk_mux", NULL);
+	clk_register_clkdev(clk[wdt_eclk_gate], "wdt_eclk", NULL);
+
+	clk_register_clkdev(clk[timer0_eclk_mux], "timer0_eclk_mux", NULL);
+	clk_register_clkdev(clk[timer0_eclk_gate], "timer0_eclk", NULL);
+	clk_register_clkdev(clk[timer1_eclk_mux], "timer1_eclk_mux", NULL);
+	clk_register_clkdev(clk[timer1_eclk_gate], "timer1_eclk", NULL);
+	clk_register_clkdev(clk[timer2_eclk_mux], "timer2_eclk_mux", NULL);
+	clk_register_clkdev(clk[timer2_eclk_gate], "timer2_eclk", NULL);
+	clk_register_clkdev(clk[timer3_eclk_mux], "timer3_eclk_mux", NULL);
+	clk_register_clkdev(clk[timer3_eclk_gate], "timer3_eclk", NULL);
+	clk_register_clkdev(clk[timer4_eclk_mux], "timer4_eclk_mux", NULL);
+	clk_register_clkdev(clk[timer4_eclk_gate], "timer4_eclk", NULL);
+	clk_register_clkdev(clk[timer5_eclk_mux], "timer5_eclk_mux", NULL);
+	clk_register_clkdev(clk[timer5_eclk_gate], "timer5_eclk", NULL);
+
+	clk_register_clkdev(clk[sdh0_eclk_mux], "sdh0_eclk_mux", NULL);
+	clk_register_clkdev(clk[sdh0_eclk_div], "sdh0_eclk_div", NULL);
+	clk_register_clkdev(clk[sdh0_eclk_gate], "sdh0_eclk", NULL);
+
+	clk_register_clkdev(clk[sdh1_eclk_mux], "sdh1_eclk_mux", NULL);
+	clk_register_clkdev(clk[sdh1_eclk_div], "sdh1_eclk_div", NULL);
+	clk_register_clkdev(clk[sdh1_eclk_gate], "sdh1_eclk", NULL);
+
+	clk_register_clkdev(clk[cko_eclk_mux], "cko_eclk_mux", NULL);
+	clk_register_clkdev(clk[cko_eclk_div], "cko_eclk_div", NULL);
+	clk_register_clkdev(clk[cko_eclk_gate], "cko_eclk", NULL);
+
+	//PCLK
+	clk_register_clkdev(clk[pclk0_div], "pclk0div", NULL);
+	clk_register_clkdev(clk[pclk0_gate], "pclk0", NULL);
+	clk_register_clkdev(clk[pclk4096_div], "pclk4096_div", NULL);
+	clk_register_clkdev(clk[i2c0_gate], "i2c0", NULL);
+	clk_register_clkdev(clk[i2c2_gate], "i2c2", NULL);
+	clk_register_clkdev(clk[qspi0_gate], "qspi0", NULL);
+	clk_register_clkdev(clk[spi1_gate], "spi1", NULL);
+	clk_register_clkdev(clk[timer0_gate], "timer0", NULL);
+	clk_register_clkdev(clk[timer1_gate], "timer1", NULL);
+	clk_register_clkdev(clk[timer4_gate], "timer4", NULL);
+	clk_register_clkdev(clk[timer5_gate], "timer5", NULL);
+	clk_register_clkdev(clk[uart0_gate], "uart0", NULL);
+	clk_register_clkdev(clk[uart2_gate], "uart2", NULL);
+	clk_register_clkdev(clk[uart4_gate], "uart4", NULL);
+	clk_register_clkdev(clk[uart6_gate], "uart6", NULL);
+	clk_register_clkdev(clk[uart8_gate], "uart8", NULL);
+
+	clk_register_clkdev(clk[pclk1_div], "pclk1div", NULL);
+	clk_register_clkdev(clk[pclk1_gate], "pclk1", NULL);
+	clk_register_clkdev(clk[i2c1_gate], "i2c1", NULL);
+	clk_register_clkdev(clk[i2c3_gate], "i2c3", NULL);
+	clk_register_clkdev(clk[spi0_gate], "spi0", NULL);
+	clk_register_clkdev(clk[timer2_gate], "timer2", NULL);
+	clk_register_clkdev(clk[timer3_gate], "timer3", NULL);
+	clk_register_clkdev(clk[uart1_gate], "uart1", NULL);
+	clk_register_clkdev(clk[uart3_gate], "uart3", NULL);
+	clk_register_clkdev(clk[uart5_gate], "uart5", NULL);
+	clk_register_clkdev(clk[uart7_gate], "uart7", NULL);
+	clk_register_clkdev(clk[uart9_gate], "uart9", NULL);
+	clk_register_clkdev(clk[adc_gate], "adc", NULL);
+
+	clk_register_clkdev(clk[pclk2_div], "pclk2div", NULL);
+	clk_register_clkdev(clk[pclk2_gate], "pclk2", NULL);
+	clk_register_clkdev(clk[pclk24096_div], "pclk24096_div", NULL);
+	clk_register_clkdev(clk[rtc_gate], "rtc", NULL);
+	clk_register_clkdev(clk[wdt_gate], "wdt", NULL);
+	clk_register_clkdev(clk[wwdt_gate], "wwdt", NULL);
+	clk_register_clkdev(clk[can0_gate], "can0", NULL);
+	clk_register_clkdev(clk[can1_gate], "can1", NULL);
+	clk_register_clkdev(clk[can2_gate], "can2", NULL);
+	clk_register_clkdev(clk[can3_gate], "can3", NULL);
+	//clk_register_clkdev(clk[gpio_gate], "gpio", NULL);
+	clk_register_clkdev(clk[smc0_gate], "smc0", NULL);
+	clk_register_clkdev(clk[smc1_gate], "smc1", NULL);
+	clk_register_clkdev(clk[pwm0_gate], "pwm0", NULL);
+	clk_register_clkdev(clk[pwm1_gate], "pwm1", NULL);
+
+	// enable some important clocks
+	clk_prepare(clk_get(NULL, "cpu"));
+	clk_enable(clk_get(NULL, "cpu"));
+
+	clk_prepare(clk_get(NULL, "hclk"));
+	clk_enable(clk_get(NULL, "hclk"));
+
+	clk_prepare(clk_get(NULL, "sram"));
+	clk_enable(clk_get(NULL, "sram"));
+
+	clk_prepare(clk_get(NULL, "dram"));
+	clk_enable(clk_get(NULL, "dram"));
+
+	clk_prepare(clk_get(NULL, "ddr_hclk"));
+	clk_enable(clk_get(NULL, "ddr_hclk"));
+
+	return 0;
+}
diff -uprN linux-4.4.194/drivers/clk/nuvoton/clk-nuc980.h NUC980-linux-4.4.194/drivers/clk/nuvoton/clk-nuc980.h
--- linux-4.4.194/drivers/clk/nuvoton/clk-nuc980.h	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/clk/nuvoton/clk-nuc980.h	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,59 @@
+#ifndef __MACH_NUC980_CLK_CCF_H
+#define __MACH_NUC980_CLK_CCF_H
+
+#include <linux/clk.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/spinlock.h>
+#include <linux/clk-provider.h>
+
+extern struct clk *nuc980_clk_apll(const char *name, const char *parent,
+				   void __iomem *base);
+extern struct clk *nuc980_clk_upll(const char *name, const char *parent,
+				   void __iomem *base);
+
+extern spinlock_t nuc980_lock;
+
+static inline struct clk *nuc980_clk_fixed(const char *name, int rate)
+{
+
+	return clk_register_fixed_rate(NULL, name, NULL, CLK_IS_ROOT, rate);
+}
+
+static inline struct clk *nuc980_clk_mux(const char *name,
+					 void __iomem *reg,
+					 u8 shift,
+					 u8 width, const char **parents,
+					 int num_parents)
+{
+	return clk_register_mux(NULL, name, parents, num_parents, 0, reg,
+				shift, width, 0, &nuc980_lock);
+}
+
+static inline struct clk *nuc980_clk_divider(const char *name,
+					     const char *parent,
+					     void __iomem *reg, u8 shift,
+					     u8 width)
+{
+	return clk_register_divider(NULL, name, parent, 0,
+				    reg, shift, width, 0, &nuc980_lock);
+}
+
+static inline struct clk *nuc980_clk_fixed_factor(const char *name,
+						  const char *parent,
+						  unsigned int mult,
+						  unsigned int div)
+{
+	return clk_register_fixed_factor(NULL, name, parent,
+					 CLK_SET_RATE_PARENT, mult, div);
+}
+
+static inline struct clk *nuc980_clk_gate(const char *name,
+					  const char *parent,
+					  void __iomem *reg, u8 shift)
+{
+	return clk_register_gate(NULL, name, parent, CLK_SET_RATE_PARENT, reg,
+				 shift, 0, &nuc980_lock);
+}
+
+#endif
diff -uprN linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-upll.c NUC980-linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-upll.c
--- linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-upll.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/clk/nuvoton/clk-nuc980-upll.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,86 @@
+/*
+ * linux/arch/arm/mach-nuc980/clk-upll.c
+ *
+ * Copyright (c) 2017 Nuvoton Technology Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ */
+
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+#include <linux/kernel.h>
+#include <linux/err.h>
+
+#include "clk-nuc980.h"
+
+struct clk_upll {
+	struct clk_hw hw;
+	void __iomem *base;
+};
+
+#define to_clk_upll(clk) (container_of(clk, struct clk_upll, clk))
+static unsigned long clk_upll_recalc_rate(struct clk_hw *hw,
+					  unsigned long parent_rate)
+{
+
+	struct clk_upll *pll = to_clk_upll(hw);
+	long long ll;
+	u32 reg = readl(pll->base) & 0x0FFFFFFF;
+
+	if (parent_rate != 12000000)
+		return 0;
+
+	switch (reg) {
+	case 0x15:
+		ll = 264000000;
+		break;
+	case 0x18:
+		ll = 300000000;
+		break;
+	default:
+		ll = 264000000;
+		break;
+	}
+	return ll;
+}
+
+static struct clk_ops clk_upll_ops = {
+	.recalc_rate = clk_upll_recalc_rate,
+};
+
+struct clk *nuc980_clk_upll(const char *name, const char *parent,
+			    void __iomem *base)
+{
+	struct clk_upll *pll;
+	struct clk *clk;
+	struct clk_init_data init;
+
+	pll = kmalloc(sizeof(*pll), GFP_KERNEL);
+
+	if (!pll)
+		return ERR_PTR(-ENOMEM);
+
+	pll->base = base;
+	init.name = name;
+	init.ops = &clk_upll_ops;
+	init.flags = 0;
+	init.parent_names = &parent;
+	init.num_parents = 1;
+	pll->hw.init = &init;
+	clk = clk_register(NULL, &pll->hw);
+
+	if (IS_ERR(clk))
+		kfree(pll);
+
+	return clk;
+}
diff -uprN linux-4.4.194/drivers/clk/nuvoton/Makefile NUC980-linux-4.4.194/drivers/clk/nuvoton/Makefile
--- linux-4.4.194/drivers/clk/nuvoton/Makefile	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/clk/nuvoton/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,4 @@
+#
+# Makefile for mmp specific clk
+#
+obj-$(CONFIG_ARCH_NUC980) += clk-nuc980-ccf.o clk-nuc980-upll.o clk-nuc980-apll.o
diff -uprN linux-4.4.194/drivers/crypto/Kconfig NUC980-linux-4.4.194/drivers/crypto/Kconfig
--- linux-4.4.194/drivers/crypto/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/crypto/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -416,6 +416,23 @@ config CRYPTO_DEV_ATMEL_SHA
 	  To compile this driver as a module, choose M here: the module
 	  will be called atmel-sha.
 
+config CRYPTO_DEV_NUC980
+	tristate "Support for NUC980 Cryptographic Accelerator"
+	depends on ARCH_NUC980
+	select CRYPTO_CBC
+	select CRYPTO_ECB
+	select CRYPTO_AES
+	select CRYPTO_ALGAPI
+	select CRYPTO_BLKCIPHER
+	select CRYPTO_SHA1
+	select CRYPTO_SHA224
+	select CRYPTO_SHA256
+	select CRYPTO_SHA384
+	select CRYPTO_SHA512
+	help
+	  To compile this driver as a module, choose M here: the module
+	  will be called nuc980-crypto.
+
 config CRYPTO_DEV_CCP
 	bool "Support for AMD Cryptographic Coprocessor"
 	depends on ((X86 && PCI) || (ARM64 && (OF_ADDRESS || ACPI))) && HAS_IOMEM
diff -uprN linux-4.4.194/drivers/crypto/Makefile NUC980-linux-4.4.194/drivers/crypto/Makefile
--- linux-4.4.194/drivers/crypto/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/crypto/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -29,3 +29,5 @@ obj-$(CONFIG_CRYPTO_DEV_QAT) += qat/
 obj-$(CONFIG_CRYPTO_DEV_QCE) += qce/
 obj-$(CONFIG_CRYPTO_DEV_VMX) += vmx/
 obj-$(CONFIG_CRYPTO_DEV_SUN4I_SS) += sunxi-ss/
+obj-$(CONFIG_CRYPTO_DEV_NUC980) += nuc980-crypto.o
+obj-$(CONFIG_CRYPTO_DEV_NUC980) += nuc980-crypto-raw.o
diff -uprN linux-4.4.194/drivers/crypto/nuc980-crypto.c NUC980-linux-4.4.194/drivers/crypto/nuc980-crypto.c
--- linux-4.4.194/drivers/crypto/nuc980-crypto.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/crypto/nuc980-crypto.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1140 @@
+/* Copyright (C) 2018-2020, Nuvoton Technology Corporation
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License as published by
+* the Free Software Foundation; either version 2 of the License, or
+* (at your option) any later version.
+*/
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/crypto.h>
+#include <linux/cryptohash.h>
+#include <linux/spinlock.h>
+#include <linux/scatterlist.h>
+#include <crypto/scatterwalk.h>
+#include <crypto/algapi.h>
+#include <crypto/aes.h>
+#include <crypto/sha.h>
+#include <crypto/hash.h>
+#include <crypto/internal/hash.h>
+
+#include <linux/io.h>
+#include <linux/delay.h>
+#include <linux/clk.h>
+
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-crypto.h>
+#include <mach/nuc980-crypto.h>
+
+
+#define DMA_BUFSZ           	(4096)
+
+/* Static structures */
+
+struct nuc980_ctx
+{
+	int     channel;
+	u32     mode;
+	u32     keysize;
+	u32     aes_key[8];
+	volatile struct nuc980_aes_regs  *aes_regs;
+	int     hmac_key_len;
+	int     sha_buffer_cnt;     /* byte count of data bufferred */
+};
+
+struct cryp_algo_template
+{
+	u32   algomode;
+	struct crypto_alg crypto;
+};
+
+
+struct nuc980_crypto_dev  nuc980_crdev;
+
+
+static int nuc980_do_aes_crypt(struct ablkcipher_request *areq, u32 encrypt)
+{
+	struct nuc980_ctx *ctx = crypto_ablkcipher_ctx(crypto_ablkcipher_reqtfm(areq));
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	volatile struct nuc980_aes_regs *aes_regs = ctx->aes_regs;
+	struct scatterlist   *in_sg, *out_sg;
+	int  i, req_len, dma_len, copy_len, offset;
+	int  in_sg_off, out_sg_off;
+	unsigned long   timeout;
+	u8   *ivec;
+
+	// printk("[%s],ctx=0x%x, chn=%d\n", __func__, (int)ctx, ctx->channel);
+
+	BUG_ON(!areq->info);
+
+	mutex_lock(&nuc980_crdev.aes_lock);
+
+	crpt_regs->CRPT_INTEN |= (AESIEN | AESERRIEN);
+	crpt_regs->CRPT_AES_CTL = 0;
+	crpt_regs->CRPT_INTSTS = (AESIF | AESERRIF);
+
+	crpt_regs->CRPT_AES_CTL = ctx->keysize | ctx->mode | AES_INSWAP | AES_OUTSWAP |
+							  AES_DMAEN | (ctx->channel << 24);
+
+	memcpy((void *)aes_regs->key, (void *)ctx->aes_key, 32);
+	
+	ivec = (u8 *)areq->info;
+	for (i = 0; i < 4; i++)
+	{
+		aes_regs->iv[i] = (ivec[i*4]<<24) | (ivec[i*4+1]<<16) | (ivec[i*4+2]<<8) | ivec[i*4+3];
+		// printk("AES IV %d = %08x\n", i, aes_regs->iv[i]);
+	}
+
+	if (encrypt)
+		crpt_regs->CRPT_AES_CTL |= AES_ENCRYPT;
+
+	req_len = areq->nbytes;
+	in_sg = areq->src;
+	out_sg = areq->dst;
+	in_sg_off = 0;
+	out_sg_off = 0;
+
+	while (req_len > 0)
+	{
+		if ((in_sg == NULL) || (out_sg == NULL))
+		{
+			printk("[%s] - NULL sg!\n", __func__);
+			return 1;
+		}
+
+		/*
+		 *  Fill DMA source buffer
+		 */
+		dma_len = 0;
+		while ((req_len > 0) && (dma_len < DMA_BUFSZ))
+		{
+			copy_len = min((int)in_sg->length - in_sg_off, req_len);
+			if (DMA_BUFSZ - dma_len < copy_len)
+				copy_len = DMA_BUFSZ - dma_len;
+
+			memcpy((char *)nuc980_crdev.aes_inbuf + dma_len, (char *)sg_virt(in_sg) + in_sg_off, copy_len);
+
+			dma_len += copy_len;
+			req_len -= copy_len;
+			in_sg_off += copy_len;
+
+			if (in_sg_off >= in_sg->length)
+			{
+				in_sg = sg_next(in_sg);
+				in_sg_off = 0;
+			}
+		}
+
+		/*
+		 *  Execute AES encrypt/decrypt
+		 */
+		//printk("dma_len = %d\n", dma_len);
+		aes_regs->count = dma_len;
+		aes_regs->src_addr = nuc980_crdev.aes_inbuf_dma_addr;
+		aes_regs->dst_addr = nuc980_crdev.aes_outbuf_dma_addr;
+
+		crpt_regs->CRPT_AES_CTL |= AES_START;
+
+		timeout = jiffies+200;
+		while ((((crpt_regs->CRPT_INTSTS & (AESIF|AESERRIF)) == 0) || (crpt_regs->CRPT_AES_STS & AES_BUSY)) && 
+				time_before(jiffies, timeout))
+		{
+		}
+
+		if (!time_before(jiffies, timeout))
+		{
+			printk("Crypto AES engine failed!\n");
+			mutex_unlock(&nuc980_crdev.aes_lock);
+			return 1;
+		}
+		crpt_regs->CRPT_INTSTS = (AESIF|AESERRIF);
+
+		//dma_sync_single_for_cpu(&nuc980_crdev.dev, nuc980_crdev.aes_outbuf, DMA_BUFSZ, DMA_FROM_DEVICE);
+
+		/*
+		 *  Copy output data from DMA destination buffer
+		 */
+		offset = 0;
+		while ((dma_len > 0) && (out_sg != NULL))
+		{
+			copy_len = min((int)out_sg->length - out_sg_off, dma_len);
+			memcpy((char *)sg_virt(out_sg) + out_sg_off, (char *)((u32)nuc980_crdev.aes_outbuf + offset), copy_len);
+			dma_len -= copy_len;
+			offset += copy_len;
+			out_sg_off += copy_len;
+
+			if (out_sg_off >= out_sg->length)
+			{
+				out_sg = sg_next(out_sg);
+				out_sg_off = 0;
+			}
+		}
+		crpt_regs->CRPT_AES_CTL |= AES_DMACSCAD;
+	}
+
+	mutex_unlock(&nuc980_crdev.aes_lock);
+
+	return 0;
+}
+
+static int nuc980_aes_decrypt(struct ablkcipher_request *areq)
+{
+	return nuc980_do_aes_crypt(areq, 0);
+}
+
+static int nuc980_aes_encrypt(struct ablkcipher_request *areq)
+{
+	return nuc980_do_aes_crypt(areq, 1);
+}
+
+static int nuc980_aes_setkey(struct crypto_ablkcipher *cipher,
+							 const u8 *key, unsigned int keylen)
+{
+	struct nuc980_ctx  *ctx = crypto_ablkcipher_ctx(cipher);
+	u32 *flags = &cipher->base.crt_flags;
+	int  i;
+
+	//printk("[%s],ctx=0x%x, chn=%d\n", __func__, (int)ctx, ctx->channel);
+
+	switch (keylen)
+	{
+	case AES_KEYSIZE_128:
+		ctx->keysize = AES_KEYSZ_128;
+		break;
+
+	case AES_KEYSIZE_192:
+		ctx->keysize = AES_KEYSZ_192;
+		break;
+
+	case AES_KEYSIZE_256:
+		ctx->keysize = AES_KEYSZ_256;
+		break;
+
+	default:
+		printk("[%s]: Unsupported keylen %d!\n", __func__, keylen);
+		*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;
+		return -EINVAL;
+	}
+
+	//printk("aes_regs = 0x%x\n", (u32)aes_regs);
+	for (i = 0; i < keylen/4; i++)
+	{
+		ctx->aes_key[i] = (key[i*4]<<24) | (key[i*4+1]<<16) | (key[i*4+2]<<8) | key[i*4+3];
+		// printk("AES KEY %d = 0x%x\n", i, ctx->aes_key[i]);
+	}
+	return 0;
+}
+
+static int nuc980_aes_init(struct crypto_tfm *tfm)
+{
+	struct nuc980_ctx  *ctx = crypto_tfm_ctx(tfm);
+	struct crypto_alg *alg = tfm->__crt_alg;
+	struct cryp_algo_template *cryp_alg = container_of(alg, struct cryp_algo_template, crypto);
+
+	mutex_lock(&nuc980_crdev.aes_lock);
+
+	ctx->mode = cryp_alg->algomode;
+	ctx->channel = 0;    /*  NUC980 has only one channel, the channel 0.  */
+	ctx->aes_regs = (struct nuc980_aes_regs *)((u32)nuc980_crdev.regs + 0x110);
+
+	mutex_unlock(&nuc980_crdev.aes_lock);
+
+	//printk("[%s],ctx=0x%x, chn=%d\n", __func__, (int)ctx, ctx->channel);
+
+	return 0;
+}
+
+static void nuc980_aes_exit(struct crypto_tfm *tfm)
+{
+	//struct nuc980_ctx  *ctx = crypto_tfm_ctx(tfm);
+
+	mutex_lock(&nuc980_crdev.aes_lock);
+	nuc980_crdev.regs->CRPT_AES_CTL = AES_STOP;
+	mutex_unlock(&nuc980_crdev.aes_lock);
+}
+
+
+static struct cryp_algo_template nuc980_crypto_algs[] =
+{
+	{
+		.algomode = AES_ECB_MODE,
+		.crypto = {
+			.cra_name = "ecb(aes)",
+			.cra_driver_name = "ecb-aes-nuc980",
+			.cra_priority = 300,
+			.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct nuc980_ctx),
+			.cra_alignmask = 0xf,
+			.cra_type = &crypto_ablkcipher_type,
+			.cra_init = nuc980_aes_init,
+			.cra_exit = nuc980_aes_exit,
+			.cra_module = THIS_MODULE,
+			.cra_u = {
+				.ablkcipher = {
+					.min_keysize = AES_MIN_KEY_SIZE,
+					.max_keysize = AES_MAX_KEY_SIZE,
+					.setkey = nuc980_aes_setkey,
+					.ivsize = AES_BLOCK_SIZE,
+					.encrypt = nuc980_aes_encrypt,
+					.decrypt = nuc980_aes_decrypt,
+				}
+			}
+		}
+	},
+	{
+		.algomode = AES_CBC_MODE,
+		.crypto = {
+			.cra_name = "cbc(aes)",
+			.cra_driver_name = "cbc-aes-nuc980",
+			.cra_priority = 300,
+			.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct nuc980_ctx),
+			.cra_alignmask = 0xf,
+			.cra_type = &crypto_ablkcipher_type,
+			.cra_init = nuc980_aes_init,
+			.cra_exit = nuc980_aes_exit,
+			.cra_module = THIS_MODULE,
+			.cra_u = {
+				.ablkcipher = {
+					.min_keysize = AES_MIN_KEY_SIZE,
+					.max_keysize = AES_MAX_KEY_SIZE,
+					.setkey = nuc980_aes_setkey,
+					.ivsize = AES_BLOCK_SIZE,
+					.encrypt = nuc980_aes_encrypt,
+					.decrypt = nuc980_aes_decrypt,
+				}
+			}
+		}
+	},
+	{
+		.algomode = AES_CFB_MODE,
+		.crypto = {
+			.cra_name = "cfb(aes)",
+			.cra_driver_name = "cfb-aes-nuc980",
+			.cra_priority = 300,
+			.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct nuc980_ctx),
+			.cra_alignmask = 0xf,
+			.cra_type = &crypto_ablkcipher_type,
+			.cra_init = nuc980_aes_init,
+			.cra_exit = nuc980_aes_exit,
+			.cra_module = THIS_MODULE,
+			.cra_u = {
+				.ablkcipher = {
+					.min_keysize = AES_MIN_KEY_SIZE,
+					.max_keysize = AES_MAX_KEY_SIZE,
+					.ivsize = AES_BLOCK_SIZE,
+					.setkey = nuc980_aes_setkey,
+					.encrypt = nuc980_aes_encrypt,
+					.decrypt = nuc980_aes_decrypt,
+				}
+			}
+		}
+	},
+	{
+		.algomode = AES_OFB_MODE,
+		.crypto = {
+			.cra_name = "ofb(aes)",
+			.cra_driver_name = "ofb-aes-nuc980",
+			.cra_priority = 300,
+			.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct nuc980_ctx),
+			.cra_alignmask = 0xf,
+			.cra_type = &crypto_ablkcipher_type,
+			.cra_init = nuc980_aes_init,
+			.cra_exit = nuc980_aes_exit,
+			.cra_module = THIS_MODULE,
+			.cra_u = {
+				.ablkcipher = {
+					.min_keysize = AES_MIN_KEY_SIZE,
+					.max_keysize = AES_MAX_KEY_SIZE,
+					.setkey = nuc980_aes_setkey,
+					.ivsize = AES_BLOCK_SIZE,
+					.encrypt = nuc980_aes_encrypt,
+					.decrypt = nuc980_aes_decrypt,
+				}
+			}
+		}
+	},
+	{
+		.algomode = AES_CTR_MODE,
+		.crypto = {
+			.cra_name = "ctr(aes)",
+			.cra_driver_name = "ctr-aes-nuc980",
+			.cra_priority = 300,
+			.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct nuc980_ctx),
+			.cra_alignmask = 0xf,
+			.cra_type = &crypto_ablkcipher_type,
+			.cra_init = nuc980_aes_init,
+			.cra_exit = nuc980_aes_exit,
+			.cra_module = THIS_MODULE,
+			.cra_u = {
+				.ablkcipher = {
+					.min_keysize = AES_MIN_KEY_SIZE,
+					.max_keysize = AES_MAX_KEY_SIZE,
+					.setkey = nuc980_aes_setkey,
+					.ivsize = AES_BLOCK_SIZE,
+					.encrypt = nuc980_aes_encrypt,
+					.decrypt = nuc980_aes_decrypt,
+				}
+			}
+		}
+	},
+	{
+		.algomode = AES_CBCCS1_MODE,
+		.crypto = {
+			.cra_name = "cbc-cs1(aes)",
+			.cra_driver_name = "cbc-cs1-aes-nuc980",
+			.cra_priority = 300,
+			.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct nuc980_ctx),
+			.cra_alignmask = 0xf,
+			.cra_type = &crypto_ablkcipher_type,
+			.cra_init = nuc980_aes_init,
+			.cra_exit = nuc980_aes_exit,
+			.cra_module = THIS_MODULE,
+			.cra_u = {
+				.ablkcipher = {
+					.min_keysize = AES_MIN_KEY_SIZE,
+					.max_keysize = AES_MAX_KEY_SIZE,
+					.setkey = nuc980_aes_setkey,
+					.ivsize = AES_BLOCK_SIZE,
+					.encrypt = nuc980_aes_encrypt,
+					.decrypt = nuc980_aes_decrypt,
+				}
+			}
+		}
+	},
+	{
+		.algomode = AES_CBCCS2_MODE,
+		.crypto = {
+			.cra_name = "cbc-cs2(aes)",
+			.cra_driver_name = "cbc-cs2-aes-nuc980",
+			.cra_priority = 300,
+			.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct nuc980_ctx),
+			.cra_alignmask = 0xf,
+			.cra_type = &crypto_ablkcipher_type,
+			.cra_init = nuc980_aes_init,
+			.cra_exit = nuc980_aes_exit,
+			.cra_module = THIS_MODULE,
+			.cra_u = {
+				.ablkcipher = {
+					.min_keysize = AES_MIN_KEY_SIZE,
+					.max_keysize = AES_MAX_KEY_SIZE,
+					.setkey = nuc980_aes_setkey,
+					.ivsize = AES_BLOCK_SIZE,
+					.encrypt = nuc980_aes_encrypt,
+					.decrypt = nuc980_aes_decrypt,
+				}
+			}
+		}
+	},
+	{
+		.algomode = AES_CBCCS3_MODE,
+		.crypto = {
+			.cra_name = "cbc-cs3(aes)",
+			.cra_driver_name = "cbc-cs3-aes-nuc980",
+			.cra_priority = 300,
+			.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct nuc980_ctx),
+			.cra_alignmask = 0xf,
+			.cra_type = &crypto_ablkcipher_type,
+			.cra_init = nuc980_aes_init,
+			.cra_exit = nuc980_aes_exit,
+			.cra_module = THIS_MODULE,
+			.cra_u = {
+				.ablkcipher = {
+					.min_keysize = AES_MIN_KEY_SIZE,
+					.max_keysize = AES_MAX_KEY_SIZE,
+					.setkey = nuc980_aes_setkey,
+					.ivsize = AES_BLOCK_SIZE,
+					.encrypt = nuc980_aes_encrypt,
+					.decrypt = nuc980_aes_decrypt,
+				}
+			}
+		}
+	},
+};
+
+
+
+/*******************************************************************************/
+/*******************************************************************************/
+/*******************************************************************************/
+
+
+/*---------------------------------------------------------------------*/
+/*                                                                     */
+/*        NUC980 SHA/HMAC driver                                       */
+/*                                                                     */
+/*---------------------------------------------------------------------*/
+
+
+void  nuc980_dump_digest(void)
+{
+	struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	int  i;
+
+	printk("DIGEST: ");
+	for (i = 0; i < 8; i++)
+		printk("0x%x\n", crpt_regs->CRPT_HMAC_DGST[i]);
+	printk("\n");
+}
+
+
+static int do_sha(struct ahash_request *req, int is_last)
+{
+	struct nuc980_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
+	struct scatterlist   *in_sg;
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	int  req_len, sg_remain_len, sg_offset, do_len;
+	unsigned long   timeout;
+
+	in_sg = req->src;
+	req_len = req->nbytes;
+
+	// printk("do_sha - keylen = %d, req_len = %d, sha_buffer_cnt=%d\n", ctx->hmac_key_len, req_len, ctx->sha_buffer_cnt);
+
+	if (is_last)
+	{
+		if (ctx->sha_buffer_cnt <= 0)
+		{
+			printk("do_sha - sha last has no data!\n");
+			return -1;
+		}
+		
+		mutex_lock(&nuc980_crdev.sha_lock);
+
+		crpt_regs->CRPT_HMAC_DMACNT = ctx->sha_buffer_cnt;
+		crpt_regs->CRPT_HMAC_SADDR = nuc980_crdev.hmac_inbuf_dma_addr;
+		crpt_regs->CRPT_HMAC_CTL |= HMAC_START | HMAC_DMAEN | HMAC_DMALAST;
+
+		timeout = jiffies+100;
+		while ((crpt_regs->CRPT_HMAC_STS & HMAC_BUSY) && time_before(jiffies, timeout))
+		{
+		}
+		
+		mutex_unlock(&nuc980_crdev.sha_lock);
+		
+		if (!time_before(jiffies, timeout))
+		{
+			printk("keylen=%d, dma_len = %d, req_len = %d\n", ctx->hmac_key_len, ctx->sha_buffer_cnt, req_len);
+			printk("Crypto SHA/HMAC engine failed!\n");
+			return 1;
+		}
+		return 0;
+	}
+		
+	while ((req_len > 0) && in_sg)
+	{
+		sg_remain_len = in_sg->length;
+		sg_offset = 0;
+		
+		while (sg_remain_len > 0)
+		{
+			do_len = DMA_BUFSZ - ctx->sha_buffer_cnt;
+			do_len = min(do_len, sg_remain_len);
+			
+			memcpy(&nuc980_crdev.hmac_inbuf[ctx->sha_buffer_cnt], (u8 *)sg_virt(in_sg) + sg_offset, do_len); 
+			
+			sg_remain_len -= do_len;
+			sg_offset += do_len;
+			ctx->sha_buffer_cnt += do_len;
+			req_len -= do_len;
+			
+			if ((sg_remain_len == 0) && (sg_next(in_sg) == NULL))
+			{
+				return 0;    /* no more data, data in DMA buffer will be left to next/last call */
+			}
+			
+			mutex_lock(&nuc980_crdev.sha_lock);
+
+			crpt_regs->CRPT_HMAC_DMACNT = ctx->sha_buffer_cnt;
+			crpt_regs->CRPT_HMAC_SADDR = nuc980_crdev.hmac_inbuf_dma_addr;
+
+			crpt_regs->CRPT_HMAC_CTL |= HMAC_START | HMAC_DMAEN;
+
+			timeout = jiffies+100;
+			while ((crpt_regs->CRPT_HMAC_STS & HMAC_BUSY) && time_before(jiffies, timeout))
+			{
+			}
+			
+			mutex_unlock(&nuc980_crdev.sha_lock);
+			
+			if (!time_before(jiffies, timeout))
+			{
+				printk("keylen=%d, dma_len = %d, req_len = %d\n", ctx->hmac_key_len, ctx->sha_buffer_cnt, req_len);
+				printk("Crypto SHA/HMAC engine failed!\n");
+				return -1;
+			}
+			ctx->sha_buffer_cnt = 0;
+		}
+		in_sg = sg_next(in_sg);
+	}
+			
+	return 0;
+}
+
+
+static int nuc980_sha_update(struct ahash_request *req)
+{
+	//printk("nuc980_sha_update - %d bytes\n", req->nbytes);
+	return do_sha(req, 0);
+}
+
+static int nuc980_sha_final(struct ahash_request *req)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+
+	//printk("nuc980_sha_final - %d bytes\n", req->nbytes);
+
+	do_sha(req, 1);
+
+	if ((crpt_regs->CRPT_HMAC_CTL & HMAC_OPMODE_MASK) == HMAC_SHA1)
+		memcpy(req->result, (u8 *)&(crpt_regs->CRPT_HMAC_DGST[0]), SHA1_DIGEST_SIZE);
+	else if ((crpt_regs->CRPT_HMAC_CTL & HMAC_OPMODE_MASK) == HMAC_SHA224)
+		memcpy(req->result, (u8 *)&(crpt_regs->CRPT_HMAC_DGST[0]), SHA224_DIGEST_SIZE);
+	else if ((crpt_regs->CRPT_HMAC_CTL & HMAC_OPMODE_MASK) == HMAC_SHA256)
+		memcpy(req->result, (u8 *)&(crpt_regs->CRPT_HMAC_DGST[0]), SHA256_DIGEST_SIZE);
+	else if ((crpt_regs->CRPT_HMAC_CTL & HMAC_OPMODE_MASK) == HMAC_SHA384)
+		memcpy(req->result, (u8 *)&(crpt_regs->CRPT_HMAC_DGST[0]), SHA384_DIGEST_SIZE);
+	else
+		memcpy(req->result, (u8 *)&(crpt_regs->CRPT_HMAC_DGST[0]), SHA512_DIGEST_SIZE);
+
+	return 0;
+}
+
+static int nuc980_hmac_sha_init(struct ahash_request *req, int is_hmac)
+{
+	struct crypto_ahash *tfm = crypto_ahash_reqtfm(req);
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	
+	crpt_regs->CRPT_HMAC_CTL = HMAC_STOP;
+	//printk("nuc980_sha_init: digest size: %d %s\n", crypto_ahash_digestsize(tfm), is_hmac ? "(HMAC)" : "");
+	crpt_regs->CRPT_HMAC_CTL = HMAC_INSWAP | HMAC_OUTSWAP;
+
+	if (is_hmac)
+		crpt_regs->CRPT_HMAC_CTL |= HMAC_EN;
+	else
+		crpt_regs->CRPT_HMAC_KEYCNT = 0;
+
+	switch (crypto_ahash_digestsize(tfm))
+	{
+	case SHA1_DIGEST_SIZE:
+		crpt_regs->CRPT_HMAC_CTL |= HMAC_SHA1;
+		break;
+
+	case SHA224_DIGEST_SIZE:
+		crpt_regs->CRPT_HMAC_CTL |= HMAC_SHA224;
+		break;
+
+	case SHA256_DIGEST_SIZE:
+		crpt_regs->CRPT_HMAC_CTL |= HMAC_SHA256;
+		break;
+
+	case SHA384_DIGEST_SIZE:
+		crpt_regs->CRPT_HMAC_CTL |= HMAC_SHA384;
+		break;
+
+	case SHA512_DIGEST_SIZE:
+		crpt_regs->CRPT_HMAC_CTL |= HMAC_SHA512;
+		break;
+
+	default:
+		return -EINVAL;
+		break;
+	}
+
+	return 0;
+}
+
+
+static int nuc980_sha_init(struct ahash_request *req)
+{
+	return nuc980_hmac_sha_init(req, 0);
+}
+
+static int nuc980_hmac_init(struct ahash_request *req)
+{
+	return nuc980_hmac_sha_init(req, 1);
+}
+
+static int nuc980_hmac_setkey(struct crypto_ahash *tfm, const u8 *key, unsigned int keylen)
+{
+	struct nuc980_ctx *ctx = crypto_ahash_ctx(tfm);
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+
+	//printk("[%s],keylen=%d\n", __func__, keylen);
+
+	memcpy((u8 *)nuc980_crdev.hmac_inbuf, key, keylen);
+	ctx->sha_buffer_cnt = keylen;
+
+	ctx->hmac_key_len = keylen;
+	crpt_regs->CRPT_HMAC_KEYCNT = keylen;
+
+	return 0;
+}
+
+
+static int nuc980_sha_finup(struct ahash_request *req)
+{
+	int err1, err2;
+
+	//printk("nuc980_sha_finup.\n");
+
+	err1 = nuc980_sha_update(req);
+	if (err1 == -EINPROGRESS || err1 == -EBUSY)
+		return err1;
+
+	/*
+	 * final() has to be always called to cleanup resources
+	 * even if udpate() failed, except EINPROGRESS
+	 */
+	err2 = nuc980_sha_final(req);
+
+	return err1 ?: err2;
+}
+
+static int nuc980_sha_digest(struct ahash_request *req)
+{
+	//printk("nuc980_sha_digest.\n");
+	return nuc980_hmac_sha_init(req, 0) ?: nuc980_sha_finup(req);
+}
+
+static int nuc980_hmac_digest(struct ahash_request *req)
+{
+	//printk("nuc980_sha_digest.\n");
+	return nuc980_hmac_sha_init(req, 1) ?: nuc980_sha_finup(req);
+}
+
+
+static int nuc980_sha_cra_init(struct crypto_tfm *tfm)
+{
+	struct nuc980_ctx  *ctx = crypto_tfm_ctx(tfm);
+	ctx->sha_buffer_cnt = 0;
+	return 0;
+}
+
+static void nuc980_sha_cra_exit(struct crypto_tfm *tfm)
+{
+}
+
+
+static struct ahash_alg nuc980_hash_algs[] =
+{
+	{
+		.init       = nuc980_sha_init,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_sha_digest,
+		.halg = {
+			.digestsize = SHA1_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha1_state),
+			.base   = {
+				.cra_name       = "sha1",
+				.cra_driver_name    = "nuc980-sha1",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA1_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+	{
+		.init       = nuc980_sha_init,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_sha_digest,
+		.halg = {
+			.digestsize = SHA224_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha256_state),
+			.base   = {
+				.cra_name       = "sha224",
+				.cra_driver_name    = "nuc980-sha224",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA224_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+	{
+		.init       = nuc980_sha_init,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_sha_digest,
+		.halg = {
+			.digestsize = SHA256_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha256_state),
+			.base   = {
+				.cra_name       = "sha256",
+				.cra_driver_name    = "nuc980-sha256",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA256_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+	{
+		.init       = nuc980_sha_init,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_sha_digest,
+		.halg = {
+			.digestsize = SHA384_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha512_state),
+			.base   = {
+				.cra_name       = "sha384",
+				.cra_driver_name    = "nuc980-sha384",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA384_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+	{
+		.init       = nuc980_sha_init,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_sha_digest,
+		.halg = {
+			.digestsize = SHA512_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha512_state),
+			.base   = {
+				.cra_name       = "sha512",
+				.cra_driver_name    = "nuc980-sha512",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA512_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+	{
+		.init       = nuc980_hmac_init,
+		.setkey     = nuc980_hmac_setkey,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_hmac_digest,
+		.halg = {
+			.digestsize = SHA1_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha1_state),
+			.base   = {
+				.cra_name       = "hmac-sha1",
+				.cra_driver_name    = "nuc980-hmac-sha1",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA1_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+	{
+		.init       = nuc980_hmac_init,
+		.setkey     = nuc980_hmac_setkey,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_hmac_digest,
+		.halg = {
+			.digestsize = SHA224_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha256_state),
+			.base   = {
+				.cra_name       = "hmac-sha224",
+				.cra_driver_name    = "nuc980-hmac-sha224",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA224_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+	{
+		.init       = nuc980_hmac_init,
+		.setkey     = nuc980_hmac_setkey,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_hmac_digest,
+		.halg = {
+			.digestsize = SHA256_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha256_state),
+			.base   = {
+				.cra_name       = "hmac-sha256",
+				.cra_driver_name    = "nuc980-hmac-sha256",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA256_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+	{
+		.init       = nuc980_hmac_init,
+		.setkey     = nuc980_hmac_setkey,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_hmac_digest,
+		.halg = {
+			.digestsize = SHA384_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha512_state),
+			.base   = {
+				.cra_name       = "hmac-sha384",
+				.cra_driver_name    = "nuc980-hmac-sha384",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA384_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+	{
+		.init       = nuc980_hmac_init,
+		.setkey     = nuc980_hmac_setkey,
+		.update     = nuc980_sha_update,
+		.final      = nuc980_sha_final,
+		.finup      = nuc980_sha_finup,
+		.digest     = nuc980_hmac_digest,
+		.halg = {
+			.digestsize = SHA512_DIGEST_SIZE,
+			.statesize  = sizeof(struct sha512_state),
+			.base   = {
+				.cra_name       = "hmac-sha512",
+				.cra_driver_name    = "nuc980-hmac-sha512",
+				.cra_priority   = 100,
+				.cra_flags      = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK,
+				.cra_blocksize  = SHA512_BLOCK_SIZE,
+				.cra_ctxsize    = sizeof(struct nuc980_ctx),
+				.cra_alignmask  = 0,
+				.cra_module     = THIS_MODULE,
+				.cra_init       = nuc980_sha_cra_init,
+				.cra_exit       = nuc980_sha_cra_exit,
+			}
+		}
+	},
+};
+
+static int nuc980_crypto_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	int   i, err, ret;
+
+	if (IS_ERR(clk_get(NULL, "crypto_hclk")))
+	{
+		printk("nuc980_crypto_probe clk_get error!!\n");
+		return -1;
+	}
+
+	/* Enable Cryptographic Accerlator clock */
+	clk_prepare(clk_get(NULL, "crypto_hclk"));
+	clk_enable(clk_get(NULL, "crypto_hclk"));
+
+	memset((u8 *)&nuc980_crdev, 0, sizeof(nuc980_crdev));
+
+	nuc980_crdev.dev = &pdev->dev;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res)
+		return -ENXIO;
+
+	if (!request_mem_region(res->start, resource_size(res), pdev->name))
+		return -EBUSY;
+
+	nuc980_crdev.regs = ioremap(res->start, resource_size(res));
+	if (!nuc980_crdev.regs)
+		return -ENOMEM;
+
+	//printk("nuc980_crdev.regs = 0x%x\n", (u32)nuc980_crdev.regs);
+
+	nuc980_crdev.aes_inbuf = dma_alloc_coherent(dev, DMA_BUFSZ, &nuc980_crdev.aes_inbuf_dma_addr, GFP_KERNEL);
+	nuc980_crdev.aes_outbuf = dma_alloc_coherent(dev, DMA_BUFSZ, &nuc980_crdev.aes_outbuf_dma_addr, GFP_KERNEL);
+	nuc980_crdev.hmac_inbuf = dma_alloc_coherent(dev, DMA_BUFSZ, &nuc980_crdev.hmac_inbuf_dma_addr, GFP_KERNEL);
+
+	if (!nuc980_crdev.aes_inbuf || !nuc980_crdev.aes_outbuf || !nuc980_crdev.hmac_inbuf)
+	{
+		ret = -ENOMEM;
+		goto failed;
+	}
+
+	nuc980_crdev.aes_inbuf_size  = DMA_BUFSZ;
+	nuc980_crdev.aes_outbuf_size = DMA_BUFSZ;
+	nuc980_crdev.hmac_inbuf_size = DMA_BUFSZ;
+
+	for (i = 0; i < ARRAY_SIZE(nuc980_crypto_algs); i++)
+	{
+		err = crypto_register_alg(&nuc980_crypto_algs[i].crypto);
+		if (err)
+			goto failed;
+	}
+
+	for (i = 0; i < ARRAY_SIZE(nuc980_hash_algs); i++)
+	{
+		err = crypto_register_ahash(&nuc980_hash_algs[i]);
+		if (err)
+			goto failed;
+	}
+
+	mutex_init(&(nuc980_crdev.aes_lock));
+	mutex_init(&(nuc980_crdev.sha_lock));
+
+	printk(KERN_NOTICE "NUC980 Crypto engine enabled.\n");
+	return 0;
+
+failed:
+
+	if (nuc980_crdev.aes_inbuf)
+		dma_free_coherent(dev, DMA_BUFSZ, nuc980_crdev.aes_inbuf, nuc980_crdev.aes_inbuf_dma_addr);
+	if (nuc980_crdev.aes_outbuf)
+		dma_free_coherent(dev, DMA_BUFSZ, nuc980_crdev.aes_outbuf, nuc980_crdev.aes_outbuf_dma_addr);
+	if (nuc980_crdev.hmac_inbuf)
+		dma_free_coherent(dev, DMA_BUFSZ, nuc980_crdev.hmac_inbuf, nuc980_crdev.hmac_inbuf_dma_addr);
+
+	iounmap(nuc980_crdev.regs);
+	release_mem_region(res->start, resource_size(res));
+
+	printk("NUC980 Crypto initialization failed.\n");
+	return ret;
+}
+
+static int nuc980_crypto_remove(struct platform_device *pdev)
+{
+	int  i;
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+
+	for (i = 0; i < ARRAY_SIZE(nuc980_crypto_algs); i++)
+		crypto_unregister_alg(&nuc980_crypto_algs[i].crypto);
+
+	for (i = 0; i < ARRAY_SIZE(nuc980_hash_algs); i++)
+		crypto_unregister_ahash(&nuc980_hash_algs[i]);
+
+	dma_free_coherent(dev, DMA_BUFSZ, nuc980_crdev.aes_inbuf, nuc980_crdev.aes_inbuf_dma_addr);
+	dma_free_coherent(dev, DMA_BUFSZ, nuc980_crdev.aes_outbuf, nuc980_crdev.aes_outbuf_dma_addr);
+	dma_free_coherent(dev, DMA_BUFSZ, nuc980_crdev.hmac_inbuf, nuc980_crdev.hmac_inbuf_dma_addr);
+
+	iounmap(nuc980_crdev.regs);
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	release_mem_region(res->start, resource_size(res));
+
+	clk_disable(clk_get(NULL, "crypto_hclk"));
+
+	return 0;
+}
+
+static int nuc980_crypto_suspend(struct platform_device *pdev,pm_message_t state)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	unsigned long  timeout;
+
+	timeout = jiffies+200;   // 2 seconds time out
+
+	while (time_before(jiffies, timeout))
+	{
+		if (crpt_regs->CRPT_AES_STS & AES_BUSY)
+			continue;
+
+		if (crpt_regs->CRPT_HMAC_STS & HMAC_BUSY)
+			continue;
+
+		break;
+	}
+
+	clk_disable(clk_get(NULL, "crypto_hclk"));
+
+	return 0;
+}
+
+static int nuc980_crypto_resume(struct platform_device *pdev)
+{
+	clk_enable(clk_get(NULL, "crypto_hclk"));
+	return 0;
+}
+
+
+static const struct of_device_id nuc980_crypto_of_match[] =
+{
+	{ .compatible = "nuvoton,nuc980-crypto" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_crypto_of_match);
+
+
+static struct platform_driver nuc980_crypto_driver =
+{
+	.probe      = nuc980_crypto_probe,
+	.remove     = nuc980_crypto_remove,
+	.resume     = nuc980_crypto_resume,
+	.suspend    = nuc980_crypto_suspend,
+	.driver     = {
+		.name   = "nuc980-crypto",
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_crypto_of_match),
+	},
+};
+
+module_platform_driver(nuc980_crypto_driver);
+
+MODULE_AUTHOR("Nuvoton Technology Corporation");
+MODULE_DESCRIPTION("NUC980 Cryptographic Accerlerator");
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/crypto/nuc980-crypto-raw.c NUC980-linux-4.4.194/drivers/crypto/nuc980-crypto-raw.c
--- linux-4.4.194/drivers/crypto/nuc980-crypto-raw.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/crypto/nuc980-crypto-raw.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1789 @@
+/* linux/driver/crypto/nuc980-crypto-raw.c
+ *
+ * Copyright (c) 2018 Nuvoton Technology Corporation
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+
+
+#include <linux/fs.h>
+#include <linux/miscdevice.h>
+#include <linux/device.h>
+#include <linux/mutex.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+
+#include <mach/map.h>
+#include <mach/regs-crypto.h>
+#include <mach/nuc980-crypto.h>
+
+
+extern struct nuc980_crypto_dev  nuc980_crdev;    /* declared in nuc980-crypto.c */
+
+
+/*-----------------------------------------------------------------------------------------------*/
+/*                                                                                               */
+/*    AES                                                                                        */
+/*                                                                                               */
+/*-----------------------------------------------------------------------------------------------*/
+
+
+// This function does not block, transaction complete in write(), this API is only for user to read back card response.
+static ssize_t nvt_aes_read(struct file *filp, char __user *buf, size_t count, loff_t *f_pos)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	u32    t0;
+	int    ret = 0;
+
+	mutex_lock(&nuc980_crdev.aes_lock);
+
+	t0 = jiffies;
+	while (crpt_regs->CRPT_AES_STS & AES_BUSY) {
+		if (jiffies - t0 >= 100) { /* 1s time-out */
+			ret = -EFAULT;
+			goto out;
+		}
+	}
+
+	if (copy_to_user(buf, (u8 *)nuc980_crdev.aes_outbuf, count)) {
+		ret = -EFAULT;
+		goto out;
+	}
+
+out:
+	mutex_unlock(&nuc980_crdev.aes_lock);
+	return ret;
+}
+
+
+static ssize_t nvt_aes_write(struct file *filp, const char __user *buf, size_t count, loff_t *f_pos)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	int   ret = 0;
+
+	mutex_lock(&nuc980_crdev.aes_lock);
+
+	if (copy_from_user((u8 *)nuc980_crdev.aes_inbuf, buf, count)) {
+		ret = -EFAULT;
+	} else {
+		crpt_regs->CRPT_AES_CTL |= AES_START;
+	}
+
+	mutex_unlock(&nuc980_crdev.aes_lock);
+	return ret;
+}
+
+static int nvt_aes_mmap(struct file *filp, struct vm_area_struct * vma)
+{
+	unsigned long pageFrameNo = 0, size;
+
+	pageFrameNo = __phys_to_pfn(nuc980_crdev.aes_inbuf_dma_addr);
+
+	size = vma->vm_end - vma->vm_start;
+	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+	vma->vm_flags |= (VM_DONTEXPAND | VM_DONTDUMP);
+	if (remap_pfn_range(vma, vma->vm_start, pageFrameNo,size, vma->vm_page_prot)) {
+		printk(KERN_INFO "nvt_aes_mmap() : remap_pfn_range() failed !\n");
+		return -EINVAL;
+	}
+	return 0;
+}
+
+
+static long nvt_aes_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	u32   t0, param;
+
+	mutex_lock(&nuc980_crdev.aes_lock);
+
+	switch(cmd) {
+	case AES_IOC_SET_MODE:
+		//printk("Set AES mode\n");
+		crpt_regs->CRPT_AES_CTL = arg | AES_DMAEN;
+		crpt_regs->CRPT_AES0_SADDR = nuc980_crdev.aes_inbuf_dma_addr;
+		crpt_regs->CRPT_AES0_DADDR = nuc980_crdev.aes_outbuf_dma_addr;
+		crpt_regs->CRPT_AES0_CNT = 16;   /* one AES block */
+		break;
+
+	case AES_IOC_SET_LEN:
+		crpt_regs->CRPT_AES0_CNT = arg;
+		break;
+
+	case AES_IOC_SET_IV:
+		copy_from_user((void *)&(crpt_regs->CRPT_AES0_IV[0]), (const void *)arg, 16);
+		//printk("AES_IOC_SET_IV: 0x%x-0x%x-0x%x-0x%x\n", crpt_regs->CRPT_AES0_IV[0], crpt_regs->CRPT_AES0_IV[1], crpt_regs->CRPT_AES0_IV[2], crpt_regs->CRPT_AES0_IV[3]);
+		break;
+
+	case AES_IOC_SET_KEY:
+		copy_from_user((void *)&(crpt_regs->CRPT_AES0_KEY[0]), (const void *)arg, 32);
+		//printk("AES_IOC_SET_KEY: 0x%x-0x%x-0x%x-0x%x\n", crpt_regs->CRPT_AES0_KEY[0], crpt_regs->CRPT_AES0_KEY[1], crpt_regs->CRPT_AES0_KEY[2], crpt_regs->CRPT_AES0_KEY[3]);
+		break;
+
+	case AES_IOC_GET_BUFSIZE:
+		param = nuc980_crdev.aes_inbuf_size * 2;    /* input buffer plus output buffer, they are contiguous */
+		copy_to_user((u8 *)arg, (u8 *)&param, 4);
+		break;
+
+	case AES_IOC_START:
+		crpt_regs->CRPT_AES_CTL = (crpt_regs->CRPT_AES_CTL & ~AES_DMACSCAD) | AES_START;
+		t0 = jiffies;
+		while (crpt_regs->CRPT_AES_STS & AES_BUSY) {
+			if (jiffies - t0 >= 100) { /* 1s time-out */
+				mutex_unlock(&nuc980_crdev.aes_lock);
+				return -EFAULT;
+			}
+		}
+		break;
+
+	case AES_IOC_C_START:
+		crpt_regs->CRPT_AES_CTL |= (AES_DMACSCAD | AES_START);
+		t0 = jiffies;
+		while (crpt_regs->CRPT_AES_STS & AES_BUSY) {
+			if (jiffies - t0 >= 100) { /* 1s time-out */
+				mutex_unlock(&nuc980_crdev.aes_lock);
+				return -EFAULT;
+			}
+		}
+		break;
+
+	case AES_IOC_UPDATE_IV:
+		copy_to_user((u8 *)arg, (u8 *)&(crpt_regs->CRPT_AES_FDBCK[0]), 16);
+		break;
+
+	default:
+		mutex_unlock(&nuc980_crdev.aes_lock);
+		return -ENOTTY;
+	}
+	mutex_unlock(&nuc980_crdev.aes_lock);
+	return 0;
+}
+
+
+struct file_operations nvt_aes_fops = {
+	.owner		= THIS_MODULE,
+	.read		= nvt_aes_read,
+	.write		= nvt_aes_write,
+	.mmap       = nvt_aes_mmap,
+	.unlocked_ioctl	= nvt_aes_ioctl,
+};
+
+static struct miscdevice nvt_aes_dev = {
+	.minor		= MISC_DYNAMIC_MINOR,
+	.name		= "nuvoton-aes",
+	.fops		= &nvt_aes_fops,
+};
+
+
+/*-----------------------------------------------------------------------------------------------*/
+/*                                                                                               */
+/*    SHA                                                                                        */
+/*                                                                                               */
+/*-----------------------------------------------------------------------------------------------*/
+
+#define SHA_BUFF_SIZE       256
+static unsigned char  sha_buffer[SHA_BUFF_SIZE];
+static int   sha_remaining_cnt = 0;
+
+static ssize_t nvt_sha_read(struct file *filp, char __user *buf, size_t count, loff_t *f_pos)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	u32    t0;
+	int    ret = 0;
+
+	if (sha_remaining_cnt != 0) {
+		printk("SHA_IOC_FINISH missed!\n");
+		return -EFAULT;
+	}
+
+	mutex_lock(&nuc980_crdev.sha_lock);
+
+	t0 = jiffies;
+	while (crpt_regs->CRPT_HMAC_STS & HMAC_BUSY) {
+		if (jiffies - t0 >= 100) { /* 1s time-out */
+			ret = -EFAULT;
+			goto out;
+		}
+	}
+
+	if (copy_to_user(buf, (u8 *)&crpt_regs->CRPT_HMAC_DGST[0], count)) {
+		ret = -EFAULT;
+		goto out;
+	}
+
+out:
+	mutex_unlock(&nuc980_crdev.sha_lock);
+	return ret;
+}
+
+
+static ssize_t nvt_sha_write(struct file *filp, const char __user *buf, size_t count, loff_t *f_pos)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	u32   *data_ptr;
+	int   rcnt, ret = 0;
+
+	mutex_lock(&nuc980_crdev.sha_lock);
+
+	while (count > 0) {
+		rcnt = SHA_BUFF_SIZE - sha_remaining_cnt;
+
+		if (count < rcnt)
+			rcnt = count;
+
+		if (copy_from_user(&sha_buffer[sha_remaining_cnt], buf, rcnt)) {
+			ret = -EFAULT;
+		}
+
+		buf += rcnt;
+		count -= rcnt;
+		sha_remaining_cnt += rcnt;
+
+		if ((sha_remaining_cnt == SHA_BUFF_SIZE) && (count > 0)) {
+			/*
+			 * If SHA buffer full and still have input data, flush the buffer to SHA engine.
+			 */
+			data_ptr = (u32 *)&sha_buffer[0];
+			while (sha_remaining_cnt > 0) {
+				if (crpt_regs->CRPT_HMAC_STS & HMAC_DINREQ) {
+					crpt_regs->CRPT_HMAC_DATIN = *data_ptr++;
+					sha_remaining_cnt -= 4;
+				}
+			}
+			sha_remaining_cnt = 0;
+		}
+	}
+	mutex_unlock(&nuc980_crdev.sha_lock);
+	return ret;
+}
+
+static long nvt_sha_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	u32   *data_ptr;
+
+	mutex_lock(&nuc980_crdev.sha_lock);
+
+	switch(cmd) {
+	case SHA_IOC_INIT:
+		sha_remaining_cnt = 0;
+		crpt_regs->CRPT_HMAC_CTL = arg | HMAC_START;
+		crpt_regs->CRPT_HMAC_DMACNT = 0x10000000;
+		break;
+
+	case SHA_IOC_FINISH:
+		if (sha_remaining_cnt) {
+			crpt_regs->CRPT_HMAC_DMACNT = sha_remaining_cnt;
+			data_ptr = (u32 *)&sha_buffer[0];
+			while (sha_remaining_cnt > 0) {
+				if (crpt_regs->CRPT_HMAC_STS & HMAC_DINREQ) {
+					if (sha_remaining_cnt <= 4) {
+						crpt_regs->CRPT_HMAC_CTL |= HMAC_START | HMAC_DMALAST;
+					}
+					crpt_regs->CRPT_HMAC_DATIN = *data_ptr++;
+					sha_remaining_cnt -= 4;
+				}
+			}
+			sha_remaining_cnt = 0;
+		} else {
+			/* SHA was started, but no data pushed! */
+			return -EFAULT;
+		}
+		break;
+
+
+	default:
+		mutex_unlock(&nuc980_crdev.sha_lock);
+		return -ENOTTY;
+	}
+
+	mutex_unlock(&nuc980_crdev.sha_lock);
+	return 0;
+}
+
+struct file_operations nvt_sha_fops = {
+	.owner		= THIS_MODULE,
+	.read		= nvt_sha_read,        /* used to read SHA output digest            */
+	.write		= nvt_sha_write,       /* used to push SHA input data               */
+	.unlocked_ioctl	= nvt_sha_ioctl,   /* used to start and finish a SHA operation  */
+};
+
+static struct miscdevice nvt_sha_dev = {
+	.minor		= MISC_DYNAMIC_MINOR,
+	.name		= "nuvoton-sha",
+	.fops		= &nvt_sha_fops,
+};
+
+
+/*-----------------------------------------------------------------------------------------------*/
+/*                                                                                               */
+/*    ECC                                                                                        */
+/*                                                                                               */
+/*-----------------------------------------------------------------------------------------------*/
+
+/*
+ *  Define elliptic curve (EC)
+ */
+typedef struct e_curve_t {
+	u32   curve_id;
+	int   Echar;
+	char  Ea[144];
+	char  Eb[144];
+	char  Px[144];
+	char  Py[144];
+	int   Epl;
+	char  Pp[176];
+	int   Eol;
+	char  Eorder[176];
+	int   key_len;
+	int   irreducible_k1;
+	int   irreducible_k2;
+	int   irreducible_k3;
+	int   GF;
+}  ECC_CURVE;
+
+static const ECC_CURVE _Curve[] = {
+	{
+		/* NIST: Curve P-192 : y^2=x^3-ax+b (mod p) */
+		ECC_CURVE_P_192,
+		48,     /* Echar */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFFFFFFFFFC",   /* "000000000000000000000000000000000000000000000003" */
+		"64210519e59c80e70fa7e9ab72243049feb8deecc146b9b1",
+		"188da80eb03090f67cbf20eb43a18800f4ff0afd82ff1012",
+		"07192b95ffc8da78631011ed6b24cdd573f977a11e794811",
+		58,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFFFFFFFFFF",   /* "6277101735386680763835789423207666416083908700390324961279" */
+		58,     /* Eol */
+		"FFFFFFFFFFFFFFFFFFFFFFFF99DEF836146BC9B1B4D22831",   /* "6277101735386680763835789423176059013767194773182842284081" */
+		192,    /* key_len */
+		7,
+		2,
+		1,
+		CURVE_GF_P
+	},
+	{
+		/* NIST: Curve P-224 : y^2=x^3-ax+b (mod p) */
+		ECC_CURVE_P_224,
+		56,     /* Echar */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFE",  /* "00000000000000000000000000000000000000000000000000000003" */
+		"b4050a850c04b3abf54132565044b0b7d7bfd8ba270b39432355ffb4",
+		"b70e0cbd6bb4bf7f321390b94a03c1d356c21122343280d6115c1d21",
+		"bd376388b5f723fb4c22dfe6cd4375a05a07476444d5819985007e34",
+		70,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "0026959946667150639794667015087019630673557916260026308143510066298881" */
+		70,     /* Eol */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFF16A2E0B8F03E13DD29455C5C2A3D",  /* "0026959946667150639794667015087019625940457807714424391721682722368061" */
+		224,    /* key_len */
+		9,
+		8,
+		3,
+		CURVE_GF_P
+	},
+	{
+		/* NIST: Curve P-256 : y^2=x^3-ax+b (mod p) */
+		ECC_CURVE_P_256,
+		64,     /* Echar */
+		"FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFC",  /* "0000000000000000000000000000000000000000000000000000000000000003" */
+		"5ac635d8aa3a93e7b3ebbd55769886bc651d06b0cc53b0f63bce3c3e27d2604b",
+		"6b17d1f2e12c4247f8bce6e563a440f277037d812deb33a0f4a13945d898c296",
+		"4fe342e2fe1a7f9b8ee7eb4a7c0f9e162bce33576b315ececbb6406837bf51f5",
+		78,     /* Epl */
+		"FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFF",  /* "115792089210356248762697446949407573530086143415290314195533631308867097853951" */
+		78,     /* Eol */
+		"FFFFFFFF00000000FFFFFFFFFFFFFFFFBCE6FAADA7179E84F3B9CAC2FC632551",  /* "115792089210356248762697446949407573529996955224135760342422259061068512044369" */
+		256,    /* key_len */
+		10,
+		5,
+		2,
+		CURVE_GF_P
+	},
+	{
+		/* NIST: Curve P-384 : y^2=x^3-ax+b (mod p) */
+		ECC_CURVE_P_384,
+		96,     /* Echar */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFF0000000000000000FFFFFFFC",  /* "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000003" */
+		"b3312fa7e23ee7e4988e056be3f82d19181d9c6efe8141120314088f5013875ac656398d8a2ed19d2a85c8edd3ec2aef",
+		"aa87ca22be8b05378eb1c71ef320ad746e1d3b628ba79b9859f741e082542a385502f25dbf55296c3a545e3872760ab7",
+		"3617de4a96262c6f5d9e98bf9292dc29f8f41dbd289a147ce9da3113b5f0b8c00a60b1ce1d7e819d7a431d7c90ea0e5f",
+		116,    /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFF0000000000000000FFFFFFFF",  /* "39402006196394479212279040100143613805079739270465446667948293404245721771496870329047266088258938001861606973112319" */
+		116,    /* Eol */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFC7634D81F4372DDF581A0DB248B0A77AECEC196ACCC52973",  /* "39402006196394479212279040100143613805079739270465446667946905279627659399113263569398956308152294913554433653942643" */
+		384,    /* key_len */
+		12,
+		3,
+		2,
+		CURVE_GF_P
+	},
+	{
+		/* NIST: Curve P-521 : y^2=x^3-ax+b (mod p)*/
+		ECC_CURVE_P_521,
+		131,    /* Echar */
+		"1FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFC",  /* "00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000003" */
+		"051953eb9618e1c9a1f929a21a0b68540eea2da725b99b315f3b8b489918ef109e156193951ec7e937b1652c0bd3bb1bf073573df883d2c34f1ef451fd46b503f00",
+		"0c6858e06b70404e9cd9e3ecb662395b4429c648139053fb521f828af606b4d3dbaa14b5e77efe75928fe1dc127a2ffa8de3348b3c1856a429bf97e7e31c2e5bd66",
+		"11839296a789a3bc0045c8a5fb42c7d1bd998f54449579b446817afbd17273e662c97ee72995ef42640c550b9013fad0761353c7086a272c24088be94769fd16650",
+		157,    /* Epl */
+		"1FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF",  /* "6864797660130609714981900799081393217269435300143305409394463459185543183397656052122559640661454554977296311391480858037121987999716643812574028291115057151" */
+		157,    /* Eol */
+		"1FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFA51868783BF2F966B7FCC0148F709A5D03BB5C9B8899C47AEBB6FB71E91386409",  /* "6864797660130609714981900799081393217269435300143305409394463459185543183397655394245057746333217197532963996371363321113864768612440380340372808892707005449" */
+		521,    /* key_len */
+		32,
+		32,
+		32,
+		CURVE_GF_P
+	},
+	{
+		/* NIST: Curve B-163 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_B_163,
+		41,     /* Echar */
+		"00000000000000000000000000000000000000001",
+		"20a601907b8c953ca1481eb10512f78744a3205fd",
+		"3f0eba16286a2d57ea0991168d4994637e8343e36",
+		"0d51fbc6c71a0094fa2cdd545b11c5c0c797324f1",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		49,     /* Eol */
+		"40000000000000000000292FE77E70C12A4234C33",   /* "5846006549323611672814742442876390689256843201587" */
+		163,    /* key_len */
+		7,
+		6,
+		3,
+		CURVE_GF_2M
+	},
+	{
+		/* NIST: Curve B-233 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_B_233,
+		59,     /* Echar 59 */
+		"00000000000000000000000000000000000000000000000000000000001",
+		"066647ede6c332c7f8c0923bb58213b333b20e9ce4281fe115f7d8f90ad",
+		"0fac9dfcbac8313bb2139f1bb755fef65bc391f8b36f8f8eb7371fd558b",
+		"1006a08a41903350678e58528bebf8a0beff867a7ca36716f7e01f81052",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		70,     /* Eol */
+		"1000000000000000000000000000013E974E72F8A6922031D2603CFE0D7",  /* "6901746346790563787434755862277025555839812737345013555379383634485463" */
+		233,    /* key_len */
+		74,
+		74,
+		74,
+		CURVE_GF_2M
+	},
+	{
+		/* NIST: Curve B-283 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_B_283,
+		71,     /* Echar */
+		"00000000000000000000000000000000000000000000000000000000000000000000001",
+		"27b680ac8b8596da5a4af8a19a0303fca97fd7645309fa2a581485af6263e313b79a2f5",
+		"5f939258db7dd90e1934f8c70b0dfec2eed25b8557eac9c80e2e198f8cdbecd86b12053",
+		"3676854fe24141cb98fe6d4b20d02b4516ff702350eddb0826779c813f0df45be8112f4",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		85,     /* Eol */
+		"3FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEF90399660FC938A90165B042A7CEFADB307",  /* "7770675568902916283677847627294075626569625924376904889109196526770044277787378692871" */
+		283,    /* key_len */
+		12,
+		7,
+		5,
+		CURVE_GF_2M
+	},
+	{
+		/* NIST: Curve B-409 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_B_409,
+		103,    /* Echar */
+		"0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001",
+		"021a5c2c8ee9feb5c4b9a753b7b476b7fd6422ef1f3dd674761fa99d6ac27c8a9a197b272822f6cd57a55aa4f50ae317b13545f",
+		"15d4860d088ddb3496b0c6064756260441cde4af1771d4db01ffe5b34e59703dc255a868a1180515603aeab60794e54bb7996a7",
+		"061b1cfab6be5f32bbfa78324ed106a7636b9c5a7bd198d0158aa4f5488d08f38514f1fdf4b4f40d2181b3681c364ba0273c706",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		123,    /* Eol */
+		"10000000000000000000000000000000000000000000000000001E2AAD6A612F33307BE5FA47C3C9E052F838164CD37D9A21173",  /* "661055968790248598951915308032771039828404682964281219284648798304157774827374805208143723762179110965979867288366567526771" */
+		409,    /* key_len */
+		87,
+		87,
+		87,
+		CURVE_GF_2M
+	},
+	{
+		/* NIST: Curve B-571 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_B_571,
+		143,    /* Echar */
+		"00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001",
+		"2f40e7e2221f295de297117b7f3d62f5c6a97ffcb8ceff1cd6ba8ce4a9a18ad84ffabbd8efa59332be7ad6756a66e294afd185a78ff12aa520e4de739baca0c7ffeff7f2955727a",
+		"303001d34b856296c16c0d40d3cd7750a93d1d2955fa80aa5f40fc8db7b2abdbde53950f4c0d293cdd711a35b67fb1499ae60038614f1394abfa3b4c850d927e1e7769c8eec2d19",
+		"37bf27342da639b6dccfffeb73d69d78c6c27a6009cbbca1980f8533921e8a684423e43bab08a576291af8f461bb2a8b3531d2f0485c19b16e2f1516e23dd3c1a4827af1b8ac15b",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		172,    /* Eol */
+		"3FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFE661CE18FF55987308059B186823851EC7DD9CA1161DE93D5174D66E8382E9BB2FE84E47",  /* "3864537523017258344695351890931987344298927329706434998657235251451519142289560424536143999389415773083133881121926944486246872462816813070234528288303332411393191105285703" */
+		571,    /* key_len */
+		10,
+		5,
+		2,
+		CURVE_GF_2M
+	},
+	{
+		/* NIST: Curve K-163 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_K_163,
+		41,     /* Echar */
+		"00000000000000000000000000000000000000001",
+		"00000000000000000000000000000000000000001",
+		"2fe13c0537bbc11acaa07d793de4e6d5e5c94eee8",
+		"289070fb05d38ff58321f2e800536d538ccdaa3d9",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		49,     /* Eol */
+		"4000000000000000000020108A2E0CC0D99F8A5EF",  /* "5846006549323611672814741753598448348329118574063" */
+		163,    /* key_len */
+		7,
+		6,
+		3,
+		CURVE_GF_2M
+	},
+	{
+		/* NIST: Curve K-233 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_K_233,
+		59,     /* Echar 59 */
+		"00000000000000000000000000000000000000000000000000000000000",
+		"00000000000000000000000000000000000000000000000000000000001",
+		"17232ba853a7e731af129f22ff4149563a419c26bf50a4c9d6eefad6126",
+		"1db537dece819b7f70f555a67c427a8cd9bf18aeb9b56e0c11056fae6a3",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",    /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		70,     /* Eol */
+		"8000000000000000000000000000069D5BB915BCD46EFB1AD5F173ABDF",  /* "3450873173395281893717377931138512760570940988862252126328087024741343" */
+		233,    /* key_len */
+		74,
+		74,
+		74,
+		CURVE_GF_2M
+	},
+	{
+		/* NIST: Curve K-283 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_K_283,
+		71,     /* Echar */
+		"00000000000000000000000000000000000000000000000000000000000000000000000",
+		"00000000000000000000000000000000000000000000000000000000000000000000001",
+		"503213f78ca44883f1a3b8162f188e553cd265f23c1567a16876913b0c2ac2458492836",
+		"1ccda380f1c9e318d90f95d07e5426fe87e45c0e8184698e45962364e34116177dd2259",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		85,     /* Eol */
+		"1FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFE9AE2ED07577265DFF7F94451E061E163C61",  /* "3885337784451458141838923813647037813284811733793061324295874997529815829704422603873" */
+		283,    /* key_len */
+		12,
+		7,
+		5,
+		CURVE_GF_2M
+	},
+	{
+		/* NIST: Curve K-409 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_K_409,
+		103,    /* Echar */
+		"0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000",
+		"0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001",
+		"060f05f658f49c1ad3ab1890f7184210efd0987e307c84c27accfb8f9f67cc2c460189eb5aaaa62ee222eb1b35540cfe9023746",
+		"1e369050b7c4e42acba1dacbf04299c3460782f918ea427e6325165e9ea10e3da5f6c42e9c55215aa9ca27a5863ec48d8e0286b",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		123,    /* Eol */
+		"7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFE5F83B2D4EA20400EC4557D5ED3E3E7CA5B4B5C83B8E01E5FCF",  /* "330527984395124299475957654016385519914202341482140609642324395022880711289249191050673258457777458014096366590617731358671" */
+		409,    /* key_len */
+		87,
+		87,
+		87,
+		CURVE_GF_2M
+	},
+	{
+		/* NIST: Curve K-571 : y^2+xy=x^3+ax^2+b */
+		ECC_CURVE_K_571,
+		143,    /* Echar */
+		"00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000",
+		"00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001",
+		"26eb7a859923fbc82189631f8103fe4ac9ca2970012d5d46024804801841ca44370958493b205e647da304db4ceb08cbbd1ba39494776fb988b47174dca88c7e2945283a01c8972",
+		"349dc807f4fbf374f4aeade3bca95314dd58cec9f307a54ffc61efc006d8a2c9d4979c0ac44aea74fbebbb9f772aedcb620b01a7ba7af1b320430c8591984f601cd4c143ef1c7a3",
+		68,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001",  /* "26959946667150639794667015087019630673557916260026308143510066298881" */
+		172,    /* Eol */
+		"20000000000000000000000000000000000000000000000000000000000000000000000131850E1F19A63E4B391A8DB917F4138B630D84BE5D639381E91DEB45CFE778F637C1001",  /* "1932268761508629172347675945465993672149463664853217499328617625725759571144780212268133978522706711834706712800825351461273674974066617311929682421617092503555733685276673" */
+		571,    /* key_len */
+		10,
+		5,
+		2,
+		CURVE_GF_2M
+	},
+	{
+		/* Koblitz: Curve secp192k1 : y2 = x3+ax+b over Fp */
+		ECC_CURVE_KO_192,
+		48,     /* Echar */
+		"00000000000000000000000000000000000000000",
+		"00000000000000000000000000000000000000003",
+		"DB4FF10EC057E9AE26B07D0280B7F4341DA5D1B1EAE06C7D",
+		"9B2F2F6D9C5628A7844163D015BE86344082AA88D95E2F9D",
+		58,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFEE37",  /* p */
+		58,     /* Eol */
+		"FFFFFFFFFFFFFFFFFFFFFFFE26F2FC170F69466A74DEFD8D",  /* n */
+		192,    /* key_len */
+		7,
+		2,
+		1,
+		CURVE_GF_P
+	},
+	{
+		/* Koblitz: Curve secp224k1 : y2 = x3+ax+b over Fp */
+		ECC_CURVE_KO_224,
+		56,     /* Echar */
+		"00000000000000000000000000000000000000000000000000000000",
+		"00000000000000000000000000000000000000000000000000000005",
+		"A1455B334DF099DF30FC28A169A467E9E47075A90F7E650EB6B7A45C",
+		"7E089FED7FBA344282CAFBD6F7E319F7C0B0BD59E2CA4BDB556D61A5",
+		70,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFE56D",  /* p */
+		70,     /* Eol */
+		"0000000000000000000000000001DCE8D2EC6184CAF0A971769FB1F7",  /* n */
+		224,    /* key_len */
+		7,
+		2,
+		1,
+		CURVE_GF_P
+	},
+	{
+		/* Koblitz: Curve secp256k1 : y2 = x3+ax+b over Fp */
+		ECC_CURVE_KO_256,
+		64,     /* Echar */
+		"0000000000000000000000000000000000000000000000000000000000000000",
+		"0000000000000000000000000000000000000000000000000000000000000007",
+		"79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798",
+		"483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8",
+		78,     /* Epl */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F",  /* p */
+		78,     /* Eol */
+		"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141",  /* n */
+		256,    /* key_len */
+		7,
+		2,
+		1,
+		CURVE_GF_P
+	},
+	{
+		/* Brainpool: Curve brainpoolP256r1 */
+		ECC_CURVE_BP_256,
+		64,     /* Echar */
+		"7D5A0975FC2C3057EEF67530417AFFE7FB8055C126DC5C6CE94A4B44F330B5D9",  /* A */
+		"26DC5C6CE94A4B44F330B5D9BBD77CBF958416295CF7E1CE6BCCDC18FF8C07B6",  /* B */
+		"8BD2AEB9CB7E57CB2C4B482FFC81B7AFB9DE27E1E3BD23C23A4453BD9ACE3262",  /* x */
+		"547EF835C3DAC4FD97F8461A14611DC9C27745132DED8E545C1D54C72F046997",  /* y */
+		78,     /* Epl */
+		"A9FB57DBA1EEA9BC3E660A909D838D726E3BF623D52620282013481D1F6E5377",  /* p */
+		78,     /* Eol */
+		"A9FB57DBA1EEA9BC3E660A909D838D718C397AA3B561A6F7901E0E82974856A7",  /* q */
+		256,    /* key_len */
+		7,
+		2,
+		1,
+		CURVE_GF_P
+	},
+	{
+		/* Brainpool: Curve brainpoolP384r1 */
+		ECC_CURVE_BP_384,
+		96,     /* Echar */
+		"7BC382C63D8C150C3C72080ACE05AFA0C2BEA28E4FB22787139165EFBA91F90F8AA5814A503AD4EB04A8C7DD22CE2826",  /* A */
+		"04A8C7DD22CE28268B39B55416F0447C2FB77DE107DCD2A62E880EA53EEB62D57CB4390295DBC9943AB78696FA504C11",  /* B */
+		"1D1C64F068CF45FFA2A63A81B7C13F6B8847A3E77EF14FE3DB7FCAFE0CBD10E8E826E03436D646AAEF87B2E247D4AF1E",  /* x */
+		"8ABE1D7520F9C2A45CB1EB8E95CFD55262B70B29FEEC5864E19C054FF99129280E4646217791811142820341263C5315",  /* y */
+		116,     /* Epl */
+		"8CB91E82A3386D280F5D6F7E50E641DF152F7109ED5456B412B1DA197FB71123ACD3A729901D1A71874700133107EC53",  /* p */
+		116,     /* Eol */
+		"8CB91E82A3386D280F5D6F7E50E641DF152F7109ED5456B31F166E6CAC0425A7CF3AB6AF6B7FC3103B883202E9046565",  /* q */
+		384,    /* key_len */
+		7,
+		2,
+		1,
+		CURVE_GF_P
+	},
+	{
+		/* Brainpool: Curve brainpoolP512r1 */
+		ECC_CURVE_BP_512,
+		128,     /* Echar */
+		"7830A3318B603B89E2327145AC234CC594CBDD8D3DF91610A83441CAEA9863BC2DED5D5AA8253AA10A2EF1C98B9AC8B57F1117A72BF2C7B9E7C1AC4D77FC94CA",  /* A */
+		"3DF91610A83441CAEA9863BC2DED5D5AA8253AA10A2EF1C98B9AC8B57F1117A72BF2C7B9E7C1AC4D77FC94CADC083E67984050B75EBAE5DD2809BD638016F723",  /* B */
+		"81AEE4BDD82ED9645A21322E9C4C6A9385ED9F70B5D916C1B43B62EEF4D0098EFF3B1F78E2D0D48D50D1687B93B97D5F7C6D5047406A5E688B352209BCB9F822",  /* x */
+		"7DDE385D566332ECC0EABFA9CF7822FDF209F70024A57B1AA000C55B881F8111B2DCDE494A5F485E5BCA4BD88A2763AED1CA2B2FA8F0540678CD1E0F3AD80892",  /* y */
+		156,     /* Epl */
+		"AADD9DB8DBE9C48B3FD4E6AE33C9FC07CB308DB3B3C9D20ED6639CCA703308717D4D9B009BC66842AECDA12AE6A380E62881FF2F2D82C68528AA6056583A48F3",  /* p */
+		156,     /* Eol */
+		"AADD9DB8DBE9C48B3FD4E6AE33C9FC07CB308DB3B3C9D20ED6639CCA70330870553E5C414CA92619418661197FAC10471DB1D381085DDADDB58796829CA90069",  /* q */
+		512,    /* key_len */
+		7,
+		2,
+		1,
+		CURVE_GF_P
+	},
+	{
+		ECC_CURVE_25519,
+		64,		// Echar
+		"0000000000000000000000000000000000000000000000000000000000076D06",  // "0000000000000000000000000000000000000000000000000000000000000003",
+		"0000000000000000000000000000000000000000000000000000000000000001",
+		"0000000000000000000000000000000000000000000000000000000000000009",
+		"20ae19a1b8a086b4e01edd2c7748d14c923d4d7e6d7c61b229e9c5a27eced3d9",
+		78,		// Epl
+		"7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffed",  // "115792089210356248762697446949407573530086143415290314195533631308867097853951",
+		78,		// Eol
+		"1000000000000000000000000000000014def9dea2f79cd65812631a5cf5d3ed",  // "115792089210356248762697446949407573529996955224135760342422259061068512044369",
+		255,	// key_len
+		10,
+		5,
+		2,
+		CURVE_GF_P
+	},
+};
+
+u32 _curve_used = ECC_CURVE_P_256;
+static ECC_CURVE  *pCurve = (ECC_CURVE *)&_Curve[0];
+static ECC_CURVE  Curve_Copy;
+static char  temp_hex_str[160];
+static char  ecc_x1[160], ecc_y1[160], ecc_d[160], ecc_k[160], ecc_msg[160], ecc_r[160], ecc_s[160];
+static char  hex_char_tbl[] = "0123456789abcdef";
+
+static void dump_ecc_reg(char *str, uint32_t volatile regs[], int32_t count)
+{
+#if 0
+	int32_t  i;
+
+	printk("%s => ", str);
+	for (i = 0; i < count; i++) {
+		printk("0x%08x ", regs[i]);
+	}
+	printk("\n");
+#endif
+}
+
+static char  ch2hex(char ch)
+{
+	if (ch <= '9') {
+		ch = ch - '0';
+	} else if ((ch <= 'z') && (ch >= 'a')) {
+		ch = ch - 'a' + 10U;
+	} else {
+		ch = ch - 'A' + 10U;
+	}
+	return ch;
+}
+
+static void Hex2Reg(char input[], u32 volatile reg[])
+{
+	char      hex;
+	int       si, ri;
+	u32       i, val32;
+
+	si = (int)strlen(input) - 1;
+	ri = 0;
+
+	while (si >= 0) {
+		val32 = 0UL;
+		for (i = 0UL; (i < 8UL) && (si >= 0); i++) {
+			hex = ch2hex(input[si]);
+			val32 |= (uint32_t)hex << (i * 4UL);
+			si--;
+		}
+		reg[ri++] = val32;
+	}
+}
+
+static char get_Nth_nibble_char(u32 val32, u32 idx)
+{
+	return hex_char_tbl[ (val32 >> (idx * 4U)) & 0xfU ];
+}
+
+static void Reg2Hex(int count, u32 volatile reg[], char output[])
+{
+	int    idx, ri;
+	u32    i;
+
+	output[count] = 0U;
+	idx = count - 1;
+
+	for (ri = 0; idx >= 0; ri++) {
+		for (i = 0UL; (i < 8UL) && (idx >= 0); i++) {
+			output[idx] = get_Nth_nibble_char(reg[ri], i);
+			idx--;
+		}
+	}
+}
+
+static int ecc_strcmp(char *s1, char *s2)
+{
+	char  c1, c2;
+
+	while (*s1 == '0') s1++;
+	while (*s2 == '0') s2++;
+
+	for ( ; *s1 || *s2; s1++, s2++) {
+		if ((*s1 >= 'A') && (*s1 <= 'Z'))
+			c1 = *s1 + 32;
+		else
+			c1 = *s1;
+
+		if ((*s2 >= 'A') && (*s2 <= 'Z'))
+			c2 = *s2 + 32;
+		else
+			c2 = *s2;
+
+		if (c1 != c2)
+			return 1;
+	}
+	return 0;
+}
+
+static ECC_CURVE * get_curve(u32 ecc_curve)
+{
+	u32     i;
+	ECC_CURVE  *ret = NULL;
+
+	for (i = 0UL; i < sizeof(_Curve) / sizeof(ECC_CURVE); i++) {
+		if (ecc_curve == _Curve[i].curve_id) {
+			memcpy((char *)&Curve_Copy, &_Curve[i], sizeof(ECC_CURVE));
+			ret = &Curve_Copy;   /* (ECC_CURVE *)&_Curve[i]; */
+			break;
+		}
+	}
+	return ret;
+}
+
+static int ecc_init_curve(u32 ecc_curve)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	int  i;
+
+	pCurve = get_curve(ecc_curve);
+	if (pCurve == NULL)
+		return -1;
+
+	for (i = 0; i < 18; i++) {
+		crpt_regs->ECC_A[i] = 0UL;
+		crpt_regs->ECC_B[i] = 0UL;
+		crpt_regs->ECC_X1[i] = 0UL;
+		crpt_regs->ECC_Y1[i] = 0UL;
+		crpt_regs->ECC_N[i] = 0UL;
+	}
+
+	Hex2Reg(pCurve->Ea, crpt_regs->ECC_A);
+	Hex2Reg(pCurve->Eb, crpt_regs->ECC_B);
+	Hex2Reg(pCurve->Px, crpt_regs->ECC_X1);
+	Hex2Reg(pCurve->Py, crpt_regs->ECC_Y1);
+
+	//printk("Key length = %d\n", pCurve->key_len);
+	dump_ecc_reg("CRPT_ECC_CURVE_A", crpt_regs->ECC_A, 10);
+	dump_ecc_reg("CRPT_ECC_CURVE_B", crpt_regs->ECC_B, 10);
+	dump_ecc_reg("CRPT_ECC_POINT_X1", crpt_regs->ECC_X1, 10);
+	dump_ecc_reg("CRPT_ECC_POINT_Y1", crpt_regs->ECC_Y1, 10);
+
+	if (pCurve->GF == (int)CURVE_GF_2M) {
+		crpt_regs->ECC_N[0] = 0x1UL;
+		crpt_regs->ECC_N[(pCurve->key_len) / 32] |= (1UL << ((pCurve->key_len) % 32));
+		crpt_regs->ECC_N[(pCurve->irreducible_k1) / 32] |= (1UL << ((pCurve->irreducible_k1) % 32));
+		crpt_regs->ECC_N[(pCurve->irreducible_k2) / 32] |= (1UL << ((pCurve->irreducible_k2) % 32));
+		crpt_regs->ECC_N[(pCurve->irreducible_k3) / 32] |= (1UL << ((pCurve->irreducible_k3) % 32));
+	} else {
+		Hex2Reg(pCurve->Pp, crpt_regs->ECC_N);
+	}
+	dump_ecc_reg("CRPT_ECC_CURVE_N", crpt_regs->ECC_N, 10);
+	return 0;
+}
+
+static int run_ecc_codec(uint32_t mode)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	volatile int32_t  t0;
+
+	if ((mode & CRPT_ECC_CTL_ECCOP_Mask) == ECCOP_MODULE) {
+		crpt_regs->ECC_CTL = CRPT_ECC_CTL_FSEL_Mask;
+	} else {
+		if (pCurve->GF == (int)CURVE_GF_2M)
+			crpt_regs->ECC_CTL = 0UL;    /* point */
+		else
+			crpt_regs->ECC_CTL = CRPT_ECC_CTL_FSEL_Mask;  /* CURVE_GF_P */
+	}
+
+	t0 = jiffies;
+	crpt_regs->ECC_CTL |= ((u32)pCurve->key_len << CRPT_ECC_CTL_CURVE_M_Pos) | mode | CRPT_ECC_CTL_START_Mask;
+	while (crpt_regs->ECC_STS & CRPT_ECC_STS_BUSY_Mask) {
+		if (jiffies - t0 >= 100) {
+			printk("run_ecc_codec time-out!\n");
+			return -1;
+		}
+	}
+	return 0;
+}
+
+//int32_t  ECC_Mutiply(CRPT_T *crpt, E_ECC_CURVE ecc_curve, char x1[], char y1[], char *k, char x2[], char y2[])
+static int ECC_Mutiply(void)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	volatile int32_t  i, t0;
+
+	if (ecc_init_curve(_curve_used) != 0)
+		return -1;
+
+	for (i = 0; i < 18; i++)
+	{
+		crpt_regs->ECC_X1[i] = 0UL;
+		crpt_regs->ECC_Y1[i] = 0UL;
+		crpt_regs->ECC_K[i] = 0UL;
+	}
+	Hex2Reg(ecc_x1, crpt_regs->ECC_X1);
+	Hex2Reg(ecc_y1, crpt_regs->ECC_Y1);
+	Hex2Reg(ecc_k, crpt_regs->ECC_K);
+
+	/* set FSEL (Field selection) */
+	if (pCurve->GF == (int)CURVE_GF_2M)
+		crpt_regs->ECC_CTL = 0UL;
+	else
+		crpt_regs->ECC_CTL = CRPT_ECC_CTL_FSEL_Mask;  /*  CURVE_GF_P */
+
+	crpt_regs->ECC_CTL |= ((u32)pCurve->key_len << CRPT_ECC_CTL_CURVE_M_Pos) |
+					 ECCOP_POINT_MUL | CRPT_ECC_CTL_START_Mask;
+
+	t0 = jiffies;
+	while (crpt_regs->ECC_STS & CRPT_ECC_STS_BUSY_Mask) {
+		if (jiffies - t0 >= 100) {
+			printk("ECC mul time-out!\n");
+			return -1;
+		}
+	}
+	Reg2Hex(pCurve->Echar, crpt_regs->ECC_X1, ecc_x1);
+	Reg2Hex(pCurve->Echar, crpt_regs->ECC_Y1, ecc_y1);
+	return 0;
+}
+
+//int32_t  ECC_GeneratePublicKey(CRPT_T *crpt, E_ECC_CURVE ecc_curve, char *private_k, char public_k1[], char public_k2[])
+static int  ECC_GeneratePublicKey(void)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	volatile int32_t  i, t0;
+
+	if (ecc_init_curve(_curve_used) != 0)
+		return -1;
+
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_K[i] = 0UL;
+
+	Hex2Reg(ecc_d, crpt_regs->ECC_K);
+
+	/* set FSEL (Field selection) */
+	if (pCurve->GF == (int)CURVE_GF_2M)
+		crpt_regs->ECC_CTL = 0UL;
+	else  /*  CURVE_GF_P */
+		crpt_regs->ECC_CTL = CRPT_ECC_CTL_FSEL_Mask;
+
+	crpt_regs->ECC_CTL |= ((u32)pCurve->key_len << CRPT_ECC_CTL_CURVE_M_Pos) | ECCOP_POINT_MUL | CRPT_ECC_CTL_START_Mask;
+
+	t0 = jiffies;
+	while (crpt_regs->ECC_STS & CRPT_ECC_STS_BUSY_Mask) {
+		if (jiffies - t0 >= 100) {
+			printk("ECC gen key time-out!\n");
+			return -1;
+		}
+	}
+
+	Reg2Hex(pCurve->Echar, crpt_regs->ECC_X1, ecc_x1);
+	Reg2Hex(pCurve->Echar, crpt_regs->ECC_Y1, ecc_y1);
+	return 0;
+}
+
+
+//int32_t  ECC_GenerateSignature(CRPT_T *crpt, E_ECC_CURVE ecc_curve, char *message,
+//                               char *d, char *k, char *R, char *S)
+static int  ECC_GenerateSignature(void)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	volatile int32_t  i;
+	uint32_t volatile temp_result1[18], temp_result2[18];
+
+	if (ecc_init_curve(_curve_used) != 0)
+		return -1;
+
+	/*
+	 *   1. Calculate e = HASH(m), where HASH is a cryptographic hashing algorithm, (i.e. SHA-1)
+	 *      (1) Use SHA to calculate e
+	 */
+
+	/*   2. Select a random integer k form [1, n-1]
+	 *      (1) Notice that n is order, not prime modulus or irreducible polynomial function
+	 */
+
+	/*
+	 *   3. Compute r = x1 (mod n), where (x1, y1) = k * G. If r = 0, go to step 2
+	 *      (1) Write the curve parameter A, B, and curve length M to corresponding registers
+	 *      (2) Write the prime modulus or irreducible polynomial function to N registers according
+	 *      (3) Write the point G(x, y) to X1, Y1 registers
+	 *      (4) Write the random integer k to K register
+	 *      (5) Set ECCOP(CRPT_ECC_CTL[10:9]) to 00
+	 *      (6) Set FSEL(CRPT_ECC_CTL[8]) according to used curve of prime field or binary field
+	 *      (7) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (8) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (9) Write the curve order and curve length to N ,M registers according
+	 *      (10) Write 0x0 to Y1 registers
+	 *      (11) Set ECCOP(CRPT_ECC_CTL[10:9]) to 01
+	 *      (12) Set MOPOP(CRPT_ECC_CTL[12:11]) to 10
+	 *      (13) Set START(CRPT_ECC_CTL[0]) to 1         *
+	 *      (14) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (15) Read X1 registers to get r
+	 */
+
+	/* 3-(4) Write the random integer k to K register */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_K[i] = 0UL;
+
+	Hex2Reg(ecc_k, crpt_regs->ECC_K);
+
+	if (run_ecc_codec(ECCOP_POINT_MUL) != 0)
+		return -1;
+
+	/*  3-(9) Write the curve order to N registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_N[i] = 0UL;
+	Hex2Reg(pCurve->Eorder, crpt_regs->ECC_N);
+
+	/* 3-(10) Write 0x0 to Y1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_Y1[i] = 0UL;
+
+	if (run_ecc_codec(ECCOP_MODULE | MODOP_ADD) != 0)
+		return -1;
+
+	/* 3-(15) Read X1 registers to get r */
+	for (i = 0; i < 18; i++)
+		temp_result1[i] = crpt_regs->ECC_X1[i];
+
+	Reg2Hex(pCurve->Echar, temp_result1, ecc_r);
+
+	/*
+	 *   4. Compute s = k ? 1 \A1\D1 (e + d \A1\D1 r)(mod n). If s = 0, go to step 2
+	 *      (1) Write the curve order to N registers according
+	 *      (2) Write 0x1 to Y1 registers
+	 *      (3) Write the random integer k to X1 registers according
+	 *      (4) Set ECCOP(CRPT_ECC_CTL[10:9]) to 01
+	 *      (5) Set MOPOP(CRPT_ECC_CTL[12:11]) to 00
+	 *      (6) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (7) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (8) Read X1 registers to get k^-1
+	 *      (9) Write the curve order and curve length to N ,M registers
+	 *      (10) Write r, d to X1, Y1 registers
+	 *      (11) Set ECCOP(CRPT_ECC_CTL[10:9]) to 01
+	 *      (12) Set MOPOP(CRPT_ECC_CTL[12:11]) to 01
+	 *      (13) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (14) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (15) Write the curve order to N registers
+	 *      (16) Write e to Y1 registers
+	 *      (17) Set ECCOP(CRPT_ECC_CTL[10:9]) to 01
+	 *      (18) Set MOPOP(CRPT_ECC_CTL[12:11]) to 10
+	 *      (19) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (20) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (21) Write the curve order and curve length to N ,M registers
+	 *      (22) Write k^-1 to Y1 registers
+	 *      (23) Set ECCOP(CRPT_ECC_CTL[10:9]) to 01
+	 *      (24) Set MOPOP(CRPT_ECC_CTL[12:11]) to 01
+	 *      (25) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (26) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (27) Read X1 registers to get s
+	 */
+
+	/* S/W: GFp_add_mod_order(pCurve->key_len+2, 0, x1, a, R); */
+
+	/*  4-(1) Write the curve order to N registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_N[i] = 0UL;
+	Hex2Reg(pCurve->Eorder, crpt_regs->ECC_N);
+
+	/*  4-(2) Write 0x1 to Y1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_Y1[i] = 0UL;
+	crpt_regs->ECC_Y1[0] = 0x1UL;
+
+	/*  4-(3) Write the random integer k to X1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_X1[i] = 0UL;
+	Hex2Reg(ecc_k, crpt_regs->ECC_X1);
+
+	if (run_ecc_codec(ECCOP_MODULE | MODOP_DIV) != 0)
+		return -1;
+
+	/* debug print */
+	// Reg2Hex(pCurve->Echar, crpt->ECC_X1, temp_hex_str);
+	// CRPT_DBGMSG("(7) output = %s\n", temp_hex_str);
+
+	/*  4-(8) Read X1 registers to get k^-1 */
+
+	for (i = 0; i < 18; i++)
+		temp_result2[i] = crpt_regs->ECC_X1[i];
+
+	/* debug print */
+	// Reg2Hex(pCurve->Echar, temp_result2, temp_hex_str);
+	// CRPT_DBGMSG("k^-1 = %s\n", temp_hex_str);
+
+	/*  4-(9) Write the curve order and curve length to N ,M registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_N[i] = 0UL;
+	Hex2Reg(pCurve->Eorder, crpt_regs->ECC_N);
+
+	/*  4-(10) Write r, d to X1, Y1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_X1[i] = temp_result1[i];
+
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_Y1[i] = 0UL;
+
+	Hex2Reg(ecc_d, crpt_regs->ECC_Y1);
+
+	if (run_ecc_codec(ECCOP_MODULE | MODOP_MUL) != 0)
+		return -1;
+
+	/* debug print */
+	// Reg2Hex(pCurve->Echar, crpt->ECC_X1, temp_hex_str);
+	// printk("(14) output = %s\n", temp_hex_str);
+
+	/*  4-(15) Write the curve order to N registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_N[i] = 0UL;
+
+	Hex2Reg(pCurve->Eorder, crpt_regs->ECC_N);
+
+	/*  4-(16) Write e to Y1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_Y1[i] = 0UL;
+
+	Hex2Reg(ecc_msg, crpt_regs->ECC_Y1);
+
+	if (run_ecc_codec(ECCOP_MODULE | MODOP_ADD) != 0)
+		return -1;
+
+	/* debug print */
+	// Reg2Hex(pCurve->Echar, crpt->ECC_X1, temp_hex_str);
+	// CRPT_DBGMSG("(20) output = %s\n", temp_hex_str);
+
+	/*  4-(21) Write the curve order and curve length to N ,M registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_N[i] = 0UL;
+
+	Hex2Reg(pCurve->Eorder, crpt_regs->ECC_N);
+
+	/*  4-(22) Write k^-1 to Y1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_Y1[i] = temp_result2[i];
+
+	if (run_ecc_codec(ECCOP_MODULE | MODOP_MUL) != 0)
+		return -1;
+
+	/*  4-(27) Read X1 registers to get s */
+	for (i = 0; i < 18; i++)
+		temp_result2[i] = crpt_regs->ECC_X1[i];
+
+	Reg2Hex(pCurve->Echar, temp_result2, ecc_s);
+	return 0;
+}
+
+//int32_t  ECC_VerifySignature(CRPT_T *crpt, E_ECC_CURVE ecc_curve, char *message,
+//                             char *public_k1, char *public_k2, char *R, char *S)
+int  ECC_VerifySignature(void)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	uint32_t  temp_result1[18], temp_result2[18];
+	uint32_t  temp_x[18], temp_y[18];
+	int32_t   i;
+
+	/*
+	 *   1. Verify that r and s are integers in the interval [1, n-1]. If not, the signature is invalid
+	 *   2. Compute e = HASH (m), where HASH is the hashing algorithm in signature generation
+	 *      (1) Use SHA to calculate e
+	 */
+
+	/*
+	 *   3. Compute w = s^-1 (mod n)
+	 *      (1) Write the curve order to N registers
+	 *      (2) Write 0x1 to Y1 registers
+	 *      (3) Write s to X1 registers
+	 *      (4) Set ECCOP(CRPT_ECC_CTL[10:9]) to 01
+	 *      (5) Set MOPOP(CRPT_ECC_CTL[12:11]) to 00
+	 *      (6) Set FSEL(CRPT_ECC_CTL[8]) according to used curve of prime field or binary field
+	 *      (7) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (8) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (9) Read X1 registers to get w
+	 */
+
+	if (ecc_init_curve(_curve_used) != 0)
+		return -1;
+
+	/*  3-(1) Write the curve order to N registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_N[i] = 0UL;
+
+	Hex2Reg(pCurve->Eorder, crpt_regs->ECC_N);
+
+	/*  3-(2) Write 0x1 to Y1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_Y1[i] = 0UL;
+
+	crpt_regs->ECC_Y1[0] = 0x1UL;
+
+	/*  3-(3) Write s to X1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_X1[i] = 0UL;
+
+	Hex2Reg(ecc_s, crpt_regs->ECC_X1);
+
+	if (run_ecc_codec(ECCOP_MODULE | MODOP_DIV) != 0)
+		return -1;
+
+	/*  3-(9) Read X1 registers to get w */
+	for (i = 0; i < 18; i++)
+		temp_result2[i] = crpt_regs->ECC_X1[i];
+
+	/* debug print */
+	//CRPT_DBGMSG("e = %s\n", message);
+	//Reg2Hex(pCurve->Echar, temp_result2, temp_hex_str);
+	//CRPT_DBGMSG("w = %s\n", temp_hex_str);
+	//CRPT_DBGMSG("o = %s (order)\n", pCurve->Eorder);
+
+	/*
+	 *   4. Compute u1 = e \A1\D1 w (mod n) and u2 = r \A1\D1 w (mod n)
+	 *      (1) Write the curve order and curve length to N ,M registers
+	 *      (2) Write e, w to X1, Y1 registers
+	 *      (3) Set ECCOP(CRPT_ECC_CTL[10:9]) to 01
+	 *      (4) Set MOPOP(CRPT_ECC_CTL[12:11]) to 01
+	 *      (5) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (6) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (7) Read X1 registers to get u1
+	 *      (8) Write the curve order and curve length to N ,M registers
+	 *      (9) Write r, w to X1, Y1 registers
+	 *      (10) Set ECCOP(CRPT_ECC_CTL[10:9]) to 01
+	 *      (11) Set MOPOP(CRPT_ECC_CTL[12:11]) to 01
+	 *      (12) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (13) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (14) Read X1 registers to get u2
+	 */
+
+	/*  4-(1) Write the curve order and curve length to N ,M registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_N[i] = 0UL;
+
+	Hex2Reg(pCurve->Eorder, crpt_regs->ECC_N);
+
+	/* 4-(2) Write e, w to X1, Y1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_X1[i] = 0UL;
+
+	Hex2Reg(ecc_msg, crpt_regs->ECC_X1);
+
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_Y1[i] = temp_result2[i];
+
+	if (run_ecc_codec(ECCOP_MODULE | MODOP_MUL) != 0)
+		return -1;
+
+	/*  4-(7) Read X1 registers to get u1 */
+	for (i = 0; i < 18; i++)
+		temp_result1[i] = crpt_regs->ECC_X1[i];
+
+	/* debug print */
+	//Reg2Hex(pCurve->Echar, temp_result1, temp_hex_str);
+	//CRPT_DBGMSG("u1 = %s\n", temp_hex_str);
+
+	/*  4-(8) Write the curve order and curve length to N ,M registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_N[i] = 0UL;
+
+	Hex2Reg(pCurve->Eorder, crpt_regs->ECC_N);
+
+	/* 4-(9) Write r, w to X1, Y1 registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_X1[i] = 0UL;
+
+	Hex2Reg(ecc_r, crpt_regs->ECC_X1);
+
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_Y1[i] = temp_result2[i];
+
+	run_ecc_codec(ECCOP_MODULE | MODOP_MUL);
+
+	/*  4-(14) Read X1 registers to get u2 */
+	for (i = 0; i < 18; i++)
+		temp_result2[i] = crpt_regs->ECC_X1[i];
+
+	/* debug print */
+	//Reg2Hex(pCurve->Echar, temp_result2, temp_hex_str);
+	//CRPT_DBGMSG("u2 = %s\n", temp_hex_str);
+
+	/*
+	 *   5. Compute X\A1\A6 (x1\A1\A6, y1\A1\A6) = u1 * G + u2 * Q
+	 *      (1) Write the curve parameter A, B, N, and curve length M to corresponding registers
+	 *      (2) Write the point G(x, y) to X1, Y1 registers
+	 *      (3) Write u1 to K registers
+	 *      (4) Set ECCOP(CRPT_ECC_CTL[10:9]) to 00
+	 *      (5) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (6) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (7) Read X1, Y1 registers to get u1*G
+	 *      (8) Write the curve parameter A, B, N, and curve length M to corresponding registers
+	 *      (9) Write the public key Q(x,y) to X1, Y1 registers
+	 *      (10) Write u2 to K registers
+	 *      (11) Set ECCOP(CRPT_ECC_CTL[10:9]) to 00
+	 *      (12) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (13) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (14) Write the curve parameter A, B, N, and curve length M to corresponding registers
+	 *      (15) Write the result data u1*G to X2, Y2 registers
+	 *      (16) Set ECCOP(CRPT_ECC_CTL[10:9]) to 10
+	 *      (17) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (18) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (19) Read X1, Y1 registers to get X\A1\A6(x1\A1\A6, y1\A1\A6)
+	 *      (20) Write the curve order and curve length to N ,M registers
+	 *      (21) Write x1\A1\A6 to X1 registers
+	 *      (22) Write 0x0 to Y1 registers
+	 *      (23) Set ECCOP(CRPT_ECC_CTL[10:9]) to 01
+	 *      (24) Set MOPOP(CRPT_ECC_CTL[12:11]) to 10
+	 *      (25) Set START(CRPT_ECC_CTL[0]) to 1
+	 *      (26) Wait for BUSY(CRPT_ECC_STS[0]) be cleared
+	 *      (27) Read X1 registers to get x1\A1\A6 (mod n)
+	 *
+	 *   6. The signature is valid if x1\A1\A6 = r, otherwise it is invalid
+	 */
+
+	/*
+	 *  (1) Write the curve parameter A, B, N, and curve length M to corresponding registers
+	 *  (2) Write the point G(x, y) to X1, Y1 registers
+	 */
+	ecc_init_curve(_curve_used);
+
+	/* (3) Write u1 to K registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_K[i] = temp_result1[i];
+
+	if (run_ecc_codec(ECCOP_POINT_MUL) != 0)
+		return -1;
+
+	/* (7) Read X1, Y1 registers to get u1*G */
+	for (i = 0; i < 18; i++) {
+		temp_x[i] = crpt_regs->ECC_X1[i];
+		temp_y[i] = crpt_regs->ECC_Y1[i];
+	}
+
+	/* debug print */
+	//Reg2Hex(pCurve->Echar, temp_x, temp_hex_str);
+	//CRPT_DBGMSG("5-(7) u1*G, x = %s\n", temp_hex_str);
+	//Reg2Hex(pCurve->Echar, temp_y, temp_hex_str);
+	//CRPT_DBGMSG("5-(7) u1*G, y = %s\n", temp_hex_str);
+
+	/* (8) Write the curve parameter A, B, N, and curve length M to corresponding registers */
+	ecc_init_curve(_curve_used);
+
+	/* (9) Write the public key Q(x,y) to X1, Y1 registers */
+	for (i = 0; i < 18; i++) {
+		crpt_regs->ECC_X1[i] = 0UL;
+		crpt_regs->ECC_Y1[i] = 0UL;
+	}
+
+	Hex2Reg(ecc_x1, crpt_regs->ECC_X1);
+	Hex2Reg(ecc_y1, crpt_regs->ECC_Y1);
+
+	/* (10) Write u2 to K registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_K[i] = temp_result2[i];
+
+	if (run_ecc_codec(ECCOP_POINT_MUL) != 0)
+		return -1;
+
+	for (i = 0; i < 18; i++) {
+		temp_result1[i] = crpt_regs->ECC_X1[i];
+		temp_result2[i] = crpt_regs->ECC_Y1[i];
+	}
+
+	/* debug print */
+	//Reg2Hex(pCurve->Echar, temp_result1, temp_hex_str);
+	//CRPT_DBGMSG("5-(13) u2*Q, x = %s\n", temp_hex_str);
+	//Reg2Hex(pCurve->Echar, temp_result2, temp_hex_str);
+	//CRPT_DBGMSG("5-(13) u2*Q, y = %s\n", temp_hex_str);
+
+	/* (14) Write the curve parameter A, B, N, and curve length M to corresponding registers */
+	ecc_init_curve(_curve_used);
+
+	/* Write the result data u2*Q to X1, Y1 registers */
+	for (i = 0; i < 18; i++) {
+		crpt_regs->ECC_X1[i] = temp_result1[i];
+		crpt_regs->ECC_Y1[i] = temp_result2[i];
+	}
+
+	/* (15) Write the result data u1*G to X2, Y2 registers */
+	for (i = 0; i < 18; i++) {
+		crpt_regs->ECC_X2[i] = temp_x[i];
+		crpt_regs->ECC_Y2[i] = temp_y[i];
+	}
+
+	if (run_ecc_codec(ECCOP_POINT_ADD) != 0)
+		return -1;
+
+	/* (19) Read X1, Y1 registers to get X\A1\A6(x1\A1\A6, y1\A1\A6) */
+	for (i = 0; i < 18; i++) {
+		temp_x[i] = crpt_regs->ECC_X1[i];
+		temp_y[i] = crpt_regs->ECC_Y1[i];
+	}
+
+	/* debug print */
+	//Reg2Hex(pCurve->Echar, temp_x, temp_hex_str);
+	//CRPT_DBGMSG("5-(19) x' = %s\n", temp_hex_str);
+	//Reg2Hex(pCurve->Echar, temp_y, temp_hex_str);
+	//CRPT_DBGMSG("5-(19) y' = %s\n", temp_hex_str);
+
+	/*  (20) Write the curve order and curve length to N ,M registers */
+	for (i = 0; i < 18; i++)
+		crpt_regs->ECC_N[i] = 0UL;
+
+	Hex2Reg(pCurve->Eorder, crpt_regs->ECC_N);
+
+	/*
+	 *  (21) Write x1\A1\A6 to X1 registers
+	 *  (22) Write 0x0 to Y1 registers
+	 */
+	for (i = 0; i < 18; i++) {
+		crpt_regs->ECC_X1[i] = temp_x[i];
+		crpt_regs->ECC_Y1[i] = 0UL;
+	}
+
+	/* debug print */
+	//Reg2Hex(pCurve->Echar, crpt->ECC_X1, temp_hex_str);
+	//CRPT_DBGMSG("5-(21) x' = %s\n", temp_hex_str);
+	//Reg2Hex(pCurve->Echar, crpt->ECC_Y1, temp_hex_str);
+	//CRPT_DBGMSG("5-(22) y' = %s\n", temp_hex_str);
+
+	if (run_ecc_codec(ECCOP_MODULE | MODOP_ADD) != 0)
+		return -1;
+
+	/*  (27) Read X1 registers to get x1\A1\A6 (mod n) */
+	Reg2Hex(pCurve->Echar, crpt_regs->ECC_X1, temp_hex_str);
+	//printk("5-(27) x1' (mod n) = %s\n", temp_hex_str);
+
+	/* 6. The signature is valid if x1\A1\A6 = r, otherwise it is invalid */
+
+	/* Compare with test pattern to check if r is correct or not */
+	if (ecc_strcmp(temp_hex_str, ecc_r) != 0) {
+		printk("x1' (mod n) != R Test filed!!\n");
+		printk("Signature R [%s] is not matched with expected R [%s]!\n", temp_hex_str, ecc_r);
+		return -2;
+	}
+	return 0;
+}
+
+static long nvt_ecc_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	switch(cmd) {
+	case ECC_IOC_SEL_CURVE:
+		if (get_curve(arg) == NULL)
+			return -1;
+		_curve_used = arg;
+		if (ecc_init_curve(_curve_used) != 0)
+			return -1;
+		//printk("Select curve 0x%x\n", pCurve->curve_id);
+		break;
+
+	case ECC_IOC_SET_PRI_KEY:
+		memset(ecc_d, 0, sizeof(ecc_d));
+		copy_from_user(ecc_d, (char *)arg, pCurve->Echar);
+		break;
+
+	case ECC_IOC_SET_PUB_K1:
+		memset(ecc_x1, 0, sizeof(ecc_x1));
+		copy_from_user(ecc_x1, (char *)arg, pCurve->Echar);
+		break;
+
+	case ECC_IOC_SET_PUB_K2:
+		memset(ecc_y1, 0, sizeof(ecc_y1));
+		copy_from_user(ecc_y1, (char *)arg, pCurve->Echar);
+		break;
+
+	case ECC_IOC_SET_SCALAR_K:
+		memset(ecc_k, 0, sizeof(ecc_k));
+		copy_from_user(ecc_k, (char *)arg, pCurve->Echar);
+		break;
+
+	case ECC_IOC_SET_MSG:
+		memset(ecc_msg, 0, sizeof(ecc_msg));
+		copy_from_user(ecc_msg, (char *)arg, pCurve->Echar);
+		break;
+
+	case ECC_IOC_SET_SIG_R:
+		memset(ecc_r, 0, sizeof(ecc_r));
+		copy_from_user(ecc_r, (char *)arg, pCurve->Echar);
+		break;
+
+	case ECC_IOC_SET_SIG_S:
+		memset(ecc_s, 0, sizeof(ecc_s));
+		copy_from_user(ecc_s, (char *)arg, pCurve->Echar);
+		break;
+
+	case ECC_IOC_GET_PUB_K1:
+		copy_to_user((char *)arg, ecc_x1, pCurve->Echar);
+		break;
+
+	case ECC_IOC_GET_PUB_K2:
+		copy_to_user((char *)arg, ecc_y1, pCurve->Echar);
+		break;
+
+	case ECC_IOC_GET_SIG_R:
+		copy_to_user((char *)arg, ecc_r, pCurve->Echar);
+		break;
+
+	case ECC_IOC_GET_SIG_S:
+		copy_to_user((char *)arg, ecc_s, pCurve->Echar);
+		break;
+
+	case ECC_IOC_GEN_PUB_KEY:
+		return ECC_GeneratePublicKey();
+
+	case ECC_IOC_ECDSA_SIGN:
+		return ECC_GenerateSignature();
+
+	case ECC_IOC_ECDSA_VERIFY:
+		return ECC_VerifySignature();
+		
+	case ECC_IOC_POINT_MUL:
+		return ECC_Mutiply();
+
+	default:
+		return -ENOTTY;
+	}
+	return 0;
+}
+
+struct file_operations nvt_ecc_fops = {
+	.owner		= THIS_MODULE,
+	.unlocked_ioctl	= nvt_ecc_ioctl,
+};
+
+static struct miscdevice nvt_ecc_dev = {
+	.minor		= MISC_DYNAMIC_MINOR,
+	.name		= "nuvoton-ecc",
+	.fops		= &nvt_ecc_fops,
+};
+
+
+/*-----------------------------------------------------------------------------------------------*/
+/*                                                                                               */
+/*    RSA                                                                                        */
+/*                                                                                               */
+/*-----------------------------------------------------------------------------------------------*/
+
+#define RSA_MAX_KLEN      (2048)
+#define RSA_KBUF_HLEN     (RSA_MAX_KLEN/4 + 8)
+#define RSA_KBUF_BLEN     (RSA_MAX_KLEN + 32)
+
+static int   g_rsa_len = RSA_MAX_KLEN;
+static char  g_rsa_N[RSA_KBUF_HLEN];
+static char  g_rsa_E[RSA_KBUF_HLEN];
+static char  g_rsa_d[RSA_KBUF_HLEN];
+static char  g_rsa_C[RSA_KBUF_HLEN];
+static char  g_rsa_Msg[RSA_KBUF_HLEN];
+static char  g_rsa_Sig[RSA_KBUF_HLEN];
+
+/**
+  * @brief  RSA digital signature generation.
+  * @param[in]  rsa_len     RSA key length
+  * @param[in]  n           The modulus for both the public and private keys
+  * @param[in]  d           (n,d) is the private key
+  * @param[in]  C           The constant value of Montgomery domain.
+  * @param[in]  msg         The message to be signed.
+  * @param[out] sign        The output signature.
+  * @return  0     Success.
+  * @return  -1    Error
+  */
+int  RSA_GenerateSignature(int rsa_len, char *n, char *d, char *C, char *msg, char *sig)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	int  i;
+	
+	for (i = 0; i < 128; i++)
+	{
+		crpt_regs->RSA_N[i] = 0;
+		crpt_regs->RSA_E[i] = 0;
+		crpt_regs->RSA_M[i] = 0;
+	}
+	
+	Hex2Reg(n, (uint32_t *)&crpt_regs->RSA_N[0]);
+	Hex2Reg(d, (uint32_t *)&crpt_regs->RSA_E[0]);
+	Hex2Reg(msg, (uint32_t *)&crpt_regs->RSA_M[0]);
+	Hex2Reg(C, (uint32_t *)&crpt_regs->RSA_C[0]);
+	
+	crpt_regs->RSA_CTL = (rsa_len << CRPT_RSA_CTL_KEYLEN_Pos) | CRPT_RSA_CTL_START_Msk;
+	while (crpt_regs->RSA_STS & CRPT_RSA_STS_BUSY_Msk) ;
+
+	Reg2Hex(rsa_len/4, (uint32_t *)crpt_regs->RSA_M, sig);
+	return 0;
+}
+
+/**
+  * @brief  RSA digital signature generation.
+  * @param[in]  rsa_len     RSA key length
+  * @param[in]  n           The modulus for both the public and private keys
+  * @param[in]  e           (n,e) is the public key
+  * @param[in]  C           The constant value of Montgomery domain.
+  * @param[in]  sign        The signature to be verified.
+  * @param[out] msg         The message to be compared.
+  * @return  0     Success.
+  * @return  -1    Verify failed
+  */
+int RSA_VerifySignature(int rsa_len, char *n, char *e, char *C, char *sig, char *msg)
+{
+	volatile struct nuc980_crypto_regs  *crpt_regs = nuc980_crdev.regs;
+	char output[RSA_KBUF_HLEN];
+	int  i;
+	
+	for (i = 0; i < 128; i++)
+	{
+		crpt_regs->RSA_N[i] = 0;
+		crpt_regs->RSA_E[i] = 0;
+		crpt_regs->RSA_M[i] = 0;
+	}
+	
+	Hex2Reg(n, (uint32_t *)&crpt_regs->RSA_N[0]);
+	Hex2Reg(e, (uint32_t *)&crpt_regs->RSA_E[0]);
+	Hex2Reg(sig, (uint32_t *)&crpt_regs->RSA_M[0]);
+	Hex2Reg(C, (uint32_t *)&crpt_regs->RSA_C[0]);
+	
+	crpt_regs->RSA_CTL = (rsa_len << CRPT_RSA_CTL_KEYLEN_Pos) | CRPT_RSA_CTL_START_Msk;
+	while (crpt_regs->RSA_STS & CRPT_RSA_STS_BUSY_Msk) ;
+
+	Reg2Hex(rsa_len/4, (uint32_t *)crpt_regs->RSA_M, output);
+	
+	//printk("RSA verify: %s\n", output);
+	
+	if (ecc_strcmp(output, msg) != 0)
+	{
+		printk("RSA verify output [%s] is not matched with expected [%s]!\n", output, msg);
+		return -1;
+	}
+	return 0;
+}
+
+static long nvt_rsa_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	switch(cmd) {
+	case RSA_IOC_SET_BIT_LEN:
+		if (arg & 0xf) return -1;
+		if ((arg < 1024) || (arg > 2048)) return -1;
+		g_rsa_len = arg;
+		break;
+
+	case RSA_IOC_SET_N:
+		memset(g_rsa_N, 0, sizeof(g_rsa_N));
+		copy_from_user(g_rsa_N, (char *)arg, g_rsa_len/4);
+		break;
+
+	case RSA_IOC_SET_E:
+		memset(g_rsa_E, 0, sizeof(g_rsa_E));
+		copy_from_user(g_rsa_E, (char *)arg, g_rsa_len/4);
+		break;
+
+	case RSA_IOC_SET_D:
+		memset(g_rsa_d, 0, sizeof(g_rsa_d));
+		copy_from_user(g_rsa_d, (char *)arg, g_rsa_len/4);
+		break;
+
+	case RSA_IOC_SET_C:
+		memset(g_rsa_C, 0, sizeof(g_rsa_C));
+		copy_from_user(g_rsa_C, (char *)arg, g_rsa_len/4);
+		break;
+
+	case RSA_IOC_SET_MSG:
+		memset(g_rsa_Msg, 0, sizeof(g_rsa_Msg));
+		copy_from_user(g_rsa_Msg, (char *)arg, g_rsa_len/4);
+		break;
+
+	case RSA_IOC_SET_SIG:
+		memset(g_rsa_Sig, 0, sizeof(g_rsa_Sig));
+		copy_from_user(g_rsa_Sig, (char *)arg, g_rsa_len/4);
+		break;
+
+	case RSA_IOC_GET_MSG:
+		copy_to_user((char *)arg, g_rsa_Msg, g_rsa_len/4);
+		break;
+
+	case RSA_IOC_GET_SIG:
+		copy_to_user((char *)arg, g_rsa_Sig, g_rsa_len/4);
+		break;
+		
+	case RSA_IOC_DO_SIGN:
+		return RSA_GenerateSignature(g_rsa_len, g_rsa_N, g_rsa_d, g_rsa_C, g_rsa_Msg, g_rsa_Sig);
+
+	case RSA_IOC_DO_VERIFY:
+		return RSA_VerifySignature(g_rsa_len, g_rsa_N, g_rsa_E, g_rsa_C, g_rsa_Sig, g_rsa_Msg);
+
+	default:
+		return -ENOTTY;
+	}
+	return 0;
+}
+
+struct file_operations nvt_rsa_fops = {
+	.owner		= THIS_MODULE,
+	.unlocked_ioctl	= nvt_rsa_ioctl,
+};
+
+static struct miscdevice nvt_rsa_dev = {
+	.minor		= MISC_DYNAMIC_MINOR,
+	.name		= "nuvoton-rsa",
+	.fops		= &nvt_rsa_fops,
+};
+
+static int nuc980_crypto_raw_probe(struct platform_device *pdev)
+{
+	misc_register(&nvt_aes_dev);
+	misc_register(&nvt_sha_dev);
+	misc_register(&nvt_ecc_dev);
+	misc_register(&nvt_rsa_dev);
+	return 0;
+}
+
+static int nuc980_crypto_raw_remove(struct platform_device *pdev)
+{
+	misc_deregister(&nvt_aes_dev);
+	misc_deregister(&nvt_sha_dev);
+	misc_deregister(&nvt_ecc_dev);
+	misc_deregister(&nvt_rsa_dev);
+	return 0;
+}
+
+
+static const struct of_device_id nuc980_crypto_raw_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-crypto-raw" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_crypto_raw_of_match);
+
+
+static struct platform_driver nuc980_crypto_raw_driver = {
+	.probe      = nuc980_crypto_raw_probe,
+	.remove     = nuc980_crypto_raw_remove,
+	.driver     = {
+		.name   = "nuc980-crypto-raw",
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_crypto_raw_of_match),
+	},
+};
+
+module_platform_driver(nuc980_crypto_raw_driver);
+
+MODULE_AUTHOR("Nuvoton Technology Corporation");
+MODULE_DESCRIPTION("NUC980 Cryptographic Accerlerator Raw");
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/dma/Kconfig NUC980-linux-4.4.194/drivers/dma/Kconfig
--- linux-4.4.194/drivers/dma/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/dma/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -172,6 +172,21 @@ config EP93XX_DMA
 	help
 	  Enable support for the Cirrus Logic EP93xx M2P/M2M DMA controller.
 
+config NUC980_DMA
+        bool "NUC980 DMA support"
+        depends on ARCH_NUC980
+        select DMA_ENGINE
+        help
+          Enable support for the NUC980 M2M/M2P/P2M DMA controller.
+
+config NUC980_DMA_M2M
+        bool "M2M Demo Code"
+        depends on ARCH_NUC980
+	depends on NUC980_DMA
+        select DMA_ENGINE
+        help
+          Enable support for the NUC980 M2M DMA controller.
+
 config FSL_DMA
 	tristate "Freescale Elo series DMA support"
 	depends on FSL_SOC
diff -uprN linux-4.4.194/drivers/dma/Makefile NUC980-linux-4.4.194/drivers/dma/Makefile
--- linux-4.4.194/drivers/dma/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/dma/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -27,6 +27,22 @@ obj-$(CONFIG_DMA_SUN4I) += sun4i-dma.o
 obj-$(CONFIG_DMA_SUN6I) += sun6i-dma.o
 obj-$(CONFIG_DW_DMAC_CORE) += dw/
 obj-$(CONFIG_EP93XX_DMA) += ep93xx_dma.o
+obj-$(CONFIG_NUC980_DMA) += nuc980_dma.o
+obj-$(CONFIG_NUC980_DMA_UART1) += nuc980_dma_uart1.o
+obj-$(CONFIG_NUC980_DMA_UART2) += nuc980_dma_uart2.o
+obj-$(CONFIG_NUC980_DMA_UART3) += nuc980_dma_uart3.o
+obj-$(CONFIG_NUC980_DMA_UART4) += nuc980_dma_uart4.o
+obj-$(CONFIG_NUC980_DMA_UART5) += nuc980_dma_uart5.o
+obj-$(CONFIG_NUC980_DMA_UART6) += nuc980_dma_uart6.o
+obj-$(CONFIG_NUC980_DMA_UART7) += nuc980_dma_uart7.o
+obj-$(CONFIG_NUC980_DMA_UART8) += nuc980_dma_uart8.o
+obj-$(CONFIG_NUC980_DMA_UART9) += nuc980_dma_uart9.o
+obj-$(CONFIG_NUC980_DMA_M2M) += nuc980_dma_m2m.o
+#obj-$(CONFIG_NUC980_DMA) += nuc980_dma_cyclic_test.o
+obj-$(CONFIG_NUC980_DMA_QSPI0) += nuc980_dma_slave_qspi0.o
+obj-$(CONFIG_NUC980_DMA_SPI0) += nuc980_dma_slave_spi0.o
+obj-$(CONFIG_NUC980_DMA_SPI1) += nuc980_dma_slave_spi1.o
+obj-$(CONFIG_NUC980_I2C_PDMA) += nuc980_i2c_dma_test.o
 obj-$(CONFIG_FSL_DMA) += fsldma.o
 obj-$(CONFIG_FSL_EDMA) += fsl-edma.o
 obj-$(CONFIG_FSL_RAID) += fsl_raid.o
diff -uprN linux-4.4.194/drivers/dma/nuc980_dma.c NUC980-linux-4.4.194/drivers/dma/nuc980_dma.c
--- linux-4.4.194/drivers/dma/nuc980_dma.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/dma/nuc980_dma.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1664 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/clk.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/dmaengine.h>
+#include <linux/module.h>
+#include <linux/completion.h>
+#include <linux/kthread.h>
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+
+#include <linux/delay.h>
+#include <linux/slab.h>
+#include <linux/of.h>
+#include <linux/platform_data/dma-nuc980.h>
+#include <asm/irq.h>
+#include <mach/map.h>
+#include <mach/regs-pdma.h>
+#include <mach/regs-clock.h>
+#include <linux/platform_device.h>
+
+//-----------------------------------------------------------------------------------
+#define PDMA0               ((PDMA_T *)  NUC980_VA_PDMA0)
+#define PDMA1               ((PDMA_T *)  NUC980_VA_PDMA1)
+//-----------------------------------------------------------------------------------
+
+#include "dmaengine.h"
+
+#ifdef CONFIG_USE_OF
+extern struct nuc980_dma_platform_data nuc980_dma_data;
+#endif
+
+#if 0
+#define ENTRY()                 printk("[%-20s] : Enter...\n", __FUNCTION__)
+#define LEAVE()                 printk("[%-20s] : Leave...\n", __FUNCTION__)
+#else
+#define ENTRY()
+#define LEAVE()
+#endif
+
+#if 0
+#define DMA_DEBUG printk
+#define DMA_DEBUG2 printk
+#else
+#define DMA_DEBUG(fmt,args...)
+#define DMA_DEBUG2(fmt,args...)
+#endif
+
+
+#define DMA_MAX_CHAN_DESCRIPTORS    32
+#define DMA_MAX_CHAN_BYTES      0x10000
+
+struct nuc980_dma_engine;
+
+/**
+ * struct nuc980_dma_desc - NUC980 specific transaction descriptor
+ * @src_addr: source address of the transaction
+ * @dst_addr: destination address of the transaction
+ * @size: size of the transaction (in bytes)
+ * @complete: this descriptor is completed
+ * @txd: dmaengine API descriptor
+ * @tx_list: list of linked descriptors
+ * @node: link used for putting this into a channel queue
+ */
+struct nuc980_dma_desc {
+	u32             src_addr;
+	u32             dst_addr;
+	size_t              size;
+	u32                     ctl;
+	bool                    complete;
+	struct dma_async_tx_descriptor  txd;
+	struct list_head        tx_list;
+	struct list_head        node;
+	struct nuc980_dma_config config;
+	DSCT_T dsct[2];
+	u32 			dir;
+};
+
+/**
+ * struct nuc980_dma_chan - an NUC980 DMA M2M channel
+ * @chan: dmaengine API channel
+ * @edma: pointer to to the engine device
+ * @regs: memory mapped registers
+ * @irq: interrupt number of the channel
+ * @clk: clock used by this channel
+ * @tasklet: channel specific tasklet used for callbacks
+ * @lock: lock protecting the fields following
+ * @flags: flags for the channel
+ * @buffer: which buffer to use next (0/1)
+ * @active: flattened chain of descriptors currently being processed
+ * @queue: pending descriptors which are handled next
+ * @free_list: list of free descriptors which can be used
+ * @runtime_addr: physical address currently used as dest/src (M2M only). This
+ *                is set via %DMA_SLAVE_CONFIG before slave operation is
+ *                prepared
+ * @runtime_ctrl: M2M runtime values for the control register.
+ *
+ * As NUC980 DMA controller doesn't support real chained DMA descriptors we
+ * will have slightly different scheme here: @active points to a head of
+ * flattened DMA descriptor chain.
+ *
+ * @queue holds pending transactions. These are linked through the first
+ * descriptor in the chain. When a descriptor is moved to the @active queue,
+ * the first and chained descriptors are flattened into a single list.
+ *
+ * @chan.private holds pointer to &struct nuc980_dma_data which contains
+ * necessary channel configuration information. For memcpy channels this must
+ * be %NULL.
+ */
+struct nuc980_dma_chan {
+	struct dma_chan         chan;
+	const struct nuc980_dma_engine  *edma;
+	void __iomem            *regs;
+	int             irq;
+	u32             id;
+	struct tasklet_struct       tasklet;
+	struct tasklet_struct       tasklet_sc;
+	/* protects the fields following */
+	spinlock_t          lock;
+	spinlock_t      wklock;
+	unsigned long           flags;
+	/* Channel is configured for cyclic transfers */
+#define NUC980_DMA_IS_CYCLIC        0
+
+	int             buffer;
+	struct list_head        active;
+	struct list_head        queue;
+	struct list_head        free_list;
+	u32             runtime_addr;
+	u32             runtime_ctrl;
+};
+
+struct mutex pdma0_mutex; /* shared between the threads */
+struct mutex pdma1_mutex; /* shared between the threads */
+
+/**
+ * struct nuc980_dma_engine - the NUC980 DMA engine instance
+ * @dma_dev: holds the dmaengine device
+ * @hw_setup: method which sets the channel up for operation
+ * @hw_shutdown: shuts the channel down and flushes whatever is left
+ * @hw_submit: pushes active descriptor(s) to the hardware
+ * @hw_interrupt: handle the interrupt
+ * @num_channels: number of channels for this instance
+ * @channels: array of channels
+ *
+ * There is one instance of this struct for the M2M channels.
+ * hw_xxx() methods are used to perform operations which are
+ * different on M2M and M2P channels. These methods are called with channel
+ * lock held and interrupts disabled so they cannot sleep.
+ */
+struct nuc980_dma_engine {
+	struct dma_device   dma_dev;
+	bool          m2m;
+	int         (*hw_setup)(struct nuc980_dma_chan *);
+	void        (*hw_shutdown)(struct nuc980_dma_chan *);
+	void        (*hw_submit)(struct nuc980_dma_chan *);
+	int         (*hw_interrupt)(struct nuc980_dma_chan *);
+#define INTERRUPT_UNKNOWN   0
+#define INTERRUPT_DONE      1
+#define INTERRUPT_NEXT_BUFFER   2
+#define INTERRUPT_TIMEOUT         3
+
+	size_t          num_channels;
+	struct nuc980_dma_chan  channels[];
+};
+
+static inline struct device *chan2dev(struct nuc980_dma_chan *edmac) {
+	ENTRY();
+	return &edmac->chan.dev->device;
+}
+
+static struct nuc980_dma_chan *to_nuc980_dma_chan(struct dma_chan *chan) {
+	ENTRY();
+	return container_of(chan, struct nuc980_dma_chan, chan);
+}
+
+
+void nuc980_set_transfer_mode(PDMA_T * pdma,uint32_t u32Ch,uint32_t u32Peripheral)
+{
+
+	switch(u32Ch) {
+	case 0ul:
+		pdma->REQSEL0_3 = (pdma->REQSEL0_3 & ~PDMA_REQSEL0_3_REQSRC0_Msk) | u32Peripheral;
+		break;
+	case 1ul:
+		pdma->REQSEL0_3 = (pdma->REQSEL0_3 & ~PDMA_REQSEL0_3_REQSRC1_Msk) | (u32Peripheral << PDMA_REQSEL0_3_REQSRC1_Pos);
+		break;
+	case 2ul:
+		pdma->REQSEL0_3 = (pdma->REQSEL0_3 & ~PDMA_REQSEL0_3_REQSRC2_Msk) | (u32Peripheral << PDMA_REQSEL0_3_REQSRC2_Pos);
+		break;
+	case 3ul:
+		pdma->REQSEL0_3 = (pdma->REQSEL0_3 & ~PDMA_REQSEL0_3_REQSRC3_Msk) | (u32Peripheral << PDMA_REQSEL0_3_REQSRC3_Pos);
+		break;
+	case 4ul:
+		pdma->REQSEL4_7 = (pdma->REQSEL4_7 & ~PDMA_REQSEL4_7_REQSRC4_Msk) | u32Peripheral;
+		break;
+	case 5ul:
+		pdma->REQSEL4_7 = (pdma->REQSEL4_7 & ~PDMA_REQSEL4_7_REQSRC5_Msk) | (u32Peripheral << PDMA_REQSEL4_7_REQSRC5_Pos);
+		break;
+	case 6ul:
+		pdma->REQSEL4_7 = (pdma->REQSEL4_7 & ~PDMA_REQSEL4_7_REQSRC6_Msk) | (u32Peripheral << PDMA_REQSEL4_7_REQSRC6_Pos);
+		break;
+	case 7ul:
+		pdma->REQSEL4_7 = (pdma->REQSEL4_7 & ~PDMA_REQSEL4_7_REQSRC7_Msk) | (u32Peripheral << PDMA_REQSEL4_7_REQSRC7_Pos);
+		break;
+	case 8ul:
+		pdma->REQSEL8_11 = (pdma->REQSEL8_11 & ~PDMA_REQSEL8_11_REQSRC8_Msk) | u32Peripheral;
+		break;
+	case 9ul:
+		pdma->REQSEL8_11 = (pdma->REQSEL8_11 & ~PDMA_REQSEL8_11_REQSRC9_Msk) | (u32Peripheral << PDMA_REQSEL8_11_REQSRC9_Pos);
+		break;
+	case 10ul:
+		pdma->REQSEL8_11 = (pdma->REQSEL8_11 & ~PDMA_REQSEL8_11_REQSRC10_Msk) | (u32Peripheral << PDMA_REQSEL8_11_REQSRC10_Pos);
+		break;
+	case 11ul:
+		pdma->REQSEL8_11 = (pdma->REQSEL8_11 & ~PDMA_REQSEL8_11_REQSRC11_Msk) | (u32Peripheral << PDMA_REQSEL8_11_REQSRC11_Pos);
+		break;
+	case 12ul:
+		pdma->REQSEL12_15 = (pdma->REQSEL12_15 & ~PDMA_REQSEL12_15_REQSRC12_Msk) | u32Peripheral;
+		break;
+	case 13ul:
+		pdma->REQSEL12_15 = (pdma->REQSEL12_15 & ~PDMA_REQSEL12_15_REQSRC13_Msk) | (u32Peripheral << PDMA_REQSEL12_15_REQSRC13_Pos);
+		break;
+	case 14ul:
+		pdma->REQSEL12_15 = (pdma->REQSEL12_15 & ~PDMA_REQSEL12_15_REQSRC14_Msk) | (u32Peripheral << PDMA_REQSEL12_15_REQSRC14_Pos);
+		break;
+	case 15ul:
+		pdma->REQSEL12_15 = (pdma->REQSEL12_15 & ~PDMA_REQSEL12_15_REQSRC15_Msk) | (u32Peripheral << PDMA_REQSEL12_15_REQSRC15_Pos);
+		break;
+	default:
+		break;
+	}
+}
+
+/**
+ * nuc980_dma_set_active - set new active descriptor chain
+ * @edmac: channel
+ * @desc: head of the new active descriptor chain
+ *
+ * Sets @desc to be the head of the new active descriptor chain. This is the
+ * chain which is processed next. The active list must be empty before calling
+ * this function.
+ *
+ * Called with @edmac->lock held and interrupts disabled.
+ */
+static void nuc980_dma_set_active(struct nuc980_dma_chan *edmac,
+                                  struct nuc980_dma_desc *desc)
+{
+	ENTRY();
+	BUG_ON(!list_empty(&edmac->active));
+
+	list_add_tail(&desc->node, &edmac->active);
+
+	/* Flatten the @desc->tx_list chain into @edmac->active list */
+	while (!list_empty(&desc->tx_list)) {
+		struct nuc980_dma_desc *d = list_first_entry(&desc->tx_list,
+		                            struct nuc980_dma_desc, node);
+
+		/*
+		 * We copy the callback parameters from the first descriptor
+		 * to all the chained descriptors. This way we can call the
+		 * callback without having to find out the first descriptor in
+		 * the chain. Useful for cyclic transfers.
+		 */
+		d->txd.callback = desc->txd.callback;
+		d->txd.callback_param = desc->txd.callback_param;
+
+		list_move_tail(&d->node, &edmac->active);
+	}
+	LEAVE();
+}
+
+/* Called with @edmac->lock held and interrupts disabled */
+static struct nuc980_dma_desc *
+nuc980_dma_get_active(struct nuc980_dma_chan *edmac) {
+	DMA_DEBUG("NUC980 GDMA %s\n", __FUNCTION__ );
+	if (list_empty(&edmac->active))
+		return NULL;
+	return list_first_entry(&edmac->active, struct nuc980_dma_desc, node);
+}
+
+/**
+ * nuc980_dma_advance_active - advances to the next active descriptor
+ * @edmac: channel
+ *
+ * Function advances active descriptor to the next in the @edmac->active and
+ * returns %true if we still have descriptors in the chain to process.
+ * Otherwise returns %false.
+ *
+ * When the channel is in cyclic mode always returns %true.
+ *
+ * Called with @edmac->lock held and interrupts disabled.
+ */
+static bool nuc980_dma_advance_active(struct nuc980_dma_chan *edmac)
+{
+	struct nuc980_dma_desc *desc;
+	DMA_DEBUG("NUC980 GDMA %s\n", __FUNCTION__ );
+	list_rotate_left(&edmac->active);
+
+	if (test_bit(NUC980_DMA_IS_CYCLIC, &edmac->flags))
+		return true;
+
+	desc = nuc980_dma_get_active(edmac);
+	if (!desc)
+		return false;
+
+	/*
+	 * If txd.cookie is set it means that we are back in the first
+	 * descriptor in the chain and hence done with it.
+	 */
+	return !desc->txd.cookie;
+}
+
+/*
+ 000 = PDMA channel 1 time-out clock source is HCLK/(2^8).
+ 001 = PDMA channel 1 time-out clock source is HCLK/(2^9).
+ 010 = PDMA channel 1 time-out clock source is HCLK/(2^10).
+ 011 = PDMA channel 1 time-out clock source is HCLK/(2^11).
+ 100 = PDMA channel 1 time-out clock source is HCLK/(2^12).
+ 101 = PDMA channel 1 time-out clock source is HCLK/(2^13).
+ */
+void nuc980_dma_SetTimeOut(struct nuc980_dma_chan *edmac,u32 prescaler,u32 counter)
+{
+
+	struct nuc980_dma_desc *desc;
+	int ch;
+	PDMA_T * pdma;
+	ENTRY();
+	desc = nuc980_dma_get_active(edmac);
+	if (!desc) {
+		dev_warn(chan2dev(edmac), "PDMA: empty descriptor list\n");
+		return;
+	}
+
+	if(edmac->irq==IRQ_PDMA0) {
+		mutex_lock(&pdma0_mutex);
+		pdma=PDMA0;
+	} else {
+		mutex_lock(&pdma1_mutex);
+		pdma=PDMA1;
+	}
+	ch =edmac->id ;
+
+	if(prescaler ==0 && counter ==0) {
+		pdma->TOUTIEN &=~(1 << ch);
+		pdma->TOUTEN &=~(1 << ch);  /* Enable time-out funciton */
+
+		if(edmac->irq==IRQ_PDMA0)
+			mutex_unlock(&pdma0_mutex);
+		else
+			mutex_unlock(&pdma1_mutex);
+
+		return;
+	}
+
+	if(ch<=7) {
+		pdma->TOUTPSC &= ~(0x7 << (PDMA_TOUTPSC_TOUTPSC1_Pos * ch));
+		pdma->TOUTPSC |= ((prescaler&0x7) << (PDMA_TOUTPSC_TOUTPSC1_Pos * ch));
+	} else {
+		pdma->TOUTPSC2 &= ~(0x7 << (PDMA_TOUTPSC_TOUTPSC1_Pos * (ch-8)));
+		pdma->TOUTPSC2 |= ((prescaler&0x7) << (PDMA_TOUTPSC_TOUTPSC1_Pos * (ch-8)));
+	}
+
+	if(ch==0 || ch==1) {
+		pdma->TOC0_1 &= ~( (0xffff) << (PDMA_TOC0_1_TOC1_Pos * ch));
+		pdma->TOC0_1 |= ((counter&0xffff) << (PDMA_TOC0_1_TOC1_Pos * ch));
+	} else if(ch==2 || ch==3) {
+		pdma->TOC2_3 &= ~( (0xffff) << (PDMA_TOC0_1_TOC1_Pos * (ch-2)));
+		pdma->TOC2_3 |= ((counter&0xffff)<< (PDMA_TOC0_1_TOC1_Pos * (ch-2)));
+	} else if(ch==4 || ch==5) {
+		pdma->TOC4_5 &= ~( (0xffff) << (PDMA_TOC0_1_TOC1_Pos * (ch-4)));
+		pdma->TOC4_5 |= ((counter&0xffff) << (PDMA_TOC0_1_TOC1_Pos * (ch-4)));
+	} else if(ch==6 || ch==7) {
+		pdma->TOC6_7 &= ~( (0xffff) << (PDMA_TOC0_1_TOC1_Pos * (ch-6)));
+		pdma->TOC6_7 |= ((counter&0xffff) << (PDMA_TOC0_1_TOC1_Pos * (ch-6)));
+	} else if(ch==8 || ch==9) {
+		pdma->TOC8_9 &= ~( (0xffff) << (PDMA_TOC0_1_TOC1_Pos * (ch-8)));
+		pdma->TOC8_9 |= ((counter&0xffff) << (PDMA_TOC0_1_TOC1_Pos * (ch-8)));
+	}
+
+
+	pdma->TOUTEN |= (1 << ch);  /* Enable time-out funciton */
+	pdma->TOUTIEN |= (1 << ch); /* Enable time-out interrupt */
+	if(edmac->irq==IRQ_PDMA0)
+		mutex_unlock(&pdma0_mutex);
+	else
+		mutex_unlock(&pdma1_mutex);
+
+	LEAVE();
+}
+
+
+/*
+ * DMA implementation
+ */
+
+static int hw_setup(struct nuc980_dma_chan *edmac)
+{
+#if 0
+	const struct nuc980_dma_data *data = edmac->chan.private;
+	//u32 control = 0;
+	DMA_DEBUG("NUC980 GDMA %s\n", __FUNCTION__ );
+	if (!data) {
+		/* This is memcpy channel, nothing to configure */
+		return 0;
+	}
+
+	switch (data->port) {
+	case NUC980_DMA_MEM:
+		break;
+
+	default:
+		return -EINVAL;
+	}
+#endif
+	//writel(control, edmac->regs + M2M_CONTROL);
+	return 0;
+}
+
+static void hw_shutdown(struct nuc980_dma_chan *edmac)
+{
+	ENTRY();
+	/* Just disable the channel */
+
+	if(edmac->irq==IRQ_PDMA0) {
+		PDMA0->CHCTL &= ~(1<<edmac->id);
+	} else {
+		PDMA1->CHCTL &= ~(1<<edmac->id);
+	}
+	LEAVE();
+}
+
+static void fill_desc(struct nuc980_dma_chan *edmac)
+{
+	struct nuc980_dma_desc *desc;
+	u32 regT;
+	PDMA_T * pdma;
+	//u32 tcnt,config;
+
+	ENTRY();
+	desc = nuc980_dma_get_active(edmac);
+	if (!desc) {
+		dev_warn(chan2dev(edmac), "PDMA: empty descriptor list\n");
+		return;
+	}
+
+	DMA_DEBUG("edmac->runtime_ctrl=0x%08x\n",edmac->runtime_ctrl);
+	DMA_DEBUG("desc->ctl=0x%08x\n",desc->ctl);
+	if(edmac->irq==IRQ_PDMA0) {
+		mutex_lock(&pdma0_mutex);
+		DMA_DEBUG("PDMA0[%d] CTL=0x%08x\n",edmac->id,PDMA0->DSCT[edmac->id].CTL);
+		if((PDMA0->DSCT[edmac->id].CTL & 0x3)!=0) {
+			regT=PDMA0->CHCTL;
+			PDMA0->DSCT[edmac->id].CTL=0;
+			PDMA0->CHRST = (1<<edmac->id);
+			PDMA0->CHCTL = (regT | (1<<edmac->id));
+		} else {
+			PDMA0->DSCT[edmac->id].CTL=0;
+			PDMA0->CHCTL |= (1<<edmac->id);
+		}
+		PDMA0->INTEN |= (1<<edmac->id);
+		nuc980_set_transfer_mode(PDMA0,edmac->id,desc->config.reqsel);
+		mutex_unlock(&pdma0_mutex);
+		pdma = PDMA0;
+	} else {
+		mutex_lock(&pdma1_mutex);
+		DMA_DEBUG("PDMA1[%d] CTL=0x%08x\n",edmac->id,PDMA1->DSCT[edmac->id].CTL);
+		if((PDMA1->DSCT[edmac->id].CTL & 0x3)!=0) {
+			regT=PDMA1->CHCTL;
+			PDMA1->DSCT[edmac->id].CTL=0;
+			PDMA1->CHRST = (1<<edmac->id);
+			PDMA1->CHCTL = (regT | (1<<edmac->id));
+		} else {
+			PDMA1->DSCT[edmac->id].CTL=0;
+			PDMA1->CHCTL |= (1<<edmac->id);
+		}
+		PDMA1->INTEN |= (1<<edmac->id);
+		nuc980_set_transfer_mode(PDMA1,edmac->id,desc->config.reqsel);
+		mutex_unlock(&pdma1_mutex);
+		pdma = PDMA1;
+	}
+	pdma->DSCT[edmac->id].CTL |= (edmac->runtime_ctrl | ((desc->size - 1UL) << PDMA_DSCT_CTL_TXCNT_Pos));
+	pdma->DSCT[edmac->id].SA   = desc->src_addr;
+	pdma->DSCT[edmac->id].DA   = desc->dst_addr;
+
+	DMA_DEBUG2("===============pdma=============\n");
+	DMA_DEBUG2("(0x%08x)pdma->DSCT[%d].CTL=0x%08x\n",&pdma->DSCT[edmac->id].CTL,edmac->id,pdma->DSCT[edmac->id].CTL);
+	DMA_DEBUG2("(0x%08x)pdma->DSCT[%d].SA=0x%08x\n",&pdma->DSCT[edmac->id].SA,edmac->id,pdma->DSCT[edmac->id].SA);
+	DMA_DEBUG2("(0x%08x)pdma->DSCT[%d].DA=0x%08x\n",&pdma->DSCT[edmac->id].DA,edmac->id,pdma->DSCT[edmac->id].DA);
+	DMA_DEBUG2("(0x%08x)pdma->CHCTL=0x%08x\n",&pdma->CHCTL,pdma->CHCTL);
+	DMA_DEBUG2("(0x%08x)pdma->INTEN=0x%08x\n",&pdma->INTEN,pdma->INTEN);
+	DMA_DEBUG2("(0x%08x)pdma->INTSTS=0x%08x\n",&pdma->INTSTS,pdma->INTSTS);
+	DMA_DEBUG2("(0x%08x)pdma->TDSTS=0x%08x\n",&pdma->TDSTS,pdma->TDSTS);
+	DMA_DEBUG2("(0x%08x)pdma->REQSEL0_3=0x%08x\n",&pdma->REQSEL0_3,pdma->REQSEL0_3);
+	DMA_DEBUG2("===============================\n");
+	LEAVE();
+}
+
+static void fill_desc_sc(struct nuc980_dma_chan *edmac)
+{
+	struct nuc980_dma_desc *desc=NULL;
+	//DSCT_T *dsct=NULL;
+	u32 regT;
+	ENTRY();
+	desc = nuc980_dma_get_active(edmac);
+
+	if(edmac->irq==IRQ_PDMA0) {
+		mutex_lock(&pdma0_mutex);
+		DMA_DEBUG("SC PDMA0[%d] CTL=0x%08x\n",edmac->id,PDMA0->DSCT[edmac->id].CTL);
+		if((PDMA0->DSCT[edmac->id].CTL & 0x3)!=0) {
+			regT=PDMA0->CHCTL;
+			PDMA0->DSCT[edmac->id].CTL=0;
+			PDMA0->CHRST = (1<<edmac->id);
+			PDMA0->CHCTL = (regT | (1<<edmac->id));
+		} else {
+			PDMA0->DSCT[edmac->id].CTL=0;
+			PDMA0->CHCTL |= (1<<edmac->id);
+		}
+		nuc980_set_transfer_mode(PDMA0,edmac->id,desc->config.reqsel);
+		PDMA0->INTEN |= (1<<edmac->id);
+		mutex_unlock(&pdma0_mutex);
+	} else {
+		mutex_lock(&pdma1_mutex);
+		DMA_DEBUG("SC PDMA1[%d] CTL=0x%08x\n",edmac->id,PDMA1->DSCT[edmac->id].CTL);
+		if((PDMA1->DSCT[edmac->id].CTL & 0x3)!=0) {
+			regT=PDMA1->CHCTL;
+			PDMA1->DSCT[edmac->id].CTL=0;
+			PDMA1->CHRST = (1<<edmac->id);
+			PDMA1->CHCTL = (regT | (1<<edmac->id));
+		} else {
+			PDMA1->DSCT[edmac->id].CTL=0;
+			PDMA1->CHCTL |= (1<<edmac->id);
+		}
+		nuc980_set_transfer_mode(PDMA1,edmac->id,desc->config.reqsel);
+		PDMA1->INTEN |= (1<<edmac->id);
+		mutex_unlock(&pdma1_mutex);
+	}
+
+	if(desc->dir ==DMA_DEV_TO_MEM) {
+		desc->dsct[0].CTL =   (edmac->runtime_ctrl | (((desc->size/2) - 1UL) << PDMA_DSCT_CTL_TXCNT_Pos) | PDMA_OP_SCATTER);
+		desc->dsct[0].SA =  desc->src_addr;
+		desc->dsct[0].DA =  desc->dst_addr;
+		desc->dsct[0].NEXT =virt_to_phys(&desc->dsct[1].CTL);
+
+		desc->dsct[1].CTL =  (edmac->runtime_ctrl | (((desc->size/2) - 1UL) << PDMA_DSCT_CTL_TXCNT_Pos) | PDMA_OP_SCATTER);
+		desc->dsct[1].SA =  desc->src_addr;
+		desc->dsct[1].DA =  desc->dst_addr+(desc->size/2);
+		desc->dsct[1].NEXT = virt_to_phys(&desc->dsct[0].CTL);
+	} else if(desc->dir ==DMA_MEM_TO_DEV) {
+		desc->dsct[0].CTL =   (edmac->runtime_ctrl | (((desc->size/2) - 1UL) << PDMA_DSCT_CTL_TXCNT_Pos) | PDMA_OP_SCATTER);
+		desc->dsct[0].SA =  desc->src_addr;
+		desc->dsct[0].DA =  desc->dst_addr;
+		desc->dsct[0].NEXT =virt_to_phys(&desc->dsct[1].CTL);
+
+		desc->dsct[1].CTL =  (edmac->runtime_ctrl | (((desc->size/2) - 1UL) << PDMA_DSCT_CTL_TXCNT_Pos) | PDMA_OP_SCATTER);
+		desc->dsct[1].SA =  desc->src_addr+(desc->size/2);
+		desc->dsct[1].DA =  desc->dst_addr;
+		desc->dsct[1].NEXT = virt_to_phys(&desc->dsct[0].CTL);
+	}
+
+
+	//DMA_DEBUG2("===============pdma=============\n");
+	//DMA_DEBUG2("(0x%08x)desc->dsct[0].CTL=0x%08x\n",&desc->dsct[0].CTL,desc->dsct[0].CTL);
+	//DMA_DEBUG2("(0x%08x)desc->dsct[0].NEXT=0x%08x\n",&desc->dsct[0].NEXT,desc->dsct[0].NEXT);
+	//DMA_DEBUG2("(0x%08x)desc->dsct[1].CTL=0x%08x\n",&desc->dsct[1].CTL,desc->dsct[1].CTL);
+	//DMA_DEBUG2("(0x%08x)desc->dsct[1].NEXT=0x%08x\n",&desc->dsct[1].NEXT,desc->dsct[1].NEXT);
+	//DMA_DEBUG2("===============================\n");
+
+	LEAVE();
+
+}
+
+
+static void hw_submit(struct nuc980_dma_chan *edmac)
+{
+	struct nuc980_dma_desc *desc;
+	ENTRY();
+	desc = nuc980_dma_get_active(edmac);
+	/*
+	 * Since we allow clients to configure PW (peripheral width) we always
+	 * clear PW bits here and then set them according what is given in
+	 * the runtime configuration.
+	 */
+	if(desc->config.en_sc==0) {
+		fill_desc(edmac);
+		nuc980_dma_SetTimeOut(edmac,desc->config.timeout_prescaler,desc->config.timeout_counter);
+		if(edmac->irq==IRQ_PDMA0) {
+			PDMA0->DSCT[edmac->id].CTL = (PDMA0->DSCT[edmac->id].CTL & ~PDMA_DSCT_CTL_OPMODE_Msk) | PDMA_OP_BASIC;
+			if(desc->config.reqsel==0) {
+				PDMA0->SWREQ = 1<<(edmac->id);
+			}
+		} else {
+			PDMA1->DSCT[edmac->id].CTL = (PDMA1->DSCT[edmac->id].CTL & ~PDMA_DSCT_CTL_OPMODE_Msk) | PDMA_OP_BASIC;
+			if(desc->config.reqsel==0) {
+				PDMA1->SWREQ = 1<<(edmac->id);
+			}
+		}
+	} else {
+		fill_desc_sc(edmac);
+		nuc980_dma_SetTimeOut(edmac,desc->config.timeout_prescaler,desc->config.timeout_counter);
+		if(edmac->irq==IRQ_PDMA0) {
+			PDMA0->DSCT[edmac->id].NEXT = virt_to_phys(&desc->dsct[0].CTL);
+			PDMA0->DSCT[edmac->id].CTL = PDMA_OP_SCATTER;
+			if(desc->config.reqsel==0) {
+				PDMA0->SWREQ = 1<<(edmac->id);
+			}
+		} else {
+			PDMA1->DSCT[edmac->id].NEXT =  virt_to_phys(&desc->dsct[0].CTL);
+			PDMA1->DSCT[edmac->id].CTL = PDMA_OP_SCATTER;
+			if(desc->config.reqsel==0) {
+				PDMA1->SWREQ = 1<<(edmac->id);
+			}
+		}
+
+		{
+			PDMA_T * pdma;
+			if(edmac->irq==IRQ_PDMA0)
+				pdma=PDMA0;
+			else
+				pdma=PDMA1;
+
+			DMA_DEBUG2("===============pdma=============\n");
+			DMA_DEBUG2("(0x%08x)pdma->DSCT[%d].CTL=0x%08x\n",&pdma->DSCT[edmac->id].CTL,edmac->id,pdma->DSCT[edmac->id].CTL);
+			DMA_DEBUG2("(0x%08x)pdma->DSCT[%d].SA=0x%08x\n",&pdma->DSCT[edmac->id].SA,edmac->id,pdma->DSCT[edmac->id].SA);
+			DMA_DEBUG2("(0x%08x)pdma->DSCT[%d].DA=0x%08x\n",&pdma->DSCT[edmac->id].DA,edmac->id,pdma->DSCT[edmac->id].DA);
+			DMA_DEBUG2("(0x%08x)pdma->CHCTL=0x%08x\n",&pdma->CHCTL,pdma->CHCTL);
+			DMA_DEBUG2("(0x%08x)pdma->INTEN=0x%08x\n",&pdma->INTEN,pdma->INTEN);
+			DMA_DEBUG2("(0x%08x)pdma->INTSTS=0x%08x\n",&pdma->INTSTS,pdma->INTSTS);
+			DMA_DEBUG2("(0x%08x)pdma->TDSTS=0x%08x\n",&pdma->TDSTS,pdma->TDSTS);
+			DMA_DEBUG2("(0x%08x)pdma->REQSEL0_3=0x%08x\n",&pdma->REQSEL0_3,pdma->REQSEL0_3);
+			DMA_DEBUG2("===============================\n");
+		}
+	}
+
+	LEAVE();
+}
+
+/*
+ * According to NUC980 User's Guide, we should receive DONE interrupt when all
+ * M2M DMA controller transactions complete normally. This is not always the
+ * case - sometimes NUC980 M2M DMA asserts DONE interrupt when the DMA channel
+ * is still running (channel Buffer FSM in DMA_BUF_ON state, and channel
+ * Control FSM in DMA_MEM_RD state, observed at least in IDE-DMA operation).
+ * In effect, disabling the channel when only DONE bit is set could stop
+ * currently running DMA transfer. To avoid this, we use Buffer FSM and
+ * Control FSM to check current state of DMA channel.
+ */
+static int hw_interrupt(struct nuc980_dma_chan *edmac)
+{
+	bool last_done;
+	struct nuc980_dma_desc *desc;
+	ENTRY();
+	if(edmac->irq==IRQ_PDMA0) {
+		DMA_DEBUG("PDMA0->TDSTS=0x%08x,edmac->id=%d\n",PDMA0->TDSTS,edmac->id);
+		PDMA0->TDSTS = (1<<(edmac->id));
+	} else {
+		DMA_DEBUG("PDMA1->TDSTS=0x%08x,edmac->id=%d\n",PDMA1->TDSTS,edmac->id);
+		PDMA1->TDSTS = (1<<(edmac->id));
+	}
+
+	/*
+	 * Check whether we are done with descriptors or not. This, together
+	 * with DMA channel state, determines action to take in interrupt.
+	 */
+	desc = nuc980_dma_get_active(edmac);
+	last_done = !desc; //|| desc->txd.cookie;
+	DMA_DEBUG2("last_done=%d,desc=0x%08x,desc->txd.cookie=%d\n",last_done,(unsigned int)desc,desc->txd.cookie);
+	if(!last_done) {
+		if (nuc980_dma_advance_active(edmac)) {
+			DMA_DEBUG2("nuc980_dma_advance_active(edmac)!=NULL\n");
+			fill_desc(edmac);
+			if(edmac->irq==IRQ_PDMA0) {
+				PDMA0->DSCT[edmac->id].CTL = (PDMA0->DSCT[edmac->id].CTL & ~PDMA_DSCT_CTL_OPMODE_Msk) | PDMA_OP_BASIC;
+				if(desc->config.reqsel==0) {
+					PDMA0->SWREQ = 1<<(edmac->id);
+				}
+			} else {
+				PDMA1->DSCT[edmac->id].CTL = (PDMA1->DSCT[edmac->id].CTL & ~PDMA_DSCT_CTL_OPMODE_Msk) | PDMA_OP_BASIC;
+				if(desc->config.reqsel==0) {
+					PDMA1->SWREQ = 1<<(edmac->id);
+				}
+			}
+			return INTERRUPT_NEXT_BUFFER;
+		} else {
+			DMA_DEBUG2("nuc980_dma_advance_active(edmac)=NULL\n");
+			last_done = true;
+		}
+	}
+
+	if(last_done) {
+		return INTERRUPT_DONE;
+	}
+	LEAVE();
+	return INTERRUPT_NEXT_BUFFER;
+}
+
+/*
+ * DMA engine API implementation
+ */
+
+static struct nuc980_dma_desc *
+nuc980_dma_desc_get(struct nuc980_dma_chan *edmac) {
+	struct nuc980_dma_desc *desc, *_desc;
+	struct nuc980_dma_desc *ret = NULL;
+	ENTRY();
+	spin_lock(&edmac->lock);
+	list_for_each_entry_safe(desc, _desc, &edmac->free_list, node) {
+		if (async_tx_test_ack(&desc->txd)) {
+			list_del_init(&desc->node);
+
+			/* Re-initialize the descriptor */
+			desc->src_addr = 0;
+			desc->dst_addr = 0;
+			desc->size = 0;
+			desc->complete = false;
+			desc->txd.cookie = 0;
+			desc->txd.callback = NULL;
+			desc->txd.callback_param = NULL;
+
+			ret = desc;
+			break;
+		}
+	}
+	spin_unlock(&edmac->lock);
+	LEAVE();
+	return ret;
+}
+
+static void nuc980_dma_desc_put(struct nuc980_dma_chan *edmac,
+                                struct nuc980_dma_desc *desc)
+{
+	//ENTRY();
+	if (desc) {
+		spin_lock(&edmac->lock);
+		list_splice_init(&desc->tx_list, &edmac->free_list);
+		list_add(&desc->node, &edmac->free_list);
+		spin_unlock(&edmac->lock);
+	}
+}
+
+/**
+ * nuc980_dma_advance_work - start processing the next pending transaction
+ * @edmac: channel
+ *
+ * If we have pending transactions queued and we are currently idling, this
+ * function takes the next queued transaction from the @edmac->queue and
+ * pushes it to the hardware for execution.
+ */
+static void nuc980_dma_advance_work(struct nuc980_dma_chan *edmac)
+{
+	struct nuc980_dma_desc *new;
+	ENTRY();
+	spin_lock(&edmac->lock);
+	if (!list_empty(&edmac->active) || list_empty(&edmac->queue)) {
+		spin_unlock(&edmac->lock);
+		DMA_DEBUG2("nuc980_dma_advance_work  %d %d\n",list_empty(&edmac->active),list_empty(&edmac->queue));
+		return;
+	}
+
+	/* Take the next descriptor from the pending queue */
+	new = list_first_entry(&edmac->queue, struct nuc980_dma_desc, node);
+	list_del_init(&new->node);
+
+	nuc980_dma_set_active(edmac, new);
+	DMA_DEBUG2("hw_submit(edmac)\n");
+	/* Push it to the hardware */
+	edmac->edma->hw_submit(edmac);
+	spin_unlock(&edmac->lock);
+	LEAVE();
+}
+
+#if 0
+static void nuc980_dma_unmap_buffers(struct nuc980_dma_desc *desc)
+{
+	struct device *dev = desc->txd.chan->device->dev;
+	ENTRY();
+	if (!(desc->txd.flags & DMA_COMPL_SKIP_SRC_UNMAP)) {
+		if (desc->txd.flags & DMA_COMPL_SRC_UNMAP_SINGLE)
+			dma_unmap_single(dev, desc->src_addr, desc->size,
+			                 DMA_TO_DEVICE);
+		else
+			dma_unmap_page(dev, desc->src_addr, desc->size,
+			               DMA_TO_DEVICE);
+	}
+	if (!(desc->txd.flags & DMA_COMPL_SKIP_DEST_UNMAP)) {
+		if (desc->txd.flags & DMA_COMPL_DEST_UNMAP_SINGLE)
+			dma_unmap_single(dev, desc->dst_addr, desc->size,
+			                 DMA_FROM_DEVICE);
+		else
+			dma_unmap_page(dev, desc->dst_addr, desc->size,
+			               DMA_FROM_DEVICE);
+	}
+	LEAVE();
+}
+#endif
+
+static void nuc980_dma_sc_tasklet(unsigned long data)
+{
+	struct nuc980_dma_chan *edmac = (struct nuc980_dma_chan *)data;
+	struct nuc980_dma_desc *desc;
+	struct nuc980_dma_done * done=NULL;
+	dma_async_tx_callback callback = NULL;
+	void *callback_param = NULL;
+	ENTRY();
+	//spin_lock_irq(&edmac->lock);
+	desc = nuc980_dma_get_active(edmac);
+	DMA_DEBUG2("*desc=0x%08x\n",*desc);
+
+	desc->complete = true;
+	done =(struct nuc980_dma_done *)desc->txd.callback_param;
+	if(done!=NULL) {
+		done->ch = edmac->id;
+		if(desc->config.en_sc==1) {
+			if(done->base_addr!=1)
+				done->base_addr = 1;
+			else
+				done->base_addr = 2;
+		}
+		DMA_DEBUG("(0x%08x)pdma->DSCT[%d].CTL=0x%08x\n",&pdma->DSCT[edmac->id].CTL,edmac->id,pdma->DSCT[edmac->id].CTL);
+		DMA_DEBUG("(0x%08x)pdma->DSCT[%d].SA=0x%08x\n",&pdma->DSCT[edmac->id].SA,edmac->id,pdma->DSCT[edmac->id].SA);
+		DMA_DEBUG("(0x%08x)pdma->DSCT[%d].DA=0x%08x\n",&pdma->DSCT[edmac->id].DA,edmac->id,pdma->DSCT[edmac->id].DA);
+		DMA_DEBUG("(0x%08x)pdma->DSCT[%d].NEXT=0x%08x\n",&pdma->DSCT[edmac->id].NEXT,edmac->id,pdma->DSCT[edmac->id].NEXT);
+	}
+
+
+	if (desc) {
+		callback = desc->txd.callback;
+		callback_param = desc->txd.callback_param;
+	}
+	//spin_unlock_irq(&edmac->lock);
+	if (callback) {
+		callback(callback_param);
+	}
+	LEAVE();
+
+
+}
+
+static void nuc980_dma_tasklet(unsigned long data)
+{
+	struct nuc980_dma_chan *edmac = (struct nuc980_dma_chan *)data;
+	struct nuc980_dma_desc *desc, *d;
+	struct nuc980_dma_done * done=NULL;
+	dma_async_tx_callback callback = NULL;
+	void *callback_param = NULL;
+	LIST_HEAD(list);
+	ENTRY();
+	//spin_lock_irq(&edmac->lock);
+	/*
+	 * If dma_terminate_all() was called before we get to run, the active
+	 * list has become empty. If that happens we aren't supposed to do
+	 * anything more than call nuc980_dma_advance_work().
+	 */
+	desc = nuc980_dma_get_active(edmac);
+	desc->complete = true;
+	done =(struct nuc980_dma_done *)desc->txd.callback_param;
+	if(done!=NULL) {
+		done->ch = edmac->id;
+		if(desc->config.en_sc==1) {
+			if(done->base_addr!=1)
+				done->base_addr = 1;
+			else
+				done->base_addr = 2;
+		}
+		DMA_DEBUG("(0x%08x)pdma->DSCT[%d].CTL=0x%08x\n",&pdma->DSCT[edmac->id].CTL,edmac->id,pdma->DSCT[edmac->id].CTL);
+		DMA_DEBUG("(0x%08x)pdma->DSCT[%d].SA=0x%08x\n",&pdma->DSCT[edmac->id].SA,edmac->id,pdma->DSCT[edmac->id].SA);
+		DMA_DEBUG("(0x%08x)pdma->DSCT[%d].DA=0x%08x\n",&pdma->DSCT[edmac->id].DA,edmac->id,pdma->DSCT[edmac->id].DA);
+		DMA_DEBUG("(0x%08x)pdma->DSCT[%d].NEXT=0x%08x\n",&pdma->DSCT[edmac->id].NEXT,edmac->id,pdma->DSCT[edmac->id].NEXT);
+	}
+
+	DMA_DEBUG2("*desc=0x%08x\n",*desc);
+	if (desc) {
+		DMA_DEBUG2("desc->complete=%d\n",desc->complete);
+		if (desc->complete) {
+			/* mark descriptor complete for non cyclic case only */
+			if (!test_bit(NUC980_DMA_IS_CYCLIC, &edmac->flags))
+				dma_cookie_complete(&desc->txd);
+			DMA_DEBUG2("nuc980_dma_tasklet : ====>list_splice_init\n");
+			list_splice_init(&edmac->active, &list);
+		}
+		callback = desc->txd.callback;
+		callback_param = desc->txd.callback_param;
+	}
+
+	//spin_unlock_irq(&edmac->lock);
+
+	/* Pick up the next descriptor from the queue */
+	nuc980_dma_advance_work(edmac);
+
+	/* Now we can release all the chained descriptors */
+	list_for_each_entry_safe(desc, d, &list, node) {
+		/*
+		 * For the memcpy channels the API requires us to unmap the
+		 * buffers unless requested otherwise.
+		 */
+		desc->txd.flags = DMA_CTRL_ACK;
+		nuc980_dma_desc_put(edmac, desc);
+	}
+	if (callback) {
+		callback(callback_param);
+	}
+	LEAVE();
+}
+
+void nuc980_dma_emac_interrupt(struct nuc980_dma_chan *edmac,int status)
+{
+	struct nuc980_dma_desc *desc=NULL;
+	struct nuc980_dma_done * done=NULL;
+	ENTRY();
+	//spin_lock(&edmac->lock);
+	desc = nuc980_dma_get_active(edmac);
+	if (!desc) {
+		dev_warn(chan2dev(edmac),
+		         "got interrupt while active list is empty\n");
+		//spin_unlock(&edmac->lock);
+		LEAVE();
+		return;
+	}
+	if(status==INTERRUPT_TIMEOUT) {
+		done =(struct nuc980_dma_done *)desc->txd.callback_param;
+		if(done!=NULL) {
+			done->done = 0;
+			done->timeout=1;
+			if(edmac->irq==IRQ_PDMA0)
+				done->remain = (PDMA0->DSCT[edmac->id].CTL & PDMA_DSCT_CTL_TXCNT_Msk)>>PDMA_DSCT_CTL_TXCNT_Pos;
+			else
+				done->remain = (PDMA1->DSCT[edmac->id].CTL & PDMA_DSCT_CTL_TXCNT_Msk)>>PDMA_DSCT_CTL_TXCNT_Pos;
+		}
+		tasklet_schedule(&edmac->tasklet);
+		//spin_unlock(&edmac->lock);
+		return;
+	}
+
+
+	switch (edmac->edma->hw_interrupt(edmac)) {
+	case INTERRUPT_DONE: {
+		DMA_DEBUG2("INTERRUPT_DONE\n");
+		done =(struct nuc980_dma_done *)desc->txd.callback_param;
+		if(done!=NULL) {
+			done->done = 1;
+			done->timeout=0;
+			done->remain = 0;
+		}
+		if(desc->config.en_sc==0) {
+			tasklet_schedule(&edmac->tasklet);
+		} else {
+			tasklet_schedule(&edmac->tasklet_sc);
+		}
+	}
+	break;
+
+	case INTERRUPT_NEXT_BUFFER:
+		DMA_DEBUG2("INTERRUPT_NEXT_BUFFER\n");
+		if (test_bit(NUC980_DMA_IS_CYCLIC, &edmac->flags))
+			tasklet_schedule(&edmac->tasklet);
+		break;
+
+	default:
+		dev_warn(chan2dev(edmac), "unknown interrupt!\n");
+		break;
+	}
+	//spin_unlock(&edmac->lock);
+	LEAVE();
+}
+static irqreturn_t nuc980_dma_interrupt(int irq, void *dev_id)
+{
+	int i;
+	struct nuc980_dma_engine *edma= dev_id;
+	unsigned int pdma0_int_status = PDMA0->INTSTS;
+	unsigned int pdma1_int_status = PDMA1->INTSTS;
+	unsigned int pdma0_status = PDMA0->TDSTS;
+	unsigned int pdma1_status = PDMA1->TDSTS;
+
+	irqreturn_t ret = IRQ_HANDLED;
+	ENTRY();
+	DMA_DEBUG2("irqreturn_t\n");
+	DMA_DEBUG2("PDMA0->INTSTS=0x%08x,PDMA1->INTSTS=0x%08x\n",PDMA0->INTSTS,PDMA1->INTSTS);
+	DMA_DEBUG2("PDMA0->TDSTS=0x%08x,PDMA1->TDSTS=0x%08x\n",PDMA0->TDSTS,PDMA1->TDSTS);
+
+	for(i=(edma->num_channels-1); i>=0; i--) {
+		if((edma->channels[i].irq==IRQ_PDMA0) && (irq==IRQ_PDMA0)) {
+			if(pdma0_status & (1<<(edma->channels[i].id))) {
+				PDMA0->TDSTS = (1<<(edma->channels[i].id));
+				nuc980_dma_emac_interrupt(&edma->channels[i],INTERRUPT_DONE);
+				//break;
+			}
+
+			if(pdma0_int_status & (1<<(edma->channels[i].id+8))) {
+				DMA_DEBUG2("PDMA0 INTERRUPT_TIMEOUT id=%d",edma->channels[i].id);
+				nuc980_dma_emac_interrupt(&edma->channels[i],INTERRUPT_TIMEOUT);
+				PDMA0->TOUTEN &= ~(1<<(edma->channels[i].id));
+				//PDMA0->TOUTIEN  &= ~(1<<(edma->channels[i].id));
+				PDMA0->INTSTS = (1<<(edma->channels[i].id+8));
+				//break;
+			}
+
+		} else if((edma->channels[i].irq==IRQ_PDMA1) && (irq==IRQ_PDMA1)) {
+			if(pdma1_status & (1<<(edma->channels[i].id))) {
+				PDMA1->TDSTS = (1<<(edma->channels[i].id));
+				nuc980_dma_emac_interrupt(&edma->channels[i],INTERRUPT_DONE);
+				//break;
+			}
+			if(pdma1_int_status & (1<<(edma->channels[i].id+8))) {
+				DMA_DEBUG2("PDMA1 INTERRUPT_TIMEOUT id=%d",edma->channels[i].id);
+				nuc980_dma_emac_interrupt(&edma->channels[i],INTERRUPT_TIMEOUT);
+				PDMA1->TOUTEN &= ~(1<<(edma->channels[i].id));
+				//PDMA1->TOUTIEN  &= ~(1<<(edma->channels[i].id));
+				PDMA1->INTSTS = (1<<(edma->channels[i].id+8));
+				//break;
+			}
+
+		}
+	}
+	LEAVE();
+	return ret;
+}
+
+/**
+ * nuc980_dma_tx_submit - set the prepared descriptor(s) to be executed
+ * @tx: descriptor to be executed
+ *
+ * Function will execute given descriptor on the hardware or if the hardware
+ * is busy, queue the descriptor to be executed later on. Returns cookie which
+ * can be used to poll the status of the descriptor.
+ */
+static dma_cookie_t nuc980_dma_tx_submit(struct dma_async_tx_descriptor *tx)
+{
+	struct nuc980_dma_chan *edmac = to_nuc980_dma_chan(tx->chan);
+	struct nuc980_dma_desc *desc;
+	dma_cookie_t cookie;
+	ENTRY();
+	//spin_lock_irqsave(&edmac->lock, flags);
+	cookie = dma_cookie_assign(tx);
+
+	desc = container_of(tx, struct nuc980_dma_desc, txd);
+
+	/*
+	 * If nothing is currently prosessed, we push this descriptor
+	 * directly to the hardware. Otherwise we put the descriptor
+	 * to the pending queue.
+	 */
+	if (list_empty(&edmac->active)) {
+		nuc980_dma_set_active(edmac, desc);
+		edmac->edma->hw_submit(edmac);
+	} else {
+		list_add_tail(&desc->node, &edmac->queue);
+	}
+	//spin_unlock_irqrestore(&edmac->lock, flags);
+
+#if 0
+	if(edmac->irq==IRQ_PDMA0) {
+		DMA_DEBUG("(0x%08x)PDMA0->DSCT[%d].CTL=0x%08x\n",&PDMA0->DSCT[edmac->id].CTL,edmac->id,PDMA0->DSCT[edmac->id].CTL);
+		DMA_DEBUG("(0x%08x)PDMA0->DSCT[%d].SA=0x%08x\n",&PDMA0->DSCT[edmac->id].SA,edmac->id,PDMA0->DSCT[edmac->id].SA);
+		DMA_DEBUG("(0x%08x)PDMA0->DSCT[%d].DA=0x%08x\n",&PDMA0->DSCT[edmac->id].DA,edmac->id,PDMA0->DSCT[edmac->id].DA);
+		DMA_DEBUG("(0x%08x)PDMA0->CHCTL=0x%08x\n",&PDMA0->CHCTL,PDMA0->CHCTL);
+		DMA_DEBUG("(0x%08x)PDMA0->INTEN=0x%08x\n",&PDMA0->INTEN,PDMA0->INTEN);
+		DMA_DEBUG("(0x%08x)PDMA0->INTSTS=0x%08x\n",&PDMA0->INTSTS,PDMA0->INTSTS);
+		DMA_DEBUG("(0x%08x)PDMA0->TDSTS=0x%08x\n",&PDMA0->TDSTS,PDMA0->TDSTS);
+		DMA_DEBUG("(0x%08x)PDMA0->REQSEL0_3=0x%08x\n",&PDMA0->REQSEL0_3,PDMA0->REQSEL0_3);
+	} else {
+		DMA_DEBUG("(0x%08x)PDMA1->DSCT[%d].CTL=0x%08x\n",&PDMA1->DSCT[edmac->id].CTL,edmac->id,PDMA1->DSCT[edmac->id].CTL);
+		DMA_DEBUG("(0x%08x)PDMA1->DSCT[%d].SA=0x%08x\n",&PDMA1->DSCT[edmac->id].SA,edmac->id,PDMA1->DSCT[edmac->id].SA);
+		DMA_DEBUG("(0x%08x)PDMA1->DSCT[%d].DA=0x%08x\n",&PDMA1->DSCT[edmac->id].DA,edmac->id,PDMA1->DSCT[edmac->id].DA);
+		DMA_DEBUG("(0x%08x)PDMA1->CHCTL=0x%08x\n",&PDMA1->CHCTL,PDMA1->CHCTL);
+		DMA_DEBUG("(0x%08x)PDMA1->INTEN=0x%08x\n",&PDMA1->INTEN,PDMA1->INTEN);
+		DMA_DEBUG("(0x%08x)PDMA1->INTSTS=0x%08x\n",&PDMA1->INTSTS,PDMA1->INTSTS);
+		DMA_DEBUG("(0x%08x)PDMA1->TDSTS=0x%08x\n",&PDMA1->TDSTS,PDMA1->TDSTS);
+		DMA_DEBUG("(0x%08x)PDMA1->REQSEL0_3=0x%08x\n",&PDMA1->REQSEL0_3,PDMA1->REQSEL0_3);
+	}
+#endif
+
+	LEAVE();
+	return cookie;
+}
+
+/**
+ * nuc980_dma_alloc_chan_resources - allocate resources for the channel
+ * @chan: channel to allocate resources
+ *
+ * Function allocates necessary resources for the given DMA channel and
+ * returns number of allocated descriptors for the channel. Negative errno
+ * is returned in case of failure.
+ */
+static int nuc980_dma_alloc_chan_resources(struct dma_chan *chan)
+{
+	struct nuc980_dma_chan *edmac = to_nuc980_dma_chan(chan);
+	struct nuc980_dma_data *data = chan->private;
+	const char *name = dma_chan_name(chan);
+	int ret, i;
+	ENTRY();
+	DMA_DEBUG("name =%s\n", name);
+#if 0
+	/* Sanity check the channel parameters */
+	if (data) {
+		switch (data->port) {
+		case NUC980_DMA_MEM:
+			if (!is_slave_direction(data->direction))
+				return -EINVAL;
+			break;
+		default:
+			return -EINVAL;
+		}
+	}
+#endif
+
+	if (data && data->name)
+		name = data->name;
+
+	DMA_DEBUG("edmac->irq =%d\n", edmac->irq);
+
+	spin_lock_irq(&edmac->lock);
+	dma_cookie_init(&edmac->chan);
+	ret = edmac->edma->hw_setup(edmac);
+	spin_unlock_irq(&edmac->lock);
+
+	if (ret)
+		return ret;
+
+	for (i = 0; i < DMA_MAX_CHAN_DESCRIPTORS; i++) {
+		struct nuc980_dma_desc *desc;
+
+		desc = kzalloc(sizeof(*desc), GFP_KERNEL);
+		if (!desc) {
+			dev_warn(chan2dev(edmac), "not enough descriptors\n");
+			break;
+		}
+		INIT_LIST_HEAD(&desc->tx_list);
+		dma_async_tx_descriptor_init(&desc->txd, chan);
+		desc->txd.flags = DMA_CTRL_ACK;
+		desc->txd.tx_submit = nuc980_dma_tx_submit;
+		nuc980_dma_desc_put(edmac, desc);
+	}
+	DMA_DEBUG("return %d\n",i);
+	LEAVE();
+	return i;
+
+}
+
+/**
+ * nuc980_dma_free_chan_resources - release resources for the channel
+ * @chan: channel
+ *
+ * Function releases all the resources allocated for the given channel.
+ * The channel must be idle when this is called.
+ */
+static void nuc980_dma_free_chan_resources(struct dma_chan *chan)
+{
+	struct nuc980_dma_chan *edmac = to_nuc980_dma_chan(chan);
+	struct nuc980_dma_desc *desc, *d;
+	LIST_HEAD(list);
+	ENTRY();
+	//BUG_ON(!list_empty(&edmac->active));
+	BUG_ON(!list_empty(&edmac->queue));
+	spin_lock(&edmac->lock);
+	edmac->edma->hw_shutdown(edmac);
+	edmac->runtime_addr = 0;
+	edmac->runtime_ctrl = 0;
+	list_splice_init(&edmac->free_list, &list);
+	spin_unlock(&edmac->lock);
+	list_for_each_entry_safe(desc, d, &list, node)
+	kfree(desc);
+	LEAVE();
+}
+
+/**
+ * nuc980_dma_prep_dma_memcpy - prepare a memcpy DMA operation
+ * @chan: channel
+ * @dest: destination bus address
+ * @src: source bus address
+ * @len: size of the transaction
+ * @flags: flags for the descriptor
+ *
+ * Returns a valid DMA descriptor or %NULL in case of failure.
+ */
+static struct dma_async_tx_descriptor *
+nuc980_dma_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest,
+                           dma_addr_t src, size_t len, unsigned long flags) {
+	struct nuc980_dma_chan *edmac = to_nuc980_dma_chan(chan);
+	struct nuc980_dma_desc *desc, *first;
+	size_t bytes, offset;
+	ENTRY();
+	first = NULL;
+	for (offset = 0; offset < len; offset += bytes) {
+		desc = nuc980_dma_desc_get(edmac);
+		if (!desc) {
+			dev_warn(chan2dev(edmac), "couln't get descriptor\n");
+			goto fail;
+		}
+
+		bytes = min_t(size_t, len - offset, DMA_MAX_CHAN_BYTES);
+
+		desc->src_addr = src + offset;
+		desc->dst_addr = dest + offset;
+		desc->size = bytes;
+		desc->config.reqsel = 0;
+		desc->config.timeout_counter=0;
+		desc->config.timeout_prescaler=0;
+		desc->config.en_sc = 0;
+		desc->dir = DMA_MEM_TO_MEM;
+		edmac->runtime_ctrl = 0;
+		DMA_DEBUG("src_addr=0x%08x\n",desc->src_addr);
+		DMA_DEBUG("dst_addr=0x%08x\n",desc->dst_addr);
+		DMA_DEBUG("size=0x%08x\n",desc->size);
+		DMA_DEBUG("offset=0x%08x\n",offset);
+		if (!first)
+			first = desc;
+		else
+			list_add_tail(&desc->node, &first->tx_list);
+	}
+
+	first->txd.cookie = -EBUSY;
+	first->txd.flags = flags;
+	LEAVE();
+
+	return &first->txd;
+fail:
+	DMA_DEBUG("%s fail =>\n", __FUNCTION__);
+	nuc980_dma_desc_put(edmac, first);
+	LEAVE();
+	return NULL;
+}
+
+/**
+ * nuc980_dma_prep_slave_sg - prepare a slave DMA operation
+ * @chan: channel
+ * @sgl: list of buffers to transfer
+ * @sg_len: number of entries in @sgl
+ * @dir: direction of tha DMA transfer
+ * @flags: flags for the descriptor
+ * @context: operation context (ignored)
+ *
+ * Returns a valid DMA descriptor or %NULL in case of failure.
+ */
+static struct dma_async_tx_descriptor *
+nuc980_dma_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,
+                         unsigned int sg_len, enum dma_transfer_direction dir,
+                         unsigned long flags, void *context) {
+	struct nuc980_dma_chan *edmac = to_nuc980_dma_chan(chan);
+	struct nuc980_dma_desc *desc, *first;
+	struct scatterlist *sg;
+	struct nuc980_dma_config *config;
+	int i;
+	ENTRY();
+
+	{
+		struct nuc980_dma_desc *d;
+		LIST_HEAD(list);
+		list_splice_init(&edmac->active, &list);
+		/* Now we can release all the chained descriptors */
+		list_for_each_entry_safe(desc, d, &list, node) {
+			desc->txd.flags = DMA_CTRL_ACK;
+			nuc980_dma_desc_put(edmac, desc);
+		}
+	}
+	config =(struct nuc980_dma_config *)context;
+
+
+
+	if (test_bit(NUC980_DMA_IS_CYCLIC, &edmac->flags)) {
+		dev_warn(chan2dev(edmac),
+		         "channel is already used for cyclic transfers\n");
+		return NULL;
+	}
+
+	first = NULL;
+	for_each_sg(sgl, sg, sg_len, i) {
+		if (sg_dma_len(sg) > DMA_MAX_CHAN_BYTES) {
+			dev_warn(chan2dev(edmac), "too big transfer size %d\n",
+			         sg_dma_len(sg));
+			goto fail;
+		}
+
+		desc = nuc980_dma_desc_get(edmac);
+		if (!desc) {
+			dev_warn(chan2dev(edmac), "couln't get descriptor\n");
+			goto fail;
+		}
+
+		if (dir == DMA_MEM_TO_DEV) {
+			desc->src_addr = sg_dma_address(sg);
+			desc->dst_addr = edmac->runtime_addr;
+			desc->dir = DMA_MEM_TO_DEV;
+		} else {
+			desc->src_addr = edmac->runtime_addr;
+			desc->dst_addr = sg_dma_address(sg);
+			desc->dir = DMA_DEV_TO_MEM;
+		}
+		desc->size = sg_dma_len(sg);
+		desc->config.reqsel= config->reqsel;
+		desc->config.timeout_counter=config->timeout_counter;
+		desc->config.timeout_prescaler=config->timeout_prescaler;
+		desc->config.en_sc = config->en_sc;
+#if 1
+		DMA_DEBUG("desc->src_addr=%x\n",desc->src_addr);
+		DMA_DEBUG("desc->dst_addr=%x\n",desc->dst_addr);
+		DMA_DEBUG("desc->size=%x\n",desc->size);
+		DMA_DEBUG("*context=%x\n",*(u32 *)context);
+#endif
+
+		if (!first)
+			first = desc;
+		else
+			list_add_tail(&desc->node, &first->tx_list);
+	}
+
+	first->txd.cookie = -EBUSY;
+	first->txd.flags = flags;
+	LEAVE();
+	return &first->txd;
+
+fail:
+	DMA_DEBUG("%s fail =>\n", __FUNCTION__);
+	nuc980_dma_desc_put(edmac, first);
+	LEAVE();
+	return NULL;
+}
+
+/**
+ * nuc980_dma_prep_dma_cyclic - prepare a cyclic DMA operation
+ * @chan: channel
+ * @dma_addr: DMA mapped address of the buffer
+ * @buf_len: length of the buffer (in bytes)
+ * @period_len: length of a single period
+ * @dir: direction of the operation
+ * @flags: tx descriptor status flags
+ * @context: operation context (ignored)
+ *
+ * Prepares a descriptor for cyclic DMA operation. This means that once the
+ * descriptor is submitted, we will be submitting in a @period_len sized
+ * buffers and calling callback once the period has been elapsed. Transfer
+ * terminates only when client calls dmaengine_terminate_all() for this
+ * channel.
+ *
+ * Returns a valid DMA descriptor or %NULL in case of failure.
+ */
+static struct dma_async_tx_descriptor *
+nuc980_dma_prep_dma_cyclic(struct dma_chan *chan, dma_addr_t dma_addr,
+                           size_t buf_len, size_t period_len,
+                           enum dma_transfer_direction dir, unsigned long flags) {
+	struct nuc980_dma_chan *edmac = to_nuc980_dma_chan(chan);
+	struct nuc980_dma_desc *desc, *first;
+	size_t offset = 0;
+	ENTRY();
+#if 0
+	if (dir != nuc980_dma_chan_direction(chan)) {
+		dev_warn(chan2dev(edmac),
+		         "channel was configured with different direction\n");
+		return NULL;
+	}
+#endif
+	if (test_and_set_bit(NUC980_DMA_IS_CYCLIC, &edmac->flags)) {
+		dev_warn(chan2dev(edmac),
+		         "channel is already used for cyclic transfers\n");
+		return NULL;
+	}
+
+	if (period_len > DMA_MAX_CHAN_BYTES) {
+		dev_warn(chan2dev(edmac), "too big period length %d\n",
+		         period_len);
+		return NULL;
+	}
+
+	/* Split the buffer into period size chunks */
+	first = NULL;
+	for (offset = 0; offset < buf_len; offset += period_len) {
+		desc = nuc980_dma_desc_get(edmac);
+		if (!desc) {
+			dev_warn(chan2dev(edmac), "couln't get descriptor\n");
+			goto fail;
+		}
+
+		desc->size = period_len;
+
+		if (!first)
+			first = desc;
+		else
+			list_add_tail(&desc->node, &first->tx_list);
+	}
+
+	first->txd.cookie = -EBUSY;
+	LEAVE();
+	return &first->txd;
+
+fail:
+	nuc980_dma_desc_put(edmac, first);
+	LEAVE();
+	return NULL;
+}
+
+static int nuc980_dma_slave_config(struct dma_chan *chan,
+                                   struct dma_slave_config *config)
+{
+	struct nuc980_dma_chan *edmac = to_nuc980_dma_chan(chan);
+	enum dma_slave_buswidth width;
+	u32 addr, ctrl;
+
+	ENTRY();
+
+	switch (config->direction) {
+	case DMA_DEV_TO_MEM:
+		ctrl    = PDMA_DSCT_CTL_SAINC_Msk|PDMA_DSCT_CTL_TXTYPE_Msk;
+		width = config->src_addr_width;
+		addr    = config->src_addr;
+		break;
+
+	case DMA_MEM_TO_DEV:
+		ctrl    = PDMA_DSCT_CTL_DAINC_Msk|PDMA_DSCT_CTL_TXTYPE_Msk;
+		width = config->dst_addr_width;
+		addr    = config->dst_addr;
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+
+	switch (width) {
+	case DMA_SLAVE_BUSWIDTH_1_BYTE:
+		ctrl |= 0<<PDMA_DSCT_CTL_TXWIDTH_Pos;
+		break;
+	case DMA_SLAVE_BUSWIDTH_2_BYTES:
+		ctrl |= 1<<PDMA_DSCT_CTL_TXWIDTH_Pos;
+		break;
+	case DMA_SLAVE_BUSWIDTH_4_BYTES:
+		ctrl |= 2<<PDMA_DSCT_CTL_TXWIDTH_Pos;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	//spin_lock_irqsave(&edmac->lock, flags);
+	edmac->runtime_addr = addr;
+	edmac->runtime_ctrl = ctrl;
+	//spin_unlock_irqrestore(&edmac->lock, flags);
+
+	LEAVE();
+	return 0;
+}
+
+/**
+ * nuc980_dma_tx_status - check if a transaction is completed
+ * @chan: channel
+ * @cookie: transaction specific cookie
+ * @state: state of the transaction is stored here if given
+ *
+ * This function can be used to query state of a given transaction.
+ */
+static enum dma_status nuc980_dma_tx_status(struct dma_chan *chan,
+                dma_cookie_t cookie,
+                struct dma_tx_state *state)
+{
+	struct nuc980_dma_chan *edmac = to_nuc980_dma_chan(chan);
+	enum dma_status ret;
+
+	spin_lock(&edmac->lock);
+	ret = dma_cookie_status(chan, cookie, state);
+	spin_unlock(&edmac->lock);
+	return ret;
+}
+
+/**
+ * nuc980_dma_issue_pending - push pending transactions to the hardware
+ * @chan: channel
+ *
+ * When this function is called, all pending transactions are pushed to the
+ * hardware and executed.
+ */
+static void nuc980_dma_issue_pending(struct dma_chan *chan)
+{
+	ENTRY();
+	nuc980_dma_advance_work(to_nuc980_dma_chan(chan));
+	LEAVE();
+}
+
+
+static int nuc980_dma_probe(struct platform_device *pdev)
+{
+	struct nuc980_dma_platform_data *pdata;
+	struct nuc980_dma_engine *edma;
+	struct dma_device *dma_dev;
+	size_t edma_size;
+	struct clk *clk;
+	int ret, i;
+	ENTRY();
+#ifdef CONFIG_USE_OF
+	platform_device_add_data(pdev, &nuc980_dma_data,sizeof(nuc980_dma_data));
+#endif
+	printk("%s - pdev = %s\n", __func__, pdev->name);
+	pdata = dev_get_platdata(&pdev->dev);
+	edma_size = pdata->num_channels * sizeof(struct nuc980_dma_chan);
+	edma = kzalloc(sizeof(*edma) + edma_size, GFP_KERNEL);
+
+	if (!edma) {
+		DMA_DEBUG("NUC980 GDMA -ENOMEM\n");
+		return -ENOMEM;
+	}
+	DMA_DEBUG("NUC980 GDMA !!!\n");
+
+	/* enable pdma0/pdma1 clock */
+	clk = clk_get(NULL, "pdma0_hclk");
+	if (IS_ERR(clk)) {
+		dev_err(&pdev->dev, "cannot get clock\n");
+		return -ENOENT;
+	}
+	dev_dbg(&pdev->dev, "clock source %p\n", clk);
+	clk_prepare(clk);
+	clk_enable(clk);
+
+	clk = clk_get(NULL, "pdma1_hclk");
+	if (IS_ERR(clk)) {
+		dev_err(&pdev->dev, "cannot get clock\n");
+		return -ENOENT;
+	}
+	dev_dbg(&pdev->dev, "clock source %p\n", clk);
+	clk_prepare(clk);
+	clk_enable(clk);
+
+
+	dma_dev = &edma->dma_dev;
+	edma->num_channels = pdata->num_channels;
+
+	INIT_LIST_HEAD(&dma_dev->channels);
+	for (i = 0; i < pdata->num_channels; i++) {
+		const struct nuc980_dma_chan_data *cdata = &pdata->channels[i];
+		struct nuc980_dma_chan *edmac = &edma->channels[i];
+		DMA_DEBUG("ch=%d\n",i);
+		edmac->chan.device = dma_dev;
+		edmac->chan.private = 0;
+		edmac->regs = cdata->base;
+		edmac->irq = cdata->irq;
+		edmac->edma = edma;
+		edmac->id = (((unsigned int)(edmac->regs)&0xF0)>>4);
+		spin_lock_init(&edmac->lock);
+		spin_lock_init(&edmac->wklock);
+		INIT_LIST_HEAD(&edmac->active);
+		INIT_LIST_HEAD(&edmac->queue);
+		INIT_LIST_HEAD(&edmac->free_list);
+		tasklet_init(&edmac->tasklet, nuc980_dma_tasklet,
+		             (unsigned long)edmac);
+		tasklet_init(&edmac->tasklet_sc, nuc980_dma_sc_tasklet,
+		             (unsigned long)edmac);
+
+		list_add_tail(&edmac->chan.device_node,
+		              &dma_dev->channels);
+	}
+
+	ret = request_irq(IRQ_PDMA0, nuc980_dma_interrupt, IRQF_SHARED, "PDMA0", edma);
+	if (ret) {
+		printk("request irq(IRQ_PDMA0) fialed\n");
+		return ret;
+	}
+	ret = request_irq(IRQ_PDMA1, nuc980_dma_interrupt, IRQF_SHARED, "PDMA1", edma);
+	if (ret) {
+		printk("request irq(IRQ_PDMA1) fialed\n");
+		return ret;
+	}
+
+	dma_cap_zero(dma_dev->cap_mask);
+	dma_cap_set(DMA_SLAVE, dma_dev->cap_mask);
+	dma_cap_set(DMA_CYCLIC, dma_dev->cap_mask);
+
+	dma_dev->dev = &pdev->dev;
+	dma_dev->device_alloc_chan_resources = nuc980_dma_alloc_chan_resources;
+	dma_dev->device_free_chan_resources = nuc980_dma_free_chan_resources;
+	dma_dev->device_prep_slave_sg = nuc980_dma_prep_slave_sg;
+	dma_dev->device_prep_dma_cyclic = nuc980_dma_prep_dma_cyclic;
+	dma_dev->device_config = nuc980_dma_slave_config;
+	dma_dev->device_issue_pending = nuc980_dma_issue_pending;
+	dma_dev->device_tx_status = nuc980_dma_tx_status;
+
+	dma_set_max_seg_size(dma_dev->dev, DMA_MAX_CHAN_BYTES);
+
+	dma_cap_set(DMA_MEMCPY, dma_dev->cap_mask);
+	dma_dev->device_prep_dma_memcpy = nuc980_dma_prep_dma_memcpy;
+
+	edma->hw_setup = hw_setup;
+	edma->hw_shutdown = hw_shutdown;
+	edma->hw_submit = hw_submit;
+	edma->hw_interrupt = hw_interrupt;
+	dma_cap_set(DMA_PRIVATE, dma_dev->cap_mask);
+	mutex_init(&pdma0_mutex);
+	mutex_init(&pdma1_mutex);
+
+	platform_set_drvdata(pdev, edma);
+
+	ret = dma_async_device_register(dma_dev);
+	if (unlikely(ret)) {
+#if 0
+		for (i = 0; i < edma->num_channels; i++) {
+			struct nuc980_dma_chan *edmac = &edma->channels[i];
+			if (!IS_ERR_OR_NULL(edmac->clk))
+				clk_put(edmac->clk);
+		}
+#endif
+		kfree(edma);
+	} else {
+		dev_info(dma_dev->dev, "NUC980 DMA ready\n");
+	}
+	LEAVE();
+
+	return ret;
+}
+
+static int nuc980_dma_suspend(struct platform_device *pdev,pm_message_t state)
+{
+	struct nuc980_dma_engine *edma = platform_get_drvdata(pdev);
+	struct nuc980_dma_chan *edmac = &edma->channels[0];
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int nuc980_dma_resume(struct platform_device *pdev)
+{
+	struct nuc980_dma_engine *edma = platform_get_drvdata(pdev);
+	struct nuc980_dma_chan *edmac = &edma->channels[0];
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static struct platform_device_id nuc980_dma_driver_ids[] = {
+	{ "nuc980-dma", 0 },
+	{ },
+};
+
+static const struct of_device_id nuc980_dma_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-dma" },
+	{},
+};
+
+static struct platform_driver nuc980_dma_driver = {
+	.driver     = {
+		.name   = "nuc980-dma",
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_dma_of_match),
+	},
+	.probe      = nuc980_dma_probe,
+	.resume     = nuc980_dma_resume,
+	.suspend    = nuc980_dma_suspend,
+	.id_table   = nuc980_dma_driver_ids,
+};
+module_platform_driver(nuc980_dma_driver);
+
+
+MODULE_DESCRIPTION("NUC980 DMA driver");
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/dma/nuc980_dma_m2m.c NUC980-linux-4.4.194/drivers/dma/nuc980_dma_m2m.c
--- linux-4.4.194/drivers/dma/nuc980_dma_m2m.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/dma/nuc980_dma_m2m.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,212 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/dmaengine.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/cdev.h>
+#include <linux/device.h>
+#include <linux/fs.h>
+#include <linux/workqueue.h>
+#include <asm/uaccess.h>
+#include <linux/platform_data/dma-nuc980.h>
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-pdma.h>
+
+#include <linux/kthread.h>
+
+static volatile int m2m_done_state=0;
+static DECLARE_WAIT_QUEUE_HEAD(m2m_done);
+
+
+/* The following data structure represents a single channel of DMA, transmit or receive in the case
+ * when using DMA.  It contains all the data to be maintained for the channel.
+ */
+struct dma_proxy_channel {
+	struct device *proxy_device_p;              /* character device support */
+	struct device *dma_device_p;
+	struct nuc980_mem_alloc src_mem_p;
+	struct nuc980_mem_alloc dest_mem_p;
+	struct nuc980_mem_dma_param mem_dma_p;
+	dev_t dev_node;
+	struct cdev cdev;
+	struct class *class_p;
+
+	struct dma_chan *channel_p;             /* dma support */
+	struct completion cmp;
+	dma_cookie_t cookie;
+	dma_addr_t dma_handle;
+	u32 direction;                      /* DMA_MEM_TO_MEM */
+};
+
+
+/* Allocate the channels for this example statically rather than dynamically for simplicity.
+ */
+static struct dma_proxy_channel channels;
+
+struct nuc980_dma_done  dma_m2m_done;// = { .wait = &done_wait };
+
+
+int M2M_Compare(void)
+{
+	int i;
+	struct dma_proxy_channel *pchannel_p=&channels;
+	for(i=0; i<pchannel_p->src_mem_p.size; i++) {
+		if(*((unsigned char *)(pchannel_p->src_mem_p.vir_addr )+i)!=
+		    *((unsigned char *)(pchannel_p->dest_mem_p.vir_addr)+i)) {
+			printk("[Compare Error]%d %d %d\n",i,
+			       *((unsigned char *)(pchannel_p->src_mem_p.vir_addr )+i),
+			       *((unsigned char *)(pchannel_p->dest_mem_p.vir_addr)+i)
+			      );
+			return 0;
+		}
+	}
+	printk("M2M Compare Data Pass\n");
+	return 0;
+}
+
+static void nuc980_m2m_dma_callback(void *arg)
+{
+
+	struct nuc980_dma_done *done = arg;
+	//printk("m2m done->done=%d, done->timeout=%d\n",done->done,done->timeout);
+	done->done = true;
+	m2m_done_state = 1;
+	wake_up_interruptible(&m2m_done);
+	return;
+}
+
+int M2M_Trigger(void)
+{
+	int i;
+	struct dma_async_tx_descriptor *tx = NULL;
+	dma_cookie_t        cookie;
+	struct dma_proxy_channel *pchannel_p=&channels;
+	struct nuc980_mem_dma_param *dma_param = &pchannel_p->mem_dma_p;
+	dma_cap_mask_t mask;
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_MEMCPY, mask);
+
+	for(i=0; i<pchannel_p->src_mem_p.size; i++) {
+		*((unsigned char *)pchannel_p->src_mem_p.vir_addr+i)=i;
+		*((unsigned char *)pchannel_p->dest_mem_p.vir_addr+i)=0;
+	}
+
+	dma_param->src_addr=pchannel_p->src_mem_p.phy_addr;
+	dma_param->dst_addr=pchannel_p->dest_mem_p.phy_addr;
+	dma_param->size=pchannel_p->dest_mem_p.size;
+	tx = pchannel_p->channel_p->device->device_prep_dma_memcpy(pchannel_p->channel_p,
+	                dma_param->dst_addr,
+	                dma_param->src_addr,
+	                dma_param->size,
+	                dma_param->cfg);
+
+	dma_m2m_done.done = false;
+	tx->callback = nuc980_m2m_dma_callback;
+	tx->callback_param = &dma_m2m_done;
+	cookie = tx->tx_submit(tx);
+	return 0;
+}
+
+extern int  emac0_m2m_state;
+
+volatile int m2m_first=1;
+static int M2M_Thread_Retrigger(void *data)
+{
+	if(m2m_first) {
+		int i;
+		struct dma_proxy_channel *pchannel_p=&channels;
+		pchannel_p->src_mem_p.size=1*1024; //set to 1Kbytes
+		pchannel_p->src_mem_p.vir_addr = (unsigned int)dma_alloc_writecombine(NULL,
+		                                 PAGE_ALIGN(pchannel_p->src_mem_p.size),
+		                                 &pchannel_p->src_mem_p.phy_addr,
+		                                 GFP_KERNEL);
+
+		for(i=0; i<pchannel_p->src_mem_p.size; i++)
+			*((unsigned char *)pchannel_p->src_mem_p.vir_addr+i)=i;
+
+		pchannel_p->dest_mem_p.size=pchannel_p->src_mem_p.size;
+		pchannel_p->dest_mem_p.vir_addr = (unsigned int)dma_alloc_writecombine(NULL,
+		                                  PAGE_ALIGN(pchannel_p->dest_mem_p.size),
+		                                  &pchannel_p->dest_mem_p.phy_addr,
+		                                  GFP_KERNEL);
+		m2m_first=0;
+	}
+	while(1) {
+		wait_event_interruptible(m2m_done, (m2m_done_state != 0));
+		m2m_done_state=0;
+		M2M_Compare();
+		msleep(100);
+		M2M_Trigger();
+	}
+	return 0;
+}
+
+static int __init MyDmaM2M_init(void)
+{
+	struct dma_proxy_channel *pchannel_p=&channels;
+	struct nuc980_mem_dma_param *dma_param = &pchannel_p->mem_dma_p;
+	dma_cap_mask_t mask;
+
+	struct dma_async_tx_descriptor *tx = NULL;
+	dma_cookie_t        cookie;
+
+	printk("nuc980 dma m2m test...........");
+	/* Zero out the capability mask then initialize it for a slave channel that is
+	 * private.
+	 */
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_MEMCPY, mask);
+
+	/* Request the DMA channel from the DMA engine and then use the device from
+	 * the channel for the proxy channel also.
+	 */
+	pchannel_p->channel_p = dma_request_channel(mask, NULL, NULL);
+	if (!pchannel_p->channel_p) {
+		dev_err(pchannel_p->dma_device_p, "DMA channel request error\n");
+		return -1;
+	}
+	printk("PDMA M2M channel: %s\n", dma_chan_name(pchannel_p->channel_p));
+	kthread_run(M2M_Thread_Retrigger, pchannel_p, "PDMA_m2m_test");
+	pchannel_p->channel_p->private=(void *)1;
+	pchannel_p->direction = DMA_MEM_TO_MEM;
+	while(m2m_first);
+	dma_param->src_addr=pchannel_p->src_mem_p.phy_addr;
+	dma_param->dst_addr=pchannel_p->dest_mem_p.phy_addr;
+	dma_param->size=pchannel_p->dest_mem_p.size;
+	tx = pchannel_p->channel_p->device->device_prep_dma_memcpy(pchannel_p->channel_p,
+	                dma_param->dst_addr,
+	                dma_param->src_addr,
+	                dma_param->size,
+	                dma_param->cfg);
+
+	dma_m2m_done.done = false;
+	tx->callback = nuc980_m2m_dma_callback;
+	tx->callback_param = &dma_m2m_done;
+	cookie = tx->tx_submit(tx);
+
+	return 0;
+}
+
+static void __exit MyDmaM2M_exit(void)
+{
+	return;
+}
+
+module_init(MyDmaM2M_init);
+module_exit(MyDmaM2M_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Mister X");
diff -uprN linux-4.4.194/drivers/dma/nuc980_dma_uart1.c NUC980-linux-4.4.194/drivers/dma/nuc980_dma_uart1.c
--- linux-4.4.194/drivers/dma/nuc980_dma_uart1.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/dma/nuc980_dma_uart1.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,349 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/dmaengine.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/cdev.h>
+#include <linux/device.h>
+#include <linux/fs.h>
+#include <linux/workqueue.h>
+#include <linux/delay.h>
+#include <asm/uaccess.h>
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-serial.h>
+#include <mach/regs-pdma.h>
+#include <linux/clk.h>
+#include <mach/sram.h>
+#include <linux/platform_data/dma-nuc980.h>
+#include <linux/kthread.h>
+
+static volatile int slave_done_state=0;
+static DECLARE_WAIT_QUEUE_HEAD(slave_done);
+
+
+
+#define UARTx_BA UART1_BA
+#define UARTx_PA UART1_PA
+#define PDMA_UARTx_TX PDMA_UART1_TX
+#define PDMA_UARTx_RX PDMA_UART1_RX
+
+
+/* Allocate the channels for this example statically rather than dynamically for simplicity.
+ */
+static struct nuc980_ip_rx_dma dma_rx;
+static struct nuc980_ip_tx_dma dma_tx;
+static struct nuc980_mem_alloc src_mem_p;
+static struct nuc980_mem_alloc dest_mem_p;
+static struct nuc980_dma_done   dma_slave_done;
+
+static void Slave_Compare(void)
+{
+	int i;
+	for(i=0; i<src_mem_p.size; i++) {
+		if(*((unsigned char *)(src_mem_p.vir_addr )+i)!=
+		    *((unsigned char *)(dest_mem_p.vir_addr)+i)) {
+			printk("[Compare Error]%d %d %d\n",i,
+			       *((unsigned char *)(src_mem_p.vir_addr )+i),
+			       *((unsigned char *)(dest_mem_p.vir_addr)+i)
+			      );
+			return;
+		}
+	}
+	printk("Slave Compare Pass\n");
+}
+
+static void nuc980_slave_dma_callback(void *arg)
+{
+	struct nuc980_dma_done *done = arg;
+	if(done->done)
+		printk("transfer1 passed\n");
+	if(done->timeout)
+		printk("transfer1 timeout\n");
+
+	slave_done_state = 1;
+	wake_up_interruptible(&slave_done);
+	//printk("nuc980_slave_dma_callback END\n");
+	return;
+}
+
+static void Slave_Trigger(void)
+{
+	int i;
+	struct nuc980_ip_rx_dma *pdma_rx=&dma_rx;
+	struct nuc980_ip_tx_dma *pdma_tx=&dma_tx;
+	struct nuc980_dma_config dma_crx,dma_ctx;
+	dma_cookie_t        cookie;
+	__raw_writel(__raw_readl(UARTx_BA+0x4)&~(0x1<<14),(UARTx_BA+0x4)); //Enable UARTx TX PDMA
+	__raw_writel(__raw_readl(UARTx_BA+0x4)&~(0x1<<15),(UARTx_BA+0x4)); //Enable UARTx RX PDMA
+
+	__raw_writel(__raw_readl(UARTx_BA+0x8)|0x6, (UARTx_BA+0x8));  // Reaset TX and RX FIFO
+
+	for(i=0; i<src_mem_p.size; i++) {
+		*((unsigned char *)src_mem_p.vir_addr+i)=i;
+		*((unsigned char *)dest_mem_p.vir_addr+i)=0;
+	}
+
+	/* prepare the RX dma transfer */
+	pdma_rx->slave_config.src_addr = UARTx_PA;
+	pdma_rx->slave_config.src_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+	pdma_rx->slave_config.src_maxburst = 1;
+	pdma_rx->slave_config.direction = DMA_DEV_TO_MEM;
+	pdma_rx->slave_config.device_fc = false;
+	dmaengine_slave_config(pdma_rx->chan_rx,&(pdma_rx->slave_config));
+
+	sg_init_table(pdma_rx->sgrx, 1);
+	pdma_rx->sgrx[0].dma_address=dest_mem_p.phy_addr;
+	pdma_rx->sgrx[0].length=dest_mem_p.size;
+	dma_crx.reqsel = PDMA_UARTx_RX;
+	dma_crx.timeout_counter = 0x3FF;
+	dma_crx.timeout_prescaler = 7;
+	dma_crx.en_sc = 0;
+	pdma_rx->rxdesc=pdma_rx->chan_rx->device->device_prep_slave_sg(pdma_rx->chan_rx,
+	                pdma_rx->sgrx,
+	                1,
+	                DMA_FROM_DEVICE,
+	                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+	                (void *)&dma_crx); //PDMA Request Source Select
+	if (!pdma_rx->rxdesc) {
+		printk("pdma->rxdesc=NULL\n");
+		while(1);
+	}
+	dma_slave_done.done = false;
+	pdma_rx->rxdesc->callback = nuc980_slave_dma_callback;
+	pdma_rx->rxdesc->callback_param = &dma_slave_done;
+	//printk("pdma->rxdesc->callback_param=0x%08x\n",(unsigned int)pdma->rxdesc->callback_param);
+	cookie = pdma_rx->rxdesc->tx_submit(pdma_rx->rxdesc);
+	if (dma_submit_error(cookie)) {
+		printk("rx cookie=%d\n",cookie);
+		while(1);
+	}
+
+	/* prepare the TX dma transfer */
+	pdma_tx->slave_config.dst_addr = UARTx_PA;
+	pdma_tx->slave_config.dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+	pdma_tx->slave_config.dst_maxburst = 1;
+	pdma_tx->slave_config.direction = DMA_MEM_TO_DEV;
+	dmaengine_slave_config(pdma_tx->chan_tx,&(pdma_tx->slave_config));
+	sg_init_table(pdma_tx->sgtx, 1);
+	pdma_tx->sgtx[0].dma_address=src_mem_p.phy_addr;
+	pdma_tx->sgtx[0].length=src_mem_p.size;
+	dma_ctx.reqsel = PDMA_UARTx_TX;
+	dma_ctx.timeout_counter = 0;
+	dma_ctx.timeout_prescaler = 0;
+	dma_ctx.en_sc = 0;
+	pdma_tx->txdesc=pdma_tx->chan_tx->device->device_prep_slave_sg(pdma_tx->chan_tx,
+	                pdma_tx->sgtx,
+	                1,
+	                DMA_TO_DEVICE,
+	                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+	                (void *)&dma_ctx);
+	if (!pdma_tx->txdesc) {
+		printk("pdma->txdex=NULL\n");
+		while(1);
+	}
+	pdma_tx->txdesc->callback = NULL;
+	pdma_tx->txdesc->callback_param = NULL;
+	cookie = pdma_tx->txdesc->tx_submit(pdma_tx->txdesc);
+	if (dma_submit_error(cookie)) {
+		printk("tx cookie=%d\n",cookie);
+		while(1);
+	}
+
+	__raw_writel(__raw_readl(UARTx_BA+0x4)|(0x1<<14),UARTx_BA+0x4); //Enable UARTx TX PDMA
+	__raw_writel(__raw_readl(UARTx_BA+0x4)|(0x1<<15),UARTx_BA+0x4); //Enable UARTx RX PDMA
+
+	//printk("Slave_Trigger ENDEND\n");
+	//return 0;
+}
+
+static volatile int slave_first=1;
+static int Slave_Thread_Retrigger(void *data)
+{
+	printk("Slave_Thread_Retrigger...UART1\n");
+	if(slave_first) {
+		int i;
+#if 0
+		src_mem_p.size= PDMA_UART_TEST_LEN; //set to 1Kbytes
+		src_mem_p.vir_addr = (unsigned int)dma_alloc_writecombine(NULL,
+		                     PAGE_ALIGN(src_mem_p.size),
+		                     &src_mem_p.phy_addr,
+		                     GFP_KERNEL);
+
+		for(i=0; i<src_mem_p.size; i++)
+			*((unsigned char *)src_mem_p.vir_addr+i)=i;
+
+		dest_mem_p.size=src_mem_p.size;
+		dest_mem_p.vir_addr = (unsigned int)dma_alloc_writecombine(NULL,
+		                      PAGE_ALIGN(dest_mem_p.size),
+		                      &dest_mem_p.phy_addr,
+		                      GFP_KERNEL);
+#else
+		src_mem_p.size= PDMA_UART_TEST_LEN; //set to 1Kbytes
+		src_mem_p.vir_addr = (u32)sram_alloc(1024,&src_mem_p.phy_addr);
+		for(i=0; i<src_mem_p.size; i++)
+			*((unsigned char *)src_mem_p.vir_addr+i)=i;
+		dest_mem_p.size=src_mem_p.size;
+		dest_mem_p.vir_addr =(u32)sram_alloc(1024,&dest_mem_p.phy_addr);
+#endif
+		slave_first=0;
+	}
+	while(1) {
+		if (wait_event_interruptible_timeout(slave_done, (slave_done_state != 0), 2000) == 0) {
+			printk("UART1 time-out!!\n");
+			while(1);
+		} else {
+			slave_done_state = 0;
+			Slave_Compare();
+			dma_slave_done.timeout = 0;
+			dma_slave_done.done = 0;
+		}
+		Slave_Trigger();
+	}
+	return 0;
+}
+//drivers/spi/spi-atmel.c
+
+static int __init MyDmaSlave_init(void)
+{
+	struct nuc980_ip_rx_dma *pdma_rx=&dma_rx;
+	struct nuc980_ip_tx_dma *pdma_tx=&dma_tx;
+	struct nuc980_dma_config dma_crx,dma_ctx;
+
+	dma_cap_mask_t mask;
+	dma_cookie_t        cookie;
+
+	struct clk      *clk;
+	clk = clk_get(NULL, "uart1");
+	clk_prepare(clk);
+	clk_enable(clk);
+	clk = clk_get(NULL, "uart1_eclk");
+	clk_prepare(clk);
+	clk_enable(clk);
+
+	printk("DMA Slave Test...........");
+	/* Zero out the capability mask then initialize it for a slave channel that is
+	 * private.
+	 */
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_SLAVE, mask);
+	dma_cap_set(DMA_PRIVATE, mask);
+
+	kthread_run(Slave_Thread_Retrigger, NULL, "PDMA_slave_test");
+	while(slave_first);
+
+	//UARTx initial
+	__raw_writel(__raw_readl(UARTx_BA+0x10)|0x10,UARTx_BA+0x10); // internal loopback
+	__raw_writel(__raw_readl(UARTx_BA+0x0C)|0x07,UARTx_BA+0x0C);  /* LCR */
+	__raw_writel(0x30000066,UARTx_BA+0x24); /*BAUD : 12MHz reference clock input, 115200 */
+
+	/* Request the DMA channel from the DMA engine and then use the device from
+	 * the channel for the proxy channel also.
+	 */
+	pdma_rx->chan_rx = dma_request_channel(mask, NULL, NULL);
+	if (!pdma_rx->chan_rx) {
+		printk("RX DMA channel request error\n");
+		return -1;
+	}
+	pdma_rx->chan_rx->private=(void *)1;
+	//printk("RX %s: %s module removed\n",__func__, dma_chan_name(pdma->chan_rx));
+
+	pdma_tx->chan_tx = dma_request_channel(mask, NULL, NULL);
+	if (!pdma_tx->chan_tx) {
+		printk("TX DMA channel request error\n");
+		return -1;
+	}
+	pdma_tx->chan_tx->private=(void *)1;
+	//printk("TX %s: %s module removed\n",__func__, dma_chan_name(pdma->chan_tx));
+
+	/* prepare the RX dma transfer */
+	pdma_rx->slave_config.src_addr = UARTx_PA;
+	pdma_rx->slave_config.src_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+	pdma_rx->slave_config.src_maxburst = 1;
+	pdma_rx->slave_config.direction = DMA_DEV_TO_MEM;
+	pdma_rx->slave_config.device_fc = false;
+	dmaengine_slave_config(pdma_rx->chan_rx,&(pdma_rx->slave_config));
+
+	sg_init_table(pdma_rx->sgrx, 1);
+	pdma_rx->sgrx[0].dma_address=dest_mem_p.phy_addr;
+	pdma_rx->sgrx[0].length=dest_mem_p.size;
+	dma_crx.reqsel = PDMA_UARTx_RX;
+	dma_crx.timeout_counter = 0x3FF;
+	dma_crx.timeout_prescaler = 7;
+	dma_crx.en_sc = 0;
+	pdma_rx->rxdesc=pdma_rx->chan_rx->device->device_prep_slave_sg(pdma_rx->chan_rx,
+	                pdma_rx->sgrx,
+	                1,
+	                DMA_FROM_DEVICE,
+	                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+	                (void *)&dma_crx); //PDMA Request Source Select
+	if (!pdma_rx->rxdesc) {
+		printk("pdma->rxdes==NULL\n");
+		while(1);
+	}
+	dma_slave_done.done = false;
+	pdma_rx->rxdesc->callback = nuc980_slave_dma_callback;
+	pdma_rx->rxdesc->callback_param = &dma_slave_done;
+	cookie = pdma_rx->rxdesc->tx_submit(pdma_rx->rxdesc);
+	if (dma_submit_error(cookie)) {
+		printk("dma_submit_error\n");
+		while(1);
+	}
+	/* prepare the TX dma transfer */
+	pdma_tx->slave_config.dst_addr = UARTx_PA;
+	pdma_tx->slave_config.dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+	pdma_tx->slave_config.dst_maxburst = 1;
+	pdma_tx->slave_config.direction = DMA_MEM_TO_DEV;
+	dmaengine_slave_config(pdma_tx->chan_tx,&(pdma_tx->slave_config));
+	sg_init_table(pdma_tx->sgtx, 1);
+	pdma_tx->sgtx[0].dma_address=src_mem_p.phy_addr;
+	pdma_tx->sgtx[0].length=src_mem_p.size;
+	dma_ctx.reqsel = PDMA_UARTx_TX;
+	dma_ctx.timeout_counter = 0;
+	dma_ctx.timeout_prescaler = 0;
+	dma_ctx.en_sc = 0;
+	pdma_tx->txdesc=pdma_tx->chan_tx->device->device_prep_slave_sg(pdma_tx->chan_tx,
+	                pdma_tx->sgtx,
+	                1,
+	                DMA_TO_DEVICE,
+	                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+	                (void *)&dma_ctx);
+	if (!pdma_tx->txdesc) {
+		printk("pdma->txdes==NULL\n");
+		while(1);
+	}
+	cookie = pdma_tx->txdesc->tx_submit(pdma_tx->txdesc);
+	if (dma_submit_error(cookie)) {
+		printk("dma_submit_error\n");
+		while(1);
+	}
+
+	__raw_writel(__raw_readl(UARTx_BA+0x4)|(0x1<<14),UARTx_BA+0x4); //Enable UARTx TX PDMA
+	__raw_writel(__raw_readl(UARTx_BA+0x4)|(0x1<<15),UARTx_BA+0x4); //Enable UARTx RX PDMA
+
+
+	//while(1);
+	return 0;
+}
+
+static void __exit MyDmaSlave_exit(void)
+{
+	return;
+}
+
+module_init(MyDmaSlave_init);
+module_exit(MyDmaSlave_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Mister X");
diff -uprN linux-4.4.194/drivers/gpio/gpio-nuc980.c NUC980-linux-4.4.194/drivers/gpio/gpio-nuc980.c
--- linux-4.4.194/drivers/gpio/gpio-nuc980.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/gpio/gpio-nuc980.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,709 @@
+/*
+ *  linux/drivers/drivers/gpio/nuc980-gpio.c - Nuvoton NUC980 GPIO Driver
+ *
+ *  Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License 2 as published
+ *  by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; see the file COPYING.  If not,     write to
+ *  the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.  /gpio-tc3589x.c/
+ */
+
+
+
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/io.h>
+#include <linux/errno.h>
+#include <linux/acpi.h>
+#include <linux/platform_device.h>
+#include <mach/gpio.h>
+#include <linux/clk.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+
+#include <mach/map.h>
+#include <mach/regs-gpio.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-gcr.h>
+
+#include <mach/irqs.h>
+
+//#define GPIO_DEBUG_ENABLE_ENTER_LEAVE
+#ifdef GPIO_DEBUG_ENABLE_ENTER_LEAVE
+#define ENTRY()                 printk("[%-20s] : Enter...\n", __FUNCTION__)
+#define LEAVE()                 printk("[%-20s] : Leave...\n", __FUNCTION__)
+#else
+#define ENTRY()
+#define LEAVE()
+#endif
+
+#define GPIO_PMD_INPUT              0x0UL                  /*!< Input Mode */
+#define GPIO_PMD_OUTPUT             0x1UL                  /*!< Output Mode */
+#define GPIO_PMD_OPEN_DRAIN         0x2UL                  /*!< Open-Drain Mode */
+#define GPIO_PMD_QUASI              0x3UL                  /*!< Quasi-bidirectional Mode */
+#define GPIO_PMD_MODE(pin, mode)    ((mode) << ((pin)<<1)) /*!< Generate the PMD mode setting for each pin  */
+
+
+static DEFINE_SPINLOCK(gpio_lock);
+
+static unsigned short gpio_ba;
+
+struct gpio_port {
+	volatile unsigned int * dir;
+	volatile unsigned int * out;
+	volatile unsigned int * in;
+};
+
+static const struct gpio_port port_class[] = {
+	{
+		(volatile unsigned int *)REG_GPIOA_MODE, (volatile unsigned int *)REG_GPIOA_DOUT,
+		(volatile unsigned int *)REG_GPIOA_PIN
+	},
+	{
+		(volatile unsigned int *)REG_GPIOB_MODE, (volatile unsigned int *)REG_GPIOB_DOUT,
+		(volatile unsigned int *)REG_GPIOB_PIN
+	},
+	{
+		(volatile unsigned int *)REG_GPIOC_MODE, (volatile unsigned int *)REG_GPIOC_DOUT,
+		(volatile unsigned int *)REG_GPIOC_PIN
+	},
+	{
+		(volatile unsigned int *)REG_GPIOD_MODE, (volatile unsigned int *)REG_GPIOD_DOUT,
+		(volatile unsigned int *)REG_GPIOD_PIN
+	},
+	{
+		(volatile unsigned int *)REG_GPIOE_MODE, (volatile unsigned int *)REG_GPIOE_DOUT,
+		(volatile unsigned int *)REG_GPIOE_PIN
+	},
+	{
+		(volatile unsigned int *)REG_GPIOF_MODE, (volatile unsigned int *)REG_GPIOF_DOUT,
+		(volatile unsigned int *)REG_GPIOF_PIN
+	},
+	{
+		(volatile unsigned int *)REG_GPIOG_MODE, (volatile unsigned int *)REG_GPIOG_DOUT,
+		(volatile unsigned int *)REG_GPIOG_PIN
+	},
+	{},
+};
+
+static const struct gpio_port *nuc980_gpio_cla_port(unsigned gpio_num,
+                unsigned *group,unsigned *num) {
+	*group = gpio_num / GPIO_OFFSET;
+	*num = gpio_num % GPIO_OFFSET;
+	return &port_class[*group];
+}
+
+static int nuc980_gpio_core_direction_in(struct gpio_chip *gc,
+                unsigned gpio_num)
+{
+	int port_num,group_num;
+	unsigned long value;
+	const struct gpio_port *port =
+	        nuc980_gpio_cla_port(gpio_num, &group_num, &port_num);
+	ENTRY();
+	spin_lock(&gpio_lock);
+	value = __raw_readl(port->dir);
+	value &= ~GPIO_PMD_MODE(port_num,GPIO_PMD_QUASI);
+	value |= GPIO_PMD_MODE(port_num,GPIO_PMD_INPUT);
+	__raw_writel(value, port->dir);
+	spin_unlock(&gpio_lock);
+	LEAVE();
+	return 0;
+}
+
+static int nuc980_gpio_core_get(struct gpio_chip *gc, unsigned gpio_num)
+{
+	int port_num,group_num;
+	const struct gpio_port *port;
+	ENTRY();
+	port = nuc980_gpio_cla_port(gpio_num, &group_num, &port_num);
+	LEAVE();
+	return GPIO_PIN_DATA(group_num,port_num);
+}
+
+static void nuc980_gpio_core_set(struct gpio_chip *gc, unsigned gpio_num,
+                                 int val)
+{
+	int port_num,group_num;
+	const struct gpio_port *port;
+	ENTRY();
+	port = nuc980_gpio_cla_port(gpio_num, &group_num, &port_num);
+	GPIO_PIN_DATA(group_num,port_num)=val;
+	LEAVE();
+}
+
+static int nuc980_gpio_core_direction_out(struct gpio_chip *gc,
+                unsigned gpio_num, int val)
+{
+	int port_num,group_num;
+	unsigned long value;
+	const struct gpio_port *port =
+	        nuc980_gpio_cla_port(gpio_num, &group_num, &port_num);
+	ENTRY();
+	spin_lock(&gpio_lock);
+	value = __raw_readl(port->dir);
+	value &= ~GPIO_PMD_MODE(port_num,GPIO_PMD_QUASI);
+	value |= GPIO_PMD_MODE(port_num,GPIO_PMD_OUTPUT);
+	__raw_writel(value, port->dir);
+	spin_unlock(&gpio_lock);
+	nuc980_gpio_core_set(gc, gpio_num, val);
+	LEAVE();
+	return 0;
+}
+
+static int nuc980_gpio_core_to_request(struct gpio_chip *chip, unsigned offset)
+{
+	unsigned int group,num1,num,reg,value;
+	ENTRY();
+	group = offset / GPIO_OFFSET;
+	num1  = num = offset % GPIO_OFFSET;
+	reg   = (unsigned int)REG_MFP_GPA_L+(group* 0x08);
+	if(num>7) {
+		num -= 8;
+		reg = reg + 0x04 ;
+	}
+
+	value = ( __raw_readl((volatile unsigned int *)reg) & (0xf<<(num*4)))>>(num*4);
+	if(value>0 && value<0xf) {
+		printk(KERN_ERR "Please Check GPIO%c%02d's multi-function = 0x%x \n",(char)(65+group),num1,value);
+		LEAVE();
+		return -EINVAL;
+	}
+	LEAVE();
+	return 0;
+}
+
+static void nuc980_gpio_core_to_free(struct gpio_chip *chip, unsigned offset)
+{
+	ENTRY();
+}
+
+static int nuc980_gpio_core_to_irq(struct gpio_chip *chip, unsigned offset)
+{
+	unsigned int irqno= IRQ_GPIO_START+offset;
+	ENTRY();
+	switch(offset) {
+	case NUC980_PA0:
+		if((__raw_readl(REG_MFP_GPA_L) & (0xf<<0))==(0x5<<0))
+			irqno = IRQ_EXT0_A0;
+		break;
+
+	case NUC980_PA1:
+		if((__raw_readl(REG_MFP_GPA_L) & (0xf<<4))==(0x5<<4))
+			irqno = IRQ_EXT1_A1;
+		break;
+	case NUC980_PD0:
+		if((__raw_readl(REG_MFP_GPD_L) & (0xf<<0))==(0x4<<0))
+			irqno = IRQ_EXT2_D0;
+		break;
+	case NUC980_PD1:
+		if((__raw_readl(REG_MFP_GPD_L) & (0xf<<4))==(0x4<<4))
+			irqno = IRQ_EXT3_D1;
+		break;
+	case NUC980_PA13:
+		if((__raw_readl(REG_MFP_GPA_H) & (0xf<<20))==(0x8<<20))
+			irqno = IRQ_EXT0_A13;
+		break;
+	case NUC980_PA14:
+		if((__raw_readl(REG_MFP_GPA_H) & (0xf<<24))==(0x8<<24))
+			irqno = IRQ_EXT1_A14;
+		break;
+	case NUC980_PE10:
+		if((__raw_readl(REG_MFP_GPE_H) & (0xf<<8))==(0x5<<8))
+			irqno = IRQ_EXT2_E10;
+		break;
+	case NUC980_PE12:
+		if((__raw_readl(REG_MFP_GPE_H) & (0xf<<16))==(0x5<<16))
+			irqno = IRQ_EXT3_E12;
+		break;
+	case NUC980_PB3:
+		if((__raw_readl(REG_MFP_GPB_L) & (0xf<<12))==(0x3<<12))
+			irqno = IRQ_EXT2_B3;
+		break;
+	case NUC980_PB13:
+		if((__raw_readl(REG_MFP_GPB_H) & (0xf<<20))==(0x2<<20))
+			irqno = IRQ_EXT2_B13;
+		break;
+	case NUC980_PG15:
+		if((__raw_readl(REG_MFP_GPG_H) & (0xf<<24))==(0x4<<24))
+			irqno = IRQ_EXT3_G15;
+		break;
+	default:
+		irqno = IRQ_GPIO_START+offset;
+		break;
+	}
+	LEAVE();
+	return irqno;
+}
+
+static struct gpio_chip nuc980_gpio_port = {
+	.label = "nuc980_gpio_port",
+	.owner = THIS_MODULE,
+	.direction_input = nuc980_gpio_core_direction_in,
+	.get = nuc980_gpio_core_get,
+	.direction_output = nuc980_gpio_core_direction_out,
+	.set = nuc980_gpio_core_set,
+	.request = nuc980_gpio_core_to_request,
+	.free = nuc980_gpio_core_to_free,
+	.to_irq = nuc980_gpio_core_to_irq,
+	.base = 0,
+	.ngpio = NUMGPIO,
+};
+
+
+#ifndef CONFIG_USE_OF
+/*
+ * @brief       External Interrupt 0 Handler
+ * @details     This function will be used by EINT0,
+ *              when enable IRQ_EXT0_A0 or IRQ_EXT0_A13 in eint0
+ */
+/*
+static irqreturn_t nuc980_eint0_interrupt(int irq, void *dev_id){
+    printk("@0\n");
+    return IRQ_HANDLED;
+}
+*/
+
+/* If enable IRQ_EXT0_A0 or IRQ_EXT0_A13 , linux will enable EINT0
+ * User can modify trigger tiypes as below :
+ * IRQF_TRIGGER_FALLING / IRQF_TRIGGER_RISING / IRQF_TRIGGER_HIGH / IRQF_TRIGGER_LOW
+ */
+struct nuc980_eint_pins eint0[]= {
+//{IRQ_EXT0_A0, nuc980_eint0_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint0"},
+//{IRQ_EXT0_A13,nuc980_eint0_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint0"},
+	{0,0,0,0}
+};
+
+/*
+ * @brief       External Interrupt 0 Handler
+ * @details     This function will be used by EINT1,
+ *              when enable IRQ_EXT1_A1 or IRQ_EXT1_A14 in eint1
+ */
+/*
+static irqreturn_t nuc980_eint1_interrupt(int irq, void *dev_id){
+    printk("@1\n");
+    return IRQ_HANDLED;
+}
+*/
+
+/* If enable IRQ_EXT1_A1 or IRQ_EXT1_A14 , linux will enable EINT1
+ * User can modify trigger tiypes as below :
+ * IRQF_TRIGGER_FALLING / IRQF_TRIGGER_RISING / IRQF_TRIGGER_HIGH / IRQF_TRIGGER_LOW
+ */
+struct nuc980_eint_pins eint1[]= {
+//{IRQ_EXT1_A1, nuc980_eint1_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint1"},
+//{IRQ_EXT1_A14,nuc980_eint1_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint1"},
+	{0,0,0,0}
+};
+
+/*
+ * @brief       External Interrupt 2 Handler
+ * @details     This function will be used by EINT2,
+ *              when enable IRQ_EXT2_D0 , IRQ_EXT2_E10 , IRQ_EXT2_B3 or IRQ_EXT2_B13 in eint2
+ */
+/*
+static irqreturn_t nuc980_eint2_interrupt(int irq, void *dev_id){
+    printk("@2\n");
+    return IRQ_HANDLED;
+}
+*/
+
+
+/* If enable IRQ_EXT2_D0 , IRQ_EXT2_E10 , IRQ_EXT2_B3 , IRQ_EXT2_B13 , linux will enable EINT2
+ * User can modify trigger tiypes as below :
+ * IRQF_TRIGGER_FALLING / IRQF_TRIGGER_RISING / IRQF_TRIGGER_HIGH / IRQF_TRIGGER_LOW
+ */
+struct nuc980_eint_pins eint2[]= {
+//{IRQ_EXT2_D0, nuc980_eint2_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint2"},
+//{IRQ_EXT2_E10,nuc980_eint2_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint2"},
+//{IRQ_EXT2_B3,nuc980_eint2_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint2"},
+//{IRQ_EXT2_B13,nuc980_eint2_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint2"},
+	{0,0,0,0}
+};
+
+/*
+ * @brief       External Interrupt 3 Handler
+ * @details     This function will be used by EINT3,
+ *              when enable IRQ_EXT3_D1 , IRQ_EXT3_E12 or IRQ_EXT3_G15 in eint3
+ */
+/*
+static irqreturn_t nuc980_eint3_interrupt(int irq, void *dev_id){
+    printk("@3\n");
+    return IRQ_HANDLED;
+}
+*/
+
+
+/* If enable IRQ_EXT3_D1 , IRQ_EXT3_E12 or IRQ_EXT3_G15 , linux will enable EINT31
+ * User can modify trigger tiypes as below :
+ * IRQF_TRIGGER_FALLING / IRQF_TRIGGER_RISING / IRQF_TRIGGER_HIGH / IRQF_TRIGGER_LOW
+ */
+struct nuc980_eint_pins eint3[]= {
+//{IRQ_EXT3_D1, nuc980_eint3_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint3"},
+//{IRQ_EXT3_E12,nuc980_eint3_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint3"},
+//{IRQ_EXT3_G15,nuc980_eint3_interrupt,IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING,"eint3"},
+	{0,0,0,0}
+};
+
+static int nuc980_enable_eint(uint32_t flag,struct platform_device *pdev)
+{
+	int err;
+	struct nuc980_eint_pins *peint;
+	struct pinctrl *p = NULL;
+	switch(pdev->id) {
+	case 1:
+		peint=eint0;
+		while(peint->pin!=(u32)0) {
+			if ((err = request_irq(peint->pin,peint->handler, peint->trigger|IRQF_NO_SUSPEND, peint->name, 0)) != 0) {
+				printk("register %s irq failed %d\n",peint->name ,err);
+			}
+			if(flag==1) {
+				__raw_writel((1<<4) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+				enable_irq_wake(peint->pin);
+			}
+			switch(peint->pin) {
+			case IRQ_EXT0_A0:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint0-PA0");
+				break;
+			case IRQ_EXT0_A13:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint0-PA13");
+				break;
+			}
+			if (IS_ERR(p)) {
+				dev_err(&pdev->dev, "unable to reserve pin\n");
+				return PTR_ERR(p);
+			}
+			peint++;
+		}
+		break;
+	case 2:
+		peint=eint1;
+		while(peint->pin!=(u32)0) {
+			if ((err = request_irq(peint->pin,peint->handler, peint->trigger|IRQF_NO_SUSPEND, peint->name, 0)) != 0) {
+				printk("register %s irq failed %d\n",peint->name ,err);
+			}
+			if(flag==1) {
+				__raw_writel((1<<5) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+				enable_irq_wake(peint->pin);
+			}
+			switch(peint->pin) {
+			case IRQ_EXT1_A1:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint1-PA1");
+				break;
+			case IRQ_EXT1_A14:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint1-PA14");
+				break;
+			}
+			if (IS_ERR(p)) {
+				dev_err(&pdev->dev, "unable to reserve pin\n");
+				return PTR_ERR(p);
+			}
+			peint++;
+		}
+		break;
+	case 3:
+		peint=eint2;
+		while(peint->pin!=(u32)0) {
+			if ((err = request_irq(peint->pin,peint->handler, peint->trigger|IRQF_NO_SUSPEND, peint->name, 0)) != 0) {
+				printk("register %s irq failed %d\n",peint->name ,err);
+			}
+			if(flag==1) {
+				__raw_writel((1<<6) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+				enable_irq_wake(peint->pin);
+			}
+			switch(peint->pin) {
+			case IRQ_EXT2_D0:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint2-PD0");
+				break;
+			case IRQ_EXT2_E10:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint2-PE10");
+				break;
+			case IRQ_EXT2_B3:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint2-PB3");
+				break;
+			case IRQ_EXT2_B13:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint2-PB13");
+				break;
+			}
+			if (IS_ERR(p)) {
+				dev_err(&pdev->dev, "unable to reserve pin\n");
+				return PTR_ERR(p);
+			}
+			peint++;
+		}
+		break;
+	case 4:
+		peint=eint3;
+		while(peint->pin!=(u32)0) {
+			if ((err = request_irq(peint->pin,peint->handler, peint->trigger|IRQF_NO_SUSPEND, peint->name, 0)) != 0) {
+				printk("register %s irq failed %d\n",peint->name ,err);
+			}
+			if(flag==1) {
+				__raw_writel((1<<7) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+				enable_irq_wake(peint->pin);
+			}
+			switch(peint->pin) {
+			case IRQ_EXT3_D1:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint3-PD1");
+				break;
+			case IRQ_EXT3_E12:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint3-PE12");
+				break;
+			case IRQ_EXT3_G15:
+				p = devm_pinctrl_get_select(&pdev->dev, "eint3-PG15");
+				break;
+			}
+			if (IS_ERR(p)) {
+				dev_err(&pdev->dev, "unable to reserve pin\n");
+				return PTR_ERR(p);
+			}
+			peint++;
+		}
+		break;
+	}
+	return 0;
+}
+#else
+
+static irqreturn_t nuc980_eint0_interrupt(int irq, void *dev_id)
+{
+	printk("@0\n");
+	return IRQ_HANDLED;
+}
+__attribute__ ((unused)) static irqreturn_t nuc980_eint1_interrupt(int irq, void *dev_id)
+{
+	printk("@1\n");
+	return IRQ_HANDLED;
+}
+__attribute__ ((unused)) static irqreturn_t nuc980_eint2_interrupt(int irq, void *dev_id)
+{
+	printk("@2\n");
+	return IRQ_HANDLED;
+}
+__attribute__ ((unused)) static irqreturn_t nuc980_eint3_interrupt(int irq, void *dev_id)
+{
+	printk("@3\n");
+	return IRQ_HANDLED;
+}
+
+u32 trigger_type[5]= {   (IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING),
+                         IRQF_TRIGGER_RISING,
+                         IRQF_TRIGGER_FALLING,
+                         IRQF_TRIGGER_HIGH,
+                         IRQF_TRIGGER_LOW
+                     };
+
+static int nuc980_enable_eint(uint32_t flag,struct platform_device *pdev)
+{
+	int err;
+	u32 val32[3];
+	u32 irqnum,irqflag;
+
+	//eint 0
+	if (of_property_read_u32_array(pdev->dev.of_node, "eint0-config", val32, 3) != 0) {
+		printk("%s - eint0 can not get port-number!\n", __func__);
+		return -EINVAL;
+	}
+	if(val32[0]==1) {
+		irqnum=(val32[1]==0)?(IRQ_EXT0_A0):(IRQ_EXT0_A13);
+		irqflag=trigger_type[val32[2]]|IRQF_NO_SUSPEND;
+		if(flag==1) {
+			__raw_writel((1<<4) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+			enable_irq_wake(irqnum);
+		}
+		if ((err = request_irq(irqnum,nuc980_eint0_interrupt,irqflag, "eint0", 0)) != 0) {
+			printk("%s - eint0 can not get irq!\n", __func__);
+			return -EINVAL;
+		}
+	}
+
+	//eint 1
+	if (of_property_read_u32_array(pdev->dev.of_node, "eint1-config", val32, 3) != 0) {
+		printk("%s - eint1 can not get port-number!\n", __func__);
+		return -EINVAL;
+	}
+	if(val32[0]==1) {
+		irqnum=(val32[1]==0)?(IRQ_EXT1_A1):(IRQ_EXT1_A14);
+		irqflag=trigger_type[val32[2]]|IRQF_NO_SUSPEND;
+		if(flag==1) {
+			__raw_writel((1<<5) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+			enable_irq_wake(irqnum);
+		}
+		if ((err = request_irq(irqnum,nuc980_eint1_interrupt,irqflag, "eint1", 0)) != 0) {
+			printk("%s - eint1 can not get irq!\n", __func__);
+			return -EINVAL;
+		}
+	}
+
+	//eint 2
+	if (of_property_read_u32_array(pdev->dev.of_node, "eint2-config", val32, 3) != 0) {
+		printk("%s - eint2 can not get port-number!\n", __func__);
+		return -EINVAL;
+	}
+	if(val32[0]==1) {
+		if(val32[1]==0)
+			irqnum = IRQ_EXT2_D0;
+		else if(val32[1]==1)
+			irqnum = IRQ_EXT2_E10;
+		else if(val32[1]==2) {
+			printk("======================>IRQ_EXT2_B3\n");
+			irqnum = IRQ_EXT2_B3;
+		} else
+			irqnum = IRQ_EXT2_B13;
+		irqflag=trigger_type[val32[2]]|IRQF_NO_SUSPEND;
+		if(flag==1) {
+			__raw_writel((1<<6) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+			enable_irq_wake(irqnum);
+		}
+		if ((err = request_irq(irqnum,nuc980_eint2_interrupt,irqflag, "eint2", 0)) != 0) {
+			printk("%s - eint2 can not get irq!\n", __func__);
+			return -EINVAL;
+		}
+	}
+
+	//eint 3
+	if (of_property_read_u32_array(pdev->dev.of_node, "eint3-config", val32, 3) != 0) {
+		printk("%s - eint3 can not get port-number!\n", __func__);
+		return -EINVAL;
+	}
+	if(val32[0]==1) {
+		if(val32[1]==0)
+			irqnum = IRQ_EXT3_D1;
+		else if(val32[1]==1)
+			irqnum = IRQ_EXT3_E12;
+		else
+			irqnum = IRQ_EXT3_G15;
+
+		irqflag=trigger_type[val32[2]]|IRQF_NO_SUSPEND;
+		if(flag==3) {
+			__raw_writel((1<<7) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+			enable_irq_wake(irqnum);
+		}
+		if ((err = request_irq(irqnum,nuc980_eint3_interrupt,irqflag, "eint3", 0)) != 0) {
+			printk("%s - eint3 can not get irq!\n", __func__);
+			return -EINVAL;
+		}
+	}
+	return 0;
+}
+#endif
+
+static int nuc980_gpio_probe(struct platform_device *pdev)
+{
+	int err;
+	struct clk *clk;
+
+#ifndef CONFIG_USE_OF
+	if(pdev->id == 0)
+#endif
+	{
+		printk("%s - pdev = %s\n", __func__, pdev->name);
+		/* Enable GPIO clock */
+		clk = clk_get(NULL, "gpio_hclk");
+		if (IS_ERR(clk)) {
+			printk(KERN_ERR "nuc980-gpio:failed to get gpio clock source\n");
+			err = PTR_ERR(clk);
+			return err;
+		}
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		nuc980_gpio_port.dev = &pdev->dev;
+		err = gpiochip_add(&nuc980_gpio_port);
+		if (err < 0) {
+			goto err_nuc980_gpio_port;
+		}
+
+	}
+
+#ifdef CONFIG_USE_OF
+	{
+		struct pinctrl *pinctrl;
+		pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+		if (IS_ERR(pinctrl)) {
+			return PTR_ERR(pinctrl);
+		}
+	}
+#endif
+#ifdef CONFIG_GPIO_NUC980_EINT_WKUP
+	nuc980_enable_eint(1,pdev);
+#else
+	nuc980_enable_eint(0,pdev);
+#endif
+
+	return 0;
+
+err_nuc980_gpio_port:
+	gpio_ba = 0;
+	return err;
+}
+
+static int nuc980_gpio_remove(struct platform_device *pdev)
+{
+	struct clk *clk;
+
+	/* Disable GPIO clock */
+	clk = clk_get(NULL, "gpio");
+	if (IS_ERR(clk)) {
+		int err;
+
+		printk(KERN_ERR "nuc980-gpio:failed to get gpio clock source\n");
+		err = PTR_ERR(clk);
+		return err;
+	}
+
+	clk_disable(clk);
+
+	if (gpio_ba) {
+		gpiochip_remove(&nuc980_gpio_port);
+	}
+
+	return 0;
+}
+
+static int nuc980_gpio_resume(struct platform_device *pdev)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int nuc980_gpio_suspend(struct platform_device *pdev,pm_message_t state)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static const struct of_device_id nuc980_gpio_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-gpio" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_serial_of_match);
+
+static struct platform_driver nuc980_gpio_driver = {
+	.probe      = nuc980_gpio_probe,
+	.remove     = nuc980_gpio_remove,
+	.resume     = nuc980_gpio_resume,
+	.suspend    = nuc980_gpio_suspend,
+	.driver     = {
+		.name   = DRIVER_NAME,
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_gpio_of_match),
+	},
+};
+module_platform_driver(nuc980_gpio_driver);
+
+MODULE_DESCRIPTION("GPIO interface for Nuvoton NUC980 GPIO Drive");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980_gpio");
diff -uprN linux-4.4.194/drivers/gpio/Kconfig NUC980-linux-4.4.194/drivers/gpio/Kconfig
--- linux-4.4.194/drivers/gpio/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/gpio/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -97,6 +97,20 @@ config GPIO_MAX730X
 
 menu "Memory mapped GPIO drivers"
 
+config GPIO_NUC980
+        tristate "NUC980 GPIO support"
+        depends on GPIOLIB
+        depends on ARCH_NUC980
+        select NEED_MACH_GPIO_H
+        help
+          Say yes here to support GPIO functionality of NUC980 chip
+config GPIO_NUC980_EINT_WKUP
+        tristate "NUC980 external I/O wake-up support"
+        depends on GPIO_NUC980
+        default no
+        help
+          Say yes here to support GPIO wakeup functionality of NUC980 chip
+
 config GPIO_74XX_MMIO
 	tristate "GPIO driver for 74xx-ICs with MMIO access"
 	depends on OF_GPIO
diff -uprN linux-4.4.194/drivers/gpio/Makefile NUC980-linux-4.4.194/drivers/gpio/Makefile
--- linux-4.4.194/drivers/gpio/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/gpio/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -119,3 +119,4 @@ obj-$(CONFIG_GPIO_XTENSA)	+= gpio-xtensa
 obj-$(CONFIG_GPIO_ZEVIO)	+= gpio-zevio.o
 obj-$(CONFIG_GPIO_ZYNQ)		+= gpio-zynq.o
 obj-$(CONFIG_GPIO_ZX)		+= gpio-zx.o
+obj-$(CONFIG_GPIO_NUC980)       += gpio-nuc980.o
diff -uprN linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p0.c NUC980-linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p0.c
--- linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p0.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p0.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,947 @@
+/*
+ * linux/drivers/i2c/busses/i2c-nuc980-p0.c
+ *
+ * Copyright (c) 2014 Nuvoton technology corporation.
+ *
+ * This driver based on S3C2410 I2C driver of Ben Dooks <ben-Y5A6D6n0/KfQXOPxS62xeg@public.gmane.org>.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+
+#include <linux/i2c.h>
+#include <linux/init.h>
+#include <linux/time.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/cpufreq.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+//#include <linux/of_i2c.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+
+#include <linux/pm_runtime.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/i2c-nuc980.h>
+
+/* nuc980 i2c registers offset */
+
+#define CTL0        0x00
+#define ADDR0       0x04
+#define DAT         0x08
+#define STATUS0     0x0C
+#define CLKDIV      0x10
+#define TOCTL       0x14
+#define ADDR1       0x18
+#define ADDR2       0x1C
+#define ADDR3       0x20
+#define ADDRMSK0    0x24
+#define ADDRMSK1    0x28
+#define ADDRMSK2    0x2C
+#define ADDRMSK3    0x30
+#define WKCTL       0x3C
+#define WKSTS       0x40
+#define CTL1        0x44
+#define STATUS1     0x48
+#define TMCTL       0x4C
+#define BUSCTL      0x50
+#define BUSTCTL     0x54
+#define BUSSTS      0x58
+#define PKTSIZE     0x5C
+#define PKTCRC      0x60
+#define BUSTOUT     0x64
+#define CLKTOUT     0x68
+
+/* nuc980 i2c Status */
+// Master
+#define  M_START                 0x08  //Start
+#define  M_REPEAT_START          0x10  //Master Repeat Start
+#define  M_TRAN_ADDR_ACK         0x18  //Master Transmit Address ACK
+#define  M_TRAN_ADDR_NACK        0x20  //Master Transmit Address NACK
+#define  M_TRAN_DATA_ACK         0x28  //Master Transmit Data ACK
+#define  M_TRAN_DATA_NACK        0x30  //Master Transmit Data NACK
+#define  M_ARB_LOST              0x38  //Master Arbitration Los
+#define  M_RECE_ADDR_ACK         0x40  //Master Receive Address ACK
+#define  M_RECE_ADDR_NACK        0x48  //Master Receive Address NACK
+#define  M_RECE_DATA_ACK         0x50  //Master Receive Data ACK
+#define  M_RECE_DATA_NACK        0x58  //Master Receive Data NACK
+#define  BUS_ERROR               0x00  //Bus error
+
+// Slave
+#define  S_REPEAT_START_STOP     0xA0  //Slave Transmit Repeat Start or Stop
+#define  S_TRAN_ADDR_ACK         0xA8  //Slave Transmit Address ACK
+#define  S_TRAN_DATA_ACK         0xB8  //Slave Transmit Data ACK
+#define  S_TRAN_DATA_NACK        0xC0  //Slave Transmit Data NACK
+#define  S_TRAN_LAST_DATA_ACK    0xC8  //Slave Transmit Last Data ACK
+#define  S_RECE_ADDR_ACK         0x60  //Slave Receive Address ACK
+#define  S_RECE_ARB_LOST         0x68  //Slave Receive Arbitration Lost
+#define  S_RECE_DATA_ACK         0x80  //Slave Receive Data ACK
+#define  S_RECE_DATA_NACK        0x88  //Slave Receive Data NACK
+
+//GC Mode
+#define  GC_ADDR_ACK             0x70  //GC mode Address ACK
+#define  GC_ARB_LOST             0x78  //GC mode Arbitration Lost
+#define  GC_DATA_ACK             0x90  //GC mode Data ACK
+#define  GC_DATA_NACK            0x98  //GC mode Data NACK
+
+//Other
+#define  ADDR_TRAN_ARB_LOST      0xB0  //Address Transmit Arbitration Lost
+#define  BUS_RELEASED            0xF8  //Bus Released
+
+
+/*---------------------------------------------------------------------------------------------------------*/
+/*  I2C_CTL constant definitions.                                                                            */
+/*---------------------------------------------------------------------------------------------------------*/
+#define I2C_CTL_STA_SI            0x28UL /* I2C_CTL setting for I2C control bits. It would set STA and SI bits       */
+#define I2C_CTL_STA_SI_AA         0x2CUL /* I2C_CTL setting for I2C control bits. It would set STA, SI and AA bits   */
+#define I2C_CTL_STO_SI            0x18UL /* I2C_CTL setting for I2C control bits. It would set STO and SI bits       */
+#define I2C_CTL_STO_SI_AA         0x1CUL /* I2C_CTL setting for I2C control bits. It would set STO, SI and AA bits   */
+#define I2C_CTL_SI                0x08UL /* I2C_CTL setting for I2C control bits. It would set SI bit                */
+#define I2C_CTL_SI_AA             0x0CUL /* I2C_CTL setting for I2C control bits. It would set SI and AA bits        */
+#define I2C_CTL_STA               0x20UL /* I2C_CTL setting for I2C control bits. It would set STA bit               */
+#define I2C_CTL_STO               0x10UL /* I2C_CTL setting for I2C control bits. It would set STO bit               */
+#define I2C_CTL_AA                0x04UL /* I2C_CTL setting for I2C control bits. It would set AA bit                */
+
+#define I2C_GCMODE_ENABLE   1    /*!< Enable I2C GC Mode  \hideinitializer */
+#define I2C_GCMODE_DISABLE  0    /*!< Disable I2C GC Mode  \hideinitializer */
+
+/* i2c controller private data */
+
+struct nuc980_i2c {
+	spinlock_t      lock;
+	wait_queue_head_t   wait;
+
+	struct i2c_msg      *msg;
+	unsigned int        msg_num;
+	unsigned int        msg_idx;
+	unsigned int        msg_ptr;
+	unsigned int        irq;
+	unsigned int        arblost;
+
+	void __iomem        *regs;
+	struct clk      *clk;
+	struct device       *dev;
+	struct resource     *ioarea;
+	struct i2c_adapter  adap;
+
+	struct i2c_client *slave;
+};
+
+/* nuc980_i2c0_master_complete
+ *
+ * complete the message and wake up the caller, using the given return code,
+ * or zero to mean ok.
+*/
+
+static inline void nuc980_i2c0_master_complete(struct nuc980_i2c *i2c, int ret)
+{
+	dev_dbg(i2c->dev, "master_complete %d\n", ret);
+
+	i2c->msg_ptr = 0;
+	i2c->msg = NULL;
+	i2c->msg_idx++;
+	i2c->msg_num = 0;
+	if (ret)
+		i2c->msg_idx = ret;
+
+	wake_up(&i2c->wait);
+}
+
+/* irq enable/disable functions */
+
+static inline void nuc980_i2c0_disable_irq(struct nuc980_i2c *i2c)
+{
+	unsigned long tmp;
+
+	tmp = readl(i2c->regs + CTL0);
+	writel(tmp & ~(0x1 << 7), i2c->regs + CTL0);
+}
+
+static inline void nuc980_i2c0_enable_irq(struct nuc980_i2c *i2c)
+{
+	unsigned long tmp;
+
+	tmp = readl(i2c->regs + CTL0);
+	writel(tmp | (0x1 << 7), i2c->regs + CTL0);
+}
+
+
+/* nuc980_i2c0_message_start
+ *
+ * put the start of a message onto the bus
+*/
+
+static void nuc980_i2c0_message_start(struct nuc980_i2c *i2c)
+{
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), i2c->regs + CTL0);
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA), i2c->regs + CTL0);
+}
+
+static inline void nuc980_i2c0_stop(struct nuc980_i2c *i2c, int ret)
+{
+	unsigned int tmp, i = 0;
+
+	dev_dbg(i2c->dev, "STOP\n");
+
+	if(readl(i2c->regs+CTL0) & 0x4){
+		writel((readl(i2c->regs+CTL0) &~ (0x4)), (i2c->regs+CTL0));
+		mdelay(1);
+	}
+
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_STO | I2C_CTL_SI)), (i2c->regs+CTL0));
+
+	while(readl(i2c->regs+CTL0) & I2C_CTL_STO){
+
+		i++;
+
+		if(i > 100000){
+			tmp = readl(i2c->regs+CLKDIV);
+
+			writel(0x59, REG_WRPRTR);
+			writel(0x16, REG_WRPRTR);
+			writel(0x88, REG_WRPRTR);
+
+			writel((readl(REG_APBIPRST1) |  (0x1)), REG_APBIPRST1);
+			udelay(1);
+			writel((readl(REG_APBIPRST1) &~ (0x1)), REG_APBIPRST1);
+                 
+			writel(0x1, REG_WRPRTR);
+
+			writel(tmp, (i2c->regs+CLKDIV));
+
+			mdelay(1);
+			writel((readl(i2c->regs+CTL0) | (0x40)), (i2c->regs+CTL0));
+		}
+	}
+
+	#if defined(CONFIG_ENABLE_I2C_P0_SLAVE_MODE)
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	#endif
+
+	nuc980_i2c0_master_complete(i2c, ret);
+}
+
+/* helper functions to determine the current state in the set of
+ * messages we are sending
+*/
+
+/* is_lastmsg()
+ *
+ * returns TRUE if the current message is the last in the set
+*/
+
+static inline int is_lastmsg(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_idx >= (i2c->msg_num - 1);
+}
+
+/* is_msglast
+ *
+ * returns TRUE if we this is the last byte in the current message
+*/
+
+static inline int is_msglast(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_ptr == i2c->msg->len-1;
+}
+
+/* is_msgend
+ *
+ * returns TRUE if we reached the end of the current message
+*/
+
+static inline int is_msgend(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_ptr >= i2c->msg->len;
+}
+
+
+
+#if defined(CONFIG_ENABLE_I2C_P0_SLAVE_MODE)
+static void I2C_SlaveTRx(struct nuc980_i2c *i2c, unsigned long iicstat)
+{
+	unsigned char byte;
+
+	if (iicstat == S_RECE_ADDR_ACK) {  /* Own SLA+W has been receive; ACK has been return */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C)) | (I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_RECE_DATA_ACK)  /* Previously address with own SLA address
+	                                           Data has been received; ACK has been returned*/
+	{
+		byte = readb(i2c->regs + DAT);
+
+		i2c_slave_event(i2c->slave, I2C_SLAVE_WRITE_RECEIVED, &byte);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if(iicstat == S_TRAN_ADDR_ACK) { /* Own SLA+R has been receive; ACK has been return */
+
+		i2c_slave_event(i2c->slave, I2C_SLAVE_READ_PROCESSED, &byte);    // I2C_SLAVE_READ_PROCESSED:
+		//i2c_slave_event(i2c->slave, I2C_SLAVE_REQ_READ_START, &byte);
+
+		writel(byte, i2c->regs+DAT);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_TRAN_DATA_NACK)     /* Data byte or last data in I2CDAT has been transmitted
+	                                               Not ACK has been received */
+	{
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_RECE_DATA_NACK)     /* Previously addressed with own SLA address; NOT ACK has
+	                                               been returned */
+	{
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_REPEAT_START_STOP)  /* A STOP or repeated START has been received while still
+	                                               addressed as Slave/Receiver*/
+	{
+		i2c_slave_event(i2c->slave, I2C_SLAVE_STOP, &byte);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else {
+		/* TO DO */
+		//printk("Status 0x%x is NOT processed\n", iicstat);
+	}
+}
+#else
+static void i2c_nuc980_irq_master_TRx(struct nuc980_i2c *i2c, unsigned long iicstat)
+{
+	unsigned char byte;
+
+	if (iicstat == M_START)
+	{ /* START has been transmitted and prepare SLA+W */
+
+		if (i2c->msg->flags & I2C_M_RD)
+			writel( (((i2c->msg->addr & 0x7f) << 1)|0x1), (i2c->regs+DAT)); /* Write SLA+R to Register I2CDAT */
+		else
+			writel( ((i2c->msg->addr & 0x7f) << 1), (i2c->regs+DAT)); /* Write SLA+W to Register I2CDAT */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+	}
+	else if ((iicstat == M_TRAN_ADDR_ACK) || (iicstat == M_TRAN_DATA_ACK))
+	{ /* SLA+W has been transmitted and ACK has been received */
+		//I2C_SET_DATA(I2C0, g_au8I2C_MasterTxData[g_u8I2C_MasterTxDataCnt++]);
+		//I2C_SET_CONTROL_REG(I2C0, I2C_SI);
+
+		if(iicstat == M_TRAN_ADDR_ACK)
+		{
+			if (is_lastmsg(i2c) && i2c->msg->len == 0)
+			{
+				nuc980_i2c0_stop(i2c, 0);
+				return;
+			}
+		}
+
+		if (!is_msgend(i2c))
+		{
+			byte = i2c->msg->buf[i2c->msg_ptr++];
+			writel(byte, i2c->regs+DAT);
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else if (!is_lastmsg(i2c))
+		{ /* we need to go to the next i2c message */
+			dev_dbg(i2c->dev, "WRITE: Next Message\n");
+
+			i2c->msg_ptr = 0;
+			i2c->msg_idx++;
+			i2c->msg++;
+
+			/* send the new start */
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else
+		{ /* send stop */
+			nuc980_i2c0_stop(i2c, 0);
+		}
+	}
+	else if ((iicstat == M_TRAN_ADDR_NACK) || (iicstat == M_RECE_ADDR_NACK))
+	{	/* Master Transmit Address NACK */
+		/* 0x20: SLA+W has been transmitted and NACK has been received */
+		/* 0x48: SLA+R has been transmitted and NACK has been received */
+		//I2C_SET_CONTROL_REG(I2C0, I2C_CTL_STA | I2C_CTL_STO | I2C_CTL_SI);
+
+		if (!(i2c->msg->flags & I2C_M_IGNORE_NAK))
+		{
+			printk("\n i2c_0: ack was not received\n");
+			//writel((I2C_CTL_STA | I2C_CTL_STO | I2C_CTL_SI), (i2c->regs+CTL0));
+			nuc980_i2c0_stop(i2c, -ENXIO);
+		}
+	}
+	else if (iicstat == M_REPEAT_START)
+	{  /* Repeat START has been transmitted and prepare SLA+R */
+
+		if (i2c->msg->flags & I2C_M_RD)
+			writel( (((i2c->msg->addr & 0x7f) << 1)|0x1), (i2c->regs+DAT)); /* Write SLA+R to Register I2CDAT */
+		else
+			writel( ((i2c->msg->addr & 0x7f) << 1), (i2c->regs+DAT)); /* Write SLA+W to Register I2CDAT */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+	}
+	else if (iicstat == M_RECE_ADDR_ACK)
+	{  /* SLA+R has been transmitted and ACK has been received */
+		//I2C_SET_CONTROL_REG(I2C0, I2C_AA | I2C_SI);
+
+		if (is_lastmsg(i2c) && (i2c->msg->len == 0))
+		{
+			nuc980_i2c0_stop(i2c, 0);
+			//return;
+		}
+		else
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI_AA), (i2c->regs+CTL0));
+	}
+	else if ((iicstat == M_RECE_DATA_ACK) || (iicstat == M_RECE_DATA_NACK))
+	{ /* DATA has been transmitted and ACK has been received */
+		byte = readb(i2c->regs + DAT);
+		i2c->msg->buf[i2c->msg_ptr++] = byte;
+
+		if (is_msglast(i2c))
+		{ /* last byte of buffer */
+
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+
+			//if (is_lastmsg(i2c))
+			//	writel((readl(i2c->regs+CTL0)|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else if (is_msgend(i2c))
+		{	/* ok, we've read the entire buffer, see if there
+			 * is anything else we need to do
+			 */
+
+			if (is_lastmsg(i2c))
+			{ /* last message, send stop and complete */
+				dev_dbg(i2c->dev, "READ: Send Stop\n");
+
+				nuc980_i2c0_stop(i2c, 0);
+			}
+			else
+			{ /* go to the next transfer */
+				dev_dbg(i2c->dev, "READ: Next Transfer\n");
+
+				i2c->msg_ptr = 0;
+				i2c->msg_idx++;
+				i2c->msg++;
+
+				/* send the new start */
+				writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA|I2C_CTL_SI), (i2c->regs+CTL0));
+			}
+		}
+		else
+		{
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI_AA), (i2c->regs+CTL0));
+		}
+
+	}
+	else
+	{
+		/* TO DO */
+		//printf("Status 0x%x is NOT processed\n", u32Status);
+	}
+
+
+}
+#endif
+
+/* nuc980_i2c_irq
+ *
+ * top level IRQ servicing routine
+*/
+
+static irqreturn_t nuc980_i2c_irq(int irqno, void *dev_id)
+{
+	struct nuc980_i2c *i2c = dev_id;
+	unsigned long status;
+
+	status = readl(i2c->regs + STATUS0);
+
+	if (status == M_ARB_LOST){
+		/* deal with arbitration loss */
+		dev_err(i2c->dev, "deal with arbitration loss\n");
+		i2c->arblost = 1;
+		
+		nuc980_i2c0_disable_irq(i2c);
+		nuc980_i2c0_stop(i2c, 0);
+		goto out;
+	}
+
+	if (status == BUS_ERROR) {
+		dev_dbg(i2c->dev, "IRQ: error i2c->state == IDLE\n");
+		goto out;
+	}
+
+	/* pretty much this leaves us with the fact that we've
+	 * transmitted or received whatever byte we last sent
+	*/
+
+	#if defined(CONFIG_ENABLE_I2C_P0_SLAVE_MODE)
+	I2C_SlaveTRx(i2c, status);
+	#else
+	i2c_nuc980_irq_master_TRx(i2c, status);
+	#endif
+
+out:
+	return IRQ_HANDLED;
+}
+
+#if 0
+/* nuc980_i2c0_hangup
+ *
+ * send out some dummy clocks to let SDA free
+*/
+static void nuc980_i2c0_hangup(struct nuc980_i2c *i2c)
+{
+	int i;
+
+	for(i=0;i<2;i++) {
+		writel(0x6, i2c->regs + SWR);       //CLK Low
+		ndelay(2);
+		writel(0x7, i2c->regs + SWR);       //CLK High
+		ndelay(2);
+	}
+}
+#endif
+
+/* nuc980_i2c0_doxfer
+ *
+ * this starts an i2c transfer
+*/
+
+static int nuc980_i2c0_doxfer(struct nuc980_i2c *i2c,
+				  struct i2c_msg *msgs, int num)
+{
+	unsigned long iicstat, timeout;
+	int spins = 20;
+	int ret;
+
+	spin_lock_irq(&i2c->lock);
+
+	nuc980_i2c0_enable_irq(i2c);
+
+	i2c->msg     = msgs;
+	i2c->msg_num = num;
+	i2c->msg_ptr = 0;
+	i2c->msg_idx = 0;
+
+	nuc980_i2c0_message_start(i2c);
+	spin_unlock_irq(&i2c->lock);
+
+	timeout = wait_event_timeout(i2c->wait, i2c->msg_num == 0, HZ * 5);
+	ret = i2c->msg_idx;
+
+	/* having these next two as dev_err() makes life very
+	 * noisy when doing an i2cdetect
+	*/
+
+	if (timeout == 0)
+		dev_dbg(i2c->dev, "timeout\n");
+	else if (ret != num)
+		dev_dbg(i2c->dev, "incomplete xfer (%d)\n", ret);
+
+	/* ensure the stop has been through the bus */
+	dev_dbg(i2c->dev, "waiting for bus idle\n");
+
+	/* first, try busy waiting briefly */
+	do
+	{
+		// chekc stop bit auto clear
+		iicstat = readl(i2c->regs + CTL0);
+	} while ((iicstat & (0x1<<4)) && --spins);
+
+	/* if that timed out sleep */
+	if (!spins) {
+		msleep(1);
+		iicstat = readl(i2c->regs + CTL0);
+	}
+
+	if (iicstat & (0x1<<4))
+		dev_warn(i2c->dev, "timeout waiting for bus idle\n");
+
+	if(i2c->arblost) {
+		dev_dbg(i2c->dev, "arb lost, stop\n");
+		i2c->arblost = 0;
+		nuc980_i2c0_stop(i2c, 0);
+		msleep(1);
+		nuc980_i2c0_disable_irq(i2c);
+		//nuc980_i2c0_hangup(i2c);
+		ret = -EAGAIN;
+	}
+
+// out:
+	return ret;
+}
+
+/* nuc980_i2c0_xfer
+ *
+ * first port of call from the i2c bus code when an message needs
+ * transferring across the i2c bus.
+*/
+
+static int nuc980_i2c0_xfer(struct i2c_adapter *adap, struct i2c_msg *msgs, int num)
+{
+	struct nuc980_i2c *i2c = (struct nuc980_i2c *)adap->algo_data;
+	int retry;
+	int ret;
+
+	for (retry = 0; retry < adap->retries; retry++) {
+
+		ret = nuc980_i2c0_doxfer(i2c, msgs, num);
+
+		if (ret != -EAGAIN)
+			return ret;
+
+		dev_dbg(i2c->dev, "Retrying transmission (%d)\n", retry);
+
+		udelay(100);
+	}
+
+	return -EREMOTEIO;
+}
+
+#if defined(CONFIG_ENABLE_I2C_P0_SLAVE_MODE)
+static int nuc980_reg_slave(struct i2c_client *slave)
+{
+	struct nuc980_i2c *priv = i2c_get_adapdata(slave->adapter);
+
+	if (priv->slave)
+		return -EBUSY;
+
+	if (slave->flags & I2C_CLIENT_TEN)
+		return -EAFNOSUPPORT;
+
+	nuc980_i2c0_enable_irq(priv);
+
+	pm_runtime_forbid(priv->dev);
+
+	priv->slave = slave;
+
+	// Enable I2C
+	writel(readl(priv->regs + CTL0) | (0x1 << 6), (priv->regs + CTL0)); // CTL0
+
+	// Set Slave Address
+	writel(slave->addr, (priv->regs + ADDR0));
+
+	// I2C enter SLV mode
+	writel((readl(priv->regs+CTL0)|I2C_CTL_AA|I2C_CTL_SI), (priv->regs+CTL0));
+
+	return 0;
+}
+
+static int nuc980_unreg_slave(struct i2c_client *slave)
+{
+	struct nuc980_i2c *priv = i2c_get_adapdata(slave->adapter);
+
+	// Disable I2C
+	writel(readl(priv->regs + CTL0) &~ (0x1 << 6), (priv->regs + CTL0)); // CTL0
+	// Disable i2c interrupt
+	nuc980_i2c0_disable_irq(priv);
+
+	priv->slave = NULL;
+
+	pm_runtime_allow(priv->dev);
+
+	return 0;
+}
+#endif
+
+/* declare our i2c functionality */
+static u32 nuc980_i2c0_func(struct i2c_adapter *adap)
+{
+	return I2C_FUNC_I2C | I2C_FUNC_PROTOCOL_MANGLING | I2C_FUNC_SMBUS_EMUL ;
+}
+
+/* i2c bus registration info */
+
+static const struct i2c_algorithm nuc980_i2c0_algorithm = {
+	.master_xfer        = nuc980_i2c0_xfer,
+	.functionality      = nuc980_i2c0_func,
+#if defined(CONFIG_ENABLE_I2C_P0_SLAVE_MODE)
+	.reg_slave	= nuc980_reg_slave,
+	.unreg_slave	= nuc980_unreg_slave,
+#endif
+};
+
+/* nuc980_i2c0_probe
+ *
+ * called by the bus driver when a suitable device is found
+*/
+
+static int nuc980_i2c0_probe(struct platform_device *pdev)
+{
+	struct nuc980_i2c *i2c;
+	struct nuc980_platform_i2c *pdata=NULL;
+	struct resource *res;
+	struct i2c_adapter *adap;
+	int ret;
+	int busnum = 0, busfreq = 0;
+	struct device *dev = &pdev->dev;
+
+	struct pinctrl *pinctrl;
+
+	if (!pdev->dev.of_node) {
+		pdata = pdev->dev.platform_data;
+		if (!pdata) {
+			dev_err(&pdev->dev, "no platform data\n");
+			return -EINVAL;
+		}
+	}
+
+	i2c = kzalloc(sizeof(struct nuc980_i2c), GFP_KERNEL);
+	if (!i2c) {
+		dev_err(&pdev->dev, "no memory for state\n");
+		return -ENOMEM;
+	}
+
+	strlcpy(i2c->adap.name, "nuc980-i2c0", sizeof(i2c->adap.name));
+	i2c->adap.owner   = THIS_MODULE;
+	i2c->adap.algo    = &nuc980_i2c0_algorithm;
+	i2c->adap.retries = 2;
+	i2c->adap.class   = I2C_CLASS_HWMON | I2C_CLASS_SPD;
+
+	spin_lock_init(&i2c->lock);
+	init_waitqueue_head(&i2c->wait);
+
+	/* find the clock and enable it */
+
+	i2c->dev = &pdev->dev;
+	i2c->clk = clk_get(NULL, "i2c0");
+	if (IS_ERR(i2c->clk)) {
+		dev_err(&pdev->dev, "cannot get clock\n");
+		ret = -ENOENT;
+		goto err_noclk;
+	}
+
+	dev_dbg(&pdev->dev, "clock source %p\n", i2c->clk);
+
+	clk_prepare(i2c->clk);
+	clk_enable(i2c->clk);
+
+	/* map the registers */
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (res == NULL) {
+		dev_err(&pdev->dev, "cannot find IO resource\n");
+		ret = -ENOENT;
+		goto err_clk;
+	}
+
+#if defined(CONFIG_USE_OF)
+	i2c->regs = devm_ioremap_resource(&pdev->dev, res);
+#else
+	i2c->ioarea = request_mem_region(res->start, resource_size(res), pdev->name);
+	if (i2c->ioarea == NULL) {
+		dev_err(&pdev->dev, "cannot request IO\n");
+		ret = -ENXIO;
+		goto err_clk;
+	}
+
+	i2c->regs = ioremap(res->start, resource_size(res));
+	if (i2c->regs == NULL) {
+		dev_err(&pdev->dev, "cannot map IO\n");
+		ret = -ENXIO;
+		goto err_ioarea;
+	}
+
+	dev_dbg(&pdev->dev, "registers %p (%p, %p)\n", i2c->regs, i2c->ioarea, res);
+#endif
+
+	/* setup info block for the i2c core */
+
+	i2c->adap.algo_data = i2c;
+	i2c->adap.dev.parent = &pdev->dev;
+
+	if (pdata) {
+		busfreq = pdata->bus_freq;
+		busnum = pdata->bus_num;
+	} else {
+		of_property_read_u32(pdev->dev.of_node, "bus_freq", &busfreq);
+		of_property_read_u32(pdev->dev.of_node, "bus_num", &busnum);
+	}
+
+	// Set Clock divider
+	ret = clk_get_rate(i2c->clk)/(busfreq * 4) - 1;
+	writel(ret & 0xffff, i2c->regs + CLKDIV);
+
+	writel((readl(i2c->regs+CTL0)|(0x1 << 6)), i2c->regs + CTL0);
+
+	/* find the IRQ for this unit (note, this relies on the init call to
+	 * ensure no current IRQs pending
+	 */
+
+	i2c->irq = ret = platform_get_irq(pdev, 0);
+	if (ret <= 0) {
+		dev_err(&pdev->dev, "cannot find IRQ\n");
+		goto err_iomap;
+	}
+
+	ret = request_irq(i2c->irq, nuc980_i2c_irq, IRQF_SHARED, dev_name(&pdev->dev), i2c);
+
+	if (ret != 0) {
+		dev_err(&pdev->dev, "cannot claim IRQ %d\n", i2c->irq);
+		goto err_iomap;
+	}
+
+	/* Note, previous versions of the driver used i2c_add_adapter()
+	 * to add the bus at any number. We now pass the bus number via
+	 * the platform data, so if unset it will now default to always
+	 * being bus 0.
+	 */
+
+	adap = &i2c->adap;
+
+	i2c->adap.nr = busnum;
+	i2c->adap.dev.of_node = pdev->dev.of_node;
+
+	ret = i2c_add_numbered_adapter(&i2c->adap);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "failed to add bus to i2c core\n");
+		goto err_irq;
+	}
+	//of_i2c_register_devices(&i2c->adap);
+
+	i2c_set_adapdata(adap, i2c);
+	strlcpy(adap->name, pdev->name, sizeof(adap->name));
+
+	pm_runtime_enable(dev);
+
+	platform_set_drvdata(pdev, i2c);
+
+	dev_info(&pdev->dev, "%s: nuc980 I2C adapter\n", dev_name(&i2c->adap.dev));
+
+#if defined(CONFIG_USE_OF)
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+ #ifdef CONFIG_NUC980_I2C0_PA
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c0-PA");
+ #elif defined(CONFIG_NUC980_I2C0_PA_PG)
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c0-PA_PG");
+ #elif defined(CONFIG_NUC980_I2C0_PE)
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c0-PE");
+ #endif
+#endif
+
+	if (IS_ERR(pinctrl)) {
+		return PTR_ERR(pinctrl);
+	}
+
+	return 0;
+
+err_irq:
+	free_irq(i2c->irq, i2c);
+
+err_iomap:
+	iounmap(i2c->regs);
+
+#ifndef CONFIG_USE_OF
+err_ioarea:
+	release_resource(i2c->ioarea);
+	kfree(i2c->ioarea);
+#endif
+
+err_clk:
+	clk_disable(i2c->clk);
+	clk_put(i2c->clk);
+
+err_noclk:
+	kfree(i2c);
+	return ret;
+}
+
+/* nuc980_i2c0_remove
+ *
+ * called when device is removed from the bus
+*/
+
+static int nuc980_i2c0_remove(struct platform_device *pdev)
+{
+	struct nuc980_i2c *i2c = platform_get_drvdata(pdev);
+
+	i2c_del_adapter(&i2c->adap);
+	free_irq(i2c->irq, i2c);
+
+	clk_disable(i2c->clk);
+	clk_put(i2c->clk);
+
+	iounmap(i2c->regs);
+
+	release_resource(i2c->ioarea);
+	kfree(i2c->ioarea);
+	kfree(i2c);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_i2c0_suspend(struct device *dev)
+{
+#ifdef CONFIG_SLAVE_WAKEUP
+	struct nuc980_i2c *i2c = dev_get_drvdata(dev);
+
+	__raw_writel((1<<0) | __raw_readl(REG_WKUPSER1),REG_WKUPSER1);
+
+	nuc980_i2c0_enable_irq(i2c);
+
+	writel(I2C_CTL_SI_AA | readl(i2c->regs + CTL0), i2c->regs + CTL0);
+	writel(0x1, i2c->regs + WKCTL);
+	writel(readl(i2c->regs + WKSTS), i2c->regs + WKSTS);
+
+	enable_irq_wake(i2c->irq);
+#endif
+
+	return 0;
+}
+
+static int nuc980_i2c0_resume(struct device *dev)
+{
+#ifdef CONFIG_SLAVE_WAKEUP
+	struct nuc980_i2c *i2c = dev_get_drvdata(dev);
+
+	writel(0x0, i2c->regs + WKCTL);
+	writel(readl(i2c->regs + WKSTS), i2c->regs + WKSTS);
+#endif
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_i2c0_pmops = {
+	.suspend    = nuc980_i2c0_suspend,
+	.resume     = nuc980_i2c0_resume,
+};
+
+#define NUC980_I2C0_PMOPS (&nuc980_i2c0_pmops)
+
+#else
+#define NUC980_I2C0_PMOPS NULL
+#endif
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_i2c0_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-i2c0" },
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_i2c0_of_match);
+#endif
+
+static struct platform_driver nuc980_i2c0_driver = {
+	.probe      = nuc980_i2c0_probe,
+	.remove     = nuc980_i2c0_remove,
+	.driver     = {
+		.name   = "nuc980-i2c0",
+		.owner  = THIS_MODULE,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_i2c0_of_match),
+#endif
+		.pm = NUC980_I2C0_PMOPS,
+	},
+};
+module_platform_driver(nuc980_i2c0_driver);
+
+MODULE_DESCRIPTION("nuc980 I2C Bus driver");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-i2c0");
diff -uprN linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p1.c NUC980-linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p1.c
--- linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p1.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p1.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,947 @@
+/*
+ * linux/drivers/i2c/busses/i2c-nuc980-p1.c
+ *
+ * Copyright (c) 2014 Nuvoton technology corporation.
+ *
+ * This driver based on S3C2410 I2C driver of Ben Dooks <ben-Y5A6D6n0/KfQXOPxS62xeg@public.gmane.org>.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+
+#include <linux/i2c.h>
+#include <linux/init.h>
+#include <linux/time.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/cpufreq.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+//#include <linux/of_i2c.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+
+#include <linux/pm_runtime.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/i2c-nuc980.h>
+
+/* nuc980 i2c registers offset */
+
+#define CTL0        0x00
+#define ADDR0       0x04
+#define DAT         0x08
+#define STATUS0     0x0C
+#define CLKDIV      0x10
+#define TOCTL       0x14
+#define ADDR1       0x18
+#define ADDR2       0x1C
+#define ADDR3       0x20
+#define ADDRMSK0    0x24
+#define ADDRMSK1    0x28
+#define ADDRMSK2    0x2C
+#define ADDRMSK3    0x30
+#define WKCTL       0x3C
+#define WKSTS       0x40
+#define CTL1        0x44
+#define STATUS1     0x48
+#define TMCTL       0x4C
+#define BUSCTL      0x50
+#define BUSTCTL     0x54
+#define BUSSTS      0x58
+#define PKTSIZE     0x5C
+#define PKTCRC      0x60
+#define BUSTOUT     0x64
+#define CLKTOUT     0x68
+
+/* nuc980 i2c Status */
+// Master
+#define  M_START                 0x08  //Start
+#define  M_REPEAT_START          0x10  //Master Repeat Start
+#define  M_TRAN_ADDR_ACK         0x18  //Master Transmit Address ACK
+#define  M_TRAN_ADDR_NACK        0x20  //Master Transmit Address NACK
+#define  M_TRAN_DATA_ACK         0x28  //Master Transmit Data ACK
+#define  M_TRAN_DATA_NACK        0x30  //Master Transmit Data NACK
+#define  M_ARB_LOST              0x38  //Master Arbitration Los
+#define  M_RECE_ADDR_ACK         0x40  //Master Receive Address ACK
+#define  M_RECE_ADDR_NACK        0x48  //Master Receive Address NACK
+#define  M_RECE_DATA_ACK         0x50  //Master Receive Data ACK
+#define  M_RECE_DATA_NACK        0x58  //Master Receive Data NACK
+#define  BUS_ERROR               0x00  //Bus error
+
+// Slave
+#define  S_REPEAT_START_STOP     0xA0  //Slave Transmit Repeat Start or Stop
+#define  S_TRAN_ADDR_ACK         0xA8  //Slave Transmit Address ACK
+#define  S_TRAN_DATA_ACK         0xB8  //Slave Transmit Data ACK
+#define  S_TRAN_DATA_NACK        0xC0  //Slave Transmit Data NACK
+#define  S_TRAN_LAST_DATA_ACK    0xC8  //Slave Transmit Last Data ACK
+#define  S_RECE_ADDR_ACK         0x60  //Slave Receive Address ACK
+#define  S_RECE_ARB_LOST         0x68  //Slave Receive Arbitration Lost
+#define  S_RECE_DATA_ACK         0x80  //Slave Receive Data ACK
+#define  S_RECE_DATA_NACK        0x88  //Slave Receive Data NACK
+
+//GC Mode
+#define  GC_ADDR_ACK             0x70  //GC mode Address ACK
+#define  GC_ARB_LOST             0x78  //GC mode Arbitration Lost
+#define  GC_DATA_ACK             0x90  //GC mode Data ACK
+#define  GC_DATA_NACK            0x98  //GC mode Data NACK
+
+//Other
+#define  ADDR_TRAN_ARB_LOST      0xB0  //Address Transmit Arbitration Lost
+#define  BUS_RELEASED            0xF8  //Bus Released
+
+
+/*---------------------------------------------------------------------------------------------------------*/
+/*  I2C_CTL constant definitions.                                                                            */
+/*---------------------------------------------------------------------------------------------------------*/
+#define I2C_CTL_STA_SI            0x28UL /* I2C_CTL setting for I2C control bits. It would set STA and SI bits       */
+#define I2C_CTL_STA_SI_AA         0x2CUL /* I2C_CTL setting for I2C control bits. It would set STA, SI and AA bits   */
+#define I2C_CTL_STO_SI            0x18UL /* I2C_CTL setting for I2C control bits. It would set STO and SI bits       */
+#define I2C_CTL_STO_SI_AA         0x1CUL /* I2C_CTL setting for I2C control bits. It would set STO, SI and AA bits   */
+#define I2C_CTL_SI                0x08UL /* I2C_CTL setting for I2C control bits. It would set SI bit                */
+#define I2C_CTL_SI_AA             0x0CUL /* I2C_CTL setting for I2C control bits. It would set SI and AA bits        */
+#define I2C_CTL_STA               0x20UL /* I2C_CTL setting for I2C control bits. It would set STA bit               */
+#define I2C_CTL_STO               0x10UL /* I2C_CTL setting for I2C control bits. It would set STO bit               */
+#define I2C_CTL_AA                0x04UL /* I2C_CTL setting for I2C control bits. It would set AA bit                */
+
+#define I2C_GCMODE_ENABLE   1    /*!< Enable I2C GC Mode  \hideinitializer */
+#define I2C_GCMODE_DISABLE  0    /*!< Disable I2C GC Mode  \hideinitializer */
+
+/* i2c controller private data */
+
+struct nuc980_i2c {
+	spinlock_t      lock;
+	wait_queue_head_t   wait;
+
+	struct i2c_msg      *msg;
+	unsigned int        msg_num;
+	unsigned int        msg_idx;
+	unsigned int        msg_ptr;
+	unsigned int        irq;
+	unsigned int        arblost;
+
+	void __iomem        *regs;
+	struct clk      *clk;
+	struct device       *dev;
+	struct resource     *ioarea;
+	struct i2c_adapter  adap;
+
+	struct i2c_client *slave;
+};
+
+/* nuc980_i2c1_master_complete
+ *
+ * complete the message and wake up the caller, using the given return code,
+ * or zero to mean ok.
+*/
+
+static inline void nuc980_i2c1_master_complete(struct nuc980_i2c *i2c, int ret)
+{
+	dev_dbg(i2c->dev, "master_complete %d\n", ret);
+
+	i2c->msg_ptr = 0;
+	i2c->msg = NULL;
+	i2c->msg_idx++;
+	i2c->msg_num = 0;
+	if (ret)
+		i2c->msg_idx = ret;
+
+	wake_up(&i2c->wait);
+}
+
+/* irq enable/disable functions */
+
+static inline void nuc980_i2c1_disable_irq(struct nuc980_i2c *i2c)
+{
+	unsigned long tmp;
+
+	tmp = readl(i2c->regs + CTL0);
+	writel(tmp & ~(0x1 << 7), i2c->regs + CTL0);
+}
+
+static inline void nuc980_i2c1_enable_irq(struct nuc980_i2c *i2c)
+{
+	unsigned long tmp;
+
+	tmp = readl(i2c->regs + CTL0);
+	writel(tmp | (0x1 << 7), i2c->regs + CTL0);
+}
+
+
+/* nuc980_i2c1_message_start
+ *
+ * put the start of a message onto the bus
+*/
+
+static void nuc980_i2c1_message_start(struct nuc980_i2c *i2c)
+{
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), i2c->regs + CTL0);
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA), i2c->regs + CTL0);
+}
+
+static inline void nuc980_i2c1_stop(struct nuc980_i2c *i2c, int ret)
+{
+	unsigned int tmp, i = 0;
+
+	dev_dbg(i2c->dev, "STOP\n");
+
+	if(readl(i2c->regs+CTL0) & 0x4){
+		writel((readl(i2c->regs+CTL0) &~ (0x4)), (i2c->regs+CTL0));
+		mdelay(1);
+	}
+
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_STO | I2C_CTL_SI)), (i2c->regs+CTL0));
+
+	while(readl(i2c->regs+CTL0) & I2C_CTL_STO){
+
+		i++;
+
+		if(i > 100000){
+			tmp = readl(i2c->regs+CLKDIV);
+
+			writel(0x59, REG_WRPRTR);
+			writel(0x16, REG_WRPRTR);
+			writel(0x88, REG_WRPRTR);
+
+			writel((readl(REG_APBIPRST1) |  (0x1 << 1)), REG_APBIPRST1);
+			udelay(1);
+			writel((readl(REG_APBIPRST1) &~ (0x1 << 1)), REG_APBIPRST1);
+                 
+			writel(0x1, REG_WRPRTR);
+
+			writel(tmp, (i2c->regs+CLKDIV));
+
+			mdelay(1);
+			writel((readl(i2c->regs+CTL0) | (0x40)), (i2c->regs+CTL0));
+		}
+	}
+
+	#if defined(CONFIG_ENABLE_I2C_P1_SLAVE_MODE)
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	#endif
+
+	nuc980_i2c1_master_complete(i2c, ret);
+}
+
+/* helper functions to determine the current state in the set of
+ * messages we are sending
+*/
+
+/* is_lastmsg()
+ *
+ * returns TRUE if the current message is the last in the set
+*/
+
+static inline int is_lastmsg(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_idx >= (i2c->msg_num - 1);
+}
+
+/* is_msglast
+ *
+ * returns TRUE if we this is the last byte in the current message
+*/
+
+static inline int is_msglast(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_ptr == i2c->msg->len-1;
+}
+
+/* is_msgend
+ *
+ * returns TRUE if we reached the end of the current message
+*/
+
+static inline int is_msgend(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_ptr >= i2c->msg->len;
+}
+
+
+
+#if defined(CONFIG_ENABLE_I2C_P1_SLAVE_MODE)
+static void I2C_SlaveTRx(struct nuc980_i2c *i2c, unsigned long iicstat)
+{
+	unsigned char byte;
+
+	if (iicstat == S_RECE_ADDR_ACK) {  /* Own SLA+W has been receive; ACK has been return */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C)) | (I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_RECE_DATA_ACK)  /* Previously address with own SLA address
+	                                           Data has been received; ACK has been returned*/
+	{
+		byte = readb(i2c->regs + DAT);
+
+		i2c_slave_event(i2c->slave, I2C_SLAVE_WRITE_RECEIVED, &byte);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if(iicstat == S_TRAN_ADDR_ACK) { /* Own SLA+R has been receive; ACK has been return */
+
+		i2c_slave_event(i2c->slave, I2C_SLAVE_READ_PROCESSED, &byte);    // I2C_SLAVE_READ_PROCESSED:
+		//i2c_slave_event(i2c->slave, I2C_SLAVE_REQ_READ_START, &byte);
+
+		writel(byte, i2c->regs+DAT);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_TRAN_DATA_NACK)     /* Data byte or last data in I2CDAT has been transmitted
+	                                               Not ACK has been received */
+	{
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_RECE_DATA_NACK)     /* Previously addressed with own SLA address; NOT ACK has
+	                                               been returned */
+	{
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_REPEAT_START_STOP)  /* A STOP or repeated START has been received while still
+	                                               addressed as Slave/Receiver*/
+	{
+		i2c_slave_event(i2c->slave, I2C_SLAVE_STOP, &byte);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else {
+		/* TO DO */
+		//printk("Status 0x%x is NOT processed\n", iicstat);
+	}
+}
+#else
+static void i2c_nuc980_irq_master_TRx(struct nuc980_i2c *i2c, unsigned long iicstat)
+{
+	unsigned char byte;
+
+	if (iicstat == M_START)
+	{ /* START has been transmitted and prepare SLA+W */
+
+		if (i2c->msg->flags & I2C_M_RD)
+			writel( (((i2c->msg->addr & 0x7f) << 1)|0x1), (i2c->regs+DAT)); /* Write SLA+R to Register I2CDAT */
+		else
+			writel( ((i2c->msg->addr & 0x7f) << 1), (i2c->regs+DAT)); /* Write SLA+W to Register I2CDAT */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+	}
+	else if ((iicstat == M_TRAN_ADDR_ACK) || (iicstat == M_TRAN_DATA_ACK))
+	{ /* SLA+W has been transmitted and ACK has been received */
+		//I2C_SET_DATA(i2c1, g_au8I2C_MasterTxData[g_u8I2C_MasterTxDataCnt++]);
+		//I2C_SET_CONTROL_REG(i2c1, I2C_SI);
+
+		if(iicstat == M_TRAN_ADDR_ACK)
+		{
+			if (is_lastmsg(i2c) && i2c->msg->len == 0)
+			{
+				nuc980_i2c1_stop(i2c, 0);
+				return;
+			}
+		}
+
+		if (!is_msgend(i2c))
+		{
+			byte = i2c->msg->buf[i2c->msg_ptr++];
+			writel(byte, i2c->regs+DAT);
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else if (!is_lastmsg(i2c))
+		{ /* we need to go to the next i2c message */
+			dev_dbg(i2c->dev, "WRITE: Next Message\n");
+
+			i2c->msg_ptr = 0;
+			i2c->msg_idx++;
+			i2c->msg++;
+
+			/* send the new start */
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else
+		{ /* send stop */
+			nuc980_i2c1_stop(i2c, 0);
+		}
+	}
+	else if ((iicstat == M_TRAN_ADDR_NACK) || (iicstat == M_RECE_ADDR_NACK))
+	{	/* Master Transmit Address NACK */
+		/* 0x20: SLA+W has been transmitted and NACK has been received */
+		/* 0x48: SLA+R has been transmitted and NACK has been received */
+		//I2C_SET_CONTROL_REG(i2c1, I2C_CTL_STA | I2C_CTL_STO | I2C_CTL_SI);
+
+		if (!(i2c->msg->flags & I2C_M_IGNORE_NAK))
+		{
+			printk("\n i2c_0: ack was not received\n");
+			//writel((I2C_CTL_STA | I2C_CTL_STO | I2C_CTL_SI), (i2c->regs+CTL0));
+			nuc980_i2c1_stop(i2c, -ENXIO);
+		}
+	}
+	else if (iicstat == M_REPEAT_START)
+	{  /* Repeat START has been transmitted and prepare SLA+R */
+
+		if (i2c->msg->flags & I2C_M_RD)
+			writel( (((i2c->msg->addr & 0x7f) << 1)|0x1), (i2c->regs+DAT)); /* Write SLA+R to Register I2CDAT */
+		else
+			writel( ((i2c->msg->addr & 0x7f) << 1), (i2c->regs+DAT)); /* Write SLA+W to Register I2CDAT */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+	}
+	else if (iicstat == M_RECE_ADDR_ACK)
+	{  /* SLA+R has been transmitted and ACK has been received */
+		//I2C_SET_CONTROL_REG(i2c1, I2C_AA | I2C_SI);
+
+		if (is_lastmsg(i2c) && i2c->msg->len == 0)
+		{
+			nuc980_i2c1_stop(i2c, 0);
+			//return;
+		}
+		else
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI_AA), (i2c->regs+CTL0));
+	}
+	else if ((iicstat == M_RECE_DATA_ACK) || (iicstat == M_RECE_DATA_NACK))
+	{ /* DATA has been transmitted and ACK has been received */
+		byte = readb(i2c->regs + DAT);
+		i2c->msg->buf[i2c->msg_ptr++] = byte;
+
+		if (is_msglast(i2c))
+		{ /* last byte of buffer */
+
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+
+			//if (is_lastmsg(i2c))
+			//	writel((readl(i2c->regs+CTL0)|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else if (is_msgend(i2c))
+		{	/* ok, we've read the entire buffer, see if there
+			 * is anything else we need to do
+			 */
+
+			if (is_lastmsg(i2c))
+			{ /* last message, send stop and complete */
+				dev_dbg(i2c->dev, "READ: Send Stop\n");
+
+				nuc980_i2c1_stop(i2c, 0);
+			}
+			else
+			{ /* go to the next transfer */
+				dev_dbg(i2c->dev, "READ: Next Transfer\n");
+
+				i2c->msg_ptr = 0;
+				i2c->msg_idx++;
+				i2c->msg++;
+
+				/* send the new start */
+				writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA|I2C_CTL_SI), (i2c->regs+CTL0));
+			}
+		}
+		else
+		{
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI_AA), (i2c->regs+CTL0));
+		}
+
+	}
+	else
+	{
+		/* TO DO */
+		//printf("Status 0x%x is NOT processed\n", u32Status);
+	}
+
+
+}
+#endif
+
+/* nuc980_i2c_irq
+ *
+ * top level IRQ servicing routine
+*/
+
+static irqreturn_t nuc980_i2c_irq(int irqno, void *dev_id)
+{
+	struct nuc980_i2c *i2c = dev_id;
+	unsigned long status;
+
+	status = readl(i2c->regs + STATUS0);
+
+	if (status == M_ARB_LOST) {
+		/* deal with arbitration loss */
+		dev_err(i2c->dev, "deal with arbitration loss\n");
+		i2c->arblost = 1;
+		
+		nuc980_i2c1_disable_irq(i2c);
+		nuc980_i2c1_stop(i2c, 0);
+		goto out;
+	}
+
+	if (status == BUS_ERROR) {
+		dev_dbg(i2c->dev, "IRQ: error i2c->state == IDLE\n");
+		goto out;
+	}
+
+	/* pretty much this leaves us with the fact that we've
+	 * transmitted or received whatever byte we last sent
+	*/
+
+	#if defined(CONFIG_ENABLE_I2C_P1_SLAVE_MODE)
+	I2C_SlaveTRx(i2c, status);
+	#else
+	i2c_nuc980_irq_master_TRx(i2c, status);
+	#endif
+
+out:
+	return IRQ_HANDLED;
+}
+
+#if 0
+/* nuc980_i2c1_hangup
+ *
+ * send out some dummy clocks to let SDA free
+*/
+static void nuc980_i2c1_hangup(struct nuc980_i2c *i2c)
+{
+	int i;
+
+	for(i=0;i<2;i++) {
+		writel(0x6, i2c->regs + SWR);       //CLK Low
+		ndelay(2);
+		writel(0x7, i2c->regs + SWR);       //CLK High
+		ndelay(2);
+	}
+}
+#endif
+
+/* nuc980_i2c1_doxfer
+ *
+ * this starts an i2c transfer
+*/
+
+static int nuc980_i2c1_doxfer(struct nuc980_i2c *i2c,
+				  struct i2c_msg *msgs, int num)
+{
+	unsigned long iicstat, timeout;
+	int spins = 20;
+	int ret;
+
+	spin_lock_irq(&i2c->lock);
+
+	nuc980_i2c1_enable_irq(i2c);
+
+	i2c->msg     = msgs;
+	i2c->msg_num = num;
+	i2c->msg_ptr = 0;
+	i2c->msg_idx = 0;
+
+	nuc980_i2c1_message_start(i2c);
+	spin_unlock_irq(&i2c->lock);
+
+	timeout = wait_event_timeout(i2c->wait, i2c->msg_num == 0, HZ * 5);
+	ret = i2c->msg_idx;
+
+	/* having these next two as dev_err() makes life very
+	 * noisy when doing an i2cdetect
+	*/
+
+	if (timeout == 0)
+		dev_dbg(i2c->dev, "timeout\n");
+	else if (ret != num)
+		dev_dbg(i2c->dev, "incomplete xfer (%d)\n", ret);
+
+	/* ensure the stop has been through the bus */
+	dev_dbg(i2c->dev, "waiting for bus idle\n");
+
+	/* first, try busy waiting briefly */
+	do
+	{
+		// chekc stop bit auto clear
+		iicstat = readl(i2c->regs + CTL0);
+	} while ((iicstat & (0x1<<4)) && --spins);
+
+	/* if that timed out sleep */
+	if (!spins) {
+		msleep(1);
+		iicstat = readl(i2c->regs + CTL0);
+	}
+
+	if (iicstat & (0x1<<4))
+		dev_warn(i2c->dev, "timeout waiting for bus idle\n");
+
+	if(i2c->arblost) {
+		dev_dbg(i2c->dev, "arb lost, stop\n");
+		i2c->arblost = 0;
+		nuc980_i2c1_stop(i2c, 0);
+		msleep(1);
+		nuc980_i2c1_disable_irq(i2c);
+		//nuc980_i2c1_hangup(i2c);
+		ret = -EAGAIN;
+	}
+
+// out:
+	return ret;
+}
+
+/* nuc980_i2c1_xfer
+ *
+ * first port of call from the i2c bus code when an message needs
+ * transferring across the i2c bus.
+*/
+
+static int nuc980_i2c1_xfer(struct i2c_adapter *adap, struct i2c_msg *msgs, int num)
+{
+	struct nuc980_i2c *i2c = (struct nuc980_i2c *)adap->algo_data;
+	int retry;
+	int ret;
+
+	for (retry = 0; retry < adap->retries; retry++) {
+
+		ret = nuc980_i2c1_doxfer(i2c, msgs, num);
+
+		if (ret != -EAGAIN)
+			return ret;
+
+		dev_dbg(i2c->dev, "Retrying transmission (%d)\n", retry);
+
+		udelay(100);
+	}
+
+	return -EREMOTEIO;
+}
+
+#if defined(CONFIG_ENABLE_I2C_P1_SLAVE_MODE)
+static int nuc980_reg_slave(struct i2c_client *slave)
+{
+	struct nuc980_i2c *priv = i2c_get_adapdata(slave->adapter);
+
+	if (priv->slave)
+		return -EBUSY;
+
+	if (slave->flags & I2C_CLIENT_TEN)
+		return -EAFNOSUPPORT;
+
+	nuc980_i2c1_enable_irq(priv);
+
+	pm_runtime_forbid(priv->dev);
+
+	priv->slave = slave;
+
+	// Enable I2C
+	writel(readl(priv->regs + CTL0) | (0x1 << 6), (priv->regs + CTL0)); // CTL0
+
+	// Set Slave Address
+	writel(slave->addr, (priv->regs + ADDR0));
+
+	// I2C enter SLV mode
+	writel((readl(priv->regs+CTL0)|I2C_CTL_AA|I2C_CTL_SI), (priv->regs+CTL0));
+
+	return 0;
+}
+
+static int nuc980_unreg_slave(struct i2c_client *slave)
+{
+	struct nuc980_i2c *priv = i2c_get_adapdata(slave->adapter);
+
+	// Disable I2C
+	writel(readl(priv->regs + CTL0) &~ (0x1 << 6), (priv->regs + CTL0)); // CTL0
+	// Disable i2c interrupt
+	nuc980_i2c1_disable_irq(priv);
+
+	priv->slave = NULL;
+
+	pm_runtime_allow(priv->dev);
+
+	return 0;
+}
+#endif
+
+/* declare our i2c functionality */
+static u32 nuc980_i2c1_func(struct i2c_adapter *adap)
+{
+	return I2C_FUNC_I2C | I2C_FUNC_PROTOCOL_MANGLING | I2C_FUNC_SMBUS_EMUL ;
+}
+
+/* i2c bus registration info */
+
+static const struct i2c_algorithm nuc980_i2c1_algorithm = {
+	.master_xfer        = nuc980_i2c1_xfer,
+	.functionality      = nuc980_i2c1_func,
+#if defined(CONFIG_ENABLE_I2C_P1_SLAVE_MODE)
+	.reg_slave	= nuc980_reg_slave,
+	.unreg_slave	= nuc980_unreg_slave,
+#endif
+};
+
+/* nuc980_i2c1_probe
+ *
+ * called by the bus driver when a suitable device is found
+*/
+
+static int nuc980_i2c1_probe(struct platform_device *pdev)
+{
+	struct nuc980_i2c *i2c;
+	struct nuc980_platform_i2c *pdata=NULL;
+	struct resource *res;
+	struct i2c_adapter *adap;
+	int ret;
+	int busnum = 0, busfreq = 0;
+	struct device *dev = &pdev->dev;
+
+	struct pinctrl *pinctrl;
+
+	if (!pdev->dev.of_node) {
+		pdata = pdev->dev.platform_data;
+		if (!pdata) {
+			dev_err(&pdev->dev, "no platform data\n");
+			return -EINVAL;
+		}
+	}
+
+	i2c = kzalloc(sizeof(struct nuc980_i2c), GFP_KERNEL);
+	if (!i2c) {
+		dev_err(&pdev->dev, "no memory for state\n");
+		return -ENOMEM;
+	}
+
+	strlcpy(i2c->adap.name, "nuc980-i2c1", sizeof(i2c->adap.name));
+	i2c->adap.owner   = THIS_MODULE;
+	i2c->adap.algo    = &nuc980_i2c1_algorithm;
+	i2c->adap.retries = 2;
+	i2c->adap.class   = I2C_CLASS_HWMON | I2C_CLASS_SPD;
+
+	spin_lock_init(&i2c->lock);
+	init_waitqueue_head(&i2c->wait);
+
+	/* find the clock and enable it */
+
+	i2c->dev = &pdev->dev;
+	i2c->clk = clk_get(NULL, "i2c1");
+	if (IS_ERR(i2c->clk)) {
+		dev_err(&pdev->dev, "cannot get clock\n");
+		ret = -ENOENT;
+		goto err_noclk;
+	}
+
+	dev_dbg(&pdev->dev, "clock source %p\n", i2c->clk);
+
+	clk_prepare(i2c->clk);
+	clk_enable(i2c->clk);
+
+	/* map the registers */
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (res == NULL) {
+		dev_err(&pdev->dev, "cannot find IO resource\n");
+		ret = -ENOENT;
+		goto err_clk;
+	}
+
+#if defined(CONFIG_USE_OF)
+	i2c->regs = devm_ioremap_resource(&pdev->dev, res);
+#else
+	i2c->ioarea = request_mem_region(res->start, resource_size(res), pdev->name);
+	if (i2c->ioarea == NULL) {
+		dev_err(&pdev->dev, "cannot request IO\n");
+		ret = -ENXIO;
+		goto err_clk;
+	}
+
+	i2c->regs = ioremap(res->start, resource_size(res));
+	if (i2c->regs == NULL) {
+		dev_err(&pdev->dev, "cannot map IO\n");
+		ret = -ENXIO;
+		goto err_ioarea;
+	}
+
+	dev_dbg(&pdev->dev, "registers %p (%p, %p)\n", i2c->regs, i2c->ioarea, res);
+#endif
+
+	/* setup info block for the i2c core */
+
+	i2c->adap.algo_data = i2c;
+	i2c->adap.dev.parent = &pdev->dev;
+
+	if (pdata) {
+		busfreq = pdata->bus_freq;
+		busnum = pdata->bus_num;
+	} else {
+		of_property_read_u32(pdev->dev.of_node, "bus_freq", &busfreq);
+		of_property_read_u32(pdev->dev.of_node, "bus_num", &busnum);
+	}
+
+	// Set Clock divider
+	ret = clk_get_rate(i2c->clk)/(busfreq * 4) - 1;
+	writel(ret & 0xffff, i2c->regs + CLKDIV);
+
+	writel((readl(i2c->regs+CTL0)|(0x1 << 6)), i2c->regs + CTL0);
+
+	/* find the IRQ for this unit (note, this relies on the init call to
+	 * ensure no current IRQs pending
+	 */
+
+	i2c->irq = ret = platform_get_irq(pdev, 0);
+	if (ret <= 0) {
+		dev_err(&pdev->dev, "cannot find IRQ\n");
+		goto err_iomap;
+	}
+
+	ret = request_irq(i2c->irq, nuc980_i2c_irq, IRQF_SHARED, dev_name(&pdev->dev), i2c);
+
+	if (ret != 0) {
+		dev_err(&pdev->dev, "cannot claim IRQ %d\n", i2c->irq);
+		goto err_iomap;
+	}
+
+	/* Note, previous versions of the driver used i2c_add_adapter()
+	 * to add the bus at any number. We now pass the bus number via
+	 * the platform data, so if unset it will now default to always
+	 * being bus 0.
+	 */
+
+	adap = &i2c->adap;
+
+	i2c->adap.nr = busnum;
+	i2c->adap.dev.of_node = pdev->dev.of_node;
+
+	ret = i2c_add_numbered_adapter(&i2c->adap);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "failed to add bus to i2c core\n");
+		goto err_irq;
+	}
+	//of_i2c_register_devices(&i2c->adap);
+
+	i2c_set_adapdata(adap, i2c);
+	strlcpy(adap->name, pdev->name, sizeof(adap->name));
+
+	pm_runtime_enable(dev);
+
+	platform_set_drvdata(pdev, i2c);
+
+	dev_info(&pdev->dev, "%s: nuc980 I2C adapter\n", dev_name(&i2c->adap.dev));
+
+#if defined(CONFIG_USE_OF)
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+ #ifdef CONFIG_NUC980_I2C1_PA
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c1-PA");
+ #elif defined(CONFIG_NUC980_I2C1_PB)
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c1-PB");
+ #elif defined(CONFIG_NUC980_I2C1_PC)
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c1-PC");
+ #endif
+#endif
+
+	if (IS_ERR(pinctrl)) {
+		return PTR_ERR(pinctrl);
+	}
+
+	return 0;
+
+err_irq:
+	free_irq(i2c->irq, i2c);
+
+err_iomap:
+	iounmap(i2c->regs);
+
+#ifndef CONFIG_USE_OF
+err_ioarea:
+	release_resource(i2c->ioarea);
+	kfree(i2c->ioarea);
+#endif
+
+err_clk:
+	clk_disable(i2c->clk);
+	clk_put(i2c->clk);
+
+err_noclk:
+	kfree(i2c);
+	return ret;
+}
+
+/* nuc980_i2c1_remove
+ *
+ * called when device is removed from the bus
+*/
+
+static int nuc980_i2c1_remove(struct platform_device *pdev)
+{
+	struct nuc980_i2c *i2c = platform_get_drvdata(pdev);
+
+	i2c_del_adapter(&i2c->adap);
+	free_irq(i2c->irq, i2c);
+
+	clk_disable(i2c->clk);
+	clk_put(i2c->clk);
+
+	iounmap(i2c->regs);
+
+	release_resource(i2c->ioarea);
+	kfree(i2c->ioarea);
+	kfree(i2c);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_i2c1_suspend(struct device *dev)
+{
+#ifdef CONFIG_SLAVE_WAKEUP
+	struct nuc980_i2c *i2c = dev_get_drvdata(dev);
+
+	__raw_writel((1<<1) | __raw_readl(REG_WKUPSER1),REG_WKUPSER1);
+
+	nuc980_i2c1_enable_irq(i2c);
+
+	writel(I2C_CTL_SI_AA | readl(i2c->regs + CTL0), i2c->regs + CTL0);
+	writel(0x1, i2c->regs + WKCTL);
+	writel(readl(i2c->regs + WKSTS), i2c->regs + WKSTS);
+
+	enable_irq_wake(i2c->irq);
+#endif
+
+	return 0;
+}
+
+static int nuc980_i2c1_resume(struct device *dev)
+{
+#ifdef CONFIG_SLAVE_WAKEUP
+	struct nuc980_i2c *i2c = dev_get_drvdata(dev);
+
+	writel(0x0, i2c->regs + WKCTL);
+	writel(readl(i2c->regs + WKSTS), i2c->regs + WKSTS);
+#endif
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_i2c1_pmops = {
+	.suspend    = nuc980_i2c1_suspend,
+	.resume     = nuc980_i2c1_resume,
+};
+
+#define NUC980_i2c1_PMOPS (&nuc980_i2c1_pmops)
+
+#else
+#define NUC980_i2c1_PMOPS NULL
+#endif
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_i2c1_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-i2c1" },
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_i2c1_of_match);
+#endif
+
+static struct platform_driver nuc980_i2c1_driver = {
+	.probe      = nuc980_i2c1_probe,
+	.remove     = nuc980_i2c1_remove,
+	.driver     = {
+		.name   = "nuc980-i2c1",
+		.owner  = THIS_MODULE,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_i2c1_of_match),
+#endif
+		.pm = NUC980_i2c1_PMOPS,
+	},
+};
+module_platform_driver(nuc980_i2c1_driver);
+
+MODULE_DESCRIPTION("nuc980 I2C Bus driver");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-i2c1");
diff -uprN linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p2.c NUC980-linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p2.c
--- linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p2.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p2.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,945 @@
+/*
+ * linux/drivers/i2c/busses/i2c-nuc980-p2.c
+ *
+ * Copyright (c) 2014 Nuvoton technology corporation.
+ *
+ * This driver based on S3C2410 I2C driver of Ben Dooks <ben-Y5A6D6n0/KfQXOPxS62xeg@public.gmane.org>.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+
+#include <linux/i2c.h>
+#include <linux/init.h>
+#include <linux/time.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/cpufreq.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+//#include <linux/of_i2c.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+
+#include <linux/pm_runtime.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/i2c-nuc980.h>
+
+/* nuc980 i2c registers offset */
+
+#define CTL0        0x00
+#define ADDR0       0x04
+#define DAT         0x08
+#define STATUS0     0x0C
+#define CLKDIV      0x10
+#define TOCTL       0x14
+#define ADDR1       0x18
+#define ADDR2       0x1C
+#define ADDR3       0x20
+#define ADDRMSK0    0x24
+#define ADDRMSK1    0x28
+#define ADDRMSK2    0x2C
+#define ADDRMSK3    0x30
+#define WKCTL       0x3C
+#define WKSTS       0x40
+#define CTL1        0x44
+#define STATUS1     0x48
+#define TMCTL       0x4C
+#define BUSCTL      0x50
+#define BUSTCTL     0x54
+#define BUSSTS      0x58
+#define PKTSIZE     0x5C
+#define PKTCRC      0x60
+#define BUSTOUT     0x64
+#define CLKTOUT     0x68
+
+/* nuc980 i2c Status */
+// Master
+#define  M_START                 0x08  //Start
+#define  M_REPEAT_START          0x10  //Master Repeat Start
+#define  M_TRAN_ADDR_ACK         0x18  //Master Transmit Address ACK
+#define  M_TRAN_ADDR_NACK        0x20  //Master Transmit Address NACK
+#define  M_TRAN_DATA_ACK         0x28  //Master Transmit Data ACK
+#define  M_TRAN_DATA_NACK        0x30  //Master Transmit Data NACK
+#define  M_ARB_LOST              0x38  //Master Arbitration Los
+#define  M_RECE_ADDR_ACK         0x40  //Master Receive Address ACK
+#define  M_RECE_ADDR_NACK        0x48  //Master Receive Address NACK
+#define  M_RECE_DATA_ACK         0x50  //Master Receive Data ACK
+#define  M_RECE_DATA_NACK        0x58  //Master Receive Data NACK
+#define  BUS_ERROR               0x00  //Bus error
+
+// Slave
+#define  S_REPEAT_START_STOP     0xA0  //Slave Transmit Repeat Start or Stop
+#define  S_TRAN_ADDR_ACK         0xA8  //Slave Transmit Address ACK
+#define  S_TRAN_DATA_ACK         0xB8  //Slave Transmit Data ACK
+#define  S_TRAN_DATA_NACK        0xC0  //Slave Transmit Data NACK
+#define  S_TRAN_LAST_DATA_ACK    0xC8  //Slave Transmit Last Data ACK
+#define  S_RECE_ADDR_ACK         0x60  //Slave Receive Address ACK
+#define  S_RECE_ARB_LOST         0x68  //Slave Receive Arbitration Lost
+#define  S_RECE_DATA_ACK         0x80  //Slave Receive Data ACK
+#define  S_RECE_DATA_NACK        0x88  //Slave Receive Data NACK
+
+//GC Mode
+#define  GC_ADDR_ACK             0x70  //GC mode Address ACK
+#define  GC_ARB_LOST             0x78  //GC mode Arbitration Lost
+#define  GC_DATA_ACK             0x90  //GC mode Data ACK
+#define  GC_DATA_NACK            0x98  //GC mode Data NACK
+
+//Other
+#define  ADDR_TRAN_ARB_LOST      0xB0  //Address Transmit Arbitration Lost
+#define  BUS_RELEASED            0xF8  //Bus Released
+
+
+/*---------------------------------------------------------------------------------------------------------*/
+/*  I2C_CTL constant definitions.                                                                            */
+/*---------------------------------------------------------------------------------------------------------*/
+#define I2C_CTL_STA_SI            0x28UL /* I2C_CTL setting for I2C control bits. It would set STA and SI bits       */
+#define I2C_CTL_STA_SI_AA         0x2CUL /* I2C_CTL setting for I2C control bits. It would set STA, SI and AA bits   */
+#define I2C_CTL_STO_SI            0x18UL /* I2C_CTL setting for I2C control bits. It would set STO and SI bits       */
+#define I2C_CTL_STO_SI_AA         0x1CUL /* I2C_CTL setting for I2C control bits. It would set STO, SI and AA bits   */
+#define I2C_CTL_SI                0x08UL /* I2C_CTL setting for I2C control bits. It would set SI bit                */
+#define I2C_CTL_SI_AA             0x0CUL /* I2C_CTL setting for I2C control bits. It would set SI and AA bits        */
+#define I2C_CTL_STA               0x20UL /* I2C_CTL setting for I2C control bits. It would set STA bit               */
+#define I2C_CTL_STO               0x10UL /* I2C_CTL setting for I2C control bits. It would set STO bit               */
+#define I2C_CTL_AA                0x04UL /* I2C_CTL setting for I2C control bits. It would set AA bit                */
+
+#define I2C_GCMODE_ENABLE   1    /*!< Enable I2C GC Mode  \hideinitializer */
+#define I2C_GCMODE_DISABLE  0    /*!< Disable I2C GC Mode  \hideinitializer */
+
+/* i2c controller private data */
+
+struct nuc980_i2c {
+	spinlock_t      lock;
+	wait_queue_head_t   wait;
+
+	struct i2c_msg      *msg;
+	unsigned int        msg_num;
+	unsigned int        msg_idx;
+	unsigned int        msg_ptr;
+	unsigned int        irq;
+	unsigned int        arblost;
+
+	void __iomem        *regs;
+	struct clk      *clk;
+	struct device       *dev;
+	struct resource     *ioarea;
+	struct i2c_adapter  adap;
+
+	struct i2c_client *slave;
+};
+
+/* nuc980_i2c2_master_complete
+ *
+ * complete the message and wake up the caller, using the given return code,
+ * or zero to mean ok.
+*/
+
+static inline void nuc980_i2c2_master_complete(struct nuc980_i2c *i2c, int ret)
+{
+	dev_dbg(i2c->dev, "master_complete %d\n", ret);
+
+	i2c->msg_ptr = 0;
+	i2c->msg = NULL;
+	i2c->msg_idx++;
+	i2c->msg_num = 0;
+	if (ret)
+		i2c->msg_idx = ret;
+
+	wake_up(&i2c->wait);
+}
+
+/* irq enable/disable functions */
+
+static inline void nuc980_i2c2_disable_irq(struct nuc980_i2c *i2c)
+{
+	unsigned long tmp;
+
+	tmp = readl(i2c->regs + CTL0);
+	writel(tmp & ~(0x1 << 7), i2c->regs + CTL0);
+}
+
+static inline void nuc980_i2c2_enable_irq(struct nuc980_i2c *i2c)
+{
+	unsigned long tmp;
+
+	tmp = readl(i2c->regs + CTL0);
+	writel(tmp | (0x1 << 7), i2c->regs + CTL0);
+}
+
+
+/* nuc980_i2c2_message_start
+ *
+ * put the start of a message onto the bus
+*/
+
+static void nuc980_i2c2_message_start(struct nuc980_i2c *i2c)
+{
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), i2c->regs + CTL0);
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA), i2c->regs + CTL0);
+}
+
+static inline void nuc980_i2c2_stop(struct nuc980_i2c *i2c, int ret)
+{
+	unsigned int tmp, i = 0;
+
+	dev_dbg(i2c->dev, "STOP\n");
+
+	if(readl(i2c->regs+CTL0) & 0x4){
+		writel((readl(i2c->regs+CTL0) &~ (0x4)), (i2c->regs+CTL0));
+		mdelay(1);
+	}
+
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_STO | I2C_CTL_SI)), (i2c->regs+CTL0));
+
+	while(readl(i2c->regs+CTL0) & I2C_CTL_STO){
+
+		i++;
+
+		if(i > 100000){
+			tmp = readl(i2c->regs+CLKDIV);
+
+			writel(0x59, REG_WRPRTR);
+			writel(0x16, REG_WRPRTR);
+			writel(0x88, REG_WRPRTR);
+
+			writel((readl(REG_APBIPRST1) |  (0x1 << 2)), REG_APBIPRST1);
+			udelay(1);
+			writel((readl(REG_APBIPRST1) &~ (0x1 << 2)), REG_APBIPRST1);
+                 
+			writel(0x1, REG_WRPRTR);
+
+			writel(tmp, (i2c->regs+CLKDIV));
+
+			mdelay(1);
+			writel((readl(i2c->regs+CTL0) | (0x40)), (i2c->regs+CTL0));
+		}
+	}
+
+	#if defined(CONFIG_ENABLE_I2C_P1_SLAVE_MODE)
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	#endif
+
+	nuc980_i2c2_master_complete(i2c, ret);
+}
+
+/* helper functions to determine the current state in the set of
+ * messages we are sending
+*/
+
+/* is_lastmsg()
+ *
+ * returns TRUE if the current message is the last in the set
+*/
+
+static inline int is_lastmsg(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_idx >= (i2c->msg_num - 1);
+}
+
+/* is_msglast
+ *
+ * returns TRUE if we this is the last byte in the current message
+*/
+
+static inline int is_msglast(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_ptr == i2c->msg->len-1;
+}
+
+/* is_msgend
+ *
+ * returns TRUE if we reached the end of the current message
+*/
+
+static inline int is_msgend(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_ptr >= i2c->msg->len;
+}
+
+
+
+#if defined(CONFIG_ENABLE_I2C_P2_SLAVE_MODE)
+static void I2C_SlaveTRx(struct nuc980_i2c *i2c, unsigned long iicstat)
+{
+	unsigned char byte;
+
+	if (iicstat == S_RECE_ADDR_ACK) {  /* Own SLA+W has been receive; ACK has been return */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C)) | (I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_RECE_DATA_ACK)  /* Previously address with own SLA address
+	                                           Data has been received; ACK has been returned*/
+	{
+		byte = readb(i2c->regs + DAT);
+
+		i2c_slave_event(i2c->slave, I2C_SLAVE_WRITE_RECEIVED, &byte);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if(iicstat == S_TRAN_ADDR_ACK) { /* Own SLA+R has been receive; ACK has been return */
+
+		i2c_slave_event(i2c->slave, I2C_SLAVE_READ_PROCESSED, &byte);    // I2C_SLAVE_READ_PROCESSED:
+		//i2c_slave_event(i2c->slave, I2C_SLAVE_REQ_READ_START, &byte);
+
+		writel(byte, i2c->regs+DAT);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_TRAN_DATA_NACK)     /* Data byte or last data in I2CDAT has been transmitted
+	                                               Not ACK has been received */
+	{
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_RECE_DATA_NACK)     /* Previously addressed with own SLA address; NOT ACK has
+	                                               been returned */
+	{
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_REPEAT_START_STOP)  /* A STOP or repeated START has been received while still
+	                                               addressed as Slave/Receiver*/
+	{
+		i2c_slave_event(i2c->slave, I2C_SLAVE_STOP, &byte);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else {
+		/* TO DO */
+		//printk("Status 0x%x is NOT processed\n", iicstat);
+	}
+}
+#else
+static void i2c_nuc980_irq_master_TRx(struct nuc980_i2c *i2c, unsigned long iicstat)
+{
+	unsigned char byte;
+
+	if (iicstat == M_START)
+	{ /* START has been transmitted and prepare SLA+W */
+
+		if (i2c->msg->flags & I2C_M_RD)
+			writel( (((i2c->msg->addr & 0x7f) << 1)|0x1), (i2c->regs+DAT)); /* Write SLA+R to Register I2CDAT */
+		else
+			writel( ((i2c->msg->addr & 0x7f) << 1), (i2c->regs+DAT)); /* Write SLA+W to Register I2CDAT */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+	}
+	else if ((iicstat == M_TRAN_ADDR_ACK) || (iicstat == M_TRAN_DATA_ACK))
+	{ /* SLA+W has been transmitted and ACK has been received */
+		//I2C_SET_DATA(i2c2, g_au8I2C_MasterTxData[g_u8I2C_MasterTxDataCnt++]);
+		//I2C_SET_CONTROL_REG(i2c2, I2C_SI);
+
+		if(iicstat == M_TRAN_ADDR_ACK)
+		{
+			if (is_lastmsg(i2c) && i2c->msg->len == 0)
+			{
+				nuc980_i2c2_stop(i2c, 0);
+				return;
+			}
+		}
+
+		if (!is_msgend(i2c))
+		{
+			byte = i2c->msg->buf[i2c->msg_ptr++];
+			writel(byte, i2c->regs+DAT);
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else if (!is_lastmsg(i2c))
+		{ /* we need to go to the next i2c message */
+			dev_dbg(i2c->dev, "WRITE: Next Message\n");
+
+			i2c->msg_ptr = 0;
+			i2c->msg_idx++;
+			i2c->msg++;
+
+			/* send the new start */
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else
+		{ /* send stop */
+			nuc980_i2c2_stop(i2c, 0);
+		}
+	}
+	else if ((iicstat == M_TRAN_ADDR_NACK) || (iicstat == M_RECE_ADDR_NACK))
+	{	/* Master Transmit Address NACK */
+		/* 0x20: SLA+W has been transmitted and NACK has been received */
+		/* 0x48: SLA+R has been transmitted and NACK has been received */
+		//I2C_SET_CONTROL_REG(i2c2, I2C_CTL_STA | I2C_CTL_STO | I2C_CTL_SI);
+
+		if (!(i2c->msg->flags & I2C_M_IGNORE_NAK))
+		{
+			printk("\n i2c_0: ack was not received\n");
+			//writel((I2C_CTL_STA | I2C_CTL_STO | I2C_CTL_SI), (i2c->regs+CTL0));
+			nuc980_i2c2_stop(i2c, -ENXIO);
+		}
+	}
+	else if (iicstat == M_REPEAT_START)
+	{  /* Repeat START has been transmitted and prepare SLA+R */
+
+		if (i2c->msg->flags & I2C_M_RD)
+			writel( (((i2c->msg->addr & 0x7f) << 1)|0x1), (i2c->regs+DAT)); /* Write SLA+R to Register I2CDAT */
+		else
+			writel( ((i2c->msg->addr & 0x7f) << 1), (i2c->regs+DAT)); /* Write SLA+W to Register I2CDAT */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+	}
+	else if (iicstat == M_RECE_ADDR_ACK)
+	{  /* SLA+R has been transmitted and ACK has been received */
+		//I2C_SET_CONTROL_REG(i2c2, I2C_AA | I2C_SI);
+
+		if (is_lastmsg(i2c) && i2c->msg->len == 0)
+		{
+			nuc980_i2c2_stop(i2c, 0);
+			//return;
+		}
+		else
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI_AA), (i2c->regs+CTL0));
+	}
+	else if ((iicstat == M_RECE_DATA_ACK) || (iicstat == M_RECE_DATA_NACK))
+	{ /* DATA has been transmitted and ACK has been received */
+		byte = readb(i2c->regs + DAT);
+		i2c->msg->buf[i2c->msg_ptr++] = byte;
+
+		if (is_msglast(i2c))
+		{ /* last byte of buffer */
+
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+
+			//if (is_lastmsg(i2c))
+			//	writel((readl(i2c->regs+CTL0)|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else if (is_msgend(i2c))
+		{	/* ok, we've read the entire buffer, see if there
+			 * is anything else we need to do
+			 */
+
+			if (is_lastmsg(i2c))
+			{ /* last message, send stop and complete */
+				dev_dbg(i2c->dev, "READ: Send Stop\n");
+
+				nuc980_i2c2_stop(i2c, 0);
+			}
+			else
+			{ /* go to the next transfer */
+				dev_dbg(i2c->dev, "READ: Next Transfer\n");
+
+				i2c->msg_ptr = 0;
+				i2c->msg_idx++;
+				i2c->msg++;
+
+				/* send the new start */
+				writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA|I2C_CTL_SI), (i2c->regs+CTL0));
+			}
+		}
+		else
+		{
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI_AA), (i2c->regs+CTL0));
+		}
+
+	}
+	else
+	{
+		/* TO DO */
+		//printf("Status 0x%x is NOT processed\n", u32Status);
+	}
+
+
+}
+#endif
+
+/* nuc980_i2c_irq
+ *
+ * top level IRQ servicing routine
+*/
+
+static irqreturn_t nuc980_i2c_irq(int irqno, void *dev_id)
+{
+	struct nuc980_i2c *i2c = dev_id;
+	unsigned long status;
+
+	status = readl(i2c->regs + STATUS0);
+
+	if (status == M_ARB_LOST) {
+		/* deal with arbitration loss */
+		dev_err(i2c->dev, "deal with arbitration loss\n");
+		i2c->arblost = 1;
+		
+		nuc980_i2c2_disable_irq(i2c);
+		nuc980_i2c2_stop(i2c, 0);
+		goto out;
+	}
+
+	if (status == BUS_ERROR) {
+		dev_dbg(i2c->dev, "IRQ: error i2c->state == IDLE\n");
+		goto out;
+	}
+
+	/* pretty much this leaves us with the fact that we've
+	 * transmitted or received whatever byte we last sent
+	*/
+
+	#if defined(CONFIG_ENABLE_I2C_P2_SLAVE_MODE)
+	I2C_SlaveTRx(i2c, status);
+	#else
+	i2c_nuc980_irq_master_TRx(i2c, status);
+	#endif
+
+out:
+	return IRQ_HANDLED;
+}
+
+#if 0
+/* nuc980_i2c2_hangup
+ *
+ * send out some dummy clocks to let SDA free
+*/
+static void nuc980_i2c2_hangup(struct nuc980_i2c *i2c)
+{
+	int i;
+
+	for(i=0;i<2;i++) {
+		writel(0x6, i2c->regs + SWR);       //CLK Low
+		ndelay(2);
+		writel(0x7, i2c->regs + SWR);       //CLK High
+		ndelay(2);
+	}
+}
+#endif
+
+/* nuc980_i2c2_doxfer
+ *
+ * this starts an i2c transfer
+*/
+
+static int nuc980_i2c2_doxfer(struct nuc980_i2c *i2c,
+				  struct i2c_msg *msgs, int num)
+{
+	unsigned long iicstat, timeout;
+	int spins = 20;
+	int ret;
+
+	spin_lock_irq(&i2c->lock);
+
+	nuc980_i2c2_enable_irq(i2c);
+
+	i2c->msg     = msgs;
+	i2c->msg_num = num;
+	i2c->msg_ptr = 0;
+	i2c->msg_idx = 0;
+
+	nuc980_i2c2_message_start(i2c);
+	spin_unlock_irq(&i2c->lock);
+
+	timeout = wait_event_timeout(i2c->wait, i2c->msg_num == 0, HZ * 5);
+	ret = i2c->msg_idx;
+
+	/* having these next two as dev_err() makes life very
+	 * noisy when doing an i2cdetect
+	*/
+
+	if (timeout == 0)
+		dev_dbg(i2c->dev, "timeout\n");
+	else if (ret != num)
+		dev_dbg(i2c->dev, "incomplete xfer (%d)\n", ret);
+
+	/* ensure the stop has been through the bus */
+	dev_dbg(i2c->dev, "waiting for bus idle\n");
+
+	/* first, try busy waiting briefly */
+	do
+	{
+		// chekc stop bit auto clear
+		iicstat = readl(i2c->regs + CTL0);
+	} while ((iicstat & (0x1<<4)) && --spins);
+
+	/* if that timed out sleep */
+	if (!spins) {
+		msleep(1);
+		iicstat = readl(i2c->regs + CTL0);
+	}
+
+	if (iicstat & (0x1<<4))
+		dev_warn(i2c->dev, "timeout waiting for bus idle\n");
+
+	if(i2c->arblost) {
+		dev_dbg(i2c->dev, "arb lost, stop\n");
+		i2c->arblost = 0;
+		nuc980_i2c2_stop(i2c, 0);
+		msleep(1);
+		nuc980_i2c2_disable_irq(i2c);
+		//nuc980_i2c2_hangup(i2c);
+		ret = -EAGAIN;
+	}
+
+// out:
+	return ret;
+}
+
+/* nuc980_i2c2_xfer
+ *
+ * first port of call from the i2c bus code when an message needs
+ * transferring across the i2c bus.
+*/
+
+static int nuc980_i2c2_xfer(struct i2c_adapter *adap, struct i2c_msg *msgs, int num)
+{
+	struct nuc980_i2c *i2c = (struct nuc980_i2c *)adap->algo_data;
+	int retry;
+	int ret;
+
+	for (retry = 0; retry < adap->retries; retry++) {
+
+		ret = nuc980_i2c2_doxfer(i2c, msgs, num);
+
+		if (ret != -EAGAIN)
+			return ret;
+
+		dev_dbg(i2c->dev, "Retrying transmission (%d)\n", retry);
+
+		udelay(100);
+	}
+
+	return -EREMOTEIO;
+}
+
+#if defined(CONFIG_ENABLE_I2C_P2_SLAVE_MODE)
+static int nuc980_reg_slave(struct i2c_client *slave)
+{
+	struct nuc980_i2c *priv = i2c_get_adapdata(slave->adapter);
+
+	if (priv->slave)
+		return -EBUSY;
+
+	if (slave->flags & I2C_CLIENT_TEN)
+		return -EAFNOSUPPORT;
+
+	nuc980_i2c2_enable_irq(priv);
+
+	pm_runtime_forbid(priv->dev);
+
+	priv->slave = slave;
+
+	// Enable I2C
+	writel(readl(priv->regs + CTL0) | (0x1 << 6), (priv->regs + CTL0)); // CTL0
+
+	// Set Slave Address
+	writel(slave->addr, (priv->regs + ADDR0));
+
+	// I2C enter SLV mode
+	writel((readl(priv->regs+CTL0)|I2C_CTL_AA|I2C_CTL_SI), (priv->regs+CTL0));
+
+	return 0;
+}
+
+static int nuc980_unreg_slave(struct i2c_client *slave)
+{
+	struct nuc980_i2c *priv = i2c_get_adapdata(slave->adapter);
+
+	// Disable I2C
+	writel(readl(priv->regs + CTL0) &~ (0x1 << 6), (priv->regs + CTL0)); // CTL0
+	// Disable i2c interrupt
+	nuc980_i2c2_disable_irq(priv);
+
+	priv->slave = NULL;
+
+	pm_runtime_allow(priv->dev);
+
+	return 0;
+}
+#endif
+
+/* declare our i2c functionality */
+static u32 nuc980_i2c2_func(struct i2c_adapter *adap)
+{
+	return I2C_FUNC_I2C | I2C_FUNC_PROTOCOL_MANGLING | I2C_FUNC_SMBUS_EMUL ;
+}
+
+/* i2c bus registration info */
+
+static const struct i2c_algorithm nuc980_i2c2_algorithm = {
+	.master_xfer        = nuc980_i2c2_xfer,
+	.functionality      = nuc980_i2c2_func,
+#if defined(CONFIG_ENABLE_I2C_P2_SLAVE_MODE)
+	.reg_slave	= nuc980_reg_slave,
+	.unreg_slave	= nuc980_unreg_slave,
+#endif
+};
+
+/* nuc980_i2c2_probe
+ *
+ * called by the bus driver when a suitable device is found
+*/
+
+static int nuc980_i2c2_probe(struct platform_device *pdev)
+{
+	struct nuc980_i2c *i2c;
+	struct nuc980_platform_i2c *pdata=NULL;
+	struct resource *res;
+	struct i2c_adapter *adap;
+	int ret;
+	int busnum = 0, busfreq = 0;
+	struct device *dev = &pdev->dev;
+
+	struct pinctrl *pinctrl;
+
+	if (!pdev->dev.of_node) {
+		pdata = pdev->dev.platform_data;
+		if (!pdata) {
+			dev_err(&pdev->dev, "no platform data\n");
+			return -EINVAL;
+		}
+	}
+
+	i2c = kzalloc(sizeof(struct nuc980_i2c), GFP_KERNEL);
+	if (!i2c) {
+		dev_err(&pdev->dev, "no memory for state\n");
+		return -ENOMEM;
+	}
+
+	strlcpy(i2c->adap.name, "nuc980-i2c2", sizeof(i2c->adap.name));
+	i2c->adap.owner   = THIS_MODULE;
+	i2c->adap.algo    = &nuc980_i2c2_algorithm;
+	i2c->adap.retries = 2;
+	i2c->adap.class   = I2C_CLASS_HWMON | I2C_CLASS_SPD;
+
+	spin_lock_init(&i2c->lock);
+	init_waitqueue_head(&i2c->wait);
+
+	/* find the clock and enable it */
+
+	i2c->dev = &pdev->dev;
+	i2c->clk = clk_get(NULL, "i2c2");
+	if (IS_ERR(i2c->clk)) {
+		dev_err(&pdev->dev, "cannot get clock\n");
+		ret = -ENOENT;
+		goto err_noclk;
+	}
+
+	dev_dbg(&pdev->dev, "clock source %p\n", i2c->clk);
+
+	clk_prepare(i2c->clk);
+	clk_enable(i2c->clk);
+
+	/* map the registers */
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (res == NULL) {
+		dev_err(&pdev->dev, "cannot find IO resource\n");
+		ret = -ENOENT;
+		goto err_clk;
+	}
+
+#if defined(CONFIG_USE_OF)
+	i2c->regs = devm_ioremap_resource(&pdev->dev, res);
+#else
+	i2c->ioarea = request_mem_region(res->start, resource_size(res), pdev->name);
+	if (i2c->ioarea == NULL) {
+		dev_err(&pdev->dev, "cannot request IO\n");
+		ret = -ENXIO;
+		goto err_clk;
+	}
+
+	i2c->regs = ioremap(res->start, resource_size(res));
+	if (i2c->regs == NULL) {
+		dev_err(&pdev->dev, "cannot map IO\n");
+		ret = -ENXIO;
+		goto err_ioarea;
+	}
+
+	dev_dbg(&pdev->dev, "registers %p (%p, %p)\n", i2c->regs, i2c->ioarea, res);
+#endif
+
+	/* setup info block for the i2c core */
+
+	i2c->adap.algo_data = i2c;
+	i2c->adap.dev.parent = &pdev->dev;
+
+	if (pdata) {
+		busfreq = pdata->bus_freq;
+		busnum = pdata->bus_num;
+	} else {
+		of_property_read_u32(pdev->dev.of_node, "bus_freq", &busfreq);
+		of_property_read_u32(pdev->dev.of_node, "bus_num", &busnum);
+	}
+
+	// Set Clock divider
+	ret = clk_get_rate(i2c->clk)/(busfreq * 4) - 1;
+	writel(ret & 0xffff, i2c->regs + CLKDIV);
+
+	writel((readl(i2c->regs+CTL0)|(0x1 << 6)), i2c->regs + CTL0);
+
+	/* find the IRQ for this unit (note, this relies on the init call to
+	 * ensure no current IRQs pending
+	 */
+
+	i2c->irq = ret = platform_get_irq(pdev, 0);
+	if (ret <= 0) {
+		dev_err(&pdev->dev, "cannot find IRQ\n");
+		goto err_iomap;
+	}
+
+	ret = request_irq(i2c->irq, nuc980_i2c_irq, IRQF_SHARED, dev_name(&pdev->dev), i2c);
+
+	if (ret != 0) {
+		dev_err(&pdev->dev, "cannot claim IRQ %d\n", i2c->irq);
+		goto err_iomap;
+	}
+
+	/* Note, previous versions of the driver used i2c_add_adapter()
+	 * to add the bus at any number. We now pass the bus number via
+	 * the platform data, so if unset it will now default to always
+	 * being bus 0.
+	 */
+
+	adap = &i2c->adap;
+
+	i2c->adap.nr = busnum;
+	i2c->adap.dev.of_node = pdev->dev.of_node;
+
+	ret = i2c_add_numbered_adapter(&i2c->adap);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "failed to add bus to i2c core\n");
+		goto err_irq;
+	}
+	//of_i2c_register_devices(&i2c->adap);
+
+	i2c_set_adapdata(adap, i2c);
+	strlcpy(adap->name, pdev->name, sizeof(adap->name));
+
+	pm_runtime_enable(dev);
+
+	platform_set_drvdata(pdev, i2c);
+
+	dev_info(&pdev->dev, "%s: nuc980 I2C adapter\n", dev_name(&i2c->adap.dev));
+
+#if defined(CONFIG_USE_OF)
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+ #ifdef CONFIG_NUC980_I2C2_PB
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c2-PB");
+ #elif defined(CONFIG_NUC980_I2C2_PB_PC)
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c2-PB_PC");
+ #endif
+#endif
+
+	if (IS_ERR(pinctrl)) {
+		return PTR_ERR(pinctrl);
+	}
+
+	return 0;
+
+err_irq:
+	free_irq(i2c->irq, i2c);
+
+err_iomap:
+	iounmap(i2c->regs);
+
+#ifndef CONFIG_USE_OF
+err_ioarea:
+	release_resource(i2c->ioarea);
+	kfree(i2c->ioarea);
+#endif
+
+err_clk:
+	clk_disable(i2c->clk);
+	clk_put(i2c->clk);
+
+err_noclk:
+	kfree(i2c);
+	return ret;
+}
+
+/* nuc980_i2c2_remove
+ *
+ * called when device is removed from the bus
+*/
+
+static int nuc980_i2c2_remove(struct platform_device *pdev)
+{
+	struct nuc980_i2c *i2c = platform_get_drvdata(pdev);
+
+	i2c_del_adapter(&i2c->adap);
+	free_irq(i2c->irq, i2c);
+
+	clk_disable(i2c->clk);
+	clk_put(i2c->clk);
+
+	iounmap(i2c->regs);
+
+	release_resource(i2c->ioarea);
+	kfree(i2c->ioarea);
+	kfree(i2c);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_i2c2_suspend(struct device *dev)
+{
+#ifdef CONFIG_SLAVE_WAKEUP
+	struct nuc980_i2c *i2c = dev_get_drvdata(dev);
+
+	__raw_writel((1<<0) | __raw_readl(REG_WKUPSER1),REG_WKUPSER1);
+
+	nuc980_i2c2_enable_irq(i2c);
+
+	writel(I2C_CTL_SI_AA | readl(i2c->regs + CTL0), i2c->regs + CTL0);
+	writel(0x1, i2c->regs + WKCTL);
+	writel(readl(i2c->regs + WKSTS), i2c->regs + WKSTS);
+
+	enable_irq_wake(i2c->irq);
+#endif
+
+	return 0;
+}
+
+static int nuc980_i2c2_resume(struct device *dev)
+{
+#ifdef CONFIG_SLAVE_WAKEUP
+	struct nuc980_i2c *i2c = dev_get_drvdata(dev);
+
+	writel(0x0, i2c->regs + WKCTL);
+	writel(readl(i2c->regs + WKSTS), i2c->regs + WKSTS);
+#endif
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_i2c2_pmops = {
+	.suspend    = nuc980_i2c2_suspend,
+	.resume     = nuc980_i2c2_resume,
+};
+
+#define NUC980_i2c2_PMOPS (&nuc980_i2c2_pmops)
+
+#else
+#define NUC980_i2c2_PMOPS NULL
+#endif
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_i2c2_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-i2c2" },
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_i2c2_of_match);
+#endif
+
+static struct platform_driver nuc980_i2c2_driver = {
+	.probe      = nuc980_i2c2_probe,
+	.remove     = nuc980_i2c2_remove,
+	.driver     = {
+		.name   = "nuc980-i2c2",
+		.owner  = THIS_MODULE,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_i2c2_of_match),
+#endif
+		.pm = NUC980_i2c2_PMOPS,
+	},
+};
+module_platform_driver(nuc980_i2c2_driver);
+
+MODULE_DESCRIPTION("nuc980 I2C Bus driver");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-i2c2");
diff -uprN linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p3.c NUC980-linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p3.c
--- linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p3.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/i2c/busses/i2c-nuc980-p3.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,945 @@
+/*
+ * linux/drivers/i2c/busses/i2c-nuc980-p3.c
+ *
+ * Copyright (c) 2014 Nuvoton technology corporation.
+ *
+ * This driver based on S3C2410 I2C driver of Ben Dooks <ben-Y5A6D6n0/KfQXOPxS62xeg@public.gmane.org>.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+
+#include <linux/i2c.h>
+#include <linux/init.h>
+#include <linux/time.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/cpufreq.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+//#include <linux/of_i2c.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+
+#include <linux/pm_runtime.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/i2c-nuc980.h>
+
+/* nuc980 i2c registers offset */
+
+#define CTL0        0x00
+#define ADDR0       0x04
+#define DAT         0x08
+#define STATUS0     0x0C
+#define CLKDIV      0x10
+#define TOCTL       0x14
+#define ADDR1       0x18
+#define ADDR2       0x1C
+#define ADDR3       0x20
+#define ADDRMSK0    0x24
+#define ADDRMSK1    0x28
+#define ADDRMSK2    0x2C
+#define ADDRMSK3    0x30
+#define WKCTL       0x3C
+#define WKSTS       0x40
+#define CTL1        0x44
+#define STATUS1     0x48
+#define TMCTL       0x4C
+#define BUSCTL      0x50
+#define BUSTCTL     0x54
+#define BUSSTS      0x58
+#define PKTSIZE     0x5C
+#define PKTCRC      0x60
+#define BUSTOUT     0x64
+#define CLKTOUT     0x68
+
+/* nuc980 i2c Status */
+// Master
+#define  M_START                 0x08  //Start
+#define  M_REPEAT_START          0x10  //Master Repeat Start
+#define  M_TRAN_ADDR_ACK         0x18  //Master Transmit Address ACK
+#define  M_TRAN_ADDR_NACK        0x20  //Master Transmit Address NACK
+#define  M_TRAN_DATA_ACK         0x28  //Master Transmit Data ACK
+#define  M_TRAN_DATA_NACK        0x30  //Master Transmit Data NACK
+#define  M_ARB_LOST              0x38  //Master Arbitration Los
+#define  M_RECE_ADDR_ACK         0x40  //Master Receive Address ACK
+#define  M_RECE_ADDR_NACK        0x48  //Master Receive Address NACK
+#define  M_RECE_DATA_ACK         0x50  //Master Receive Data ACK
+#define  M_RECE_DATA_NACK        0x58  //Master Receive Data NACK
+#define  BUS_ERROR               0x00  //Bus error
+
+// Slave
+#define  S_REPEAT_START_STOP     0xA0  //Slave Transmit Repeat Start or Stop
+#define  S_TRAN_ADDR_ACK         0xA8  //Slave Transmit Address ACK
+#define  S_TRAN_DATA_ACK         0xB8  //Slave Transmit Data ACK
+#define  S_TRAN_DATA_NACK        0xC0  //Slave Transmit Data NACK
+#define  S_TRAN_LAST_DATA_ACK    0xC8  //Slave Transmit Last Data ACK
+#define  S_RECE_ADDR_ACK         0x60  //Slave Receive Address ACK
+#define  S_RECE_ARB_LOST         0x68  //Slave Receive Arbitration Lost
+#define  S_RECE_DATA_ACK         0x80  //Slave Receive Data ACK
+#define  S_RECE_DATA_NACK        0x88  //Slave Receive Data NACK
+
+//GC Mode
+#define  GC_ADDR_ACK             0x70  //GC mode Address ACK
+#define  GC_ARB_LOST             0x78  //GC mode Arbitration Lost
+#define  GC_DATA_ACK             0x90  //GC mode Data ACK
+#define  GC_DATA_NACK            0x98  //GC mode Data NACK
+
+//Other
+#define  ADDR_TRAN_ARB_LOST      0xB0  //Address Transmit Arbitration Lost
+#define  BUS_RELEASED            0xF8  //Bus Released
+
+
+/*---------------------------------------------------------------------------------------------------------*/
+/*  I2C_CTL constant definitions.                                                                            */
+/*---------------------------------------------------------------------------------------------------------*/
+#define I2C_CTL_STA_SI            0x28UL /* I2C_CTL setting for I2C control bits. It would set STA and SI bits       */
+#define I2C_CTL_STA_SI_AA         0x2CUL /* I2C_CTL setting for I2C control bits. It would set STA, SI and AA bits   */
+#define I2C_CTL_STO_SI            0x18UL /* I2C_CTL setting for I2C control bits. It would set STO and SI bits       */
+#define I2C_CTL_STO_SI_AA         0x1CUL /* I2C_CTL setting for I2C control bits. It would set STO, SI and AA bits   */
+#define I2C_CTL_SI                0x08UL /* I2C_CTL setting for I2C control bits. It would set SI bit                */
+#define I2C_CTL_SI_AA             0x0CUL /* I2C_CTL setting for I2C control bits. It would set SI and AA bits        */
+#define I2C_CTL_STA               0x20UL /* I2C_CTL setting for I2C control bits. It would set STA bit               */
+#define I2C_CTL_STO               0x10UL /* I2C_CTL setting for I2C control bits. It would set STO bit               */
+#define I2C_CTL_AA                0x04UL /* I2C_CTL setting for I2C control bits. It would set AA bit                */
+
+#define I2C_GCMODE_ENABLE   1    /*!< Enable I2C GC Mode  \hideinitializer */
+#define I2C_GCMODE_DISABLE  0    /*!< Disable I2C GC Mode  \hideinitializer */
+
+/* i2c controller private data */
+
+struct nuc980_i2c {
+	spinlock_t      lock;
+	wait_queue_head_t   wait;
+
+	struct i2c_msg      *msg;
+	unsigned int        msg_num;
+	unsigned int        msg_idx;
+	unsigned int        msg_ptr;
+	unsigned int        irq;
+	unsigned int        arblost;
+
+	void __iomem        *regs;
+	struct clk      *clk;
+	struct device       *dev;
+	struct resource     *ioarea;
+	struct i2c_adapter  adap;
+
+	struct i2c_client *slave;
+};
+
+/* nuc980_i2c3_master_complete
+ *
+ * complete the message and wake up the caller, using the given return code,
+ * or zero to mean ok.
+*/
+
+static inline void nuc980_i2c3_master_complete(struct nuc980_i2c *i2c, int ret)
+{
+	dev_dbg(i2c->dev, "master_complete %d\n", ret);
+
+	i2c->msg_ptr = 0;
+	i2c->msg = NULL;
+	i2c->msg_idx++;
+	i2c->msg_num = 0;
+	if (ret)
+		i2c->msg_idx = ret;
+
+	wake_up(&i2c->wait);
+}
+
+/* irq enable/disable functions */
+
+static inline void nuc980_i2c3_disable_irq(struct nuc980_i2c *i2c)
+{
+	unsigned long tmp;
+
+	tmp = readl(i2c->regs + CTL0);
+	writel(tmp & ~(0x1 << 7), i2c->regs + CTL0);
+}
+
+static inline void nuc980_i2c3_enable_irq(struct nuc980_i2c *i2c)
+{
+	unsigned long tmp;
+
+	tmp = readl(i2c->regs + CTL0);
+	writel(tmp | (0x1 << 7), i2c->regs + CTL0);
+}
+
+
+/* nuc980_i2c3_message_start
+ *
+ * put the start of a message onto the bus
+*/
+
+static void nuc980_i2c3_message_start(struct nuc980_i2c *i2c)
+{
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), i2c->regs + CTL0);
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA), i2c->regs + CTL0);
+}
+
+static inline void nuc980_i2c3_stop(struct nuc980_i2c *i2c, int ret)
+{
+	unsigned int tmp, i = 0;
+
+	dev_dbg(i2c->dev, "STOP\n");
+
+	if(readl(i2c->regs+CTL0) & 0x4){
+		writel((readl(i2c->regs+CTL0) &~ (0x4)), (i2c->regs+CTL0));
+		mdelay(1);
+	}
+
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_STO | I2C_CTL_SI)), (i2c->regs+CTL0));
+
+	while(readl(i2c->regs+CTL0) & I2C_CTL_STO){
+
+		i++;
+
+		if(i > 100000){
+			tmp = readl(i2c->regs+CLKDIV);
+
+			writel(0x59, REG_WRPRTR);
+			writel(0x16, REG_WRPRTR);
+			writel(0x88, REG_WRPRTR);
+
+			writel((readl(REG_APBIPRST1) |  (0x1 << 3)), REG_APBIPRST1);
+			udelay(1);
+			writel((readl(REG_APBIPRST1) &~ (0x1 << 3)), REG_APBIPRST1);
+                 
+			writel(0x1, REG_WRPRTR);
+
+			writel(tmp, (i2c->regs+CLKDIV));
+
+			mdelay(1);
+			writel((readl(i2c->regs+CTL0) | (0x40)), (i2c->regs+CTL0));
+		}
+	}
+
+	#if defined(CONFIG_ENABLE_I2C_P1_SLAVE_MODE)
+	writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	#endif
+
+	nuc980_i2c3_master_complete(i2c, ret);
+}
+
+/* helper functions to determine the current state in the set of
+ * messages we are sending
+*/
+
+/* is_lastmsg()
+ *
+ * returns TRUE if the current message is the last in the set
+*/
+
+static inline int is_lastmsg(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_idx >= (i2c->msg_num - 1);
+}
+
+/* is_msglast
+ *
+ * returns TRUE if we this is the last byte in the current message
+*/
+
+static inline int is_msglast(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_ptr == i2c->msg->len-1;
+}
+
+/* is_msgend
+ *
+ * returns TRUE if we reached the end of the current message
+*/
+
+static inline int is_msgend(struct nuc980_i2c *i2c)
+{
+	return i2c->msg_ptr >= i2c->msg->len;
+}
+
+
+
+#if defined(CONFIG_ENABLE_I2C_P3_SLAVE_MODE)
+static void I2C_SlaveTRx(struct nuc980_i2c *i2c, unsigned long iicstat)
+{
+	unsigned char byte;
+
+	if (iicstat == S_RECE_ADDR_ACK) {  /* Own SLA+W has been receive; ACK has been return */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C)) | (I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_RECE_DATA_ACK)  /* Previously address with own SLA address
+	                                           Data has been received; ACK has been returned*/
+	{
+		byte = readb(i2c->regs + DAT);
+
+		i2c_slave_event(i2c->slave, I2C_SLAVE_WRITE_RECEIVED, &byte);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if(iicstat == S_TRAN_ADDR_ACK) { /* Own SLA+R has been receive; ACK has been return */
+
+		i2c_slave_event(i2c->slave, I2C_SLAVE_READ_PROCESSED, &byte);    // I2C_SLAVE_READ_PROCESSED:
+		//i2c_slave_event(i2c->slave, I2C_SLAVE_REQ_READ_START, &byte);
+
+		writel(byte, i2c->regs+DAT);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_TRAN_DATA_NACK)     /* Data byte or last data in I2CDAT has been transmitted
+	                                               Not ACK has been received */
+	{
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_RECE_DATA_NACK)     /* Previously addressed with own SLA address; NOT ACK has
+	                                               been returned */
+	{
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else if (iicstat == S_REPEAT_START_STOP)  /* A STOP or repeated START has been received while still
+	                                               addressed as Slave/Receiver*/
+	{
+		i2c_slave_event(i2c->slave, I2C_SLAVE_STOP, &byte);
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|(I2C_CTL_SI | I2C_CTL_AA)), (i2c->regs+CTL0));
+	} else {
+		/* TO DO */
+		//printk("Status 0x%x is NOT processed\n", iicstat);
+	}
+}
+#else
+static void i2c_nuc980_irq_master_TRx(struct nuc980_i2c *i2c, unsigned long iicstat)
+{
+	unsigned char byte;
+
+	if (iicstat == M_START)
+	{ /* START has been transmitted and prepare SLA+W */
+
+		if (i2c->msg->flags & I2C_M_RD)
+			writel( (((i2c->msg->addr & 0x7f) << 1)|0x1), (i2c->regs+DAT)); /* Write SLA+R to Register I2CDAT */
+		else
+			writel( ((i2c->msg->addr & 0x7f) << 1), (i2c->regs+DAT)); /* Write SLA+W to Register I2CDAT */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+	}
+	else if ((iicstat == M_TRAN_ADDR_ACK) || (iicstat == M_TRAN_DATA_ACK))
+	{ /* SLA+W has been transmitted and ACK has been received */
+		//I2C_SET_DATA(i2c3, g_au8I2C_MasterTxData[g_u8I2C_MasterTxDataCnt++]);
+		//I2C_SET_CONTROL_REG(i2c3, I2C_SI);
+
+		if(iicstat == M_TRAN_ADDR_ACK)
+		{
+			if (is_lastmsg(i2c) && i2c->msg->len == 0)
+			{
+				nuc980_i2c3_stop(i2c, 0);
+				return;
+			}
+		}
+
+		if (!is_msgend(i2c))
+		{
+			byte = i2c->msg->buf[i2c->msg_ptr++];
+			writel(byte, i2c->regs+DAT);
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else if (!is_lastmsg(i2c))
+		{ /* we need to go to the next i2c message */
+			dev_dbg(i2c->dev, "WRITE: Next Message\n");
+
+			i2c->msg_ptr = 0;
+			i2c->msg_idx++;
+			i2c->msg++;
+
+			/* send the new start */
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else
+		{ /* send stop */
+			nuc980_i2c3_stop(i2c, 0);
+		}
+	}
+	else if ((iicstat == M_TRAN_ADDR_NACK) || (iicstat == M_RECE_ADDR_NACK))
+	{	/* Master Transmit Address NACK */
+		/* 0x20: SLA+W has been transmitted and NACK has been received */
+		/* 0x48: SLA+R has been transmitted and NACK has been received */
+		//I2C_SET_CONTROL_REG(i2c3, I2C_CTL_STA | I2C_CTL_STO | I2C_CTL_SI);
+
+		if (!(i2c->msg->flags & I2C_M_IGNORE_NAK))
+		{
+			printk("\n i2c_0: ack was not received\n");
+			//writel((I2C_CTL_STA | I2C_CTL_STO | I2C_CTL_SI), (i2c->regs+CTL0));
+			nuc980_i2c3_stop(i2c, -ENXIO);
+		}
+	}
+	else if (iicstat == M_REPEAT_START)
+	{  /* Repeat START has been transmitted and prepare SLA+R */
+
+		if (i2c->msg->flags & I2C_M_RD)
+			writel( (((i2c->msg->addr & 0x7f) << 1)|0x1), (i2c->regs+DAT)); /* Write SLA+R to Register I2CDAT */
+		else
+			writel( ((i2c->msg->addr & 0x7f) << 1), (i2c->regs+DAT)); /* Write SLA+W to Register I2CDAT */
+
+		writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+	}
+	else if (iicstat == M_RECE_ADDR_ACK)
+	{  /* SLA+R has been transmitted and ACK has been received */
+		//I2C_SET_CONTROL_REG(i2c3, I2C_AA | I2C_SI);
+
+		if (is_lastmsg(i2c) && i2c->msg->len == 0)
+		{
+			nuc980_i2c3_stop(i2c, 0);
+			//return;
+		}
+		else
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI_AA), (i2c->regs+CTL0));
+	}
+	else if ((iicstat == M_RECE_DATA_ACK) || (iicstat == M_RECE_DATA_NACK))
+	{ /* DATA has been transmitted and ACK has been received */
+		byte = readb(i2c->regs + DAT);
+		i2c->msg->buf[i2c->msg_ptr++] = byte;
+
+		if (is_msglast(i2c))
+		{ /* last byte of buffer */
+
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI), (i2c->regs+CTL0));
+
+			//if (is_lastmsg(i2c))
+			//	writel((readl(i2c->regs+CTL0)|I2C_CTL_SI), (i2c->regs+CTL0));
+		}
+		else if (is_msgend(i2c))
+		{	/* ok, we've read the entire buffer, see if there
+			 * is anything else we need to do
+			 */
+
+			if (is_lastmsg(i2c))
+			{ /* last message, send stop and complete */
+				dev_dbg(i2c->dev, "READ: Send Stop\n");
+
+				nuc980_i2c3_stop(i2c, 0);
+			}
+			else
+			{ /* go to the next transfer */
+				dev_dbg(i2c->dev, "READ: Next Transfer\n");
+
+				i2c->msg_ptr = 0;
+				i2c->msg_idx++;
+				i2c->msg++;
+
+				/* send the new start */
+				writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_STA|I2C_CTL_SI), (i2c->regs+CTL0));
+			}
+		}
+		else
+		{
+			writel(((readl(i2c->regs+CTL0) &~ (0x3C))|I2C_CTL_SI_AA), (i2c->regs+CTL0));
+		}
+
+	}
+	else
+	{
+		/* TO DO */
+		//printf("Status 0x%x is NOT processed\n", u32Status);
+	}
+
+
+}
+#endif
+
+/* nuc980_i2c_irq
+ *
+ * top level IRQ servicing routine
+*/
+
+static irqreturn_t nuc980_i2c_irq(int irqno, void *dev_id)
+{
+	struct nuc980_i2c *i2c = dev_id;
+	unsigned long status;
+
+	status = readl(i2c->regs + STATUS0);
+
+	if (status == M_ARB_LOST) {
+		/* deal with arbitration loss */
+		dev_err(i2c->dev, "deal with arbitration loss\n");
+		i2c->arblost = 1;
+		
+		nuc980_i2c3_disable_irq(i2c);
+		nuc980_i2c3_stop(i2c, 0);
+		goto out;
+	}
+
+	if (status == BUS_ERROR) {
+		dev_dbg(i2c->dev, "IRQ: error i2c->state == IDLE\n");
+		goto out;
+	}
+
+	/* pretty much this leaves us with the fact that we've
+	 * transmitted or received whatever byte we last sent
+	*/
+
+	#if defined(CONFIG_ENABLE_I2C_P3_SLAVE_MODE)
+	I2C_SlaveTRx(i2c, status);
+	#else
+	i2c_nuc980_irq_master_TRx(i2c, status);
+	#endif
+
+out:
+	return IRQ_HANDLED;
+}
+
+#if 0
+/* nuc980_i2c3_hangup
+ *
+ * send out some dummy clocks to let SDA free
+*/
+static void nuc980_i2c3_hangup(struct nuc980_i2c *i2c)
+{
+	int i;
+
+	for(i=0;i<2;i++) {
+		writel(0x6, i2c->regs + SWR);       //CLK Low
+		ndelay(2);
+		writel(0x7, i2c->regs + SWR);       //CLK High
+		ndelay(2);
+	}
+}
+#endif
+
+/* nuc980_i2c3_doxfer
+ *
+ * this starts an i2c transfer
+*/
+
+static int nuc980_i2c3_doxfer(struct nuc980_i2c *i2c,
+				  struct i2c_msg *msgs, int num)
+{
+	unsigned long iicstat, timeout;
+	int spins = 20;
+	int ret;
+
+	spin_lock_irq(&i2c->lock);
+
+	nuc980_i2c3_enable_irq(i2c);
+
+	i2c->msg     = msgs;
+	i2c->msg_num = num;
+	i2c->msg_ptr = 0;
+	i2c->msg_idx = 0;
+
+	nuc980_i2c3_message_start(i2c);
+	spin_unlock_irq(&i2c->lock);
+
+	timeout = wait_event_timeout(i2c->wait, i2c->msg_num == 0, HZ * 5);
+	ret = i2c->msg_idx;
+
+	/* having these next two as dev_err() makes life very
+	 * noisy when doing an i2cdetect
+	*/
+
+	if (timeout == 0)
+		dev_dbg(i2c->dev, "timeout\n");
+	else if (ret != num)
+		dev_dbg(i2c->dev, "incomplete xfer (%d)\n", ret);
+
+	/* ensure the stop has been through the bus */
+	dev_dbg(i2c->dev, "waiting for bus idle\n");
+
+	/* first, try busy waiting briefly */
+	do
+	{
+		// chekc stop bit auto clear
+		iicstat = readl(i2c->regs + CTL0);
+	} while ((iicstat & (0x1<<4)) && --spins);
+
+	/* if that timed out sleep */
+	if (!spins) {
+		msleep(1);
+		iicstat = readl(i2c->regs + CTL0);
+	}
+
+	if (iicstat & (0x1<<4))
+		dev_warn(i2c->dev, "timeout waiting for bus idle\n");
+
+	if(i2c->arblost) {
+		dev_dbg(i2c->dev, "arb lost, stop\n");
+		i2c->arblost = 0;
+		nuc980_i2c3_stop(i2c, 0);
+		msleep(1);
+		nuc980_i2c3_disable_irq(i2c);
+		//nuc980_i2c3_hangup(i2c);
+		ret = -EAGAIN;
+	}
+
+// out:
+	return ret;
+}
+
+/* nuc980_i2c3_xfer
+ *
+ * first port of call from the i2c bus code when an message needs
+ * transferring across the i2c bus.
+*/
+
+static int nuc980_i2c3_xfer(struct i2c_adapter *adap, struct i2c_msg *msgs, int num)
+{
+	struct nuc980_i2c *i2c = (struct nuc980_i2c *)adap->algo_data;
+	int retry;
+	int ret;
+
+	for (retry = 0; retry < adap->retries; retry++) {
+
+		ret = nuc980_i2c3_doxfer(i2c, msgs, num);
+
+		if (ret != -EAGAIN)
+			return ret;
+
+		dev_dbg(i2c->dev, "Retrying transmission (%d)\n", retry);
+
+		udelay(100);
+	}
+
+	return -EREMOTEIO;
+}
+
+#if defined(CONFIG_ENABLE_I2C_P3_SLAVE_MODE)
+static int nuc980_reg_slave(struct i2c_client *slave)
+{
+	struct nuc980_i2c *priv = i2c_get_adapdata(slave->adapter);
+
+	if (priv->slave)
+		return -EBUSY;
+
+	if (slave->flags & I2C_CLIENT_TEN)
+		return -EAFNOSUPPORT;
+
+	nuc980_i2c3_enable_irq(priv);
+
+	pm_runtime_forbid(priv->dev);
+
+	priv->slave = slave;
+
+	// Enable I2C
+	writel(readl(priv->regs + CTL0) | (0x1 << 6), (priv->regs + CTL0)); // CTL0
+
+	// Set Slave Address
+	writel(slave->addr, (priv->regs + ADDR0));
+
+	// I2C enter SLV mode
+	writel((readl(priv->regs+CTL0)|I2C_CTL_AA|I2C_CTL_SI), (priv->regs+CTL0));
+
+	return 0;
+}
+
+static int nuc980_unreg_slave(struct i2c_client *slave)
+{
+	struct nuc980_i2c *priv = i2c_get_adapdata(slave->adapter);
+
+	// Disable I2C
+	writel(readl(priv->regs + CTL0) &~ (0x1 << 6), (priv->regs + CTL0)); // CTL0
+	// Disable i2c interrupt
+	nuc980_i2c3_disable_irq(priv);
+
+	priv->slave = NULL;
+
+	pm_runtime_allow(priv->dev);
+
+	return 0;
+}
+#endif
+
+/* declare our i2c functionality */
+static u32 nuc980_i2c3_func(struct i2c_adapter *adap)
+{
+	return I2C_FUNC_I2C | I2C_FUNC_PROTOCOL_MANGLING | I2C_FUNC_SMBUS_EMUL ;
+}
+
+/* i2c bus registration info */
+
+static const struct i2c_algorithm nuc980_i2c3_algorithm = {
+	.master_xfer        = nuc980_i2c3_xfer,
+	.functionality      = nuc980_i2c3_func,
+#if defined(CONFIG_ENABLE_I2C_P3_SLAVE_MODE)
+	.reg_slave	= nuc980_reg_slave,
+	.unreg_slave	= nuc980_unreg_slave,
+#endif
+};
+
+/* nuc980_i2c3_probe
+ *
+ * called by the bus driver when a suitable device is found
+*/
+
+static int nuc980_i2c3_probe(struct platform_device *pdev)
+{
+	struct nuc980_i2c *i2c;
+	struct nuc980_platform_i2c *pdata=NULL;
+	struct resource *res;
+	struct i2c_adapter *adap;
+	int ret;
+	int busnum = 0, busfreq = 0;
+	struct device *dev = &pdev->dev;
+
+	struct pinctrl *pinctrl;
+
+	if (!pdev->dev.of_node) {
+		pdata = pdev->dev.platform_data;
+		if (!pdata) {
+			dev_err(&pdev->dev, "no platform data\n");
+			return -EINVAL;
+		}
+	}
+
+	i2c = kzalloc(sizeof(struct nuc980_i2c), GFP_KERNEL);
+	if (!i2c) {
+		dev_err(&pdev->dev, "no memory for state\n");
+		return -ENOMEM;
+	}
+
+	strlcpy(i2c->adap.name, "nuc980-i2c3", sizeof(i2c->adap.name));
+	i2c->adap.owner   = THIS_MODULE;
+	i2c->adap.algo    = &nuc980_i2c3_algorithm;
+	i2c->adap.retries = 2;
+	i2c->adap.class   = I2C_CLASS_HWMON | I2C_CLASS_SPD;
+
+	spin_lock_init(&i2c->lock);
+	init_waitqueue_head(&i2c->wait);
+
+	/* find the clock and enable it */
+
+	i2c->dev = &pdev->dev;
+	i2c->clk = clk_get(NULL, "i2c3");
+	if (IS_ERR(i2c->clk)) {
+		dev_err(&pdev->dev, "cannot get clock\n");
+		ret = -ENOENT;
+		goto err_noclk;
+	}
+
+	dev_dbg(&pdev->dev, "clock source %p\n", i2c->clk);
+
+	clk_prepare(i2c->clk);
+	clk_enable(i2c->clk);
+
+	/* map the registers */
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (res == NULL) {
+		dev_err(&pdev->dev, "cannot find IO resource\n");
+		ret = -ENOENT;
+		goto err_clk;
+	}
+
+#if defined(CONFIG_USE_OF)
+	i2c->regs = devm_ioremap_resource(&pdev->dev, res);
+#else
+	i2c->ioarea = request_mem_region(res->start, resource_size(res), pdev->name);
+	if (i2c->ioarea == NULL) {
+		dev_err(&pdev->dev, "cannot request IO\n");
+		ret = -ENXIO;
+		goto err_clk;
+	}
+
+	i2c->regs = ioremap(res->start, resource_size(res));
+	if (i2c->regs == NULL) {
+		dev_err(&pdev->dev, "cannot map IO\n");
+		ret = -ENXIO;
+		goto err_ioarea;
+	}
+
+	dev_dbg(&pdev->dev, "registers %p (%p, %p)\n", i2c->regs, i2c->ioarea, res);
+#endif
+
+	/* setup info block for the i2c core */
+
+	i2c->adap.algo_data = i2c;
+	i2c->adap.dev.parent = &pdev->dev;
+
+	if (pdata) {
+		busfreq = pdata->bus_freq;
+		busnum = pdata->bus_num;
+	} else {
+		of_property_read_u32(pdev->dev.of_node, "bus_freq", &busfreq);
+		of_property_read_u32(pdev->dev.of_node, "bus_num", &busnum);
+	}
+
+	// Set Clock divider
+	ret = clk_get_rate(i2c->clk)/(busfreq * 4) - 1;
+	writel(ret & 0xffff, i2c->regs + CLKDIV);
+
+	writel((readl(i2c->regs+CTL0)|(0x1 << 6)), i2c->regs + CTL0);
+
+	/* find the IRQ for this unit (note, this relies on the init call to
+	 * ensure no current IRQs pending
+	 */
+
+	i2c->irq = ret = platform_get_irq(pdev, 0);
+	if (ret <= 0) {
+		dev_err(&pdev->dev, "cannot find IRQ\n");
+		goto err_iomap;
+	}
+
+	ret = request_irq(i2c->irq, nuc980_i2c_irq, IRQF_SHARED, dev_name(&pdev->dev), i2c);
+
+	if (ret != 0) {
+		dev_err(&pdev->dev, "cannot claim IRQ %d\n", i2c->irq);
+		goto err_iomap;
+	}
+
+	/* Note, previous versions of the driver used i2c_add_adapter()
+	 * to add the bus at any number. We now pass the bus number via
+	 * the platform data, so if unset it will now default to always
+	 * being bus 0.
+	 */
+
+	adap = &i2c->adap;
+
+	i2c->adap.nr = busnum;
+	i2c->adap.dev.of_node = pdev->dev.of_node;
+
+	ret = i2c_add_numbered_adapter(&i2c->adap);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "failed to add bus to i2c core\n");
+		goto err_irq;
+	}
+	//of_i2c_register_devices(&i2c->adap);
+
+	i2c_set_adapdata(adap, i2c);
+	strlcpy(adap->name, pdev->name, sizeof(adap->name));
+
+	pm_runtime_enable(dev);
+
+	platform_set_drvdata(pdev, i2c);
+
+	dev_info(&pdev->dev, "%s: nuc980 I2C adapter\n", dev_name(&i2c->adap.dev));
+
+#if defined(CONFIG_USE_OF)
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+ #ifdef CONFIG_NUC980_I2C3_PB
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c3-PB");
+ #elif defined(CONFIG_NUC980_I2C3_PD)
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "i2c3-PD");
+ #endif
+#endif
+
+	if (IS_ERR(pinctrl)) {
+		return PTR_ERR(pinctrl);
+	}
+
+	return 0;
+
+err_irq:
+	free_irq(i2c->irq, i2c);
+
+err_iomap:
+	iounmap(i2c->regs);
+
+#ifndef CONFIG_USE_OF
+err_ioarea:
+	release_resource(i2c->ioarea);
+	kfree(i2c->ioarea);
+#endif
+
+err_clk:
+	clk_disable(i2c->clk);
+	clk_put(i2c->clk);
+
+err_noclk:
+	kfree(i2c);
+	return ret;
+}
+
+/* nuc980_i2c3_remove
+ *
+ * called when device is removed from the bus
+*/
+
+static int nuc980_i2c3_remove(struct platform_device *pdev)
+{
+	struct nuc980_i2c *i2c = platform_get_drvdata(pdev);
+
+	i2c_del_adapter(&i2c->adap);
+	free_irq(i2c->irq, i2c);
+
+	clk_disable(i2c->clk);
+	clk_put(i2c->clk);
+
+	iounmap(i2c->regs);
+
+	release_resource(i2c->ioarea);
+	kfree(i2c->ioarea);
+	kfree(i2c);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_i2c3_suspend(struct device *dev)
+{
+#ifdef CONFIG_SLAVE_WAKEUP
+	struct nuc980_i2c *i2c = dev_get_drvdata(dev);
+
+	__raw_writel((1<<3) | __raw_readl(REG_WKUPSER1),REG_WKUPSER1);
+
+	nuc980_i2c3_enable_irq(i2c);
+
+	writel(I2C_CTL_SI_AA | readl(i2c->regs + CTL0), i2c->regs + CTL0);
+	writel(0x1, i2c->regs + WKCTL);
+	writel(readl(i2c->regs + WKSTS), i2c->regs + WKSTS);
+
+	enable_irq_wake(i2c->irq);
+#endif
+
+	return 0;
+}
+
+static int nuc980_i2c3_resume(struct device *dev)
+{
+#ifdef CONFIG_SLAVE_WAKEUP
+	struct nuc980_i2c *i2c = dev_get_drvdata(dev);
+
+	writel(0x0, i2c->regs + WKCTL);
+	writel(readl(i2c->regs + WKSTS), i2c->regs + WKSTS);
+#endif
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_i2c3_pmops = {
+	.suspend    = nuc980_i2c3_suspend,
+	.resume     = nuc980_i2c3_resume,
+};
+
+#define NUC980_i2c3_PMOPS (&nuc980_i2c3_pmops)
+
+#else
+#define NUC980_i2c3_PMOPS NULL
+#endif
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_i2c3_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-i2c3" },
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_i2c3_of_match);
+#endif
+
+static struct platform_driver nuc980_i2c3_driver = {
+	.probe      = nuc980_i2c3_probe,
+	.remove     = nuc980_i2c3_remove,
+	.driver     = {
+		.name   = "nuc980-i2c3",
+		.owner  = THIS_MODULE,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_i2c3_of_match),
+#endif
+		.pm = NUC980_i2c3_PMOPS,
+	},
+};
+module_platform_driver(nuc980_i2c3_driver);
+
+MODULE_DESCRIPTION("nuc980 I2C Bus driver");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-i2c3");
diff -uprN linux-4.4.194/drivers/i2c/busses/Kconfig NUC980-linux-4.4.194/drivers/i2c/busses/Kconfig
--- linux-4.4.194/drivers/i2c/busses/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/i2c/busses/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -690,6 +690,114 @@ config I2C_NOMADIK
 	  I2C interface from ST-Ericsson's Nomadik and Ux500 architectures,
 	  as well as the STA2X11 PCIe I/O HUB.
 
+config I2C_BUS_NUC980_P0
+	tristate "NUC980 I2C Driver for Port 0"
+	depends on ARCH_NUC980
+	help
+	  Say Y here to include support for I2C controller in the
+	  Nuvoton NUC980 based System-on-Chip devices.
+
+config ENABLE_I2C_P0_SLAVE_MODE
+	tristate "Enable NUC980 I2C Port 0 Slave Mode"
+	depends on I2C_BUS_NUC980_P0 && I2C_SLAVE
+	help
+	  Enable NUC980 I2C Port 0 Slave Mode.
+
+choice
+		prompt "NUC980 I2C0 pin selection"
+		default NUC980_I2C0_PA
+		depends on I2C_BUS_NUC980_P0
+		help
+		  Select I2C0 multi-function pin.
+
+		config NUC980_I2C0_PA
+			bool "SDA:PA_0  SCL:PA_1"
+		config NUC980_I2C0_PA_PG
+			bool "SDA:PA_15  SCL:PG_10"
+		config NUC980_I2C0_PE
+			bool "SDA:PE_10  SCL:PE_12"
+endchoice
+
+config I2C_BUS_NUC980_P1
+	tristate "NUC980 I2C Driver for Port 1"
+	depends on ARCH_NUC980
+	help
+	  Say Y here to include support for I2C controller in the
+	  Nuvoton NUC980 based System-on-Chip devices.
+
+config ENABLE_I2C_P1_SLAVE_MODE
+	tristate "Enable NUC980 I2C Port 1 Slave Mode"
+	depends on I2C_BUS_NUC980_P1 && I2C_SLAVE
+	help
+	  Enable NUC980 I2C Port 1 Slave Mode.
+
+choice
+		prompt "NUC980 I2C1 pin selection"
+		default NUC980_I2C1_PA
+		depends on I2C_BUS_NUC980_P1
+		help
+		  Select I2C1 multi-function pin.
+
+		config NUC980_I2C1_PA
+			bool "SDA:PA_13  SCL:PA_14"
+		config NUC980_I2C1_PB
+			bool "SDA:PB_6  SCL:PB_4"
+		config NUC980_I2C1_PC
+			bool "SDA:PC_4  SCL:PC_3"
+endchoice
+
+config I2C_BUS_NUC980_P2
+	tristate "NUC980 I2C Driver for Port 2"
+	depends on ARCH_NUC980
+	help
+	  Say Y here to include support for I2C controller in the
+	  Nuvoton NUC980 based System-on-Chip devices.
+
+config ENABLE_I2C_P2_SLAVE_MODE
+	tristate "Enable NUC980 I2C Port 2 Slave Mode"
+	depends on I2C_BUS_NUC980_P2 && I2C_SLAVE
+	help
+	  Enable NUC980 I2C Port 2 Slave Mode.
+
+choice
+		prompt "NUC980 I2C2 pin selection"
+		default NUC980_I2C2_PB
+		depends on I2C_BUS_NUC980_P2
+		help
+		  Select I2C2 multi-function pin.
+
+		config NUC980_I2C2_PB
+			bool "SDA:PB_7  SCL:PB_5"
+		config NUC980_I2C2_PB_PC
+			bool "SDA:PC_0  SCL:PB_8"
+endchoice
+
+config I2C_BUS_NUC980_P3
+	tristate "NUC980 I2C Driver for Port 3"
+	depends on ARCH_NUC980
+	help
+	  Say Y here to include support for I2C controller in the
+	  Nuvoton NUC980 based System-on-Chip devices.
+
+config ENABLE_I2C_P3_SLAVE_MODE
+	tristate "Enable NUC980 I2C Port 3 Slave Mode"
+	depends on I2C_BUS_NUC980_P3 && I2C_SLAVE
+	help
+	  Enable NUC980 I2C Port 3 Slave Mode.
+
+choice
+		prompt "NUC980 I2C3 pin selection"
+		default NUC980_I2C3_PB
+		depends on I2C_BUS_NUC980_P3
+		help
+		  Select I2C3 multi-function pin.
+
+		config NUC980_I2C3_PB
+			bool "SDA:PB_1  SCL:PB_3"
+		config NUC980_I2C3_PD
+			bool "SDA:PD_15  SCL:PD_14"
+endchoice
+
 config I2C_OCORES
 	tristate "OpenCores I2C Controller"
 	help
diff -uprN linux-4.4.194/drivers/i2c/busses/Makefile NUC980-linux-4.4.194/drivers/i2c/busses/Makefile
--- linux-4.4.194/drivers/i2c/busses/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/i2c/busses/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -96,6 +96,10 @@ obj-$(CONFIG_I2C_XILINX)	+= i2c-xiic.o
 obj-$(CONFIG_I2C_XLR)		+= i2c-xlr.o
 obj-$(CONFIG_I2C_XLP9XX)	+= i2c-xlp9xx.o
 obj-$(CONFIG_I2C_RCAR)		+= i2c-rcar.o
+obj-$(CONFIG_I2C_BUS_NUC980_P0)	+= i2c-nuc980-p0.o
+obj-$(CONFIG_I2C_BUS_NUC980_P1)	+= i2c-nuc980-p1.o
+obj-$(CONFIG_I2C_BUS_NUC980_P2)	+= i2c-nuc980-p2.o
+obj-$(CONFIG_I2C_BUS_NUC980_P3)	+= i2c-nuc980-p3.o
 
 # External I2C/SMBus adapter drivers
 obj-$(CONFIG_I2C_DIOLAN_U2C)	+= i2c-diolan-u2c.o
diff -uprN linux-4.4.194/drivers/iio/adc/Kconfig NUC980-linux-4.4.194/drivers/iio/adc/Kconfig
--- linux-4.4.194/drivers/iio/adc/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/iio/adc/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -406,4 +406,77 @@ config XILINX_XADC
 	  The driver can also be build as a module. If so, the module will be called
 	  xilinx-xadc.
 
+config IIO_NUC980ADC
+	tristate "Nuvoton NUC980 Normal ADC driver"
+	depends on ARCH_NUC980
+	select IIO_BUFFER
+	select IIO_TRIGGERED_BUFFER
+	select NUC980_ADC
+	help
+	  Say yes here to build support for NUC980 normal ADC.
+choice
+	prompt "Reference voltage selection"
+	default NUC980ADC_I33V
+	depends on IIO_NUC980ADC
+	help
+	  Select reference voltage source
+
+config NUC980ADC_I33V
+	bool "Internal AVDD, 3.3V"
+config NUC980ADC_VREF
+	bool "VREF input"
+endchoice
+
+config NUC980ADC_BANDGAP
+	bool "Enable internal bandgap"
+        depends on IIO_NUC980ADC
+
+config IIO_NUC980ADC_Ch0
+	tristate "Select external channel 0"
+	depends on IIO_NUC980ADC
+	help
+	Select external channel 0
+
+config IIO_NUC980ADC_Ch1
+	tristate "Select external channel 1"
+	depends on IIO_NUC980ADC
+	help
+	Select external channel 1
+
+config IIO_NUC980ADC_Ch2
+	tristate "Select external channel 2"
+	depends on IIO_NUC980ADC
+	help
+	Select external channel 2
+
+config IIO_NUC980ADC_Ch3
+	tristate "Select external channel 3"
+	depends on IIO_NUC980ADC
+	help
+	Select external channel 3
+
+config IIO_NUC980ADC_Ch4
+	tristate "Select external channel 4"
+	depends on IIO_NUC980ADC
+	help
+	Select external channel 4
+
+config IIO_NUC980ADC_Ch5
+	tristate "Select external channel 5"
+	depends on IIO_NUC980ADC
+	help
+	Select external channel 5
+
+config IIO_NUC980ADC_Ch6
+	tristate "Select external channel 6"
+	depends on IIO_NUC980ADC
+	help
+	Select external channel 6
+
+config IIO_NUC980ADC_Ch7
+	tristate "Select external channel 7"
+	depends on IIO_NUC980ADC
+	help
+	Select external channel 7
+
 endmenu
diff -uprN linux-4.4.194/drivers/iio/adc/Makefile NUC980-linux-4.4.194/drivers/iio/adc/Makefile
--- linux-4.4.194/drivers/iio/adc/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/iio/adc/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -39,3 +39,4 @@ obj-$(CONFIG_VF610_ADC) += vf610_adc.o
 obj-$(CONFIG_VIPERBOARD_ADC) += viperboard_adc.o
 xilinx-xadc-y := xilinx-xadc-core.o xilinx-xadc-events.o
 obj-$(CONFIG_XILINX_XADC) += xilinx-xadc.o
+obj-$(CONFIG_IIO_NUC980ADC) += nuc980_nadc.o
diff -uprN linux-4.4.194/drivers/iio/adc/nuc980_nadc.c NUC980-linux-4.4.194/drivers/iio/adc/nuc980_nadc.c
--- linux-4.4.194/drivers/iio/adc/nuc980_nadc.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/iio/adc/nuc980_nadc.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,369 @@
+/*
+ * NUC980 normal ADC driver
+ *
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/err.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <linux/io.h>
+#include <linux/iio/iio.h>
+#include <linux/iio/sysfs.h>
+#include <linux/iio/trigger.h>
+#include <linux/iio/buffer.h>
+#include <linux/of.h>
+
+#include <linux/iio/trigger_consumer.h>
+#include <linux/iio/triggered_buffer.h>
+
+#include <linux/clk.h>
+
+/* nuc980 adc registers offset */
+#define CTL     0x00
+#define CONF    0x04
+#define IER     0x08
+#define ISR     0x0C
+#define DATA    0x28
+
+#define NUC980_ADC_TIMEOUT	(msecs_to_jiffies(1000))
+
+#define ADC_CHANNEL(_index, _id) {			\
+	.type = IIO_VOLTAGE,				\
+	.indexed = 1,					\
+	.channel = _index,				\
+	.address = _index,				\
+	.info_mask_separate = BIT(IIO_CHAN_INFO_RAW),   \
+	.datasheet_name = _id,				\
+	.scan_index = _index,               \
+	.scan_type = {                      \
+		.sign = 'u',                    \
+		.realbits = 12,                 \
+		.storagebits = 16,              \
+		.shift = 0,                     \
+		.endianness = IIO_BE,           \
+	},                                  \
+}
+
+struct nuc980_adc_device {
+	struct clk  *clk;
+	struct clk  *eclk;
+	unsigned int    irq;
+	void __iomem    *regs;
+	struct completion   completion;
+	struct iio_trigger	*trig;
+};
+
+static const struct iio_chan_spec nuc980_adc_iio_channels[] = {
+	ADC_CHANNEL(0, "adc0"),
+	ADC_CHANNEL(1, "adc1"),
+	ADC_CHANNEL(2, "adc2"),
+	ADC_CHANNEL(3, "adc3"),
+	ADC_CHANNEL(4, "adc4"),
+	ADC_CHANNEL(5, "adc5"),
+	ADC_CHANNEL(6, "adc6"),
+	ADC_CHANNEL(7, "adc7"),
+
+};
+
+static irqreturn_t nuc980_trigger_handler(int irq, void *p)
+{
+	struct iio_poll_func *pf = p;
+	struct iio_dev *indio_dev = pf->indio_dev;
+	struct nuc980_adc_device *info = iio_priv(indio_dev);
+	int val;
+	int channel;
+	unsigned long timeout;
+
+	channel = find_first_bit(indio_dev->active_scan_mask,
+	                         indio_dev->masklength);
+
+	// enable channel
+	writel((readl(info->regs + CONF) & ~(0xf << 12)) | (channel << 12), info->regs + CONF);
+
+	// enable MST
+	writel(readl(info->regs + CTL) | 0x100, info->regs + CTL);
+
+	timeout = wait_for_completion_interruptible_timeout
+	          (&info->completion, NUC980_ADC_TIMEOUT);
+
+	val = readl(info->regs + DATA);
+
+	iio_push_to_buffers(indio_dev, (void *)&val);
+	iio_trigger_notify_done(indio_dev->trig);
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t nuc980_adc_isr(int irq, void *dev_id)
+{
+	struct nuc980_adc_device *info = (struct nuc980_adc_device *)dev_id;
+
+	if(readl(info->regs+ISR) & 1) {  //check M_F bit
+		writel(0x401, info->regs + ISR); //clear flag
+		complete(&info->completion);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static void nuc980_adc_channels_remove(struct iio_dev *indio_dev)
+{
+	kfree(indio_dev->channels);
+}
+
+static void nuc980_adc_buffer_remove(struct iio_dev *idev)
+{
+	iio_triggered_buffer_cleanup(idev);
+}
+
+static int nuc980_adc_read_raw(struct iio_dev *indio_dev,
+                               struct iio_chan_spec const *chan,
+                               int *val, int *val2, long mask)
+{
+	struct nuc980_adc_device *info = iio_priv(indio_dev);
+	unsigned long timeout;
+
+	if (mask != IIO_CHAN_INFO_RAW)
+		return -EINVAL;
+
+	mutex_lock(&indio_dev->mlock);
+
+	// enable channel
+	writel((readl(info->regs + CONF) & ~(0xf << 12)) | (chan->channel << 12), info->regs + CONF);
+
+	// enable MST
+	writel(readl(info->regs + CTL) | 0x100, info->regs + CTL);
+
+	timeout = wait_for_completion_interruptible_timeout
+	          (&info->completion, NUC980_ADC_TIMEOUT);
+
+	*val = readl(info->regs + DATA);
+
+	mutex_unlock(&indio_dev->mlock);
+
+	if (timeout == 0)
+		return -ETIMEDOUT;
+
+	return IIO_VAL_INT;
+}
+
+static int nuc980_ring_preenable(struct iio_dev *indio_dev)
+{
+	return 0;
+}
+
+static const struct iio_buffer_setup_ops nuc980_ring_setup_ops = {
+	.preenable = &nuc980_ring_preenable,
+	.postenable = &iio_triggered_buffer_postenable,
+	.predisable = &iio_triggered_buffer_predisable,
+};
+
+static const struct iio_info nuc980_adc_info = {
+	.read_raw = &nuc980_adc_read_raw,
+};
+
+static int nuc980_adc_probe(struct platform_device *pdev)
+{
+	struct iio_dev	*indio_dev;
+	struct nuc980_adc_device *info = NULL;
+	int ret = -ENODEV;
+	struct resource *res;
+	int irq;
+	int err = 0;
+	struct pinctrl *p;
+
+	indio_dev = iio_device_alloc(sizeof(struct nuc980_adc_device));
+	if (indio_dev == NULL) {
+		dev_err(&pdev->dev, "failed to allocate iio device\n");
+		ret = -ENOMEM;
+		goto err_ret;
+	}
+
+	info = iio_priv(indio_dev);
+
+	/* map the registers */
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (res == NULL) {
+		dev_err(&pdev->dev, "cannot find IO resource\n");
+		ret = -ENOENT;
+		goto err_ret;
+	}
+
+	info->regs = ioremap(res->start, resource_size(res));
+	if (info->regs == NULL) {
+		dev_err(&pdev->dev, "cannot map IO\n");
+		ret = -ENXIO;
+		goto err_ret;
+	}
+
+	indio_dev->dev.parent = &pdev->dev;
+	indio_dev->name = dev_name(&pdev->dev);
+	indio_dev->modes = INDIO_DIRECT_MODE;
+	indio_dev->info = &nuc980_adc_info;
+	indio_dev->num_channels = 8;
+	indio_dev->channels = nuc980_adc_iio_channels;
+	indio_dev->masklength = indio_dev->num_channels - 1;
+
+	/* find the clock and enable it */
+	info->eclk=clk_get(NULL, "adc_eclk");
+	clk_prepare(info->eclk);
+	clk_enable(info->eclk);
+	info->clk=clk_get(NULL, "adc");
+	clk_prepare(info->clk);
+	clk_enable(info->clk);
+
+	clk_set_rate(info->eclk, 4000000);
+
+#if defined(CONFIG_USE_OF)
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+	p = devm_pinctrl_get_select(&pdev->dev, "nadc");
+#endif
+	if(IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve nadc pin by mode\n");
+		err = PTR_ERR(p);
+		goto err_ret;
+	}
+
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0) {
+		dev_err(&pdev->dev, "no irq resource?\n");
+		ret = irq;
+		goto err_ret;
+	}
+
+	info->irq = irq;
+
+	init_completion(&info->completion);
+
+	ret = request_irq(info->irq, nuc980_adc_isr,
+	                  0, dev_name(&pdev->dev), info);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "failed requesting irq, irq = %d\n",
+		        info->irq);
+		goto err_ret;
+	}
+
+#ifdef CONFIG_NUC980ADC_VREF
+	writel(1, info->regs + CTL); //enable AD_EN
+#endif
+#ifdef CONFIG_NUC980ADC_I33V
+	writel(0x3<<6, info->regs + CONF); //select AGND33 vs AVDD33
+	writel(1, info->regs + CTL); //enable AD_EN
+#endif
+#ifdef CONFIG_NUC980ADC_BANDGAP
+	writel(readl(info->regs + CTL) | 2, info->regs + CTL); //enable bandgap
+#endif
+
+	writel(1, info->regs + IER); //enable M_IEN
+
+	ret = iio_triggered_buffer_setup(indio_dev, &iio_pollfunc_store_time,
+	                                 &nuc980_trigger_handler, &nuc980_ring_setup_ops);
+	if (ret)
+		goto err_free_channels;
+
+	ret = iio_device_register(indio_dev);
+	if (ret < 0) {
+		printk("Couldn't register NC980 ADC..\n");
+		goto err_free_channels;
+	}
+
+	platform_set_drvdata(pdev, indio_dev);
+
+	writel((readl(info->regs + CONF) | 1<<2), info->regs + CONF); //enable NACEN
+
+	printk("%s: nuc980 Normal ADC adapter\n",
+	       indio_dev->name);
+
+	return 0;
+
+err_free_channels:
+	nuc980_adc_channels_remove(indio_dev);
+	iio_device_free(indio_dev);
+err_ret:
+	return ret;
+}
+
+static int nuc980_adc_remove(struct platform_device *pdev)
+{
+	struct iio_dev *indio_dev = platform_get_drvdata(pdev);
+	struct nuc980_adc_device *info = iio_priv(indio_dev);
+
+	iio_device_unregister(indio_dev);
+	nuc980_adc_channels_remove(indio_dev);
+
+	iio_device_free(indio_dev);
+
+	clk_disable_unprepare(info->clk);
+	clk_disable_unprepare(info->eclk);
+
+	nuc980_adc_buffer_remove(indio_dev);
+	free_irq(info->irq, info);
+
+	writel(0, info->regs + CONF); //disable NACEN
+	writel(0, info->regs + CTL); //enable AD_EN
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_adc_suspend(struct device *dev)
+{
+	return 0;
+}
+
+static int nuc980_adc_resume(struct device *dev)
+{
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_adc_pm_ops = {
+	.suspend = nuc980_adc_suspend,
+	.resume = nuc980_adc_resume,
+};
+#define NUC980_ADC_PM_OPS (&nuc980_adc_pm_ops)
+#else
+#define NUC980_ADC_PM_OPS NULL
+#endif
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_nadc_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-nadc" } ,
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_spi0_of_match);
+#endif
+
+static struct platform_driver nuc980_adc_driver = {
+	.driver = {
+		.name   = "nuc980-nadc",
+		.owner	= THIS_MODULE,
+		.pm	= NUC980_ADC_PM_OPS,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_nadc_of_match),
+#endif
+	},
+	.probe	= nuc980_adc_probe,
+	.remove	= nuc980_adc_remove,
+};
+
+module_platform_driver(nuc980_adc_driver);
+
+MODULE_DESCRIPTION("NUC980 ADC controller driver");
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-nadc");
diff -uprN linux-4.4.194/drivers/media/i2c/Kconfig NUC980-linux-4.4.194/drivers/media/i2c/Kconfig
--- linux-4.4.194/drivers/media/i2c/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/media/i2c/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -248,6 +248,8 @@ config VIDEO_BT866
 	  To compile this driver as a module, choose M here: the
 	  module will be called bt866.
 
+source "drivers/media/i2c/nuvoton/Kconfig"
+
 config VIDEO_KS0127
 	tristate "KS0127 video decoder"
 	depends on VIDEO_V4L2 && I2C
diff -uprN linux-4.4.194/drivers/media/i2c/Makefile NUC980-linux-4.4.194/drivers/media/i2c/Makefile
--- linux-4.4.194/drivers/media/i2c/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/media/i2c/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -6,6 +6,8 @@ obj-$(CONFIG_VIDEO_CX25840) += cx25840/
 obj-$(CONFIG_VIDEO_M5MOLS)	+= m5mols/
 obj-y				+= soc_camera/
 
+obj-$(CONFIG_VIDEO0_NUC980)      += nuvoton/
+obj-$(CONFIG_VIDEO1_NUC980)      += nuvoton/
 obj-$(CONFIG_VIDEO_APTINA_PLL) += aptina-pll.o
 obj-$(CONFIG_VIDEO_TVAUDIO) += tvaudio.o
 obj-$(CONFIG_VIDEO_TDA7432) += tda7432.o
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/Kconfig NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/Kconfig
--- linux-4.4.194/drivers/media/i2c/nuvoton/Kconfig	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,71 @@
+config VIDEO0_NUC980
+	tristate "Nuvoton NUC980 Video-In0 Support"
+	depends on I2C && VIDEO_DEV
+	select VIDEO_BUF
+	select VIDEOBUF_DMA_CONTIG
+	---help---
+	Support for built-in video-in interface for NUC980.
+config VIN0_MAX_FRAME_BUFFER
+	int "Max frame buffer"
+	depends on VIDEO0_NUC980
+	default "3"
+config VIDEO0_FREQ
+	int "Video frequency"
+	depends on VIDEO0_NUC980
+	default "24000000"
+if !USE_OF
+choice
+	prompt "Nuvoton NUC980 Image Sensor Selection"
+	depends on VIDEO0_NUC980
+	default SENSOR0_NT99141
+config SENSOR0_OV7725
+	bool "OV7725"
+config SENSOR0_OV5640
+	bool "OV5640"
+config SENSOR0_NT99141
+	bool "NT99141"
+config SENSOR0_NT99050
+	bool "NT99050"
+config SENSOR0_TW9912
+	bool "TW9912"
+config SENSOR0_GC0308
+        bool "GC0308"
+endchoice
+endif
+
+
+config VIDEO1_NUC980
+        tristate "Nuvoton NUC980 Video-In1 Support"
+        depends on I2C && VIDEO_DEV
+        select VIDEO_BUF
+        select VIDEOBUF_DMA_CONTIG
+        ---help---
+        Support for built-in video-in interface for NUC980.
+config VIN1_MAX_FRAME_BUFFER
+        int "Max frame buffer"
+        depends on VIDEO1_NUC980
+        default "3"
+config VIDEO1_FREQ
+        int "Video frequency"
+        depends on VIDEO1_NUC980
+	default "24000000"
+if !USE_OF
+choice
+        prompt "Nuvoton NUC980 Image Sensor Selection"
+        depends on VIDEO1_NUC980
+        default SENSOR1_NT99141
+config SENSOR1_OV7725
+        bool "OV7725"
+config SENSOR1_OV5640
+        bool "OV5640"
+config SENSOR1_NT99141
+        bool "NT99141"
+config SENSOR1_NT99050
+        bool "NT99050"
+config SENSOR1_TW9912
+        bool "TW9912"
+config SENSOR1_GC0308
+        bool "GC0308"
+endchoice
+
+endif
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/Makefile NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/Makefile
--- linux-4.4.194/drivers/media/i2c/nuvoton/Makefile	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,31 @@
+
+obj-$(CONFIG_VIDEO0_NUC980) += nuc980_cap0.o
+obj-$(CONFIG_VIDEO1_NUC980) += nuc980_cap1.o
+ifeq ($(CONFIG_USE_OF),y)
+obj-y += sensor0_ov7725.o
+obj-y += sensor0_ov5640.o
+obj-y += sensor0_nt99141.o
+obj-y += sensor0_nt99050.o
+obj-y += sensor0_tw9912.o
+obj-y += sensor0_gc0308.o
+obj-y += sensor1_ov7725.o
+obj-y += sensor1_ov5640.o
+obj-y += sensor1_nt99141.o
+obj-y += sensor1_nt99050.o
+obj-y += sensor1_tw9912.o
+obj-y += sensor1_gc0308.o
+else
+obj-$(CONFIG_SENSOR0_OV7725) += sensor0_ov7725.o
+obj-$(CONFIG_SENSOR0_OV5640) += sensor0_ov5640.o
+obj-$(CONFIG_SENSOR0_NT99141) += sensor0_nt99141.o
+obj-$(CONFIG_SENSOR0_NT99050) += sensor0_nt99050.o
+obj-$(CONFIG_SENSOR0_TW9912) += sensor0_tw9912.o
+obj-$(CONFIG_SENSOR0_GC0308) += sensor0_gc0308.o
+
+obj-$(CONFIG_SENSOR1_OV7725) += sensor1_ov7725.o
+obj-$(CONFIG_SENSOR1_OV5640) += sensor1_ov5640.o
+obj-$(CONFIG_SENSOR1_NT99141) += sensor1_nt99141.o
+obj-$(CONFIG_SENSOR1_NT99050) += sensor1_nt99050.o
+obj-$(CONFIG_SENSOR1_TW9912) += sensor1_tw9912.o
+obj-$(CONFIG_SENSOR1_GC0308) += sensor1_gc0308.o
+endif
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap0.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap0.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap0.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap0.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1809 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/list.h>
+#include <linux/slab.h>
+#include <linux/clk.h>
+#include <linux/module.h>
+#include <linux/mm.h>
+#include <linux/fs.h>
+#include <linux/dma-mapping.h>
+#include <linux/interrupt.h>
+#include <linux/vmalloc.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/delay.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/gpio.h>
+
+#include <linux/videodev2.h>
+#include <media/v4l2-common.h>
+#include <media/v4l2-ioctl.h>
+#include <media/videobuf-dma-contig.h>
+#include <media/v4l2-dev.h>
+
+#include <media/v4l2-device.h>
+#include <linux/jiffies.h>
+
+#include <asm/io.h>
+
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+//#include <mach/regs-lcd.h>
+#include <mach/regs-gpio.h>
+
+#include <mach/regs-cap.h>
+#include <linux/time.h>
+
+#include "nuc980_cap.h"
+#define  CAP0_PD_PIN NUC980_PB1
+#define  CAP0_RST_PIN NUC980_PC7
+u32 sensor0_model = 1;
+u32 video0_freq = 24000000;
+
+void nuvoton_vdi0_enable(struct nuvoton_vin_device* cam)
+{
+	u8 packet=0,planar=0,engine=0;
+	ENTRY();
+	if(cam->vpe.PacketEnable==1) {
+		packet=1;
+		if(cam->sensor.bothenable==1)
+			planar=1;
+	}
+
+	if(cam->vpe.PlanarEnable==1) planar=1;
+	engine=(packet|planar);
+	__raw_writel( __raw_readl(REG_CAP0_CTL) | ( (engine<<0) | (packet<<6) | (planar<<5) ),REG_CAP0_CTL);
+	LEAVE();
+}
+
+void nuvoton_vdi0_disable(struct nuvoton_vin_device* cam)
+{
+	ENTRY();
+	if((__raw_readl(REG_CAP0_CTL) & ( (1<<6) | (1<<5) ))!= 0) {
+		__raw_writel(__raw_readl(REG_CAP0_CTL)|(1<<16),REG_CAP0_CTL);
+		while((__raw_readl(REG_CAP0_CTL) & 1)==1);
+		__raw_writel( __raw_readl(REG_CAP0_CTL) & ~( (1<<6) | (1<<5) ),REG_CAP0_CTL);
+	}
+	LEAVE();
+}
+
+/* ---- IOCTL vidioc handling  ----*/
+static int nuvoton_vidioc0_querycap(struct file* file,void* priv,struct v4l2_capability *cap)
+{
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+	strlcpy(cap->driver,"nuvoton_vin0",sizeof(cap->driver));
+	cap->version = KERNEL_VERSION(1, 1, 10);
+	cap->capabilities = V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_READWRITE | V4L2_CAP_STREAMING| V4L2_CAP_VIDEO_OVERLAY | V4L2_CAP_DEVICE_CAPS;
+	cap->device_caps = V4L2_CAP_EXT_PIX_FORMAT;
+	strlcpy(cap->card, cam->v4ldev->name, sizeof(cap->card));
+	LEAVE();
+	return 0;
+}
+
+#if 1
+/* set the parameters of frame rate control of capture DMA of NUVOTON */
+static int nuvoton_vidioc0_s_parm(struct file* file,void* priv,struct v4l2_streamparm *parm)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+/* get the frame rate parameters */
+static int nuvoton_vidioc0_g_parm(struct file* file,void* priv,struct v4l2_streamparm *parm)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+#endif
+
+/* enum all supported formats of specific device */
+static const struct cap_format cap_formats[] = {
+	{
+		.desc        = "Packet YUV422",
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+	},
+	{
+		.desc        = "Packet GREY",
+		.pixelformat = V4L2_PIX_FMT_GREY,
+	},
+	{
+		.desc        = "Packet RGB 565",
+		.pixelformat = V4L2_PIX_FMT_RGB565,
+	},
+	{
+		.desc        = "Packet RGB 555",
+		.pixelformat = V4L2_PIX_FMT_RGB555,
+	},
+
+	{
+		.desc        = "Planar YUV422",
+		.pixelformat = V4L2_PIX_FMT_YUV422P,
+	},
+	{
+		.desc        = "Planar YUV420",
+		.pixelformat = V4L2_PIX_FMT_YUV411P,
+	},
+};
+static int nuvoton_vidioc0_enum_fmt_vid_cap(struct file *file,void  *priv,struct v4l2_fmtdesc *f)
+{
+	ENTRY();
+	f->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	if (f->index >= sizeof(cap_formats)/sizeof(struct cap_format))
+		return -EINVAL;
+	strlcpy(f->description,cap_formats[f->index].desc,sizeof(f->description));
+	f->pixelformat = cap_formats[f->index].pixelformat;
+	LEAVE();
+	return 0;
+}
+
+/* get the parameters of frame, width, height, field, type, bytesperline, sizeimage */
+static int nuvoton_vidioc0_g_fmt_vid_cap(struct file *file,void *priv,struct v4l2_format *format)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct v4l2_pix_format* pfmt = &(cam->sensor.pix_format);
+	ENTRY();
+	pfmt->bytesperline = 0;
+	pfmt->sizeimage = pfmt->height * ((pfmt->width*pfmt->priv)/8);
+	pfmt->field = V4L2_FIELD_NONE;
+	memcpy(&(format->fmt.pix), pfmt, sizeof(*pfmt));
+	LEAVE();
+	return 0;
+}
+
+unsigned short GCD0(unsigned short m1, unsigned short m2)
+{
+	unsigned short m;
+	if(m1<m2) {
+		m=m1;
+		m1=m2;
+		m2=m;
+	}
+	if(m1%m2==0)
+		return m2;
+	else
+		return (GCD0(m2,m1%m2));
+}
+
+void nuvoton_cap0_SetPlanarFmt(struct nuvoton_vin_device* cam,struct v4l2_pix_format* pix)
+{
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	u32 outfmt=0;
+	u32 u32GCD;
+	if(s->planarfmt==V4L2_PIX_FMT_YUV422P)
+		outfmt  |= 0<<7;
+	else
+		outfmt  |= 1<<7;
+	__raw_writel( (__raw_readl(REG_CAP0_PAR) & ~(1<<7)) | outfmt,REG_CAP0_PAR );
+
+	VDEBUG("Planar, pix->height=%d,pix->width=%d\n",pix->height,pix->width);
+	VDEBUG("Planar, s->cropcap.bounds.height=%d,s->cropcap.bounds.width=%d\n",s->cropcap.bounds.height,s->cropcap.bounds.width);
+	__raw_writel( (__raw_readl(REG_CAP0_PAR) & ~(1<<7)) | outfmt,REG_CAP0_PAR );
+
+	/* Planar Scaling Vertical Factor Register (LSB) */
+	u32GCD=pix->height/s->cropcap.bounds.height;
+	if(u32GCD<=0) u32GCD=1;
+	__raw_writel( (__raw_readl(REG_CAP0_PLNSL) & ~(CAP_PLNSL_PLNSVNL | CAP_PLNSL_PLNSVML))|
+	              ( ((pix->height/u32GCD)&0xff)<<24 | ((s->cropcap.bounds.height/u32GCD)&0xff)<<16),REG_CAP0_PLNSL);
+
+	/* Planar Scaling Vertical Factor Register (MSB) */
+	u32GCD=pix->height/s->cropcap.bounds.height;
+	if(u32GCD<=0) u32GCD=1;
+	__raw_writel( (__raw_readl(REG_CAP0_PLNSM) & ~(CAP_PLNSM_PLNSVNH | CAP_PLNSM_PLNSVMH))|
+	              ( ((pix->height/u32GCD)>>8)<<24 | ((s->cropcap.bounds.height)>>8)/u32GCD<<16),REG_CAP0_PLNSM);
+
+	/* Planar Scaling Horizontal Factor Register (LSB) */
+	u32GCD=pix->width/s->cropcap.bounds.width;
+	if(u32GCD<=0) u32GCD=1;
+	__raw_writel( (__raw_readl(REG_CAP0_PLNSL) & ~(CAP_PLNSL_PLNSHNL | CAP_PLNSL_PLNSHML))|
+	              (((pix->width/u32GCD) & 0xff)<<8 | ((s->cropcap.bounds.width/u32GCD) & 0xff)<<0),REG_CAP0_PLNSL);
+
+	/* Planar Scaling Horizontal Factor Register (MSB) */
+	u32GCD=pix->width/s->cropcap.bounds.width;
+	if(u32GCD<=0) u32GCD=1;
+	__raw_writel( (__raw_readl(REG_CAP0_PLNSM) & ~(CAP_PLNSM_PLNSHNH | CAP_PLNSM_PLNSHMH))|
+	              (((pix->width/u32GCD) >>8)<<8 | ((s->cropcap.bounds.width/u32GCD)>>8)<<0),REG_CAP0_PLNSM);
+
+	/* Frame Output Pixel Stride Width Register(Planar) */
+#if 0
+	__raw_writel( (__raw_readl(REG_CAP0_STRIDE)& ~CAP_STRIDE_PLNSTRIDE) |
+	              (/*PacketStride*/pix->width<<16),REG_CAP0_STRIDE);
+#else
+	__raw_writel( (__raw_readl(REG_CAP0_STRIDE)& ~CAP_STRIDE_PLNSTRIDE) |
+	              (/*PacketStride*/(pix->bytesperline/2)<<16),REG_CAP0_STRIDE);
+#endif
+
+	cam->vpe.PlanarWidth=pix->width;
+	cam->vpe.PlanarHeight=pix->height;
+}
+
+/* This ioctl is similar to vidioc_s_fmt_vid_cap(). However, this ioctl is used to query the formats
+that the device supports without changing any state of the device. */
+static int nuvoton_vidioc0_try_fmt_vid_cap(struct file *file, void *priv,struct v4l2_format *format)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	struct v4l2_pix_format* pix;
+	struct v4l2_pix_format* pfmt = &(s->pix_format);
+	struct v4l2_rect* bounds = &(s->cropcap.bounds);
+	struct v4l2_rect rect;
+	u32 u32GCD0;
+	u32 heightM,heightN,widthM,widthN;
+	u32 outfmt;
+	//const u8 stream = cam->stream;
+	//const u32 nbuffers = cam->nbuffers;
+	//u32 i;
+	//int err = 0;
+	ENTRY();
+	pix = &(format->fmt.pix);
+
+	if (format->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)
+		return -EINVAL;
+	memcpy(&rect, &(s->_rect), sizeof(rect));
+
+	rect.width = pix->width;
+	rect.height = pix->height;
+	if (rect.width < 8)
+		rect.width = 8;
+	if (rect.height < 8)
+		rect.height = 8;
+	if (rect.width > bounds->left + bounds->width - rect.left)
+		rect.width = bounds->left + bounds->width - rect.left;
+	if (rect.height > bounds->top + bounds->height - rect.top)
+		rect.height = bounds->top + bounds->height - rect.top;
+	rect.width &= ~7L;
+	rect.height &= ~7L;
+
+	pix->width = rect.width;
+	pix->height = rect.height;
+	pix->priv = pfmt->priv;
+	pix->colorspace = pfmt->colorspace;
+	if(pix->bytesperline==0) {
+		pix->bytesperline = pix->width*2;
+		pfmt->bytesperline = pix->width*2;
+	}
+
+	pix->sizeimage = pix->height * (((pix->bytesperline/2) * pix->priv) / 8);
+	pix->field = V4L2_FIELD_NONE;
+	memcpy(pfmt, pix, sizeof(*pix));
+	/*Set capture format for nuvoton sensor interface */
+	__raw_writel( (__raw_readl(REG_CAP0_CWS) & ~(0x0fff0fff)) | (s->cropcap.bounds.width) | (s->cropcap.bounds.height<<16),REG_CAP0_CWS );
+	switch(pix->pixelformat) {
+		/* Packet YUV422 */
+	case V4L2_PIX_FMT_YUYV:
+	case V4L2_PIX_FMT_RGB555:
+	case V4L2_PIX_FMT_RGB565:
+	case V4L2_PIX_FMT_GREY:
+		VDEBUG("Packet\n");
+		if(pix->pixelformat==V4L2_PIX_FMT_YUYV)
+			outfmt = 0<<4;
+		if(pix->pixelformat==V4L2_PIX_FMT_GREY) {
+			pix->priv = 8;
+			outfmt = 1<<4;
+		}
+		if(pix->pixelformat==V4L2_PIX_FMT_RGB555)
+			outfmt = 2<<4;
+		if(pix->pixelformat==V4L2_PIX_FMT_RGB565)
+			outfmt = 3<<4; //infmtord
+
+		if(s->bothenable==1) {
+			nuvoton_cap0_SetPlanarFmt(cam,pix);
+		}
+
+		__raw_writel( (__raw_readl(REG_CAP0_PAR) & ~(3<<4)) | outfmt,REG_CAP0_PAR );
+		__raw_writel( (__raw_readl(REG_CAP0_PAR) & ~INMASK) | s->infmtord,REG_CAP0_PAR );
+		//VDEBUG("pix->pixelformat = V4L2_PIX_FMT_YUYV\n");
+		/* Set_Cropping start position for sensor */
+		if(cam->users==1)
+			__raw_writel( (__raw_readl(REG_CAP0_CWSP) & ~(CAP_CWSP_CWSADDRV | CAP_CWSP_CWSADDRH)) | (s->cropstart),REG_CAP0_CWSP );
+
+		/* Packet Scaling Vertical Factor Register (LSB) */
+		VDEBUG("pix->height=%d, s->cropcap.bounds.height = %d\n",pix->height,s->cropcap.bounds.height);
+		if(pix->height > s->cropcap.bounds.height) {
+			heightN=1;
+			heightM=1;
+		} else {
+			heightM = s->cropcap.bounds.height;
+			heightN = pix->height;
+		}
+		__raw_writel( (__raw_readl(REG_CAP0_PKTSL) & ~(CAP_PKTSL_PKTSVNL | CAP_PKTSL_PKTSVML))|
+		              ((heightN & 0xff)<<24|(heightM & 0xff)<<16),REG_CAP0_PKTSL);
+
+		/* Packet Scaling Vertical Factor Register (MSB) */
+		__raw_writel( (__raw_readl(REG_CAP0_PKTSM) & ~(CAP_PKTSM_PKTSVNH | CAP_PKTSM_PKTSVMH))|
+		              ((heightN>>8)<<24|(heightM>>8)<<16),REG_CAP0_PKTSM);
+		/* Packet Scaling Horizontal Factor Register (LSB) */
+		VDEBUG("pix->width=%d, s->cropcap.bounds.width = %d\n",pix->width,s->cropcap.bounds.width);
+		if(pix->width > s->cropcap.bounds.width) {
+			widthN=1;
+			widthM=1;
+		} else {
+			widthM = s->cropcap.bounds.width;
+			widthN = pix->width;
+		}
+		__raw_writel( (__raw_readl(REG_CAP0_PKTSL) & ~(CAP_PKTSL_PKTSHNL | CAP_PKTSL_PKTSHML))|
+		              ((widthN & 0xff)<<8 | (widthM & 0xff)<<0),REG_CAP0_PKTSL);
+
+		/* Packet Scaling Horizontal Factor Register (MSB) */
+		__raw_writel( (__raw_readl(REG_CAP0_PKTSM) & ~(CAP_PKTSM_PKTSHNH | CAP_PKTSM_PKTSHMH))|
+		              ((widthN>>8)<<8 | (widthM>>8)<<0),REG_CAP0_PKTSM);
+
+		/* Frame Output Pixel Stride Width Register(Packet/Planar) */
+#if 0
+		__raw_writel( (__raw_readl(REG_CAP0_STRIDE)& ~CAP_STRIDE_PKTSTRIDE) |
+		              (/*PacketStride*/pix->width<<0),REG_CAP0_STRIDE);
+#else
+		if(pix->pixelformat!=V4L2_PIX_FMT_GREY) {
+			__raw_writel( (__raw_readl(REG_CAP0_STRIDE)& ~CAP_STRIDE_PKTSTRIDE) |
+			              (/*PacketStride*/(pix->bytesperline/2)<<0),REG_CAP0_STRIDE);
+		} else {
+			__raw_writel( (__raw_readl(REG_CAP0_STRIDE)& ~CAP_STRIDE_PKTSTRIDE) |
+			              (/*PacketStride*/(pix->bytesperline/1)<<0),REG_CAP0_STRIDE);
+		}
+#endif
+		cam->vpe.format=pix->pixelformat;
+		cam->vpe.PacketWidth=pix->width;
+		cam->vpe.PacketHeight=pix->height;
+		cam->vpe.PacketEnable=1;
+		break;
+
+		/* Planar YUV422 */
+	case V4L2_PIX_FMT_YUV422P:
+	case V4L2_PIX_FMT_YUV411P:
+		if(pix->pixelformat==V4L2_PIX_FMT_YUV422P)  outfmt = 0<<7;
+		if(pix->pixelformat==V4L2_PIX_FMT_YUV411P)  outfmt = 1<<7;
+		VDEBUG("Planar, cam->users=%d\n",cam->users);
+		VDEBUG("Planar, pix->height=%d,pix->width=%d\n",pix->height,pix->width);
+		VDEBUG("Planar, s->cropcap.bounds.height=%d,s->cropcap.bounds.width=%d\n",s->cropcap.bounds.height,s->cropcap.bounds.width);
+		__raw_writel( (__raw_readl(REG_CAP0_PAR) & ~(1<<7)) | outfmt,REG_CAP0_PAR );
+		//VDEBUG("pix->pixelformat = V4L2_PIX_FMT_YUV422P\n");
+		/* Set_Cropping start position for sensor */
+		if(cam->users==1)
+			__raw_writel( (__raw_readl(REG_CAP0_CWSP) & ~(CAP_CWSP_CWSADDRV | CAP_CWSP_CWSADDRH)) | ( 0 | 2<<16 ),REG_CAP0_CWSP );
+		/* Planar Scaling Vertical Factor Register (LSB) */
+		u32GCD0=pix->height/s->cropcap.bounds.height;
+		if(u32GCD0<=0) u32GCD0=1;
+		__raw_writel( (__raw_readl(REG_CAP0_PLNSL) & ~(CAP_PLNSL_PLNSVNL | CAP_PLNSL_PLNSVML))|
+		              ( ((pix->height/u32GCD0)&0xff)<<24 | ((s->cropcap.bounds.height/u32GCD0)&0xff)<<16),REG_CAP0_PLNSL);
+
+		/* Planar Scaling Vertical Factor Register (MSB) */
+		u32GCD0=pix->height/s->cropcap.bounds.height;
+		if(u32GCD0<=0) u32GCD0=1;
+		__raw_writel( (__raw_readl(REG_CAP0_PLNSM) & ~(CAP_PLNSM_PLNSVNH | CAP_PLNSM_PLNSVMH))|
+		              ( ((pix->height/u32GCD0)>>8)<<24 | ((s->cropcap.bounds.height)>>8)/u32GCD0<<16),REG_CAP0_PLNSM);
+
+		/* Planar Scaling Horizontal Factor Register (LSB) */
+		u32GCD0=pix->width/s->cropcap.bounds.width;
+		if(u32GCD0<=0) u32GCD0=1;
+		__raw_writel( (__raw_readl(REG_CAP0_PLNSL) & ~(CAP_PLNSL_PLNSHNL | CAP_PLNSL_PLNSHML))|
+		              (((pix->width/u32GCD0) & 0xff)<<8 | ((s->cropcap.bounds.width/u32GCD0) & 0xff)<<0),REG_CAP0_PLNSL);
+
+		/* Planar Scaling Horizontal Factor Register (MSB) */
+		u32GCD0=pix->width/s->cropcap.bounds.width;
+		if(u32GCD0<=0) u32GCD0=1;
+		__raw_writel( (__raw_readl(REG_CAP0_PLNSM) & ~(CAP_PLNSM_PLNSHNH | CAP_PLNSM_PLNSHMH))|
+		              (((pix->width/u32GCD0) >>8)<<8 | ((s->cropcap.bounds.width/u32GCD0)>>8)<<0),REG_CAP0_PLNSM);
+
+		/* Frame Output Pixel Stride Width Register(Planar) */
+#if 0
+		__raw_writel( (__raw_readl(REG_CAP0_STRIDE)& ~CAP_STRIDE_PLNSTRIDE) |
+		              (/*PacketStride*/pix->width<<16),REG_CAP0_STRIDE);
+#else
+		__raw_writel( (__raw_readl(REG_CAP0_STRIDE)& ~CAP_STRIDE_PLNSTRIDE) |
+		              (/*PacketStride*/(pix->bytesperline/2)<<16),REG_CAP0_STRIDE);
+#endif
+
+		cam->vpe.format=pix->pixelformat;
+		cam->vpe.PlanarWidth=pix->width;
+		cam->vpe.PlanarHeight=pix->height;
+		cam->vpe.PlanarEnable=1;
+		VDEBUG("V4L2_PIX_FMT_YUV422P END\n");
+		break;
+
+#if 0  /* not surpport yet, TODO: */
+	case V4L2_PIX_FMT_NV16: /* 16  Y/CbCr 4:2:2  */
+		break;
+	case V4L2_PIX_FMT_NV61: /* 16  Y/CrCb 4:2:2  */
+		break;
+	case V4L2_PIX_FMT_YYUV:
+		break;
+	case V4L2_PIX_FMT_YUYV:
+		break;
+	case V4L2_PIX_FMT_YYUV:
+		break;
+	case V4L2_PIX_FMT_YVYU:
+		break;
+	case V4L2_PIX_FMT_UYVY:
+		break;
+	case V4L2_PIX_FMT_VYUY:
+		break;
+
+		/* packet only Y*/
+	case V4L2_PIX_FMT_GREY:
+		break;
+
+		/* Packet RGB555 */
+	case V4L2_PIX_FMT_RGB555:
+		break;
+
+		/* Packet RGB565 */
+	case V4L2_PIX_FMT_RGB565:
+		break;
+
+#endif
+
+	default :
+		return -EINVAL;
+		break;
+
+	}
+
+	if(cam->users==1) {
+		__raw_writel((__raw_readl(REG_CAP0_PAR) & ~(VSP_HI|HSP_HI|PCLKP_HI)) | s->polarity,REG_CAP0_PAR); /* set CAP Polarity */
+		__raw_writel((__raw_readl(REG_CAP0_INT) | 0x10000) ,REG_CAP0_INT);     /* Enable CAP Interrupt */
+	}
+
+	LEAVE();
+	return 0;
+}
+
+
+/* FIX ME: This seems to be generic enough to be at videodev2 */
+/* FIX ME:
+This function sets the output image resolution of the sensor, and save the parameters. */
+static int nuvoton_vidioc0_s_fmt_vid_cap(struct file *file,void *priv,struct v4l2_format *format)
+{
+	ENTRY();
+	nuvoton_vidioc0_try_fmt_vid_cap(file,priv,format);
+	LEAVE();
+	return 0;
+}
+
+/* ask kernel to allocate needed buffer */
+static int nuvoton_vidioc0_reqbufs(struct file *file, void *priv,struct v4l2_requestbuffers *rb)
+{
+	struct nuvoton_vin_device* cam=priv;
+	//struct nuvoton_vin_sensor* s = &cam->sensor;
+	u32 i;
+	int err;
+	ENTRY();
+	if (rb->type != V4L2_BUF_TYPE_VIDEO_CAPTURE || rb->memory != V4L2_MEMORY_MMAP)
+		return -EINVAL;
+
+	if (cam->io == IO_READ) {
+		VDEBUG("Close and open the device again to choose the mmap I/O method\n");
+		return -EBUSY;
+	}
+
+	for (i = 0; i < cam->nbuffers; i++)
+		if (cam->frame[i].vma_use_count) {
+			VDEBUG("VIDIOC_REQBUFS failed. Previous buffers are still mapped.\n");
+			return -EBUSY;
+		}
+
+	if (cam->stream == STREAM_ON)
+		if ((err = nuvoton_vin0_stream_interrupt(cam)))
+			return err;
+
+	nuvoton_vin0_empty_framequeues(cam);
+
+	nuvoton_vin0_release_buffers(cam);
+	if (rb->count)
+		rb->count = nuvoton_vin0_request_buffers(cam, rb->count, IO_MMAP);
+
+	cam->io = rb->count ? IO_MMAP : IO_NONE;
+
+	LEAVE();
+	return 0;
+}
+
+/* query buffer info */
+static int nuvoton_vidioc0_querybuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+	if (p->type != V4L2_BUF_TYPE_VIDEO_CAPTURE ||
+	    p->index >= cam->nbuffers || cam->io != IO_MMAP) {
+		LEAVE();
+		return -EINVAL;
+	}
+
+	memcpy(p,&(cam->frame[p->index].buf),sizeof(struct v4l2_buffer));
+
+	if (cam->frame[p->index].vma_use_count)
+		p->flags |= V4L2_BUF_FLAG_MAPPED;
+
+	if (cam->frame[p->index].state == F_DONE)
+		p->flags |= V4L2_BUF_FLAG_DONE;
+	else if (cam->frame[p->index].state != F_UNUSED)
+		p->flags |= V4L2_BUF_FLAG_QUEUED;
+
+	LEAVE();
+	return 0;
+}
+
+/* put the buffer into the list */
+static int nuvoton_vidioc0_qbuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct v4l2_buffer b;
+	unsigned long lock_flags;
+	ENTRY();
+	memcpy(&b,p,sizeof(b));
+
+	if (b.type != V4L2_BUF_TYPE_VIDEO_CAPTURE ||
+	    b.index >= cam->nbuffers || cam->io != IO_MMAP) {
+		return -EINVAL;
+	}
+	if (cam->frame[b.index].state != F_UNUSED) {
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&cam->queue_lock, lock_flags);
+	cam->frame[b.index].state = F_QUEUED;
+	list_add_tail(&cam->frame[b.index].frame, &cam->inqueue);
+	spin_unlock_irqrestore(&cam->queue_lock, lock_flags);
+
+	VDEBUG("Frame #%lu queued", (unsigned long)b.index);
+	LEAVE();
+	return 0;
+}
+
+/* de-queue a buffer from the list */
+static int nuvoton_vidioc0_dqbuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct v4l2_buffer b;
+	struct nuvoton_vin_frame_t *f;
+	unsigned long lock_flags;
+	int err = 0;
+	ENTRY();
+	memcpy(&b,p,sizeof(b));
+	if (b.type != V4L2_BUF_TYPE_VIDEO_CAPTURE)
+		return -EINVAL;
+	if (list_empty(&cam->outqueue)) {
+		if (cam->stream == STREAM_OFF)
+			return -EINVAL;
+		err = wait_event_interruptible( cam->wait_frame,(!list_empty(&cam->outqueue)));
+		if (err) return err;
+	}
+	spin_lock_irqsave(&cam->queue_lock, lock_flags);
+	f = list_entry(cam->outqueue.next, struct nuvoton_vin_frame_t, frame);
+	list_del(cam->outqueue.next);
+	spin_unlock_irqrestore(&cam->queue_lock, lock_flags);
+	f->state = F_UNUSED;
+	b = f->buf;
+	if (f->vma_use_count)
+		b.flags |= V4L2_BUF_FLAG_MAPPED;
+	memcpy(p,&b,sizeof(b));
+	VDEBUG("Frame0 #%lu dequeued", (unsigned long)f->buf.index);
+
+	LEAVE();
+	return 0;
+}
+
+/* start capturing the sensor output stream */
+static int nuvoton_vidioc0_streamon(struct file *file, void *priv, enum v4l2_buf_type i)
+{
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+
+	/* Setting Buffer address */
+	VDEBUG("cam->nbuffers=%d\n",cam->nbuffers);
+
+	if(cam->nbuffers>0) {
+		VDEBUG("cam->frame_current->bufmem=0x%08x\n",cam->frame_current->bufmem);
+		VDEBUG("cam->frame_current->pbuf=0x%08x\n",cam->frame_current->pbuf);
+		VDEBUG("cam->vpe.PacketEnable=%d\n",cam->vpe.PacketEnable);
+
+		if(cam->vpe.PacketEnable==1) {
+			if(cam->frame_current!=NULL)
+				__raw_writel(cam->frame_current->pbuf,REG_CAP0_PKTBA0);
+			else
+				VDEBUG("PacketEnable : cam->frame_current == NULL\n");
+
+			if(cam->sensor.bothenable==1) {
+				struct nuvoton_vin_sensor* s = &cam->sensor;
+				struct v4l2_rect* bounds = &(s->cropcap.bounds);
+				u32 size = bounds->height*bounds->height*2;
+				__raw_writel((unsigned int)cam->frame_current->pbuf+size,REG_CAP0_YBA);
+				__raw_writel(__raw_readl(REG_CAP0_YBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight),REG_CAP0_UBA);
+				__raw_writel(__raw_readl(REG_CAP0_UBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight)/2,REG_CAP0_VBA);
+			}
+		}
+
+		VDEBUG("cam->vpe.PlanarEnable=%d\n",cam->vpe.PlanarEnable);
+		if(cam->vpe.PlanarEnable==1) {
+			if(cam->frame_current!=NULL) {
+				__raw_writel((unsigned int)cam->frame_current->pbuf,REG_CAP0_YBA);
+				__raw_writel(__raw_readl(REG_CAP0_YBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight),REG_CAP0_UBA);
+				__raw_writel(__raw_readl(REG_CAP0_UBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight)/2,REG_CAP0_VBA);
+			} else
+				VDEBUG("PlanarEnable : cam->frame_current == NULL\n");
+		}
+	}
+	__raw_writel((__raw_readl(REG_CAP0_INT) | 0x10000) ,REG_CAP0_INT);     /* Enable CAP Interrupt */
+	/* Capture engine enable and packer/planar mode enable */
+	nuvoton_vdi0_enable(cam);
+
+	cam->stream = STREAM_ON;
+	LEAVE();
+	return 0;
+}
+
+/* stop capturing sensor output stream */
+static int nuvoton_vidioc0_streamoff(struct file *file, void *priv, enum v4l2_buf_type i)
+{
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+	cam->vpe.PacketEnable=0;
+	cam->vpe.PacketEnable=0;
+	cam->stream = STREAM_OFF;
+	nuvoton_vdi0_disable(cam);
+	LEAVE();
+	return 0;
+}
+
+/* setup the device support standard */
+static int nuvoton_vidioc0_s_std(struct file *file, void *priv, v4l2_std_id i)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+
+/* only one input in this sample driver */
+/* Enumerate the input. AVID Daytona supports several input devices
+* 1. image sensor
+* 2. native image post-processor
+* 3. analog TV tuner * * */
+static int nuvoton_vidioc0_enum_input(struct file *file,void *priv,struct v4l2_input *inp)
+{
+	ENTRY();
+	strcpy(inp->name, "Camera");
+	inp->type = V4L2_INPUT_TYPE_CAMERA;
+	LEAVE();
+	return 0;
+}
+
+/* always returns 0 (we have only one input) */
+static int nuvoton_vidioc0_g_input(struct file *file, void *priv, unsigned int *i)
+{
+	int index = 0;
+	ENTRY();
+	*i=index;
+	LEAVE();
+	return 0;
+}
+
+/* Because we have only one input, set input = 0 */
+static int nuvoton_vidioc0_s_input(struct file *file, void *priv, unsigned int i)
+{
+	ENTRY();
+	if (i != 0) {
+		LEAVE();
+		return -EINVAL;
+	}
+	LEAVE();
+	return 0;
+}
+
+/* ----- *           controls * ----- */
+/* Check if the control method is supported (via  v4l2_queryctrl)
+If yes, the parameter of the control will be returned;
+if not, error code will be returned. */
+static int nuvoton_vidioc0_queryctrl(struct file *file,void *priv,struct v4l2_queryctrl *qc)
+{
+
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	ENTRY();
+	if (qc->id && qc->id == s->qctrl.id) {
+		memcpy((char *)qc, (char *)&(s->qctrl), sizeof(qc));
+		LEAVE();
+		return 0;
+	}
+	LEAVE();
+	return -EINVAL;
+}
+
+/* get the control parameter */
+static int nuvoton_vidioc0_g_ctrl(struct file *file, void *priv,struct v4l2_control *ctrl)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	int err = 0;
+	ENTRY();
+	if (!s->get_ctrl && !s->set_ctrl)
+		return -EINVAL;
+	if (!s->get_ctrl) {
+		if (ctrl->id == s->qctrl.id) {
+			ctrl->value = s->_qctrl.default_value;
+			goto exit;
+		}
+	} else
+		err = s->get_ctrl(cam, ctrl);
+
+exit:
+	LEAVE();
+	return err;
+}
+
+/* set the control parameter */
+static int nuvoton_vidioc0_s_ctrl(struct file *file,void *priv,struct v4l2_control *ctrl)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	int err = 0;
+	ENTRY();
+	if (!s->set_ctrl)
+		return -EINVAL;
+
+	if (ctrl->id == s->qctrl.id) {
+		if (s->qctrl.flags & V4L2_CTRL_FLAG_DISABLED)
+			return -EINVAL;
+		if (ctrl->value < s->qctrl.minimum || ctrl->value > s->qctrl.maximum)
+			return -ERANGE;
+		ctrl->value -= ctrl->value % s->qctrl.step;
+	}
+	if ((err = s->set_ctrl(cam, ctrl)))
+		return err;
+	s->_qctrl.default_value = ctrl->value;
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_vidioc0_cropcap(struct file *file, void *priv, struct v4l2_cropcap *crop)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct v4l2_cropcap* cc = &(cam->sensor.cropcap);
+
+	cc->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	cc->pixelaspect.numerator = 1;
+	cc->pixelaspect.denominator = 1;
+	memcpy(crop,cc,sizeof(struct v4l2_cropcap));
+	return 0;
+}
+
+static int nuvoton_vidioc0_g_crop(struct file *file, void *priv,struct v4l2_crop *crop)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	ENTRY();
+	crop->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	memcpy(&(crop->c), &(s->_rect), sizeof(struct v4l2_rect));
+	LEAVE();
+	return 0;
+}
+static int nuvoton_vidioc0_s_crop(struct file *file, void *priv,const struct v4l2_crop *crop)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	struct v4l2_rect* rect;
+	struct v4l2_rect* bounds = &(s->cropcap.bounds);
+	//const enum unvoton_vin_stream_state stream = cam->stream;
+	const u8 stream = cam->stream;
+	const u32 nbuffers = cam->nbuffers;
+	int err = 0;
+	ENTRY();
+	rect = (struct v4l2_rect*)&(crop->c);
+
+	if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)
+		return -EINVAL;
+
+	if (!s->set_crop) {
+		memcpy(rect, &(s->_rect), sizeof(*rect));
+		return 0;
+	}
+	rect->left &= ~7L;
+	rect->top &= ~7L;
+	if (rect->width < 8)    rect->width = 8;
+	if (rect->height < 8)   rect->height = 8;
+	if (rect->width > bounds->width)        rect->width = bounds->width;
+	if (rect->height > bounds->height)  rect->height = bounds->height;
+	if (rect->left < bounds->left)  rect->left = bounds->left;
+	if (rect->top < bounds->top)        rect->top = bounds->top;
+	if (rect->left + rect->width > bounds->left + bounds->width)    rect->left = bounds->left+bounds->width - rect->width;
+	if (rect->top + rect->height > bounds->top + bounds->height)    rect->top = bounds->top+bounds->height - rect->height;
+	rect->width &= ~7L;
+	rect->height &= ~7L;
+
+	if (cam->stream == STREAM_ON)
+		if ((err = nuvoton_vin0_stream_interrupt(cam)))
+			return err;
+
+
+	if (cam->io == IO_READ)
+		nuvoton_vin0_release_buffers(cam);
+
+	if (s->set_crop)
+		err += s->set_crop(cam, rect);
+
+	if (err) { /* atomic, no rollback in ioctl() */
+		//cam->state |= DEV_MISCONFIGURED;
+		VDEBUG("VIDIOC_S_CROP failed because of hardware problems. To use the camera, close and open %s again.\n",
+		       video_device_node_name(cam->v4ldev));
+		return -EIO;
+	}
+
+	s->pix_format.width = rect->width;
+	s->pix_format.height = rect->height;
+	memcpy(&(s->_rect), rect, sizeof(*rect));
+
+	if ((cam->io == IO_READ) && nbuffers != nuvoton_vin0_request_buffers(cam, nbuffers, cam->io)) {
+		//cam->state |= DEV_MISCONFIGURED;
+		VDEBUG("VIDIOC_S_CROP failed because of not enough memory. To use the camera, close and open %s again.\n",
+		       video_device_node_name(cam->v4ldev));
+		return -ENOMEM;
+	}
+
+	if (cam->io == IO_READ)
+		nuvoton_vin0_empty_framequeues(cam);
+
+	cam->stream = stream;
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_vin0_vidioc_s_jpegcomp(struct file *file, void *priv,const struct v4l2_jpegcompression *jc)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_vidioc0_s_fbuf(struct file *file, void *priv,
+                                  const struct v4l2_framebuffer *fb)
+{
+	int i;
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+	if (fb->flags & V4L2_FBUF_FLAG_OVERLAY) {
+		cam->nbuffers = CONFIG_VIN0_MAX_FRAME_BUFFER;
+		for (i = 0; i < cam->nbuffers; i++) {
+			cam->frame[i].bufmem = cam->vir_addr[i];
+			cam->frame[i].pbuf = cam->phy_addr[i];
+			cam->frame[i].buf.index = i;
+		}
+		cam->frame_current=&cam->frame[0];
+		__raw_writel(cam->frame_current->pbuf,REG_CAP0_PKTBA0);
+		cam->type=V4L2_BUF_TYPE_VIDEO_OVERLAY;
+	} else {
+		cam->type=V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	}
+	LEAVE();
+	return 0;
+
+}
+
+static int nuvoton_vidioc0_g_fbuf(struct file *file, void *priv,
+                                  struct v4l2_framebuffer *fb)
+{
+//Bttv-driver.c
+//Fsl-viu.c
+//Ivtv-ioctl.c
+//Omap_vout.c
+//saa7134-video.c
+//Zoran_driver.c
+	ENTRY();
+	//struct nuvoton_vin_device* cam=priv;
+	//struct nuvoton_vin_sensor* s = &cam->sensor;
+	fb->capability = V4L2_FBUF_FLAG_OVERLAY;
+	fb->flags = V4L2_FBUF_FLAG_OVERLAY;
+	LEAVE();
+	return 0;
+}
+
+/* ---- Initialization v4l2 ioctrl ops   ----*/
+static const struct v4l2_ioctl_ops nuvoton_vdi0_ioctl_ops = {
+	.vidioc_querycap    = nuvoton_vidioc0_querycap,
+	.vidioc_g_fmt_vid_cap   = nuvoton_vidioc0_g_fmt_vid_cap,
+	.vidioc_enum_fmt_vid_cap = nuvoton_vidioc0_enum_fmt_vid_cap,
+	.vidioc_s_fmt_vid_cap   = nuvoton_vidioc0_s_fmt_vid_cap,
+	.vidioc_enum_input = nuvoton_vidioc0_enum_input,
+	.vidioc_g_input = nuvoton_vidioc0_g_input,
+	.vidioc_s_input = nuvoton_vidioc0_s_input,
+	.vidioc_s_std   = nuvoton_vidioc0_s_std,
+	.vidioc_reqbufs = nuvoton_vidioc0_reqbufs,
+	.vidioc_try_fmt_vid_cap = nuvoton_vidioc0_try_fmt_vid_cap,
+	.vidioc_querybuf    = nuvoton_vidioc0_querybuf,
+	.vidioc_qbuf    = nuvoton_vidioc0_qbuf,
+	.vidioc_dqbuf   = nuvoton_vidioc0_dqbuf,
+	.vidioc_streamon    = nuvoton_vidioc0_streamon,
+	.vidioc_streamoff   = nuvoton_vidioc0_streamoff,
+	.vidioc_queryctrl   = nuvoton_vidioc0_queryctrl,
+	.vidioc_g_ctrl = nuvoton_vidioc0_g_ctrl,
+	.vidioc_s_ctrl = nuvoton_vidioc0_s_ctrl,
+	.vidioc_cropcap = nuvoton_vidioc0_cropcap,
+	.vidioc_g_crop = nuvoton_vidioc0_g_crop,
+	.vidioc_s_crop = nuvoton_vidioc0_s_crop,
+	.vidioc_s_jpegcomp = nuvoton_vin0_vidioc_s_jpegcomp,
+	.vidioc_g_fbuf = nuvoton_vidioc0_g_fbuf,
+	.vidioc_s_fbuf = nuvoton_vidioc0_s_fbuf,
+	.vidioc_s_parm = nuvoton_vidioc0_s_parm,
+	.vidioc_g_parm = nuvoton_vidioc0_g_parm,
+	/*  VIDIOC_G_FBUF and VIDIOC_S_FBUF ioctl to get and set
+	    the framebuffer parameters for a Video Overlay
+	    or Video Output Overlay (OSD) */
+};
+
+
+/*****************************************************************************/
+int nuvoton_vin0_stream_interrupt(struct nuvoton_vin_device* cam)
+{
+	return 0;
+}
+
+u32 nuvoton_vin0_request_buffers(struct nuvoton_vin_device* cam, u32 count,enum nuvoton_vin_io_method io)
+{
+	struct v4l2_pix_format* p = &(cam->sensor.pix_format);
+	size_t imagesize;
+	//void* buff = NULL;
+	u32 i;
+
+	if(p->bytesperline==0)
+		imagesize = (p->width * p->height * p->priv) / 8;
+	else
+		imagesize = ((p->bytesperline/2) * p->height * p->priv) / 8;
+
+	ENTRY();
+	if (count > CONFIG_VIN0_MAX_FRAME_BUFFER)
+		count = CONFIG_VIN0_MAX_FRAME_BUFFER;
+
+	cam->nbuffers = (count);
+	for (i = 0; i < cam->nbuffers; i++) {
+		cam->frame[i].bufmem = cam->vir_addr[i];
+		cam->frame[i].pbuf = cam->phy_addr[i];
+		cam->frame[i].buf.index = i;
+		cam->frame[i].buf.m.userptr = (unsigned long)(cam->frame[i].bufmem);
+		cam->frame[i].buf.m.offset = (unsigned long)(cam->frame[i].bufmem);
+		cam->frame[i].buf.length = imagesize;
+		cam->frame[i].buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+		cam->frame[i].buf.sequence = 0;
+		cam->frame[i].buf.field = V4L2_FIELD_NONE;
+		cam->frame[i].buf.memory = V4L2_MEMORY_MMAP;
+		cam->frame[i].buf.flags = 0;
+		VDEBUG("cam->frame[%d].bufmem=0x%08x\n",i,(unsigned int)cam->frame[i].bufmem);
+		VDEBUG("cam->frame[%d].pbuf=0x%08x\n",i,(unsigned int)cam->frame[i].pbuf);
+	}
+	cam->frame_current=&cam->frame[0];
+	LEAVE();
+	return (cam->nbuffers);
+}
+
+
+void nuvoton_vin0_release_buffers(struct nuvoton_vin_device* cam)
+{
+	ENTRY();
+	if (cam->nbuffers) {
+		cam->nbuffers = 0;
+	}
+	cam->frame_current = NULL;
+	LEAVE();
+}
+
+void nuvoton_vin0_empty_framequeues(struct nuvoton_vin_device* cam)
+{
+	u32 i;
+	ENTRY();
+	INIT_LIST_HEAD(&cam->inqueue);
+	INIT_LIST_HEAD(&cam->outqueue);
+
+	for (i = 0; i < CONFIG_VIN0_MAX_FRAME_BUFFER; i++) {
+		cam->frame[i].state = F_UNUSED;
+		cam->frame[i].buf.bytesused = 0;
+	}
+	LEAVE();
+}
+
+void nuvoton_vin0_requeue_outqueue(struct nuvoton_vin_device* cam)
+{
+	struct nuvoton_vin_frame_t *i;
+
+	list_for_each_entry(i, &cam->outqueue, frame) {
+		i->state = F_QUEUED;
+		list_add(&i->frame, &cam->inqueue);
+	}
+	INIT_LIST_HEAD(&cam->outqueue);
+}
+
+
+static void nuvoton_vin0_queue_unusedframes(struct nuvoton_vin_device* cam)
+{
+	unsigned long lock_flags;
+	u32 i;
+
+	for (i = 0; i < cam->nbuffers; i++)
+		if (cam->frame[i].state == F_UNUSED) {
+			cam->frame[i].state = F_QUEUED;
+			spin_lock_irqsave(&cam->queue_lock, lock_flags);
+			list_add_tail(&cam->frame[i].frame, &cam->inqueue);
+			spin_unlock_irqrestore(&cam->queue_lock, lock_flags);
+		}
+}
+
+/*****************************************************************************/
+
+/* ---- Initialization and module stuff   ----*/
+#if 0
+static int nuvoton_vin0_init(struct nuvoton_vin_device* cam)
+{
+	ENTRY();
+	cam->state=0;
+	cam->nreadbuffers = 2;
+	LEAVE();
+	return 0;
+}
+#endif
+
+static void nuvoton_vin0_release_resources(struct kref *kref)
+{
+	struct nuvoton_vin_device *cam = container_of(kref, struct nuvoton_vin_device,kref);
+	ENTRY();
+	VDEBUG("V4L2 device %s deregistered\n",video_device_node_name(cam->v4ldev));
+	video_set_drvdata(cam->v4ldev, NULL);
+	video_unregister_device(cam->v4ldev);
+	kfree(cam->control_buffer);
+	kfree(cam);
+}
+
+
+int capture0_uninit(void)
+{
+
+	/* GPIOD2 set to low  */
+	__raw_writel( (__raw_readl(REG_MFP_GPD_L) & ~0x00000F00) ,REG_MFP_GPI_L);
+	__raw_writel(((__raw_readl(GPIO_BA+0x0C0)&~0x30) | 0x0010),(GPIO_BA+0x0C0)); /* GPIOD2 Output mode */
+	__raw_writel((__raw_readl(GPIO_BA+0x0C8) | 0x0004),(GPIO_BA+0x0C8)); /* GPIOD2 Output to High */
+	return 0;
+}
+int capture0_init(struct nuvoton_vin_device* cam)
+{
+	int ret;
+	struct clk *clkcap,*clkaplldiv,*clkmux;
+	struct clk *clk;
+	int i32Div;
+	ENTRY();
+	clk = clk_get(NULL, "cap0_eclk");
+	if (IS_ERR(clk)) {
+		return -ENOENT;
+	}
+	clk_prepare(clk);
+	clk_enable(clk);
+	clk_prepare(clk_get(NULL, "cap0_hclk"));
+	clk_enable(clk_get(NULL, "cap0_hclk"));
+	clk_prepare(clk_get(NULL, "sensor_hclk"));
+	clk_enable(clk_get(NULL, "sensor_hclk"));
+	clkmux = clk_get(NULL, "cap0_eclk_mux");
+	if (IS_ERR(clkmux)) {
+		printk(KERN_ERR "nuc980-cap0:failed to get cap clock source\n");
+		ret = PTR_ERR(clkmux);
+		return ret;
+	}
+	clkcap = clk_get(NULL, "cap0_eclk");
+	if (IS_ERR(clkcap)) {
+		printk(KERN_ERR "nuc980-cap0:failed to get cap clock source\n");
+		ret = PTR_ERR(clkcap);
+		return ret;
+	}
+	clkaplldiv = clk_get(NULL, "cap0_uplldiv");
+	//clkaplldiv = clk_get(NULL, "cap0_eclk_div");
+	if (IS_ERR(clkaplldiv)) {
+		printk(KERN_ERR "nuc980-cap0:failed to get cap clock source\n");
+		ret = PTR_ERR(clkaplldiv);
+		return ret;
+	}
+	clk_set_parent(clkmux, clkaplldiv);
+	clk_set_rate(clkcap, video0_freq);
+
+	i32Div=(300000000/video0_freq)-1;
+	if(i32Div>0xF) i32Div=0xf;
+	__raw_writel((__raw_readl(REG_CLK_DIV3) & ~(0xF<<24) ) | (i32Div<<24),REG_CLK_DIV3);
+
+
+	/* PC0 set to low; PD# */
+	ret = gpio_request(CAP0_PD_PIN, "CAP0_PD_PIN");
+	if (ret) {
+		printk("CAP0_PD_PIN failed ret=%d\n",ret);
+		return ret;
+	}
+	gpio_direction_output(CAP0_PD_PIN,1);
+	udelay(100);
+	gpio_set_value(CAP0_PD_PIN, 0 );
+
+	/* PE10 set to high; RST# */
+	ret = gpio_request(CAP0_RST_PIN, "CAP0_RST_PIN");
+	if (ret) {
+		printk("CAP0_RST_PIN failed ret=%d\n",ret);
+		return ret;
+	}
+	gpio_direction_output(CAP0_RST_PIN,0);
+	udelay(100);
+	gpio_set_value(CAP0_RST_PIN, 1 );
+	udelay(100);
+
+#if 0
+	printk("video0_freq=%d\n",video0_freq);
+	printk("GCR_BA+0x080=0x%08x\n",__raw_readl(GCR_BA+0x080));
+	printk("GCR_BA+0x080=0x%08x\n",__raw_readl(GCR_BA+0x084));
+	printk("CLK_HCLKEN=0x%08x\n",__raw_readl(CLK_BA+0x010));
+	printk("REG_CLK_DIV3=0x%08x\n",__raw_readl(CLK_BA+0x02C));
+#endif
+
+	LEAVE();
+	return 0;
+}
+
+static int vdi_user=0;
+static int nuvoton_vdi0_open(struct file *filp)
+{
+	struct nuvoton_vin_device* cam=video_drvdata(filp);
+	int err = 0;
+	ENTRY();
+	if (!down_read_trylock(&nuvoton_vin0_dev_lock))
+		return -EAGAIN;
+
+	if (wait_for_completion_interruptible(&cam->probe)) {
+		up_read(&nuvoton_vin0_dev_lock);
+		return -ERESTARTSYS;
+	}
+	kref_get(&cam->kref);
+
+	if (mutex_lock_interruptible(&cam->open_mutex)) {
+		kref_put(&cam->kref, nuvoton_vin0_release_resources);
+		up_read(&nuvoton_vin0_dev_lock);
+		return -ERESTARTSYS;
+	}
+	if (cam->users) {
+		VDEBUG("Device %s is busy...\n",video_device_node_name(cam->v4ldev));
+		VDEBUG("Simultaneous opens are not supported\n");
+		if ((filp->f_flags & O_NONBLOCK) || (filp->f_flags & O_NDELAY)) {
+			err = -EWOULDBLOCK;
+			goto out;
+		}
+		VDEBUG("A blocking open() has been requested. Wait for the device to be released...\n");
+		if (err)
+			goto out;
+	}
+
+	filp->private_data = cam;
+	cam->users=++vdi_user;
+	cam->io = IO_NONE;
+	cam->stream = STREAM_OFF;
+	cam->nbuffers = 0;
+	cam->frame_count = 0;
+	nuvoton_vin0_empty_framequeues(cam);
+	VDEBUG("Video device %s is open\n",video_device_node_name(cam->v4ldev));
+
+out:
+	mutex_unlock(&cam->open_mutex);
+	if (err)
+		kref_put(&cam->kref, nuvoton_vin0_release_resources);
+	up_read(&nuvoton_vin0_dev_lock);
+	LEAVE();
+	return err;
+
+}
+
+static int nuvoton_vdi0_close(struct file *filp)
+{
+
+	struct nuvoton_vin_device* cam = video_drvdata(filp);
+	ENTRY();
+	down_write(&nuvoton_vin0_dev_lock);
+	nuvoton_vdi0_disable(cam);
+	nuvoton_vin0_release_buffers(cam);
+	vdi_user--;
+	cam->users=0;
+	cam->vpe.PacketEnable=0;
+	cam->vpe.PlanarEnable=0;
+	cam->type=0;
+	cam->stream = STREAM_OFF;
+	VDEBUG("Video device %s closed", video_device_node_name(cam->v4ldev));
+
+	kref_put(&cam->kref, nuvoton_vin0_release_resources);
+	up_write(&nuvoton_vin0_dev_lock);
+	nuvoton_vin0_empty_framequeues(cam);
+	wake_up_interruptible(&cam->wait_frame);
+	LEAVE();
+	return 0;
+}
+
+static ssize_t nuvoton_vdi0_read(struct file* filp, char __user * buf, size_t count, loff_t* f_pos)
+{
+	struct nuvoton_vin_device *cam = video_drvdata(filp);
+	struct nuvoton_vin_frame_t* f, * i;
+	unsigned long lock_flags;
+	long timeout;
+	int err = 0;
+	ENTRY();
+	if (mutex_lock_interruptible(&cam->fileop_mutex)) {
+		return -ERESTARTSYS;
+	}
+
+	if (cam->io == IO_MMAP) {
+		VDEBUG("Close and open the device again to choose the read method\n");
+		mutex_unlock(&cam->fileop_mutex);
+		return -EBUSY;
+	}
+	if (cam->io == IO_NONE) {
+		if (!nuvoton_vin0_request_buffers(cam, cam->nreadbuffers, IO_READ)) {
+			VDEBUG("read() failed, not enough memory\n");
+			mutex_unlock(&cam->fileop_mutex);
+			return -ENOMEM;
+		}
+		cam->io = IO_READ;
+		cam->stream = STREAM_ON;
+		if(cam->nreadbuffers>0) {
+			VDEBUG("cam->nreadbuffers=%d\n",cam->nreadbuffers);
+			if(cam->vpe.PacketEnable==1) {
+				if(cam->frame_current!=NULL)
+					__raw_writel(cam->frame_current->pbuf,REG_CAP0_PKTBA0);
+				else
+					VDEBUG("PacketEnable : cam->frame_current == NULL\n");
+			}
+			if(cam->vpe.PlanarEnable==1) {
+				if(cam->frame_current!=NULL) {
+					__raw_writel((unsigned int)cam->frame_current->pbuf,REG_CAP0_YBA);
+					__raw_writel(__raw_readl(REG_CAP0_YBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight),REG_CAP0_UBA);
+					__raw_writel(__raw_readl(REG_CAP0_UBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight)/2,REG_CAP0_VBA);
+				} else
+					VDEBUG("PlanarEnable : cam->frame_current == NULL\n");
+			}
+
+			VDEBUG("cam->frame_current->bufmem=0x%08x\n",cam->frame_current->bufmem);
+			VDEBUG("cam->frame_current->pbuf=0x%08x\n",cam->frame_current->pbuf);
+			VDEBUG("cam->vpe.PacketEnable=%d\n",cam->vpe.PacketEnable);
+			VDEBUG("cam->vpe.PlanarEnable=%d\n",cam->vpe.PlanarEnable);
+		}
+		/* Capture engine enable and packet/planar mode enable */
+		nuvoton_vdi0_enable(cam);
+	}
+
+	if (list_empty(&cam->inqueue)) {
+		if (!list_empty(&cam->outqueue))
+			nuvoton_vin0_empty_framequeues(cam);
+		nuvoton_vin0_queue_unusedframes(cam);
+	}
+
+	if (!count) {
+		mutex_unlock(&cam->fileop_mutex);
+		return 0;
+	}
+
+	if (list_empty(&cam->outqueue)) {
+		timeout = wait_event_interruptible_timeout
+		          ( cam->wait_frame,(!list_empty(&cam->outqueue)),msecs_to_jiffies(NUVOTON_FRAME_TIMEOUT * 1000));
+		if (timeout < 0) {
+			mutex_unlock(&cam->fileop_mutex);
+			return timeout;
+		}
+	}
+	f = list_entry(cam->outqueue.prev, struct nuvoton_vin_frame_t, frame);
+	if (copy_to_user(buf, f->bufmem, count)) {
+		err = -EFAULT;
+		goto exit;
+	}
+	*f_pos += count;
+
+exit:
+
+	spin_lock_irqsave(&cam->queue_lock, lock_flags);
+	list_for_each_entry(i, &cam->outqueue, frame)
+	i->state = F_UNUSED;
+	INIT_LIST_HEAD(&cam->outqueue);
+	spin_unlock_irqrestore(&cam->queue_lock, lock_flags);
+
+	nuvoton_vin0_queue_unusedframes(cam);
+
+	VDEBUG("Frame #%lu, bytes read: %zu\n",(unsigned long)f->buf.index, count);
+
+	mutex_unlock(&cam->fileop_mutex);
+	LEAVE();
+	return 0;
+}
+
+static void nuvoton_vin0_vm_open(struct vm_area_struct* vma)
+{
+	struct nuvoton_vin_frame_t* f = vma->vm_private_data;
+	ENTRY();
+	f->vma_use_count++;
+}
+
+
+static void nuvoton_vin0_vm_close(struct vm_area_struct* vma)
+{
+	/* NOTE: buffers are not freed here */
+	struct nuvoton_vin_frame_t* f = vma->vm_private_data;
+	ENTRY();
+	f->vma_use_count--;
+	LEAVE();
+}
+
+
+static const struct vm_operations_struct nuvoton_vin0_vm_ops = {
+	.open = nuvoton_vin0_vm_open,
+	.close = nuvoton_vin0_vm_close,
+};
+
+static int nuvoton_vdi0_mmap(struct file* filp, struct vm_area_struct *vma)
+{
+	struct nuvoton_vin_device *cam = video_drvdata(filp);
+	unsigned long size = vma->vm_end - vma->vm_start,start = vma->vm_start;
+	void *pos;
+	u32 i;
+	ENTRY();
+	//if (mutex_lock_interruptible(&cam->fileop_mutex))
+	//  return -ERESTARTSYS;
+	if (!(vma->vm_flags & (VM_WRITE | VM_READ))) {
+		mutex_unlock(&cam->fileop_mutex);
+		return -EACCES;
+	}
+
+	if (cam->io != IO_MMAP ||
+	    size != PAGE_ALIGN(cam->frame[0].buf.length)) {
+		mutex_unlock(&cam->fileop_mutex);
+		return -EINVAL;
+	}
+
+	for (i = 0; i < cam->nbuffers; i++) {
+		if ((cam->frame[i].buf.m.offset>>PAGE_SHIFT) == vma->vm_pgoff)
+			break;
+	}
+	if (i == cam->nbuffers) {
+		mutex_unlock(&cam->fileop_mutex);
+		return -EINVAL;
+	}
+
+	vma->vm_flags |= VM_IO | VM_DONTEXPAND | VM_DONTDUMP;
+	pos = cam->frame[i].bufmem;
+	while (size > 0) { /* size is page-aligned */
+		if (vm_insert_page(vma, start, vmalloc_to_page(pos))) {
+			mutex_unlock(&cam->fileop_mutex);
+			//printk("4444\n");
+			return -EAGAIN;
+		}
+		start += PAGE_SIZE;
+		pos += PAGE_SIZE;
+		size -= PAGE_SIZE;
+	}
+	vma->vm_ops = &nuvoton_vin0_vm_ops;
+	vma->vm_private_data = &cam->frame[i];
+	nuvoton_vin0_vm_open(vma);
+
+	mutex_unlock(&cam->fileop_mutex);
+	LEAVE();
+	return 0;
+}
+
+/* ISR for buffer handling                   *
+ * for nuvoton sensor interface              *
+ *                                           */
+static int cap0_cnt=0;
+static irqreturn_t nuvoton_vdi0_isr(int irq, void *priv)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_frame_t** f=NULL;
+	ENTRY();
+	//printk("VDIN0 ISR status=0x%08x\n",__raw_readl(REG_CAP0_INT));
+	//printk("REG_CAP0_CTL=0x%08x\n",__raw_readl(REG_CAP0_CTL));
+	//printk("REG_CAP0_CURADDRY=0x%08x\n",__raw_readl(REG_CAP0_CURADDRY));
+	//printk("REG_CAP0_CURADDRU=0x%08x\n",__raw_readl(REG_CAP0_CURADDRU));
+	//printk("REG_CAP0_CURADDRV=0x%08x\n",__raw_readl(REG_CAP0_CURADDRV));
+	//printk("REG_CAP0_YBA=0x%08x\n",__raw_readl(REG_CAP0_YBA));
+	//printk("REG_CAP0_UBA=0x%08x\n",__raw_readl(REG_CAP0_UBA));
+	//printk("REG_CAP0_VBA=0x%08x\n",__raw_readl(REG_CAP0_VBA));
+	if(cap0_cnt==1) {
+		cap0_cnt=0;
+		__raw_writel(__raw_readl(REG_CAP0_INT),REG_CAP0_INT);
+		LEAVE();
+		return IRQ_NONE;
+	}
+
+	f  = &cam->frame_current;
+//      if (cam->stream == STREAM_OFF || list_empty(&cam->inqueue)) {
+	if (cam->stream == STREAM_OFF || list_is_last(&(*f)->frame,&cam->inqueue)) {
+		if(cam->stream == STREAM_ON && cam->type==V4L2_BUF_TYPE_VIDEO_OVERLAY) {
+#if 0
+			__raw_writel(cam->frame[0].pbuf,NUC970_VA_LCD+REG_LCM_VA_BADDR0);
+			__raw_writel(cam->frame[0].pbuf,REG_CAP0_PKTBA0);
+			__raw_writel(__raw_readl(REG_CAP0_CTL) | CAP_CTL_UPDATE,REG_CAP0_CTL);
+			__raw_writel((__raw_readl(REG_CAP0_INT) & ~0x10000) ,REG_CAP0_INT);        /* Disable CAP Interrupt */
+#endif
+		} else {
+			wake_up_interruptible(&cam->wait_frame);
+		}
+	}
+
+	spin_lock(&cam->queue_lock);
+	if((*f)->state == F_QUEUED) {
+		list_move_tail(&(*f)->frame, &cam->outqueue);
+	}
+	if (!list_empty(&cam->inqueue)) {
+		(*f) = list_entry(cam->inqueue.next,struct nuvoton_vin_frame_t,frame);
+		if(cam->vpe.PacketEnable==1) {
+			/* Setting packet buffer start address */
+			__raw_writel((*f)->pbuf,REG_CAP0_PKTBA0);
+			if(cam->sensor.bothenable==1) {
+				struct nuvoton_vin_sensor* s = &cam->sensor;
+				struct v4l2_rect* bounds = &(s->cropcap.bounds);
+				u32 size = bounds->height*bounds->height*2;
+				__raw_writel((*f)->pbuf+size,REG_CAP0_YBA);
+				__raw_writel(__raw_readl(REG_CAP0_YBA)+(cam->vpe.PlanarHeight*cam->vpe.PlanarWidth),REG_CAP0_UBA);
+				__raw_writel(__raw_readl(REG_CAP0_UBA)+(cam->vpe.PlanarHeight*cam->vpe.PlanarWidth)/2,REG_CAP0_VBA);
+			}
+
+		} else if(cam->vpe.PlanarEnable==1) {
+			/* Setting planar buffer Y address, U address, V address */
+			__raw_writel((unsigned int)(*f)->pbuf,REG_CAP0_YBA);
+			__raw_writel(__raw_readl(REG_CAP0_YBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight),REG_CAP0_UBA);
+			__raw_writel(__raw_readl(REG_CAP0_UBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight)/2,REG_CAP0_VBA);
+		}
+		/* Update New frame */
+		__raw_writel(__raw_readl(REG_CAP0_CTL) | CAP_CTL_UPDATE,REG_CAP0_CTL);
+		cap0_cnt++;
+		spin_unlock(&cam->queue_lock);
+		wake_up_interruptible(&cam->wait_frame);
+	}
+	__raw_writel(__raw_readl(REG_CAP0_INT),REG_CAP0_INT);
+	LEAVE();
+	return IRQ_NONE;
+}
+
+
+
+static struct v4l2_file_operations nuvoton_vdi0_fops = {
+	.owner              = THIS_MODULE,
+	.open               = nuvoton_vdi0_open,
+	.release            = nuvoton_vdi0_close,
+	.read               = nuvoton_vdi0_read,
+	//.ioctl            = video_ioctl2,         /* V4L2 ioctl handler */
+	.unlocked_ioctl     = video_ioctl2,         /* V4L2 ioctl handler */
+	.mmap               = nuvoton_vdi0_mmap,
+};
+
+/* ---- Initialization v4l2_file_operations  ----*/
+#ifndef CONFIG_USE_OF
+#if defined(CONFIG_SENSOR0_OV7725)
+extern int nuvoton_vin0_probe_ov7725(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR0_OV5640)
+extern int nuvoton_vin0_probe_ov5640(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR0_NT99141)
+extern int nuvoton_vin0_probe_nt99141(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR0_NT99050)
+extern int nuvoton_vin0_probe_nt99050(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR0_TW9912)
+extern int nuvoton_vin0_probe_tw9912(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR0_GC0308)
+extern int nuvoton_vin0_probe_gc0308(struct nuvoton_vin_device* cam);
+#endif
+#else
+extern int nuvoton_vin0_probe_ov7725(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin0_probe_ov5640(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin0_probe_nt99141(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin0_probe_nt99050(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin0_probe_tw9912(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin0_probe_gc0308(struct nuvoton_vin_device* cam);
+#endif
+int nuvoton_vdi0_device_register(struct platform_device *pdev)
+{
+	int ret;
+	struct nuvoton_vin_device* cam;
+	int err = 0;
+	ENTRY();
+
+	if (!(cam = kzalloc(sizeof(struct nuvoton_vin_device), GFP_KERNEL)))
+		return -ENOMEM;
+	if (!(cam->control_buffer = kzalloc(4, GFP_KERNEL))) {
+		VDEBUG("kmalloc() failed\n");
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	if (!(cam->frame = kzalloc(sizeof(struct nuvoton_vin_frame_t)*CONFIG_VIN0_MAX_FRAME_BUFFER, GFP_KERNEL)))
+		return -ENOMEM;
+	if (!(cam->vir_addr = (u32 **)kzalloc(sizeof(u32*)*CONFIG_VIN0_MAX_FRAME_BUFFER, GFP_KERNEL)))
+		return -ENOMEM;
+	if (!(cam->phy_addr = kzalloc(sizeof(dma_addr_t)*CONFIG_VIN0_MAX_FRAME_BUFFER, GFP_KERNEL)))
+		return -ENOMEM;
+	if (!(cam->v4ldev = video_device_alloc())) {
+		VDEBUG("video_device_alloc() failed\n");
+		err = -ENOMEM;
+		goto fail;
+	}
+	err=capture0_init(cam); /* Set capture init for nuvoton sensor interface */
+	VDEBUG("capture0_init().");
+
+	//for sensor init
+#ifndef CONFIG_USE_OF
+#if defined(CONFIG_SENSOR0_OV7725)
+	err=nuvoton_vin0_probe_ov7725(cam); //sensor probe;
+#elif defined(CONFIG_SENSOR0_OV5640)
+	err=nuvoton_vin0_probe_ov5640(cam); //sensor probe;
+#elif defined(CONFIG_SENSOR0_NT99141)
+	err=nuvoton_vin0_probe_nt99141(cam); //sensor probe;
+#elif defined(CONFIG_SENSOR0_NT99050)
+	err=nuvoton_vin0_probe_nt99050(cam); //sensor probe;
+#elif defined(CONFIG_SENSOR0_TW9912)
+	err=nuvoton_vin0_probe_tw9912(cam);//sensor probe;
+#elif defined(CONFIG_SENSOR0_GC0308)
+	err=nuvoton_vin0_probe_gc0308(cam);//sensor probe;
+#endif
+	if(err<0) {
+		gpio_free(CAP0_PD_PIN);
+		gpio_free(CAP0_RST_PIN);
+		VDEBUG("Initialization failed. I will retry on open().");
+		return err;
+	}
+#else
+	if(sensor0_model==SENSOR_OV7725)
+		err=nuvoton_vin0_probe_ov7725(cam); //sensor probe;
+	else if(sensor0_model==SENSOR_OV5640)
+		err=nuvoton_vin0_probe_ov5640(cam); //sensor probe;
+	else if(sensor0_model==SENSOR_NT99141)
+		err=nuvoton_vin0_probe_nt99141(cam); //sensor probe;
+	else if(sensor0_model==SENSOR_NT99050)
+		err=nuvoton_vin0_probe_nt99050(cam); //sensor probe;
+	else if(sensor0_model==SENSOR_TW9912)
+		err=nuvoton_vin0_probe_tw9912(cam); //sensor probe;
+	else if(sensor0_model==SENSOR_GC0308)
+		err=nuvoton_vin0_probe_gc0308(cam); //sensor probe;
+
+	if(err<0) {
+		gpio_free(CAP0_PD_PIN);
+		gpio_free(CAP0_RST_PIN);
+		VDEBUG("Initialization failed. I will retry on open().");
+		return -EAGAIN;
+	}
+#endif
+
+	{
+		int j;
+		struct v4l2_rect* defrect = &(cam->sensor.cropcap.defrect);
+
+		for(j=0; j<CONFIG_VIN0_MAX_FRAME_BUFFER; j++)
+			if((cam->vir_addr[j] = dma_alloc_writecombine(NULL,
+			                       PAGE_ALIGN(defrect->width*defrect->height*2),
+			                       &cam->phy_addr[j],
+			                       GFP_KERNEL))==NULL) {
+				printk("dma_alloc_writecombine failed\n");
+				return -EAGAIN;
+			}
+	}
+	/* INIT */
+
+	mutex_init(&cam->open_mutex);
+	mutex_init(&cam->fileop_mutex);
+	init_waitqueue_head(&cam->wait_frame);
+	init_waitqueue_head(&cam->wait_stream);
+	cam->nreadbuffers = 2;
+
+	strcpy(cam->v4ldev->name, "NUVOTON Camera0 Interface");
+	cam->stream = STREAM_OFF;
+	//cam->v4ldev->current_norm = V4L2_STD_NTSC_M;
+	cam->v4ldev->fops       = &nuvoton_vdi0_fops;
+	cam->v4ldev->release        = video_device_release;
+	cam->v4ldev->tvnorms        = V4L2_STD_525_60;
+	cam->v4ldev->ioctl_ops = &nuvoton_vdi0_ioctl_ops; /* for V4L2 ioctl handler */
+	cam->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	cam->frame_current = NULL;
+
+	ret=v4l2_device_register(&pdev->dev,&cam->v4l2_dev);
+	if (ret) {
+		printk("Unable to register v4l2 device\n");
+		v4l2_err(pdev->dev.driver,
+		         "Unable to register v4l2 device\n");
+		return ret;
+	}
+	cam->v4ldev->v4l2_dev=(struct v4l2_device *)&cam->v4l2_dev;
+	video_set_drvdata(cam->v4ldev, cam);
+	platform_set_drvdata(pdev, cam);
+	init_completion(&cam->probe);
+
+	err = video_register_device(cam->v4ldev, VFL_TYPE_GRABBER,
+	                            -1);
+
+	if (err) {
+		VDEBUG("V4L2 device registration failed\n");
+		if (err == -ENFILE)
+			VDEBUG("Free /dev/videoX node not found\n");
+		complete_all(&cam->probe);
+		goto fail;
+	}
+
+	/* Setting Interrupt(IRQ) for nuvoton sensor interface  */
+	err = request_irq(IRQ_CAP0, nuvoton_vdi0_isr, IRQF_NO_SUSPEND|IRQF_SHARED, "camera sensor 0", cam);
+	if(err < 0) {
+		VDEBUG("Interrupt(IRQ_CAP0) setup failed\n");
+		goto fail;
+	} else
+		VDEBUG("%s, main sensor isr is created\n", __func__);
+	VDEBUG("V4L2 device registered as %s\n",video_device_node_name(cam->v4ldev));
+	kref_init(&cam->kref);
+	complete_all(&cam->probe);
+	return 0;
+fail:
+	if (cam) {
+		kfree(cam->control_buffer);
+		if (cam->v4ldev)
+			video_device_release(cam->v4ldev);
+		kfree(cam);
+	}
+	return err;
+}
+
+/*****************************************************************************/ //for sensor
+void nuvoton_vin0_attach_sensor(struct nuvoton_vin_device* cam, struct nuvoton_vin_sensor* sensor)
+{
+	memcpy(&cam->sensor, sensor, sizeof(struct nuvoton_vin_sensor));
+}
+/*****************************************************************************/
+
+
+/* This routine allocates from 1 to n_devs drivers.
+The real maximum number of virtual drivers will depend on how many drivers   will succeed.
+This is limited to the maximum number of devices that   videodev supports.
+Since there are 64 minors for video grabbers, this is   currently the theoretical maximum limit.
+However, a further limit does   exist at videodev that forbids any driver to register more than 32 video   grabbers.
+Max number of video_devices can be registered at the same time: 32 */
+static int nuvoton_cap0_device_probe(struct platform_device *pdev)
+{
+	int ret = 0;
+#ifndef CONFIG_USE_OF
+	struct pinctrl *pinctrl;
+#endif
+	ENTRY();
+	printk("%s - pdev = %s\n", __func__, pdev->name);
+
+#ifndef CONFIG_USE_OF
+
+	video0_freq = CONFIG_VIDEO0_FREQ;
+
+	//__raw_writel((__raw_readl(GCR_BA+0x080)&0x00000FFF)|0x22222000,(GCR_BA+0x080));
+	//__raw_writel((__raw_readl(GCR_BA+0x084)&0x00000000)|0x22222222,(GCR_BA+0x084));
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "vcap0");
+	if (IS_ERR(pinctrl)) {
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		ret = PTR_ERR(pinctrl);
+		return ret;
+	}
+
+#else
+	{
+		const char *pstr;
+		of_property_read_u32_array(pdev->dev.of_node,"frequency", &video0_freq,1);
+		of_property_read_string(pdev->dev.of_node,"model",&pstr);
+		if(pstr[0]=='o' && pstr[1]=='v' && pstr[2]=='7' && pstr[3]=='7' && pstr[4]=='2' && pstr[5]=='5' ) {
+			sensor0_model = 0;
+		} else if(pstr[0]=='n' && pstr[1]=='t' && pstr[2]=='9' && pstr[3]=='9' && pstr[4]=='1' && pstr[5]=='4' && pstr[6]=='1' ) {
+			sensor0_model = 1;
+		} else if(pstr[0]=='n' && pstr[1]=='t' && pstr[2]=='9' && pstr[3]=='9' && pstr[4]=='0' && pstr[5]=='5' && pstr[6]=='0' ) {
+			sensor0_model = 2;
+		} else if(pstr[0]=='o' && pstr[1]=='v' && pstr[2]=='5' && pstr[3]=='6' && pstr[4]=='4' && pstr[5]=='0' ) {
+			sensor0_model = 3;
+		} else if(pstr[0]=='t' && pstr[1]=='w' && pstr[2]=='9' && pstr[3]=='9' && pstr[4]=='1' && pstr[5]=='2') {
+			sensor0_model = 4;
+		} else if(pstr[0]=='g' && pstr[1]=='c' && pstr[2]=='0' && pstr[3]=='3' && pstr[4]=='0' && pstr[5]=='8') {
+			sensor0_model = 5;
+		}
+
+		//of_property_read_string(pdev->dev.of_node,"powerdown-pin",&pstr1);
+	}
+#endif
+
+	ret = nuvoton_vdi0_device_register(pdev);
+	if(ret) {
+		printk("%s video%d, main sensor registeration fail.\n", __func__,0);
+		ret = -EPROBE_DEFER;
+		goto out;
+	} else
+		printk("%s video%d, main sensor registeration ok.\n", __func__,0);
+
+out:
+	LEAVE();
+	return ret;
+}
+
+static int nuvoton_cap0_device_remove(struct platform_device *pdev)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_cap0_device_resume(struct platform_device *pdev)
+{
+	struct nuvoton_vin_device* cam = platform_get_drvdata(pdev);
+	ENTRY();
+	capture0_init(0);
+#ifndef CONFIG_USE_OF
+#if defined(CONFIG_SENSOR0_OV7725)
+	nuvoton_vin0_probe_ov7725(cam);
+#elif defined(CONFIG_SENSOR0_OV5640)
+	nuvoton_vin0_probe_ov5640(cam);
+#elif defined(CONFIG_SENSOR0_NT99141)
+	nuvoton_vin0_probe_nt99141(cam);
+#elif defined(CONFIG_SENSOR0_NT99050)
+	nuvoton_vin0_probe_nt99050(cam);
+#elif defined(CONFIG_SENSOR0_TW9912)
+	nuvoton_vin0_probe_tw9912(cam);
+#elif defined(CONFIG_SENSOR0_GC0308)
+	nuvoton_vin0_probe_gc0308(cam);
+#endif
+#else
+	if(sensor0_model==SENSOR_OV7725)
+		nuvoton_vin0_probe_ov7725(cam);
+	else if(sensor0_model==SENSOR_OV5640)
+		nuvoton_vin0_probe_ov5640(cam);
+	else if(sensor0_model==SENSOR_NT99141)
+		nuvoton_vin0_probe_nt99141(cam);
+	else if(sensor0_model==SENSOR_NT99050)
+		nuvoton_vin0_probe_nt99050(cam);
+	else if(sensor0_model==SENSOR_TW9912)
+		nuvoton_vin0_probe_tw9912(cam);
+	else if(sensor0_model==SENSOR_GC0308)
+		nuvoton_vin0_probe_gc0308(cam);
+#endif
+	if(cam->CtlReg==1)
+		__raw_writel(__raw_readl(REG_CAP0_CTL)|0x1,REG_CAP0_CTL);
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_cap0_device_suspend(struct platform_device *pdev,pm_message_t state)
+{
+	struct nuvoton_vin_device* cam = platform_get_drvdata(pdev);
+	ENTRY();
+	if(__raw_readl(REG_CAP0_CTL)&0x1) {
+		__raw_writel(__raw_readl(REG_CAP0_CTL)|(1<<16),REG_CAP0_CTL);
+		while(__raw_readl(REG_CAP0_CTL)&0x1);
+		cam->CtlReg=1;
+	} else {
+		cam->CtlReg=0;
+	}
+	capture0_uninit();
+	LEAVE();
+	return 0;
+}
+
+static struct platform_device_id nuc980_cap0_driver_ids[] = {
+	{ "nuc980-videoin0", 0 },
+	{ },
+};
+
+static const struct of_device_id nuc980_cap0_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-cap0" },
+	{},
+};
+static struct platform_driver nuc980_cap0_driver = {
+	.probe      = nuvoton_cap0_device_probe,
+	.remove     = nuvoton_cap0_device_remove,
+	.resume   = nuvoton_cap0_device_resume,
+	.suspend  = nuvoton_cap0_device_suspend,
+	.driver     = {
+		.name   = "nuc980-cap0",
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_cap0_of_match),
+	},
+	.id_table   = nuc980_cap0_driver_ids,
+};
+
+module_platform_driver(nuc980_cap0_driver);
+MODULE_DESCRIPTION("NUVOTON sensor interface");
+MODULE_AUTHOR("SCHung");
+MODULE_LICENSE("Dual BSD/GPL");
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap1.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap1.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap1.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap1.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1797 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/list.h>
+#include <linux/slab.h>
+#include <linux/clk.h>
+#include <linux/module.h>
+#include <linux/mm.h>
+#include <linux/fs.h>
+#include <linux/dma-mapping.h>
+#include <linux/interrupt.h>
+#include <linux/vmalloc.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/delay.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/gpio.h>
+
+#include <linux/videodev2.h>
+#include <media/v4l2-common.h>
+#include <media/v4l2-ioctl.h>
+#include <media/videobuf-dma-contig.h>
+#include <media/v4l2-dev.h>
+
+#include <media/v4l2-device.h>
+#include <linux/jiffies.h>
+
+#include <asm/io.h>
+
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+//#include <mach/regs-lcd.h>
+#include <mach/regs-gpio.h>
+
+#include <mach/regs-cap.h>
+#include <mach/gpio.h>
+#include <linux/time.h>
+
+#include "nuc980_cap.h"
+#define CAP1_PD_PIN NUC980_PC0
+#define CAP1_RST_PIN NUC980_PE10
+
+u32 sensor1_model = 1;
+u32 video1_freq = 24000000;
+
+void nuvoton_vdi1_enable(struct nuvoton_vin_device* cam)
+{
+	u8 packet=0,planar=0,engine=0;
+	ENTRY();
+	if(cam->vpe.PacketEnable==1) {
+		packet=1;
+		if(cam->sensor.bothenable==1)
+			planar=1;
+	}
+
+	if(cam->vpe.PlanarEnable==1) planar=1;
+	engine=(packet|planar);
+	__raw_writel( __raw_readl(REG_CAP1_CTL) | ( (engine<<0) | (packet<<6) | (planar<<5) ),REG_CAP1_CTL);
+	LEAVE();
+}
+
+void nuvoton_vdi1_disable(struct nuvoton_vin_device* cam)
+{
+	ENTRY();
+	if((__raw_readl(REG_CAP1_CTL) & ( (1<<6) | (1<<5) ))!= 0) {
+		__raw_writel(__raw_readl(REG_CAP1_CTL)|(1<<16),REG_CAP1_CTL);
+		while((__raw_readl(REG_CAP1_CTL) & 1)==1);
+		__raw_writel( __raw_readl(REG_CAP1_CTL) & ~(  (1<<6) | (1<<5) ),REG_CAP1_CTL);
+	}
+	LEAVE();
+}
+
+/* ---- IOCTL vidioc handling  ----*/
+static int nuvoton_vidioc1_querycap(struct file* file,void* priv,struct v4l2_capability *cap)
+{
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+	strlcpy(cap->driver,"nuvoton_vin1",sizeof(cap->driver));
+	cap->version = KERNEL_VERSION(1, 1, 10);
+	cap->capabilities = V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_READWRITE | V4L2_CAP_STREAMING| V4L2_CAP_VIDEO_OVERLAY | V4L2_CAP_DEVICE_CAPS;
+	cap->device_caps = V4L2_CAP_EXT_PIX_FORMAT;
+	strlcpy(cap->card, cam->v4ldev->name, sizeof(cap->card));
+	LEAVE();
+	return 0;
+}
+
+#if 1
+/* set the parameters of frame rate control of capture DMA of NUVOTON */
+static int nuvoton_vidioc1_s_parm(struct file* file,void* priv,struct v4l2_streamparm *parm)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+/* get the frame rate parameters */
+static int nuvoton_vidioc1_g_parm(struct file* file,void* priv,struct v4l2_streamparm *parm)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+#endif
+
+/* enum all supported formats of specific device */
+static const struct cap_format cap_formats[] = {
+	{
+		.desc        = "Packet YUV422",
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+	},
+	{
+		.desc        = "Packet GREY",
+		.pixelformat = V4L2_PIX_FMT_GREY,
+	},
+	{
+		.desc        = "Packet RGB 565",
+		.pixelformat = V4L2_PIX_FMT_RGB565,
+	},
+	{
+		.desc        = "Packet RGB 555",
+		.pixelformat = V4L2_PIX_FMT_RGB555,
+	},
+
+	{
+		.desc        = "Planar YUV422",
+		.pixelformat = V4L2_PIX_FMT_YUV422P,
+	},
+	{
+		.desc        = "Planar YUV420",
+		.pixelformat = V4L2_PIX_FMT_YUV411P,
+	},
+};
+static int nuvoton_vidioc1_enum_fmt_vid_cap(struct file *file,void  *priv,struct v4l2_fmtdesc *f)
+{
+	ENTRY();
+	f->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	if (f->index >= sizeof(cap_formats)/sizeof(struct cap_format))
+		return -EINVAL;
+	strlcpy(f->description,cap_formats[f->index].desc,sizeof(f->description));
+	f->pixelformat = cap_formats[f->index].pixelformat;
+	LEAVE();
+	return 0;
+}
+
+/* get the parameters of frame, width, height, field, type, bytesperline, sizeimage */
+static int nuvoton_vidioc1_g_fmt_vid_cap(struct file *file,void *priv,struct v4l2_format *format)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct v4l2_pix_format* pfmt = &(cam->sensor.pix_format);
+	ENTRY();
+	pfmt->bytesperline = 0;
+	pfmt->sizeimage = pfmt->height * ((pfmt->width*pfmt->priv)/8);
+	pfmt->field = V4L2_FIELD_NONE;
+	memcpy(&(format->fmt.pix), pfmt, sizeof(*pfmt));
+	LEAVE();
+	return 0;
+}
+
+unsigned short GCD1(unsigned short m1, unsigned short m2)
+{
+	unsigned short m;
+	if(m1<m2) {
+		m=m1;
+		m1=m2;
+		m2=m;
+	}
+	if(m1%m2==0)
+		return m2;
+	else
+		return (GCD1(m2,m1%m2));
+}
+
+void nuvoton_cap1_SetPlanarFmt(struct nuvoton_vin_device* cam,struct v4l2_pix_format* pix)
+{
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	u32 outfmt=0;
+	u32 u32GCD;
+	if(s->planarfmt==V4L2_PIX_FMT_YUV422P)
+		outfmt  |= 0<<7;
+	else
+		outfmt  |= 1<<7;
+	__raw_writel( (__raw_readl(REG_CAP1_PAR) & ~(1<<7)) | outfmt,REG_CAP1_PAR );
+
+	VDEBUG("Planar, pix->height=%d,pix->width=%d\n",pix->height,pix->width);
+	VDEBUG("Planar, s->cropcap.bounds.height=%d,s->cropcap.bounds.width=%d\n",s->cropcap.bounds.height,s->cropcap.bounds.width);
+	__raw_writel( (__raw_readl(REG_CAP1_PAR) & ~(1<<7)) | outfmt,REG_CAP1_PAR );
+
+	/* Planar Scaling Vertical Factor Register (LSB) */
+	u32GCD=pix->height/s->cropcap.bounds.height;
+	if(u32GCD<=0) u32GCD=1;
+	__raw_writel( (__raw_readl(REG_CAP1_PLNSL) & ~(CAP_PLNSL_PLNSVNL | CAP_PLNSL_PLNSVML))|
+	              ( ((pix->height/u32GCD)&0xff)<<24 | ((s->cropcap.bounds.height/u32GCD)&0xff)<<16),REG_CAP1_PLNSL);
+
+	/* Planar Scaling Vertical Factor Register (MSB) */
+	u32GCD=pix->height/s->cropcap.bounds.height;
+	if(u32GCD<=0) u32GCD=1;
+	__raw_writel( (__raw_readl(REG_CAP1_PLNSM) & ~(CAP_PLNSM_PLNSVNH | CAP_PLNSM_PLNSVMH))|
+	              ( ((pix->height/u32GCD)>>8)<<24 | ((s->cropcap.bounds.height)>>8)/u32GCD<<16),REG_CAP1_PLNSM);
+
+	/* Planar Scaling Horizontal Factor Register (LSB) */
+	u32GCD=pix->width/s->cropcap.bounds.width;
+	if(u32GCD<=0) u32GCD=1;
+	__raw_writel( (__raw_readl(REG_CAP1_PLNSL) & ~(CAP_PLNSL_PLNSHNL | CAP_PLNSL_PLNSHML))|
+	              (((pix->width/u32GCD) & 0xff)<<8 | ((s->cropcap.bounds.width/u32GCD) & 0xff)<<0),REG_CAP1_PLNSL);
+
+	/* Planar Scaling Horizontal Factor Register (MSB) */
+	u32GCD=pix->width/s->cropcap.bounds.width;
+	if(u32GCD<=0) u32GCD=1;
+	__raw_writel( (__raw_readl(REG_CAP1_PLNSM) & ~(CAP_PLNSM_PLNSHNH | CAP_PLNSM_PLNSHMH))|
+	              (((pix->width/u32GCD) >>8)<<8 | ((s->cropcap.bounds.width/u32GCD)>>8)<<0),REG_CAP1_PLNSM);
+
+	/* Frame Output Pixel Stride Width Register(Planar) */
+#if 0
+	__raw_writel( (__raw_readl(REG_CAP1_STRIDE)& ~CAP_STRIDE_PLNSTRIDE) |
+	              (/*PacketStride*/pix->width<<16),REG_CAP1_STRIDE);
+#else
+	__raw_writel( (__raw_readl(REG_CAP1_STRIDE)& ~CAP_STRIDE_PLNSTRIDE) |
+	              (/*PacketStride*/(pix->bytesperline/2)<<16),REG_CAP1_STRIDE);
+#endif
+
+	cam->vpe.PlanarWidth=pix->width;
+	cam->vpe.PlanarHeight=pix->height;
+}
+
+/* This ioctl is similar to vidioc_s_fmt_vid_cap(). However, this ioctl is used to query the formats
+that the device supports without changing any state of the device. */
+static int nuvoton_vidioc1_try_fmt_vid_cap(struct file *file, void *priv,struct v4l2_format *format)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	struct v4l2_pix_format* pix;
+	struct v4l2_pix_format* pfmt = &(s->pix_format);
+	struct v4l2_rect* bounds = &(s->cropcap.bounds);
+	struct v4l2_rect rect;
+	u32 u32GCD1;
+	u32 heightM,heightN,widthM,widthN;
+	u32 outfmt;
+	ENTRY();
+	pix = &(format->fmt.pix);
+
+	if (format->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)
+		return -EINVAL;
+	memcpy(&rect, &(s->_rect), sizeof(rect));
+
+	rect.width = pix->width;
+	rect.height = pix->height;
+	if (rect.width < 8)
+		rect.width = 8;
+	if (rect.height < 8)
+		rect.height = 8;
+	if (rect.width > bounds->left + bounds->width - rect.left)
+		rect.width = bounds->left + bounds->width - rect.left;
+	if (rect.height > bounds->top + bounds->height - rect.top)
+		rect.height = bounds->top + bounds->height - rect.top;
+	rect.width &= ~7L;
+	rect.height &= ~7L;
+
+	pix->width = rect.width;
+	pix->height = rect.height;
+	pix->priv = pfmt->priv;
+	pix->colorspace = pfmt->colorspace;
+	if(pix->bytesperline==0) {
+		pix->bytesperline = pix->width*2;
+		pfmt->bytesperline = pix->width*2;
+	}
+
+	pix->sizeimage = pix->height * (((pix->bytesperline/2) * pix->priv) / 8);
+	pix->field = V4L2_FIELD_NONE;
+	memcpy(pfmt, pix, sizeof(*pix));
+	/*Set capture format for nuvoton sensor interface */
+	__raw_writel( (__raw_readl(REG_CAP1_CWS) & ~(0x0fff0fff)) | (s->cropcap.bounds.width) | (s->cropcap.bounds.height<<16),REG_CAP1_CWS );
+	switch(pix->pixelformat) {
+		/* Packet YUV422 */
+	case V4L2_PIX_FMT_YUYV:
+	case V4L2_PIX_FMT_RGB555:
+	case V4L2_PIX_FMT_RGB565:
+	case V4L2_PIX_FMT_GREY:
+		VDEBUG("Packet\n");
+		if(pix->pixelformat==V4L2_PIX_FMT_YUYV)
+			outfmt = 0<<4;
+		if(pix->pixelformat==V4L2_PIX_FMT_GREY) {
+			pix->priv = 8;
+			outfmt = 1<<4;
+		}
+		if(pix->pixelformat==V4L2_PIX_FMT_RGB555)
+			outfmt = 2<<4;
+		if(pix->pixelformat==V4L2_PIX_FMT_RGB565)
+			outfmt = 3<<4; //infmtord
+
+		if(s->bothenable==1) {
+			nuvoton_cap1_SetPlanarFmt(cam,pix);
+		}
+
+		__raw_writel( (__raw_readl(REG_CAP1_PAR) & ~(3<<4)) | outfmt,REG_CAP1_PAR );
+		__raw_writel( (__raw_readl(REG_CAP1_PAR) & ~INMASK) | s->infmtord,REG_CAP1_PAR );
+		//VDEBUG("pix->pixelformat = V4L2_PIX_FMT_YUYV\n");
+		/* Set_Cropping start position for sensor */
+		if(cam->users==1)
+			__raw_writel( (__raw_readl(REG_CAP1_CWSP) & ~(CAP_CWSP_CWSADDRV | CAP_CWSP_CWSADDRH)) | (s->cropstart),REG_CAP1_CWSP );
+
+		/* Packet Scaling Vertical Factor Register (LSB) */
+		VDEBUG("pix->height=%d, s->cropcap.bounds.height = %d\n",pix->height,s->cropcap.bounds.height);
+		if(pix->height > s->cropcap.bounds.height) {
+			heightN=1;
+			heightM=1;
+		} else {
+			heightM = s->cropcap.bounds.height;
+			heightN = pix->height;
+		}
+		__raw_writel( (__raw_readl(REG_CAP1_PKTSL) & ~(CAP_PKTSL_PKTSVNL | CAP_PKTSL_PKTSVML))|
+		              ((heightN & 0xff)<<24|(heightM & 0xff)<<16),REG_CAP1_PKTSL);
+
+		/* Packet Scaling Vertical Factor Register (MSB) */
+		__raw_writel( (__raw_readl(REG_CAP1_PKTSM) & ~(CAP_PKTSM_PKTSVNH | CAP_PKTSM_PKTSVMH))|
+		              ((heightN>>8)<<24|(heightM>>8)<<16),REG_CAP1_PKTSM);
+		/* Packet Scaling Horizontal Factor Register (LSB) */
+		VDEBUG("pix->width=%d, s->cropcap.bounds.width = %d\n",pix->width,s->cropcap.bounds.width);
+		if(pix->width > s->cropcap.bounds.width) {
+			widthN=1;
+			widthM=1;
+		} else {
+			widthM = s->cropcap.bounds.width;
+			widthN = pix->width;
+		}
+		__raw_writel( (__raw_readl(REG_CAP1_PKTSL) & ~(CAP_PKTSL_PKTSHNL | CAP_PKTSL_PKTSHML))|
+		              ((widthN & 0xff)<<8 | (widthM & 0xff)<<0),REG_CAP1_PKTSL);
+
+		/* Packet Scaling Horizontal Factor Register (MSB) */
+		__raw_writel( (__raw_readl(REG_CAP1_PKTSM) & ~(CAP_PKTSM_PKTSHNH | CAP_PKTSM_PKTSHMH))|
+		              ((widthN>>8)<<8 | (widthM>>8)<<0),REG_CAP1_PKTSM);
+
+		/* Frame Output Pixel Stride Width Register(Packet/Planar) */
+#if 0
+		__raw_writel( (__raw_readl(REG_CAP1_STRIDE)& ~CAP_STRIDE_PKTSTRIDE) |
+		              (/*PacketStride*/pix->width<<0),REG_CAP1_STRIDE);
+#else
+		if(pix->pixelformat!=V4L2_PIX_FMT_GREY) {
+			__raw_writel( (__raw_readl(REG_CAP1_STRIDE)& ~CAP_STRIDE_PKTSTRIDE) |
+			              (/*PacketStride*/(pix->bytesperline/2)<<0),REG_CAP1_STRIDE);
+		} else {
+			__raw_writel( (__raw_readl(REG_CAP1_STRIDE)& ~CAP_STRIDE_PKTSTRIDE) |
+			              (/*PacketStride*/(pix->bytesperline/1)<<0),REG_CAP1_STRIDE);
+		}
+#endif
+		cam->vpe.format=pix->pixelformat;
+		cam->vpe.PacketWidth=pix->width;
+		cam->vpe.PacketHeight=pix->height;
+		cam->vpe.PacketEnable=1;
+		break;
+
+		/* Planar YUV422 */
+	case V4L2_PIX_FMT_YUV422P:
+	case V4L2_PIX_FMT_YUV411P:
+		if(pix->pixelformat==V4L2_PIX_FMT_YUV422P)  outfmt = 0<<7;
+		if(pix->pixelformat==V4L2_PIX_FMT_YUV411P)  outfmt = 1<<7;
+		VDEBUG("Planar, cam->users=%d\n",cam->users);
+		VDEBUG("Planar, pix->height=%d,pix->width=%d\n",pix->height,pix->width);
+		VDEBUG("Planar, s->cropcap.bounds.height=%d,s->cropcap.bounds.width=%d\n",s->cropcap.bounds.height,s->cropcap.bounds.width);
+		__raw_writel( (__raw_readl(REG_CAP1_PAR) & ~(1<<7)) | outfmt,REG_CAP1_PAR );
+		//VDEBUG("pix->pixelformat = V4L2_PIX_FMT_YUV422P\n");
+		/* Set_Cropping start position for sensor */
+		if(cam->users==1)
+			__raw_writel( (__raw_readl(REG_CAP1_CWSP) & ~(CAP_CWSP_CWSADDRV | CAP_CWSP_CWSADDRH)) | ( 0 | 2<<16 ),REG_CAP1_CWSP );
+		/* Planar Scaling Vertical Factor Register (LSB) */
+		u32GCD1=pix->height/s->cropcap.bounds.height;
+		if(u32GCD1<=0) u32GCD1=1;
+		__raw_writel( (__raw_readl(REG_CAP1_PLNSL) & ~(CAP_PLNSL_PLNSVNL | CAP_PLNSL_PLNSVML))|
+		              ( ((pix->height/u32GCD1)&0xff)<<24 | ((s->cropcap.bounds.height/u32GCD1)&0xff)<<16),REG_CAP1_PLNSL);
+
+		/* Planar Scaling Vertical Factor Register (MSB) */
+		u32GCD1=pix->height/s->cropcap.bounds.height;
+		if(u32GCD1<=0) u32GCD1=1;
+		__raw_writel( (__raw_readl(REG_CAP1_PLNSM) & ~(CAP_PLNSM_PLNSVNH | CAP_PLNSM_PLNSVMH))|
+		              ( ((pix->height/u32GCD1)>>8)<<24 | ((s->cropcap.bounds.height)>>8)/u32GCD1<<16),REG_CAP1_PLNSM);
+
+		/* Planar Scaling Horizontal Factor Register (LSB) */
+		u32GCD1=pix->width/s->cropcap.bounds.width;
+		if(u32GCD1<=0) u32GCD1=1;
+		__raw_writel( (__raw_readl(REG_CAP1_PLNSL) & ~(CAP_PLNSL_PLNSHNL | CAP_PLNSL_PLNSHML))|
+		              (((pix->width/u32GCD1) & 0xff)<<8 | ((s->cropcap.bounds.width/u32GCD1) & 0xff)<<0),REG_CAP1_PLNSL);
+
+		/* Planar Scaling Horizontal Factor Register (MSB) */
+		u32GCD1=pix->width/s->cropcap.bounds.width;
+		if(u32GCD1<=0) u32GCD1=1;
+		__raw_writel( (__raw_readl(REG_CAP1_PLNSM) & ~(CAP_PLNSM_PLNSHNH | CAP_PLNSM_PLNSHMH))|
+		              (((pix->width/u32GCD1) >>8)<<8 | ((s->cropcap.bounds.width/u32GCD1)>>8)<<0),REG_CAP1_PLNSM);
+
+		/* Frame Output Pixel Stride Width Register(Planar) */
+#if 0
+		__raw_writel( (__raw_readl(REG_CAP1_STRIDE)& ~CAP_STRIDE_PLNSTRIDE) |
+		              (/*PacketStride*/pix->width<<16),REG_CAP1_STRIDE);
+#else
+		__raw_writel( (__raw_readl(REG_CAP1_STRIDE)& ~CAP_STRIDE_PLNSTRIDE) |
+		              (/*PacketStride*/(pix->bytesperline/2)<<16),REG_CAP1_STRIDE);
+#endif
+
+		cam->vpe.format=pix->pixelformat;
+		cam->vpe.PlanarWidth=pix->width;
+		cam->vpe.PlanarHeight=pix->height;
+		cam->vpe.PlanarEnable=1;
+		VDEBUG("V4L2_PIX_FMT_YUV422P END\n",cam->users);
+		break;
+
+#if 0  /* not surpport yet, TODO: */
+	case V4L2_PIX_FMT_NV16: /* 16  Y/CbCr 4:2:2  */
+		break;
+	case V4L2_PIX_FMT_NV61: /* 16  Y/CrCb 4:2:2  */
+		break;
+	case V4L2_PIX_FMT_YYUV:
+		break;
+	case V4L2_PIX_FMT_YUYV:
+		break;
+	case V4L2_PIX_FMT_YYUV:
+		break;
+	case V4L2_PIX_FMT_YVYU:
+		break;
+	case V4L2_PIX_FMT_UYVY:
+		break;
+	case V4L2_PIX_FMT_VYUY:
+		break;
+
+		/* packet only Y*/
+	case V4L2_PIX_FMT_GREY:
+		break;
+
+		/* Packet RGB555 */
+	case V4L2_PIX_FMT_RGB555:
+		break;
+
+		/* Packet RGB565 */
+	case V4L2_PIX_FMT_RGB565:
+		break;
+
+#endif
+
+	default :
+		return -EINVAL;
+		break;
+
+	}
+
+	if(cam->users==1) {
+		__raw_writel((__raw_readl(REG_CAP1_PAR) & ~(VSP_HI|HSP_HI|PCLKP_HI)) | s->polarity,REG_CAP1_PAR); /* set CAP Polarity */
+		__raw_writel((__raw_readl(REG_CAP1_INT) | 0x10000) ,REG_CAP1_INT);     /* Enable CAP Interrupt */
+	}
+
+	LEAVE();
+	return 0;
+}
+
+
+/* FIX ME: This seems to be generic enough to be at videodev2 */
+/* FIX ME:
+This function sets the output image resolution of the sensor, and save the parameters. */
+static int nuvoton_vidioc1_s_fmt_vid_cap(struct file *file,void *priv,struct v4l2_format *format)
+{
+	ENTRY();
+	nuvoton_vidioc1_try_fmt_vid_cap(file,priv,format);
+	LEAVE();
+	return 0;
+}
+
+/* ask kernel to allocate needed buffer */
+static int nuvoton_vidioc1_reqbufs(struct file *file, void *priv,struct v4l2_requestbuffers *rb)
+{
+	struct nuvoton_vin_device* cam=priv;
+	//struct nuvoton_vin_sensor* s = &cam->sensor;
+	u32 i;
+	int err;
+	ENTRY();
+	if (rb->type != V4L2_BUF_TYPE_VIDEO_CAPTURE || rb->memory != V4L2_MEMORY_MMAP)
+		return -EINVAL;
+
+	if (cam->io == IO_READ) {
+		VDEBUG("Close and open the device again to choose the mmap I/O method\n");
+		return -EBUSY;
+	}
+
+	for (i = 0; i < cam->nbuffers; i++)
+		if (cam->frame[i].vma_use_count) {
+			VDEBUG("VIDIOC_REQBUFS failed. Previous buffers are still mapped.\n");
+			return -EBUSY;
+		}
+
+	if (cam->stream == STREAM_ON)
+		if ((err = nuvoton_vin1_stream_interrupt(cam)))
+			return err;
+
+	nuvoton_vin1_empty_framequeues(cam);
+
+	nuvoton_vin1_release_buffers(cam);
+	if (rb->count)
+		rb->count = nuvoton_vin1_request_buffers(cam, rb->count, IO_MMAP);
+	cam->io = rb->count ? IO_MMAP : IO_NONE;
+
+	LEAVE();
+	return 0;
+}
+
+/* query buffer info */
+static int nuvoton_vidioc1_querybuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+	if (p->type != V4L2_BUF_TYPE_VIDEO_CAPTURE ||
+	    p->index >= cam->nbuffers || cam->io != IO_MMAP) {
+		LEAVE();
+		return -EINVAL;
+	}
+
+	memcpy(p,&(cam->frame[p->index].buf),sizeof(struct v4l2_buffer));
+
+	if (cam->frame[p->index].vma_use_count)
+		p->flags |= V4L2_BUF_FLAG_MAPPED;
+
+	if (cam->frame[p->index].state == F_DONE)
+		p->flags |= V4L2_BUF_FLAG_DONE;
+	else if (cam->frame[p->index].state != F_UNUSED)
+		p->flags |= V4L2_BUF_FLAG_QUEUED;
+
+	LEAVE();
+	return 0;
+}
+
+/* put the buffer into the list */
+static int nuvoton_vidioc1_qbuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct v4l2_buffer b;
+	unsigned long lock_flags;
+	ENTRY();
+	memcpy(&b,p,sizeof(b));
+
+	if (b.type != V4L2_BUF_TYPE_VIDEO_CAPTURE ||
+	    b.index >= cam->nbuffers || cam->io != IO_MMAP) {
+		return -EINVAL;
+	}
+	if (cam->frame[b.index].state != F_UNUSED) {
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&cam->queue_lock, lock_flags);
+	cam->frame[b.index].state = F_QUEUED;
+	list_add_tail(&cam->frame[b.index].frame, &cam->inqueue);
+	spin_unlock_irqrestore(&cam->queue_lock, lock_flags);
+
+	VDEBUG("Frame #%lu queued", (unsigned long)b.index);
+	LEAVE();
+	return 0;
+}
+
+/* de-queue a buffer from the list */
+static int nuvoton_vidioc1_dqbuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct v4l2_buffer b;
+	struct nuvoton_vin_frame_t *f;
+	unsigned long lock_flags;
+	int err = 0;
+	ENTRY();
+	memcpy(&b,p,sizeof(b));
+	if (b.type != V4L2_BUF_TYPE_VIDEO_CAPTURE)
+		return -EINVAL;
+	if (list_empty(&cam->outqueue)) {
+		if (cam->stream == STREAM_OFF)
+			return -EINVAL;
+		err = wait_event_interruptible( cam->wait_frame,(!list_empty(&cam->outqueue)));
+		if (err) return err;
+	}
+	spin_lock_irqsave(&cam->queue_lock, lock_flags);
+	f = list_entry(cam->outqueue.next, struct nuvoton_vin_frame_t, frame);
+	list_del(cam->outqueue.next);
+	spin_unlock_irqrestore(&cam->queue_lock, lock_flags);
+	f->state = F_UNUSED;
+	b = f->buf;
+	if (f->vma_use_count)
+		b.flags |= V4L2_BUF_FLAG_MAPPED;
+	memcpy(p,&b,sizeof(b));
+	VDEBUG("Frame1 #%lu dequeued", (unsigned long)f->buf.index);
+
+	LEAVE();
+	return 0;
+}
+
+/* start capturing the sensor output stream */
+static int nuvoton_vidioc1_streamon(struct file *file, void *priv, enum v4l2_buf_type i)
+{
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+
+	/* Setting Buffer address */
+	VDEBUG("cam->nbuffers=%d\n",cam->nbuffers);
+
+	if(cam->nbuffers>0) {
+		VDEBUG("cam->frame_current->bufmem=0x%08x\n",cam->frame_current->bufmem);
+		VDEBUG("cam->frame_current->pbuf=0x%08x\n",cam->frame_current->pbuf);
+		VDEBUG("cam->vpe.PacketEnable=%d\n",cam->vpe.PacketEnable);
+
+		if(cam->vpe.PacketEnable==1) {
+			if(cam->frame_current!=NULL)
+				__raw_writel(cam->frame_current->pbuf,REG_CAP1_PKTBA0);
+			else
+				VDEBUG("PacketEnable : cam->frame_current == NULL\n");
+
+			if(cam->sensor.bothenable==1) {
+				struct nuvoton_vin_sensor* s = &cam->sensor;
+				struct v4l2_rect* bounds = &(s->cropcap.bounds);
+				u32 size = bounds->height*bounds->height*2;
+				__raw_writel((unsigned int)cam->frame_current->pbuf+size,REG_CAP1_YBA);
+				__raw_writel(__raw_readl(REG_CAP1_YBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight),REG_CAP1_UBA);
+				__raw_writel(__raw_readl(REG_CAP1_UBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight)/2,REG_CAP1_VBA);
+			}
+		}
+
+		VDEBUG("cam->vpe.PlanarEnable=%d\n",cam->vpe.PlanarEnable);
+		if(cam->vpe.PlanarEnable==1) {
+			if(cam->frame_current!=NULL) {
+				__raw_writel((unsigned int)cam->frame_current->pbuf,REG_CAP1_YBA);
+				__raw_writel(__raw_readl(REG_CAP1_YBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight),REG_CAP1_UBA);
+				__raw_writel(__raw_readl(REG_CAP1_UBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight)/2,REG_CAP1_VBA);
+			} else
+				VDEBUG("PlanarEnable : cam->frame_current == NULL\n");
+		}
+	}
+	__raw_writel((__raw_readl(REG_CAP1_INT) | 0x10000) ,REG_CAP1_INT);     /* Enable CAP Interrupt */
+	/* Capture engine enable and packer/planar mode enable */
+	nuvoton_vdi1_enable(cam);
+
+	cam->stream = STREAM_ON;
+	LEAVE();
+	return 0;
+}
+
+/* stop capturing sensor output stream */
+static int nuvoton_vidioc1_streamoff(struct file *file, void *priv, enum v4l2_buf_type i)
+{
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+	cam->vpe.PacketEnable=0;
+	cam->vpe.PacketEnable=0;
+	cam->stream = STREAM_OFF;
+	nuvoton_vdi1_disable(cam);
+	LEAVE();
+	return 0;
+}
+
+/* setup the device support standard */
+static int nuvoton_vidioc1_s_std(struct file *file, void *priv, v4l2_std_id i)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+
+/* only one input in this sample driver */
+/* Enumerate the input. AVID Daytona supports several input devices
+* 1. image sensor
+* 2. native image post-processor
+* 3. analog TV tuner * * */
+static int nuvoton_vidioc1_enum_input(struct file *file,void *priv,struct v4l2_input *inp)
+{
+	ENTRY();
+	strcpy(inp->name, "Camera");
+	inp->type = V4L2_INPUT_TYPE_CAMERA;
+	LEAVE();
+	return 0;
+}
+
+/* always returns 0 (we have only one input) */
+static int nuvoton_vidioc1_g_input(struct file *file, void *priv, unsigned int *i)
+{
+	int index = 0;
+	ENTRY();
+	*i=index;
+	LEAVE();
+	return 0;
+}
+
+/* Because we have only one input, set input = 0 */
+static int nuvoton_vidioc1_s_input(struct file *file, void *priv, unsigned int i)
+{
+	ENTRY();
+	if (i != 0) {
+		LEAVE();
+		return -EINVAL;
+	}
+	LEAVE();
+	return 0;
+}
+
+/* ----- *           controls * ----- */
+/* Check if the control method is supported (via  v4l2_queryctrl)
+If yes, the parameter of the control will be returned;
+if not, error code will be returned. */
+static int nuvoton_vidioc1_queryctrl(struct file *file,void *priv,struct v4l2_queryctrl *qc)
+{
+
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	ENTRY();
+	if (qc->id && qc->id == s->qctrl.id) {
+		memcpy((char *)qc, (char *)&(s->qctrl), sizeof(qc));
+		LEAVE();
+		return 0;
+	}
+	LEAVE();
+	return -EINVAL;
+}
+
+/* get the control parameter */
+static int nuvoton_vidioc1_g_ctrl(struct file *file, void *priv,struct v4l2_control *ctrl)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	int err = 0;
+	ENTRY();
+	if (!s->get_ctrl && !s->set_ctrl)
+		return -EINVAL;
+	if (!s->get_ctrl) {
+		if (ctrl->id == s->qctrl.id) {
+			ctrl->value = s->_qctrl.default_value;
+			goto exit;
+		}
+	} else
+		err = s->get_ctrl(cam, ctrl);
+
+exit:
+	LEAVE();
+	return err;
+}
+
+/* set the control parameter */
+static int nuvoton_vidioc1_s_ctrl(struct file *file,void *priv,struct v4l2_control *ctrl)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	int err = 0;
+	ENTRY();
+	if (!s->set_ctrl)
+		return -EINVAL;
+
+	if (ctrl->id == s->qctrl.id) {
+		if (s->qctrl.flags & V4L2_CTRL_FLAG_DISABLED)
+			return -EINVAL;
+		if (ctrl->value < s->qctrl.minimum || ctrl->value > s->qctrl.maximum)
+			return -ERANGE;
+		ctrl->value -= ctrl->value % s->qctrl.step;
+	}
+	if ((err = s->set_ctrl(cam, ctrl)))
+		return err;
+	s->_qctrl.default_value = ctrl->value;
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_vidioc1_cropcap(struct file *file, void *priv, struct v4l2_cropcap *crop)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct v4l2_cropcap* cc = &(cam->sensor.cropcap);
+
+	cc->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	cc->pixelaspect.numerator = 1;
+	cc->pixelaspect.denominator = 1;
+	memcpy(crop,cc,sizeof(struct v4l2_cropcap));
+	return 0;
+}
+
+static int nuvoton_vidioc1_g_crop(struct file *file, void *priv,struct v4l2_crop *crop)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	ENTRY();
+	crop->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	memcpy(&(crop->c), &(s->_rect), sizeof(struct v4l2_rect));
+	LEAVE();
+	return 0;
+}
+static int nuvoton_vidioc1_s_crop(struct file *file, void *priv,const struct v4l2_crop *crop)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_sensor* s = &cam->sensor;
+	struct v4l2_rect* rect;
+	struct v4l2_rect* bounds = &(s->cropcap.bounds);
+	//const enum unvoton_vin_stream_state stream = cam->stream;
+	const u8 stream = cam->stream;
+	const u32 nbuffers = cam->nbuffers;
+	int err = 0;
+	ENTRY();
+	rect = (struct v4l2_rect*)&(crop->c);
+
+	if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)
+		return -EINVAL;
+
+	if (!s->set_crop) {
+		memcpy(rect, &(s->_rect), sizeof(*rect));
+		return 0;
+	}
+	rect->left &= ~7L;
+	rect->top &= ~7L;
+	if (rect->width < 8)    rect->width = 8;
+	if (rect->height < 8)   rect->height = 8;
+	if (rect->width > bounds->width)        rect->width = bounds->width;
+	if (rect->height > bounds->height)  rect->height = bounds->height;
+	if (rect->left < bounds->left)  rect->left = bounds->left;
+	if (rect->top < bounds->top)        rect->top = bounds->top;
+	if (rect->left + rect->width > bounds->left + bounds->width)    rect->left = bounds->left+bounds->width - rect->width;
+	if (rect->top + rect->height > bounds->top + bounds->height)    rect->top = bounds->top+bounds->height - rect->height;
+	rect->width &= ~7L;
+	rect->height &= ~7L;
+
+	if (cam->stream == STREAM_ON)
+		if ((err = nuvoton_vin1_stream_interrupt(cam)))
+			return err;
+
+
+	if (cam->io == IO_READ)
+		nuvoton_vin1_release_buffers(cam);
+
+	if (s->set_crop)
+		err += s->set_crop(cam, rect);
+
+	if (err) { /* atomic, no rollback in ioctl() */
+		//cam->state |= DEV_MISCONFIGURED;
+		VDEBUG("VIDIOC_S_CROP failed because of hardware problems. To use the camera, close and open %s again.\n",
+		       video_device_node_name(cam->v4ldev));
+		return -EIO;
+	}
+
+	s->pix_format.width = rect->width;
+	s->pix_format.height = rect->height;
+	memcpy(&(s->_rect), rect, sizeof(*rect));
+
+	if ((cam->io == IO_READ) && nbuffers != nuvoton_vin1_request_buffers(cam, nbuffers, cam->io)) {
+		//cam->state |= DEV_MISCONFIGURED;
+		VDEBUG("VIDIOC_S_CROP failed because of not enough memory. To use the camera, close and open %s again.\n",
+		       video_device_node_name(cam->v4ldev));
+		return -ENOMEM;
+	}
+
+	if (cam->io == IO_READ)
+		nuvoton_vin1_empty_framequeues(cam);
+
+	cam->stream = stream;
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_vin1_vidioc_s_jpegcomp(struct file *file, void *priv,const struct v4l2_jpegcompression *jc)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_vidioc1_s_fbuf(struct file *file, void *priv,
+                                  const struct v4l2_framebuffer *fb)
+{
+	int i;
+	struct nuvoton_vin_device* cam=priv;
+	ENTRY();
+	if (fb->flags & V4L2_FBUF_FLAG_OVERLAY) {
+		cam->nbuffers = CONFIG_VIN1_MAX_FRAME_BUFFER;
+		for (i = 0; i < cam->nbuffers; i++) {
+			cam->frame[i].bufmem = cam->vir_addr[i];
+			cam->frame[i].pbuf = cam->phy_addr[i];
+			cam->frame[i].buf.index = i;
+		}
+		cam->frame_current=&cam->frame[0];
+		__raw_writel(cam->frame_current->pbuf,REG_CAP1_PKTBA0);
+		cam->type=V4L2_BUF_TYPE_VIDEO_OVERLAY;
+	} else {
+		cam->type=V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	}
+	LEAVE();
+	return 0;
+
+}
+
+static int nuvoton_vidioc1_g_fbuf(struct file *file, void *priv,
+                                  struct v4l2_framebuffer *fb)
+{
+//Bttv-driver.c
+//Fsl-viu.c
+//Ivtv-ioctl.c
+//Omap_vout.c
+//saa7134-video.c
+//Zoran_driver.c
+	ENTRY();
+	//struct nuvoton_vin_device* cam=priv;
+	//struct nuvoton_vin_sensor* s = &cam->sensor;
+	fb->capability = V4L2_FBUF_FLAG_OVERLAY;
+	fb->flags = V4L2_FBUF_FLAG_OVERLAY;
+	LEAVE();
+	return 0;
+}
+
+/* ---- Initialization v4l2 ioctrl ops   ----*/
+static const struct v4l2_ioctl_ops nuvoton_vdi1_ioctl_ops = {
+	.vidioc_querycap    = nuvoton_vidioc1_querycap,
+	.vidioc_g_fmt_vid_cap   = nuvoton_vidioc1_g_fmt_vid_cap,
+	.vidioc_enum_fmt_vid_cap = nuvoton_vidioc1_enum_fmt_vid_cap,
+	.vidioc_s_fmt_vid_cap   = nuvoton_vidioc1_s_fmt_vid_cap,
+	.vidioc_enum_input = nuvoton_vidioc1_enum_input,
+	.vidioc_g_input = nuvoton_vidioc1_g_input,
+	.vidioc_s_input = nuvoton_vidioc1_s_input,
+	.vidioc_s_std   = nuvoton_vidioc1_s_std,
+	.vidioc_reqbufs = nuvoton_vidioc1_reqbufs,
+	.vidioc_try_fmt_vid_cap = nuvoton_vidioc1_try_fmt_vid_cap,
+	.vidioc_querybuf    = nuvoton_vidioc1_querybuf,
+	.vidioc_qbuf    = nuvoton_vidioc1_qbuf,
+	.vidioc_dqbuf   = nuvoton_vidioc1_dqbuf,
+	.vidioc_streamon    = nuvoton_vidioc1_streamon,
+	.vidioc_streamoff   = nuvoton_vidioc1_streamoff,
+	.vidioc_queryctrl   = nuvoton_vidioc1_queryctrl,
+	.vidioc_g_ctrl = nuvoton_vidioc1_g_ctrl,
+	.vidioc_s_ctrl = nuvoton_vidioc1_s_ctrl,
+	.vidioc_cropcap = nuvoton_vidioc1_cropcap,
+	.vidioc_g_crop = nuvoton_vidioc1_g_crop,
+	.vidioc_s_crop = nuvoton_vidioc1_s_crop,
+	.vidioc_s_jpegcomp = nuvoton_vin1_vidioc_s_jpegcomp,
+	.vidioc_g_fbuf = nuvoton_vidioc1_g_fbuf,
+	.vidioc_s_fbuf = nuvoton_vidioc1_s_fbuf,
+	.vidioc_s_parm = nuvoton_vidioc1_s_parm,
+	.vidioc_g_parm = nuvoton_vidioc1_g_parm,
+	/*  VIDIOC_G_FBUF and VIDIOC_S_FBUF ioctl to get and set
+	    the framebuffer parameters for a Video Overlay
+	    or Video Output Overlay (OSD) */
+};
+
+
+/*****************************************************************************/
+int nuvoton_vin1_stream_interrupt(struct nuvoton_vin_device* cam)
+{
+	return 0;
+}
+
+u32 nuvoton_vin1_request_buffers(struct nuvoton_vin_device* cam, u32 count,enum nuvoton_vin_io_method io)
+{
+	struct v4l2_pix_format* p = &(cam->sensor.pix_format);
+	size_t imagesize;
+	//void* buff = NULL;
+	u32 i;
+
+	if(p->bytesperline==0)
+		imagesize = (p->width * p->height * p->priv) / 8;
+	else
+		imagesize = ((p->bytesperline/2) * p->height * p->priv) / 8;
+
+	ENTRY();
+	if (count > CONFIG_VIN1_MAX_FRAME_BUFFER)
+		count = CONFIG_VIN1_MAX_FRAME_BUFFER;
+
+	cam->nbuffers = (count);
+	for (i = 0; i < cam->nbuffers; i++) {
+		cam->frame[i].bufmem = cam->vir_addr[i];
+		cam->frame[i].pbuf = cam->phy_addr[i];
+		cam->frame[i].buf.index = i;
+		cam->frame[i].buf.m.userptr = (unsigned long)(cam->frame[i].bufmem);
+		cam->frame[i].buf.m.offset = (unsigned long)(cam->frame[i].bufmem);
+		cam->frame[i].buf.length = imagesize;
+		cam->frame[i].buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+		cam->frame[i].buf.sequence = 0;
+		cam->frame[i].buf.field = V4L2_FIELD_NONE;
+		cam->frame[i].buf.memory = V4L2_MEMORY_MMAP;
+		cam->frame[i].buf.flags = 0;
+		VDEBUG("cam->frame[%d].bufmem=0x%08x\n",i,(unsigned int)cam->frame[i].bufmem);
+		VDEBUG("cam->frame[%d].pbuf=0x%08x\n",i,(unsigned int)cam->frame[i].pbuf);
+	}
+	cam->frame_current=&cam->frame[0];
+	LEAVE();
+	return (cam->nbuffers);
+}
+
+
+void nuvoton_vin1_release_buffers(struct nuvoton_vin_device* cam)
+{
+	ENTRY();
+	if (cam->nbuffers) {
+		cam->nbuffers = 0;
+	}
+	cam->frame_current = NULL;
+	LEAVE();
+}
+
+void nuvoton_vin1_empty_framequeues(struct nuvoton_vin_device* cam)
+{
+	u32 i;
+	ENTRY();
+	INIT_LIST_HEAD(&cam->inqueue);
+	INIT_LIST_HEAD(&cam->outqueue);
+
+	for (i = 0; i < CONFIG_VIN1_MAX_FRAME_BUFFER; i++) {
+		cam->frame[i].state = F_UNUSED;
+		cam->frame[i].buf.bytesused = 0;
+	}
+	LEAVE();
+}
+
+void nuvoton_vin1_requeue_outqueue(struct nuvoton_vin_device* cam)
+{
+	struct nuvoton_vin_frame_t *i;
+
+	list_for_each_entry(i, &cam->outqueue, frame) {
+		i->state = F_QUEUED;
+		list_add(&i->frame, &cam->inqueue);
+	}
+	INIT_LIST_HEAD(&cam->outqueue);
+}
+
+
+static void nuvoton_vin1_queue_unusedframes(struct nuvoton_vin_device* cam)
+{
+	unsigned long lock_flags;
+	u32 i;
+
+	for (i = 0; i < cam->nbuffers; i++)
+		if (cam->frame[i].state == F_UNUSED) {
+			cam->frame[i].state = F_QUEUED;
+			spin_lock_irqsave(&cam->queue_lock, lock_flags);
+			list_add_tail(&cam->frame[i].frame, &cam->inqueue);
+			spin_unlock_irqrestore(&cam->queue_lock, lock_flags);
+		}
+}
+
+static void nuvoton_vin1_release_resources(struct kref *kref)
+{
+	struct nuvoton_vin_device *cam = container_of(kref, struct nuvoton_vin_device,kref);
+	ENTRY();
+	VDEBUG("V4L2 device %s deregistered\n",video_device_node_name(cam->v4ldev));
+	video_set_drvdata(cam->v4ldev, NULL);
+	video_unregister_device(cam->v4ldev);
+	kfree(cam->control_buffer);
+	kfree(cam);
+}
+
+
+int capture1_uninit(void)
+{
+
+	__raw_writel( (__raw_readl(REG_MFP_GPD_L) & ~0x000F0000) ,REG_MFP_GPI_L);
+	__raw_writel(((__raw_readl(GPIO_BA+0x0C0)&~0x300) | 0x0100),(GPIO_BA+0x0C0)); /* GPIOD4 Output mode */
+	__raw_writel((__raw_readl(GPIO_BA+0x0C8) | 0x0010),(GPIO_BA+0x0C8)); /* GPIOD4 Output to High */
+	return 0;
+}
+int capture1_init(struct nuvoton_vin_device* cam)
+{
+	int ret;
+	struct clk *clkcap,*clkaplldiv,*clkmux;
+	struct clk *clk;
+	int i32Div;
+	ENTRY();
+	clk = clk_get(NULL, "cap1_eclk");
+	if (IS_ERR(clk)) {
+		return -ENOENT;
+	}
+	clk_prepare(clk);
+	clk_enable(clk);
+	clk_prepare(clk_get(NULL, "cap1_hclk"));
+	clk_enable(clk_get(NULL, "cap1_hclk"));
+	clk_prepare(clk_get(NULL, "sensor_hclk"));
+	clk_enable(clk_get(NULL, "sensor_hclk"));
+	clkmux = clk_get(NULL, "cap1_eclk_mux");
+	if (IS_ERR(clkmux)) {
+		printk(KERN_ERR "nuc980-cap1:failed to get cap clock source\n");
+		ret = PTR_ERR(clkmux);
+		return ret;
+	}
+	clkcap = clk_get(NULL, "cap1_eclk");
+	if (IS_ERR(clkcap)) {
+		printk(KERN_ERR "nuc980-cap1:failed to get cap clock source\n");
+		ret = PTR_ERR(clkcap);
+		return ret;
+	}
+	clkaplldiv = clk_get(NULL, "cap1_uplldiv");
+	//clkaplldiv = clk_get(NULL, "cap1_eclk_div");
+	if (IS_ERR(clkaplldiv)) {
+		printk(KERN_ERR "nuc980-cap1:failed to get cap clock source\n");
+		ret = PTR_ERR(clkaplldiv);
+		return ret;
+	}
+	clk_set_parent(clkmux, clkaplldiv);
+	clk_set_rate(clkcap, video1_freq);
+
+
+
+	i32Div=(300000000/video1_freq)-1;
+	if(i32Div>0xF) i32Div=0xf;
+	__raw_writel((__raw_readl(REG_CLK_DIV2) & ~(0xF<<24) ) | i32Div<<24,REG_CLK_DIV2);
+
+	/* PC0 set to low; PD# */
+	ret = gpio_request(CAP1_PD_PIN, "CAP1_PD_PIN");
+	if (ret) {
+		printk("CAP1_PD_PIN failed ret=%d\n",ret);
+		return ret;
+	}
+	gpio_direction_output(CAP1_PD_PIN,1);
+	udelay(100);
+	gpio_set_value(CAP1_PD_PIN, 0 );
+
+	/* PE10 set to high; RST# */
+	ret = gpio_request(CAP1_RST_PIN, "CAP1_RST_PIN");
+	if (ret) {
+		printk("CAP1_RST_PIN failed ret=%d\n",ret);
+		return ret;
+	}
+	gpio_direction_output(CAP1_RST_PIN,0);
+	udelay(100);
+	gpio_set_value(CAP1_RST_PIN, 1 );
+	udelay(100);
+
+#if 0
+	printk("video1_freq=%d\n",video1_freq);
+	printk("GCR_BA+0x090=0x%08x\n",__raw_readl(GCR_BA+0x090));
+	printk("GCR_BA+0x094=0x%08x\n",__raw_readl(GCR_BA+0x094));
+	printk("GCR_BA+0x09c=0x%08x\n",__raw_readl(GCR_BA+0x09C));
+	printk("CLK_HCLKEN=0x%08x\n",__raw_readl(CLK_BA+0x010));
+	printk("REG_CLK_DIV2=0x%08x\n",__raw_readl(CLK_BA+0x028));
+#endif
+
+	return 0;
+}
+
+static int vdi_user=0;
+static int nuvoton_vdi1_open(struct file *filp)
+{
+	struct nuvoton_vin_device* cam=video_drvdata(filp);
+	int err = 0;
+	ENTRY();
+	if (!down_read_trylock(&nuvoton_vin1_dev_lock))
+		return -EAGAIN;
+
+	if (wait_for_completion_interruptible(&cam->probe)) {
+		up_read(&nuvoton_vin1_dev_lock);
+		return -ERESTARTSYS;
+	}
+	kref_get(&cam->kref);
+
+	if (mutex_lock_interruptible(&cam->open_mutex)) {
+		kref_put(&cam->kref, nuvoton_vin1_release_resources);
+		up_read(&nuvoton_vin1_dev_lock);
+		return -ERESTARTSYS;
+	}
+	if (cam->users) {
+		VDEBUG("Device %s is busy...\n",video_device_node_name(cam->v4ldev));
+		VDEBUG("Simultaneous opens are not supported\n");
+		if ((filp->f_flags & O_NONBLOCK) || (filp->f_flags & O_NDELAY)) {
+			err = -EWOULDBLOCK;
+			goto out;
+		}
+		VDEBUG("A blocking open() has been requested. Wait for the device to be released...\n");
+		if (err)
+			goto out;
+	}
+
+	filp->private_data = cam;
+	cam->users=++vdi_user;
+	cam->io = IO_NONE;
+	cam->stream = STREAM_OFF;
+	cam->nbuffers = 0;
+	cam->frame_count = 0;
+	nuvoton_vin1_empty_framequeues(cam);
+	VDEBUG("Video device %s is open\n",video_device_node_name(cam->v4ldev));
+
+out:
+	mutex_unlock(&cam->open_mutex);
+	if (err)
+		kref_put(&cam->kref, nuvoton_vin1_release_resources);
+	up_read(&nuvoton_vin1_dev_lock);
+	LEAVE();
+	return err;
+
+}
+
+static int nuvoton_vdi1_close(struct file *filp)
+{
+
+	struct nuvoton_vin_device* cam = video_drvdata(filp);
+	ENTRY();
+	down_write(&nuvoton_vin1_dev_lock);
+	nuvoton_vdi1_disable(cam);
+	nuvoton_vin1_release_buffers(cam);
+	vdi_user--;
+	cam->users=0;
+	cam->vpe.PacketEnable=0;
+	cam->vpe.PlanarEnable=0;
+	cam->type=0;
+	cam->stream = STREAM_OFF;
+	VDEBUG("Video device %s closed", video_device_node_name(cam->v4ldev));
+
+	kref_put(&cam->kref, nuvoton_vin1_release_resources);
+	up_write(&nuvoton_vin1_dev_lock);
+	nuvoton_vin1_empty_framequeues(cam);
+	wake_up_interruptible(&cam->wait_frame);
+	LEAVE();
+	return 0;
+}
+
+static ssize_t nuvoton_vdi1_read(struct file* filp, char __user * buf, size_t count, loff_t* f_pos)
+{
+	struct nuvoton_vin_device *cam = video_drvdata(filp);
+	struct nuvoton_vin_frame_t* f, * i;
+	unsigned long lock_flags;
+	long timeout;
+	int err = 0;
+	ENTRY();
+	if (mutex_lock_interruptible(&cam->fileop_mutex)) {
+		return -ERESTARTSYS;
+	}
+
+	if (cam->io == IO_MMAP) {
+		VDEBUG("Close and open the device again to choose the read method\n");
+		mutex_unlock(&cam->fileop_mutex);
+		return -EBUSY;
+	}
+	if (cam->io == IO_NONE) {
+		if (!nuvoton_vin1_request_buffers(cam, cam->nreadbuffers, IO_READ)) {
+			VDEBUG("read() failed, not enough memory\n");
+			mutex_unlock(&cam->fileop_mutex);
+			return -ENOMEM;
+		}
+		cam->io = IO_READ;
+		cam->stream = STREAM_ON;
+		if(cam->nreadbuffers>0) {
+			VDEBUG("cam->nreadbuffers=%d\n",cam->nreadbuffers);
+			if(cam->vpe.PacketEnable==1) {
+				if(cam->frame_current!=NULL)
+					__raw_writel(cam->frame_current->pbuf,REG_CAP1_PKTBA0);
+				else
+					VDEBUG("PacketEnable : cam->frame_current == NULL\n");
+			}
+			if(cam->vpe.PlanarEnable==1) {
+				if(cam->frame_current!=NULL) {
+					__raw_writel((unsigned int)cam->frame_current->pbuf,REG_CAP1_YBA);
+					__raw_writel(__raw_readl(REG_CAP1_YBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight),REG_CAP1_UBA);
+					__raw_writel(__raw_readl(REG_CAP1_UBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight)/2,REG_CAP1_VBA);
+				} else
+					VDEBUG("PlanarEnable : cam->frame_current == NULL\n");
+			}
+
+			VDEBUG("cam->frame_current->bufmem=0x%08x\n",cam->frame_current->bufmem);
+			VDEBUG("cam->frame_current->pbuf=0x%08x\n",cam->frame_current->pbuf);
+			VDEBUG("cam->vpe.PacketEnable=%d\n",cam->vpe.PacketEnable);
+			VDEBUG("cam->vpe.PlanarEnable=%d\n",cam->vpe.PlanarEnable);
+		}
+		/* Capture engine enable and packet/planar mode enable */
+		nuvoton_vdi1_enable(cam);
+	}
+
+	if (list_empty(&cam->inqueue)) {
+		if (!list_empty(&cam->outqueue))
+			nuvoton_vin1_empty_framequeues(cam);
+		nuvoton_vin1_queue_unusedframes(cam);
+	}
+
+	if (!count) {
+		mutex_unlock(&cam->fileop_mutex);
+		return 0;
+	}
+
+	if (list_empty(&cam->outqueue)) {
+		timeout = wait_event_interruptible_timeout
+		          ( cam->wait_frame,(!list_empty(&cam->outqueue)),msecs_to_jiffies(NUVOTON_FRAME_TIMEOUT * 1000));
+		if (timeout < 0) {
+			mutex_unlock(&cam->fileop_mutex);
+			return timeout;
+		}
+	}
+	f = list_entry(cam->outqueue.prev, struct nuvoton_vin_frame_t, frame);
+	if (copy_to_user(buf, f->bufmem, count)) {
+		err = -EFAULT;
+		goto exit;
+	}
+	*f_pos += count;
+
+exit:
+
+	spin_lock_irqsave(&cam->queue_lock, lock_flags);
+	list_for_each_entry(i, &cam->outqueue, frame)
+	i->state = F_UNUSED;
+	INIT_LIST_HEAD(&cam->outqueue);
+	spin_unlock_irqrestore(&cam->queue_lock, lock_flags);
+
+	nuvoton_vin1_queue_unusedframes(cam);
+
+	VDEBUG("Frame #%lu, bytes read: %zu\n",(unsigned long)f->buf.index, count);
+
+	mutex_unlock(&cam->fileop_mutex);
+	LEAVE();
+	return 0;
+}
+
+static void nuvoton_vin1_vm_open(struct vm_area_struct* vma)
+{
+	struct nuvoton_vin_frame_t* f = vma->vm_private_data;
+	ENTRY();
+	f->vma_use_count++;
+}
+
+
+static void nuvoton_vin1_vm_close(struct vm_area_struct* vma)
+{
+	/* NOTE: buffers are not freed here */
+	struct nuvoton_vin_frame_t* f = vma->vm_private_data;
+	ENTRY();
+	f->vma_use_count--;
+	LEAVE();
+}
+
+
+static const struct vm_operations_struct nuvoton_vin1_vm_ops = {
+	.open = nuvoton_vin1_vm_open,
+	.close = nuvoton_vin1_vm_close,
+};
+
+static int nuvoton_vdi1_mmap(struct file* filp, struct vm_area_struct *vma)
+{
+	struct nuvoton_vin_device *cam = video_drvdata(filp);
+	unsigned long size = vma->vm_end - vma->vm_start,start = vma->vm_start;
+	void *pos;
+	u32 i;
+	ENTRY();
+	//if (mutex_lock_interruptible(&cam->fileop_mutex))
+	//  return -ERESTARTSYS;
+	if (!(vma->vm_flags & (VM_WRITE | VM_READ))) {
+		mutex_unlock(&cam->fileop_mutex);
+		return -EACCES;
+	}
+
+	if (cam->io != IO_MMAP ||
+	    size != PAGE_ALIGN(cam->frame[0].buf.length)) {
+		mutex_unlock(&cam->fileop_mutex);
+		return -EINVAL;
+	}
+
+	for (i = 0; i < cam->nbuffers; i++) {
+		if ((cam->frame[i].buf.m.offset>>PAGE_SHIFT) == vma->vm_pgoff)
+			break;
+	}
+	if (i == cam->nbuffers) {
+		mutex_unlock(&cam->fileop_mutex);
+		return -EINVAL;
+	}
+
+	vma->vm_flags |= VM_IO | VM_DONTEXPAND | VM_DONTDUMP;
+	pos = cam->frame[i].bufmem;
+	while (size > 0) { /* size is page-aligned */
+		if (vm_insert_page(vma, start, vmalloc_to_page(pos))) {
+			mutex_unlock(&cam->fileop_mutex);
+			//printk("4444\n");
+			return -EAGAIN;
+		}
+		start += PAGE_SIZE;
+		pos += PAGE_SIZE;
+		size -= PAGE_SIZE;
+	}
+
+	vma->vm_ops = &nuvoton_vin1_vm_ops;
+	vma->vm_private_data = &cam->frame[i];
+	nuvoton_vin1_vm_open(vma);
+
+	mutex_unlock(&cam->fileop_mutex);
+	LEAVE();
+	return 0;
+}
+
+/* ISR for buffer handling                   *
+ * for nuvoton sensor interface              *
+ *                                           */
+static int cap1_cnt=0;
+static irqreturn_t nuvoton_vdi1_isr(int irq, void *priv)
+{
+	struct nuvoton_vin_device* cam=priv;
+	struct nuvoton_vin_frame_t** f=NULL;
+	ENTRY();
+	//printk("VDIN1 ISR status=0x%08x\n",__raw_readl(REG_CAP1_INT));
+	//printk("REG_CAP1_CTL=0x%08x\n",__raw_readl(REG_CAP1_CTL));
+	//printk("REG_CAP1_CURADDRY=0x%08x\n",__raw_readl(REG_CAP1_CURADDRY));
+	//printk("REG_CAP1_CURADDRU=0x%08x\n",__raw_readl(REG_CAP1_CURADDRU));
+	//printk("REG_CAP1_CURADDRV=0x%08x\n",__raw_readl(REG_CAP1_CURADDRV));
+	//printk("REG_CAP1_YBA=0x%08x\n",__raw_readl(REG_CAP1_YBA));
+	//printk("REG_CAP1_UBA=0x%08x\n",__raw_readl(REG_CAP1_UBA));
+	//printk("REG_CAP1_VBA=0x%08x\n",__raw_readl(REG_CAP1_VBA));
+	if(cap1_cnt==1) {
+		cap1_cnt=0;
+		__raw_writel(__raw_readl(REG_CAP1_INT),REG_CAP1_INT);
+		LEAVE();
+		return IRQ_NONE;
+	}
+
+	f  = &cam->frame_current;
+//      if (cam->stream == STREAM_OFF || list_empty(&cam->inqueue)) {
+	if (cam->stream == STREAM_OFF || list_is_last(&(*f)->frame,&cam->inqueue)) {
+		if(cam->stream == STREAM_ON && cam->type==V4L2_BUF_TYPE_VIDEO_OVERLAY) {
+#if 0
+			__raw_writel(cam->frame[0].pbuf,NUC970_VA_LCD+REG_LCM_VA_BADDR0);
+			__raw_writel(cam->frame[0].pbuf,REG_CAP1_PKTBA0);
+			__raw_writel(__raw_readl(REG_CAP1_CTL) | CAP_CTL_UPDATE,REG_CAP1_CTL);
+			__raw_writel((__raw_readl(REG_CAP1_INT) & ~0x10000) ,REG_CAP1_INT);        /* Disable CAP Interrupt */
+#endif
+		} else {
+			//printk("wake_up_interruptible start\n");
+			wake_up_interruptible(&cam->wait_frame);
+			//printk("wake_up_interruptible end\n");
+		}
+	}
+	spin_lock(&cam->queue_lock );
+	if((*f)->state == F_QUEUED) {
+		list_move_tail(&(*f)->frame, &cam->outqueue);
+	}
+	if (!list_empty(&cam->inqueue)) {
+		(*f) = list_entry(cam->inqueue.next,struct nuvoton_vin_frame_t,frame);
+		if(cam->vpe.PacketEnable==1) {
+			/* Setting packet buffer start address */
+			__raw_writel((*f)->pbuf,REG_CAP1_PKTBA0);
+			if(cam->sensor.bothenable==1) {
+				struct nuvoton_vin_sensor* s = &cam->sensor;
+				struct v4l2_rect* bounds = &(s->cropcap.bounds);
+				u32 size = bounds->height*bounds->height*2;
+				__raw_writel((*f)->pbuf+size,REG_CAP1_YBA);
+				__raw_writel(__raw_readl(REG_CAP1_YBA)+(cam->vpe.PlanarHeight*cam->vpe.PlanarWidth),REG_CAP1_UBA);
+				__raw_writel(__raw_readl(REG_CAP1_UBA)+(cam->vpe.PlanarHeight*cam->vpe.PlanarWidth)/2,REG_CAP1_VBA);
+			}
+		} else if(cam->vpe.PlanarEnable==1) {
+			/* Setting planar buffer Y address, U address, V address */
+			__raw_writel((unsigned int)(*f)->pbuf,REG_CAP1_YBA);
+			__raw_writel(__raw_readl(REG_CAP1_YBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight),REG_CAP1_UBA);
+			__raw_writel(__raw_readl(REG_CAP1_UBA)+(cam->vpe.PlanarWidth*cam->vpe.PlanarHeight)/2,REG_CAP1_VBA);
+		}
+		/* Update New frame */
+		__raw_writel(__raw_readl(REG_CAP1_CTL) | CAP_CTL_UPDATE,REG_CAP1_CTL);
+		cap1_cnt++;
+		spin_unlock(&cam->queue_lock);
+		wake_up_interruptible(&cam->wait_frame);
+	}
+	__raw_writel(__raw_readl(REG_CAP1_INT),REG_CAP1_INT);
+	LEAVE();
+	return IRQ_NONE;
+}
+
+
+
+static struct v4l2_file_operations nuvoton_vdi1_fops = {
+	.owner              = THIS_MODULE,
+	.open               = nuvoton_vdi1_open,
+	.release            = nuvoton_vdi1_close,
+	.read               = nuvoton_vdi1_read,
+	//.ioctl            = video_ioctl2,         /* V4L2 ioctl handler */
+	.unlocked_ioctl     = video_ioctl2,         /* V4L2 ioctl handler */
+	.mmap               = nuvoton_vdi1_mmap,
+};
+
+/* ---- Initialization v4l2_file_operations  ----*/
+#ifndef CONFIG_USE_OF
+#if defined(CONFIG_SENSOR1_OV7725)
+extern int nuvoton_vin1_probe_ov7725(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR1_OV5640)
+extern int nuvoton_vin1_probe_ov5640(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR1_NT99141)
+extern int nuvoton_vin1_probe_nt99141(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR1_NT99050)
+extern int nuvoton_vin1_probe_nt99050(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR1_TW9912)
+extern int nuvoton_vin1_probe_tw9912(struct nuvoton_vin_device* cam);
+#elif defined(CONFIG_SENSOR1_GC0308)
+extern int nuvoton_vin1_probe_gc0308(struct nuvoton_vin_device* cam);
+#endif
+#else
+extern int nuvoton_vin1_probe_ov7725(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin1_probe_ov5640(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin1_probe_nt99141(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin1_probe_nt99050(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin1_probe_tw9912(struct nuvoton_vin_device* cam);
+extern int nuvoton_vin1_probe_gc0308(struct nuvoton_vin_device* cam);
+#endif
+int nuvoton_vdi1_device_register(struct platform_device *pdev)
+{
+	int ret;
+	struct nuvoton_vin_device* cam;
+	int err = 0;
+	ENTRY();
+
+	if (!(cam = kzalloc(sizeof(struct nuvoton_vin_device), GFP_KERNEL)))
+		return -ENOMEM;
+	if (!(cam->control_buffer = kzalloc(4, GFP_KERNEL))) {
+		VDEBUG("kmalloc() failed\n");
+		err = -ENOMEM;
+		goto fail;
+	}
+	if (!(cam->frame = kzalloc(sizeof(struct nuvoton_vin_frame_t)*CONFIG_VIN1_MAX_FRAME_BUFFER, GFP_KERNEL)))
+		return -ENOMEM;
+	if (!(cam->vir_addr = (u32 **)kzalloc(sizeof(u32 *)*CONFIG_VIN1_MAX_FRAME_BUFFER, GFP_KERNEL)))
+		return -ENOMEM;
+	if (!(cam->phy_addr = kzalloc(sizeof(dma_addr_t)*CONFIG_VIN1_MAX_FRAME_BUFFER, GFP_KERNEL)))
+		return -ENOMEM;
+	if (!(cam->v4ldev = video_device_alloc())) {
+		VDEBUG("video_device_alloc() failed\n");
+		err = -ENOMEM;
+		goto fail;
+	}
+	err=capture1_init(cam); /* Set capture init for nuvoton sensor interface */
+	VDEBUG("capture1_init().");
+
+	//for sensor init
+#ifndef CONFIG_USE_OF
+#if defined(CONFIG_SENSOR1_OV7725)
+	err=nuvoton_vin1_probe_ov7725(cam); //sensor probe;
+#elif defined(CONFIG_SENSOR1_OV5640)
+	err=nuvoton_vin1_probe_ov5640(cam); //sensor probe;
+#elif defined(CONFIG_SENSOR1_NT99141)
+	err=nuvoton_vin1_probe_nt99141(cam); //sensor probe;
+#elif defined(CONFIG_SENSOR1_NT99050)
+	err=nuvoton_vin1_probe_nt99050(cam); //sensor probe;
+#elif defined(CONFIG_SENSOR1_TW9912)
+	err=nuvoton_vin1_probe_tw9912(cam);//sensor probe;
+#elif defined(CONFIG_SENSOR1_GC0308)
+	err=nuvoton_vin1_probe_gc0308(cam);//sensor probe;
+#endif
+	if(err<0) {
+		gpio_free(CAP1_PD_PIN);
+		gpio_free(CAP1_RST_PIN);
+		VDEBUG("Initialization failed. I will retry on open().");
+		return err;
+	}
+#else
+	if(sensor1_model==SENSOR_OV7725)
+		err=nuvoton_vin1_probe_ov7725(cam); //sensor probe;
+	else if(sensor1_model==SENSOR_OV5640)
+		err=nuvoton_vin1_probe_ov5640(cam); //sensor probe;
+	else if(sensor1_model==SENSOR_NT99141)
+		err=nuvoton_vin1_probe_nt99141(cam); //sensor probe;
+	else if(sensor1_model==SENSOR_NT99050)
+		err=nuvoton_vin1_probe_nt99050(cam); //sensor probe;
+	else if(sensor1_model==SENSOR_TW9912)
+		err=nuvoton_vin1_probe_tw9912(cam); //sensor probe;
+	else if(sensor1_model==SENSOR_GC0308) {
+		err=nuvoton_vin1_probe_gc0308(cam); //sensor probe;
+	}
+
+	if(err<0) {
+		gpio_free(CAP1_PD_PIN);
+		gpio_free(CAP1_RST_PIN);
+		VDEBUG("Initialization failed. I will retry on open().");
+		return -EAGAIN;
+	}
+#endif
+
+	{
+		int j;
+		int mul=1;
+		struct v4l2_rect* defrect = &(cam->sensor.cropcap.defrect);
+		if(cam->sensor.bothenable==1) mul=2;
+		for(j=0; j<CONFIG_VIN1_MAX_FRAME_BUFFER; j++)
+			if((cam->vir_addr[j] = dma_alloc_writecombine(NULL,
+			                       PAGE_ALIGN(defrect->width*defrect->height*2*mul),
+			                       &cam->phy_addr[j],
+			                       GFP_KERNEL))==NULL) {
+				printk("dma_alloc_writecombine failed\n");
+				return -EAGAIN;
+			}
+	}
+	/* INIT */
+	mutex_init(&cam->open_mutex);
+	mutex_init(&cam->fileop_mutex);
+	init_waitqueue_head(&cam->wait_frame);
+	init_waitqueue_head(&cam->wait_stream);
+	cam->nreadbuffers = 2;
+
+	strcpy(cam->v4ldev->name, "NUVOTON Camera1 Interface");
+	cam->stream = STREAM_OFF;
+	//cam->v4ldev->current_norm = V4L2_STD_NTSC_M;
+	cam->v4ldev->fops       = &nuvoton_vdi1_fops;
+	cam->v4ldev->release        = video_device_release;
+	cam->v4ldev->tvnorms        = V4L2_STD_525_60;
+	cam->v4ldev->ioctl_ops = &nuvoton_vdi1_ioctl_ops; /* for V4L2 ioctl handler */
+	cam->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	cam->frame_current = NULL;
+
+	ret=v4l2_device_register(&pdev->dev,&cam->v4l2_dev);
+	if (ret) {
+		printk("Unable to register v4l2 device\n");
+		v4l2_err(pdev->dev.driver,
+		         "Unable to register v4l2 device\n");
+		return ret;
+	}
+	cam->v4ldev->v4l2_dev =(struct v4l2_device *) &cam->v4l2_dev;
+	video_set_drvdata(cam->v4ldev, cam);
+	platform_set_drvdata(pdev, cam);
+	init_completion(&cam->probe);
+
+	err = video_register_device(cam->v4ldev, VFL_TYPE_GRABBER,
+	                            -1);
+
+	if (err) {
+		VDEBUG("V4L2 device registration failed\n");
+		if (err == -ENFILE)
+			VDEBUG("Free /dev/videoX node not found\n");
+		complete_all(&cam->probe);
+		goto fail;
+	}
+
+	/* Setting Interrupt(IRQ) for nuvoton sensor interface  */
+	err = request_irq(IRQ_CAP1, nuvoton_vdi1_isr, IRQF_NO_SUSPEND|IRQF_SHARED, "camera sensor 1", cam);
+	if(err < 0) {
+		VDEBUG("Interrupt(IRQ_CAP1) setup failed\n");
+		goto fail;
+	} else
+		VDEBUG("%s, main sensor isr is created\n", __func__);
+	VDEBUG("V4L2 device registered as %s\n",video_device_node_name(cam->v4ldev));
+	kref_init(&cam->kref);
+	complete_all(&cam->probe);
+	return 0;
+fail:
+	if (cam) {
+		kfree(cam->control_buffer);
+		if (cam->v4ldev)
+			video_device_release(cam->v4ldev);
+		kfree(cam);
+	}
+	return err;
+}
+
+/*****************************************************************************/ //for sensor
+void nuvoton_vin1_attach_sensor(struct nuvoton_vin_device* cam, struct nuvoton_vin_sensor* sensor)
+{
+	memcpy(&cam->sensor, sensor, sizeof(struct nuvoton_vin_sensor));
+}
+/*****************************************************************************/
+
+
+/* This routine allocates from 1 to n_devs drivers.
+The real maximum number of virtual drivers will depend on how many drivers   will succeed.
+This is limited to the maximum number of devices that   videodev supports.
+Since there are 64 minors for video grabbers, this is   currently the theoretical maximum limit.
+However, a further limit does   exist at videodev that forbids any driver to register more than 32 video   grabbers.
+Max number of video_devices can be registered at the same time: 32 */
+static int nuvoton_cap1_device_probe(struct platform_device *pdev)
+{
+	int ret = 0;
+#ifndef CONFIG_USE_OF
+	struct pinctrl *pinctrl;
+#endif
+	ENTRY();
+	printk("%s - pdev = %s\n", __func__, pdev->name);
+
+#ifndef CONFIG_USE_OF
+	video1_freq = CONFIG_VIDEO1_FREQ;
+
+
+#if 0
+	__raw_writel((__raw_readl(GCR_BA+0x090)&0x00000000)|0x77777777,(GCR_BA+0x090));
+	__raw_writel((__raw_readl(GCR_BA+0x094)&0xFFF0F000)|0x00070077,(GCR_BA+0x094));
+	__raw_writel((__raw_readl(GCR_BA+0x09C)&0xFFFFF0FF)|0x00000700,(GCR_BA+0x09C));
+#else
+	pinctrl = devm_pinctrl_get_select(&pdev->dev, "vcap1");
+	if (IS_ERR(pinctrl)) {
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		ret = PTR_ERR(pinctrl);
+		return ret;
+	}
+#endif
+
+#else
+	{
+		const char *pstr;
+
+		of_property_read_u32_array(pdev->dev.of_node,"frequency", &video1_freq,1);
+		of_property_read_string(pdev->dev.of_node,"model",&pstr);
+		if(pstr[0]=='o' && pstr[1]=='v' && pstr[2]=='7' && pstr[3]=='7' && pstr[4]=='2' && pstr[5]=='5' ) {
+			sensor1_model = 0;
+		} else if(pstr[0]=='n' && pstr[1]=='t' && pstr[2]=='9' && pstr[3]=='9' && pstr[4]=='1' && pstr[5]=='4' && pstr[6]=='1' ) {
+			sensor1_model = 1;
+		} else if(pstr[0]=='n' && pstr[1]=='t' && pstr[2]=='9' && pstr[3]=='9' && pstr[4]=='0' && pstr[5]=='5' && pstr[6]=='0' ) {
+			sensor1_model = 2;
+		} else if(pstr[0]=='o' && pstr[1]=='v' && pstr[2]=='5' && pstr[3]=='6' && pstr[4]=='4' && pstr[5]=='0' ) {
+			sensor1_model = 3;
+		} else if(pstr[0]=='t' && pstr[1]=='w' && pstr[2]=='9' && pstr[3]=='9' && pstr[4]=='1' && pstr[5]=='2') {
+			sensor1_model = 4;
+		} else if(pstr[0]=='g' && pstr[1]=='c' && pstr[2]=='0' && pstr[3]=='3' && pstr[4]=='0' && pstr[5]=='8') {
+			sensor1_model = 5;
+		}
+
+		//of_property_read_string(pdev->dev.of_node,"powerdown-pin",&pstr1);
+	}
+#endif
+
+	ret = nuvoton_vdi1_device_register(pdev);
+	if(ret) {
+		printk("%s video%d, main sensor registeration fail.\n", __func__,1);
+		ret = -EPROBE_DEFER;
+		goto out;
+	} else
+		printk("%s video%d, main sensor registeration ok.\n", __func__,1);
+out:
+	LEAVE();
+	return ret;
+}
+
+static int nuvoton_cap1_device_remove(struct platform_device *pdev)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_cap1_device_resume(struct platform_device *pdev)
+{
+	struct nuvoton_vin_device* cam = platform_get_drvdata(pdev);
+	ENTRY();
+	capture1_init(0);
+#ifndef CONFIG_USE_OF
+#if defined(CONFIG_SENSOR1_OV7725)
+	nuvoton_vin1_probe_ov7725(cam);
+#elif defined(CONFIG_SENSOR1_OV5640)
+	nuvoton_vin1_probe_ov5640(cam);
+#elif defined(CONFIG_SENSOR1_NT99141)
+	nuvoton_vin1_probe_nt99141(cam);
+#elif defined(CONFIG_SENSOR1_NT99050)
+	nuvoton_vin1_probe_nt99050(cam);
+#elif defined(CONFIG_SENSOR1_TW9912)
+	nuvoton_vin1_probe_tw9912(cam);
+#elif defined(CONFIG_SENSOR1_GC0308)
+	nuvoton_vin1_probe_gc0308(cam);
+#endif
+#else
+	if(sensor1_model==SENSOR_OV7725)
+		nuvoton_vin1_probe_ov7725(cam);
+	else if(sensor1_model==SENSOR_OV5640)
+		nuvoton_vin1_probe_ov5640(cam);
+	else if(sensor1_model==SENSOR_NT99141)
+		nuvoton_vin1_probe_nt99141(cam);
+	else if(sensor1_model==SENSOR_NT99050)
+		nuvoton_vin1_probe_nt99050(cam);
+	else if(sensor1_model==SENSOR_TW9912)
+		nuvoton_vin1_probe_tw9912(cam);
+	else if(sensor1_model==SENSOR_GC0308)
+		nuvoton_vin1_probe_gc0308(cam);
+#endif
+	if(cam->CtlReg==1)
+		__raw_writel(__raw_readl(REG_CAP1_CTL)|0x1,REG_CAP1_CTL);
+	LEAVE();
+	return 0;
+}
+
+static int nuvoton_cap1_device_suspend(struct platform_device *pdev,pm_message_t state)
+{
+	struct nuvoton_vin_device* cam = platform_get_drvdata(pdev);
+	ENTRY();
+	if(__raw_readl(REG_CAP1_CTL)&0x1) {
+		__raw_writel(__raw_readl(REG_CAP1_CTL)|(1<<16),REG_CAP1_CTL);
+		while(__raw_readl(REG_CAP1_CTL)&0x1);
+		cam->CtlReg=1;
+	} else {
+		cam->CtlReg=0;
+	}
+	capture1_uninit();
+	LEAVE();
+	return 0;
+}
+
+static struct platform_device_id nuc980_cap1_driver_ids[] = {
+	{ "nuc980-videoin1", 0 },
+	{ },
+};
+
+static const struct of_device_id nuc980_cap1_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-cap1" },
+	{},
+};
+static struct platform_driver nuc980_cap1_driver = {
+	.probe  = nuvoton_cap1_device_probe,
+	.remove     = nuvoton_cap1_device_remove,
+	.resume   = nuvoton_cap1_device_resume,
+	.suspend  = nuvoton_cap1_device_suspend,
+	.driver     = {
+		.name   = "nuc980-cap1",
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_cap1_of_match),
+	},
+	.id_table   = nuc980_cap1_driver_ids,
+};
+
+module_platform_driver(nuc980_cap1_driver);
+MODULE_DESCRIPTION("NUVOTON sensor interface");
+MODULE_AUTHOR("SCHung");
+MODULE_LICENSE("Dual BSD/GPL");
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap.h NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap.h
--- linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap.h	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_cap.h	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,199 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#ifndef _NUVOTON_VDI_V4L2_H
+#define _NUVOTON_VDI_V4L2_H
+
+#include <linux/version.h>
+#include <linux/videodev2.h>
+#include <media/v4l2-common.h>
+#include <media/v4l2-ioctl.h>
+#include <media/v4l2-device.h>
+#include <linux/device.h>
+#include <linux/list.h>
+#include <linux/spinlock.h>
+#include <linux/time.h>
+#include <linux/wait.h>
+#include <linux/types.h>
+#include <linux/param.h>
+#include <linux/mutex.h>
+#include <linux/rwsem.h>
+#include <linux/stddef.h>
+#include <linux/string.h>
+#include <linux/kref.h>
+#include <linux/platform_device.h>
+#include <mach/gpio.h>
+
+
+
+
+#if 0
+#define VDI_DEBUG_ENABLE_ENTER_LEAVE
+#define VDI_DEBUG
+#endif
+
+#ifdef VDI_DEBUG
+#define VDEBUG(fmt, arg...)     printk(fmt, ##arg)
+#else
+#define VDEBUG(fmt, arg...)
+#endif
+
+#ifdef VDI_DEBUG_ENABLE_ENTER_LEAVE
+#define ENTRY()                 printk("[%-20s] : Enter...\n", __FUNCTION__)
+#define LEAVE()                 printk("[%-20s] : Leave...\n", __FUNCTION__)
+#else
+#define ENTRY()
+#define LEAVE()
+#endif
+
+#include "nuc980_sensor.h"
+
+#define NUVOTON_FORCE_MUNMAP        0
+#define NUVOTON_FRAME_TIMEOUT       2
+
+
+#define VSP_LO      0x000 /* 0 : VS pin output polarity is active low */
+#define VSP_HI      0x400 /* 1 : VS pin output polarity is active high. */
+#define HSP_LO      0x000 /* 0 : HS pin output polarity is active low */
+#define HSP_HI      0x200 /* 1 : HS pin output polarity is active high. */
+#define PCLKP_LO    0x000 /* 0 : Input video data and signals are latched by falling edge of Pixel Clock */
+#define PCLKP_HI    0x100 /* 1 : Input video data and signals are latched by rising edge of Pixel Clock. */
+
+
+#define INFMT_YCbCr  0x0        /*  Sensor Input Data Format YCbCr422 */
+#define INFMT_RGB565 0x1        /*  Sensor Input Data Format RGB565 */
+#define INTYPE_CCIR601 (0x0<<1)     /*  Sensor Input Type CCIR601 */
+#define INTYPE_CCIR656 (0x1<<1)     /*  Sensor Input Type CCIR656 */
+#define INORD_YUYV  (0x0<<2)    /*  Sensor Input Data Order YUYV */
+#define INORD_YVYU  (0x1<<2)    /*  Sensor Input Data Order YVYU */
+#define INORD_UYVY  (0x2<<2)    /*  Sensor Input Data Order UYVY */
+#define INORD_VYUY  (0x3<<2)    /*  Sensor Input Data Order VYUY */
+#define INMASK 0xF              /*  Sensor Input Mask */
+
+#define SENSOR_OV7725       0
+#define SENSOR_NT99141      1
+#define SENSOR_NT99050      2
+#define SENSOR_OV5640       3
+#define SENSOR_TW9912       4
+#define SENSOR_GC0308       5
+
+
+enum nuvoton_vin_frame_state {
+	F_UNUSED,
+	F_QUEUED,
+	F_GRABBING,
+	F_DONE,
+	F_ERROR,
+};
+
+struct nuvoton_vin_frame_t {
+	void* bufmem;
+	u32 pbuf;
+	struct v4l2_buffer buf;
+	enum nuvoton_vin_frame_state state;
+	struct list_head frame;
+	unsigned long vma_use_count;
+};
+
+enum nuvoton_vin_dev_state {
+	DEV_INITIALIZED = 0x01,
+	DEV_DISCONNECTED = 0x02,
+	DEV_MISCONFIGURED = 0x04,
+};
+
+enum nuvoton_vin_io_method {
+	IO_NONE,
+	IO_READ,
+	IO_MMAP,
+};
+
+enum nuvoton_vin_stream_state {
+	STREAM_OFF,
+	STREAM_INTERRUPT,
+	STREAM_ON,
+};
+
+struct nuvoton_vin_module_param {
+	u8 force_munmap;
+	u16 frame_timeout;
+};
+
+struct cap_format {
+	char *desc;
+	u32 pixelformat;
+};
+
+static DECLARE_RWSEM(nuvoton_vin0_dev_lock);
+static DECLARE_RWSEM(nuvoton_vin1_dev_lock);
+
+struct capture_parameter {
+	u32 format;
+	u32 PacketWidth;
+	u32 PacketHeight;
+
+	u32 PlanarWidth;
+	u32 PlanarHeight;
+
+	u8 PacketEnable;
+	u8 PlanarEnable;
+};
+
+struct nuvoton_vin_device {
+	struct video_device* v4ldev;
+	struct v4l2_device v4l2_dev;
+	struct nuvoton_vin_sensor sensor;
+	u8* control_buffer;
+	u32 type;
+	struct nuvoton_vin_frame_t *frame_current, *frame;
+	struct list_head inqueue, outqueue;
+	u32 frame_count, nbuffers, nreadbuffers;
+
+	enum nuvoton_vin_io_method io;
+	enum nuvoton_vin_stream_state stream;
+
+	struct v4l2_jpegcompression compression;
+
+	struct nuvoton_vin_module_param module_param;
+
+	struct kref kref;
+	enum nuvoton_vin_dev_state state;
+	u8 users;
+
+	struct completion probe;
+	struct mutex open_mutex, fileop_mutex;
+	spinlock_t queue_lock;
+	//wait_queue_head_t wait_open;
+	wait_queue_head_t wait_frame, wait_stream;
+
+	struct capture_parameter vpe; /*sensor interface for nuvoton */
+	dma_addr_t *phy_addr;
+	u32** vir_addr;
+	u32 CtlReg;
+};
+
+/*****************************************************************************/
+void nuvoton_vin0_attach_sensor(struct nuvoton_vin_device* cam, struct nuvoton_vin_sensor* sensor);
+void nuvoton_vin1_attach_sensor(struct nuvoton_vin_device* cam, struct nuvoton_vin_sensor* sensor);
+/*****************************************************************************/
+
+void nuvoton_vin0_release_buffers(struct nuvoton_vin_device* cam);
+void nuvoton_vin0_empty_framequeues(struct nuvoton_vin_device* cam);
+void nuvoton_vin0_requeue_outqueue(struct nuvoton_vin_device* cam);
+u32 nuvoton_vin0_request_buffers(struct nuvoton_vin_device* cam, u32 count,enum nuvoton_vin_io_method io);
+int nuvoton_vin0_stream_interrupt(struct nuvoton_vin_device* cam);
+
+
+void nuvoton_vin1_release_buffers(struct nuvoton_vin_device* cam);
+void nuvoton_vin1_empty_framequeues(struct nuvoton_vin_device* cam);
+void nuvoton_vin1_requeue_outqueue(struct nuvoton_vin_device* cam);
+u32 nuvoton_vin1_request_buffers(struct nuvoton_vin_device* cam, u32 count,enum nuvoton_vin_io_method io);
+int nuvoton_vin1_stream_interrupt(struct nuvoton_vin_device* cam);
+
+#endif /*_NUVOTON_V4L2_H*/
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_sensor.h NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_sensor.h
--- linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_sensor.h	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/nuc980_sensor.h	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,48 @@
+#ifndef _NUVOTON_SENSOR_H
+#define _NUVOTON_SENSOR_H
+
+#include <linux/delay.h>
+#include <linux/i2c.h>
+
+struct nuvoton_vin_device;
+struct nuvoton_vin_sensor;
+
+#define NUVOTON_MAX_CTRLS                           (V4L2_CID_LASTP1 - V4L2_CID_BASE + 10)
+#define NUVOTON_V4L2_CID_DAC_MAGNITUDE  (V4L2_CID_PRIVATE_BASE + 0)
+#define NUVOTON_V4L2_CID_GREEN_BALANCE  (V4L2_CID_PRIVATE_BASE + 1)
+
+struct nuvoton_vin_sensor {
+	int i2c_id;
+	char name[32];
+
+#if 0
+	struct v4l2_queryctrl qctrl[NUVOTON_MAX_CTRLS];
+#else
+	struct v4l2_queryctrl qctrl;
+#endif
+
+	struct v4l2_cropcap cropcap;
+	struct v4l2_pix_format pix_format;
+	u32 polarity;
+	u32 infmtord;
+	u32 cropstart;
+	u32 bothenable; /* bothenable(packet and planar are enabled ) is enabled , planarfmt is effective */
+	u32 planarfmt;   /* Planar YUV422: V4L2_PIX_FMT_YUV422P or Planar YUV420 : V4L2_PIX_FMT_YUV411P */
+
+	int (*init)(struct nuvoton_vin_device*);
+	int (*get_ctrl)(struct nuvoton_vin_device*, struct v4l2_control* ctrl);
+	int (*set_ctrl)(struct nuvoton_vin_device*,
+	                const struct v4l2_control* ctrl);
+	int (*set_crop)(struct nuvoton_vin_device*, const struct v4l2_rect* rect);
+
+	/* Private */
+#if 0
+	struct v4l2_queryctrl _qctrl[NUVOTON_MAX_CTRLS];
+#else
+	struct v4l2_queryctrl _qctrl;
+#endif
+
+	struct v4l2_rect _rect;
+};
+
+#endif
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_gc0308.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_gc0308.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_gc0308.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_gc0308.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,470 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap0_gc0308;
+
+struct GC_RegValue {
+	__u8	uRegAddr;
+	__u8	uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName)	sizeof(nTableName)/sizeof(struct GC_RegValue)
+#define __60HZ__
+static struct GC_RegValue RegValue[] = {
+	{0xfe,0x00},
+#ifdef __60HZ__
+	{0x01, 0x6a},	//HB
+	{0x02, 0x0C}, 	//VB
+	{0x0f, 0x00},
+
+	{0xe2, 0x00},
+	{0xe3, 0x7d}, //Flicker Step = 1/120s
+	{0xe4, 0x01},
+	{0xe5, 0xF4},
+	{0xe6, 0x03},
+	{0xe7, 0xe8},
+	{0xe8, 0x05},
+	{0xe9, 0xdc},
+	{0xea, 0x07},
+	{0xeb, 0xd0},
+	{0xec, 0x00}, //fps 30f/s
+#endif
+
+#ifdef __50HZ__
+	{0x01, 0x6a},	//HB
+	{0x02, 0x0C}, 	//VB
+	{0x0f, 0x00},
+
+	{0xe2, 0x00},
+	{0xe3, 0x96}, //Flicker Step = 1/100s
+	{0xe4, 0x01},
+	{0xe5, 0xC2},
+	{0xe6, 0x03},
+	{0xe7, 0x84},
+	{0xe8, 0x05},
+	{0xe9, 0xdc},
+	{0xea, 0x07},
+	{0xeb, 0x9e},
+	{0xec, 0x00}, //fps 30f/s
+#endif
+
+	{0x05, 0x00},	// row_start_high
+	{0x06, 0x00},	// row_start_low
+	{0x07, 0x00},	// col_start_high
+	{0x08, 0x00},	// col_start_low
+	{0x09, 0x01},	//[8]cis_win_height  488
+	{0x0a, 0xe8},	//[7:0]cis_win_height
+	{0x0b, 0x02}	,//[9:8]cis_win_width 648
+	{0x0c, 0x88},	//[7:0]cis_win_width
+	{0x0d, 0x02},	//vs_st
+	{0x0e, 0x02},	//vs_et
+	{0x10, 0x26},	//[7:4]restg_width, [3:0]sh_width
+	{0x11, 0x0d},	//fd//[7:4]tx_width, [3:0]space width,*2
+	{0x12, 0x2a},	//sh_delay
+	{0x13, 0x00},	//[3:0] row_tail_width
+	{0x14, 0x12},	//[7]hsync_always ,[6] NA,  [5:4] CFA sequence
+	// [3:2]NA,  [1]upside_down,  [0] mirror
+	{0x15, 0x0a},	//[7:6]output_mode,,[5:4]restg_mode,[3:2]sdark_mode, [1]new exposure,[0]badframe_en
+	{0x16, 0x05},	//[7:5]NA, [4]capture_ad_data_edge, [3:0]Number of A/D pipe stages
+	{0x17, 0x01},	//[7:6]analog_opa_r,[5]coltest_en, [4]ad_test_enable,
+	//[3]tx_allow,[2]black sun correction,[1:0]black sun control reg
+	{0x18, 0x44},	//[7]NA,  [6:4]column gain ee, [3]NA, [2:0]column gain eo
+	{0x19, 0x44},	//[7]NA,  [6:4]column gain oe, [3]NA, [2:0]column gain oo
+	{0x1a, 0x2a},	//1e//[7]rsv1,[6]rsv0, [5:4]coln_r,
+	//[3:2]colg_r column gain opa bias current, [1]clk_delay, [0] apwd
+	{0x1b, 0x00},	//[7:2]NA, [1:0]BIN4 AND BIN2
+	{0x1c, 0x49},	//c1//[7]hrst_enbale, [6:4]da_rsg, [3]tx high enable, [2]NA, [1:0]da18_r
+	{0x1d, 0x9a},	//08//[7]vref_en, [6:4]da_vef, [3]da25_en, [2]NA, [1:0]da25_r,set da25 voltage
+	{0x1e, 0x61},	//60//[7]LP_MTD,[6:5]opa_r,ADC's operating current,  [4:2]NA, [1:0]sref
+	{0x1f, 0x15},	//[7:6]NA, [5:4]sync_drv, [3:2]data_drv, [1:0]pclk_drv
+
+	{0x20, 0xff},	//[7]bks[6]gamma[5]cc[4]ee[3]intp[2]dn[1]dd[0]lsc
+	{0x21, 0xf8},	//[7]na[6]na[5]skin_ee[4]cbcr_hue_en[3]y_as_en[2]auto_gray_en[1]y_gamma_en[0]na
+	{0x22, 0x57},	//[7]na [6]auto_dndd [5]auto_ee [4]auto_sa [3]na [2]abs [1]awb  [0]na
+	{0x24, 0xa2},	//YCbYcr //a0
+	{0x25, 0x0f},
+	//output sync_mode
+	{0x26, 0x01},	//02
+	{0x2f, 0x01},	//debug mode3
+	//////////////////////////////////////////////////////////////
+	///////////////////// grab     ////////////////////////////////
+	///////////////////////////////////////////////////////////////
+	{0x30, 0xf7},	//blk mode [7]dark current mode:1 use exp rated dark ,0 use ndark row calculated
+	//[1]dark_current_en//[0]offset_en
+	{0x31, 0x50},	//blk_value limit.64 low align to 11bits;8 for 256 range
+	{0x32, 0x00},	//global offset
+	{0x39, 0x04},	// exp_ate_darkc
+	{0x3a, 0x20},	//{7:6}offset submode {5:0}offset ratio
+	{0x3b, 0x20},	//{7:6}darkc submode {5:0}dark current ratio
+	{0x3c, 0x00},	//manual g1 offset
+	{0x3d, 0x00},	//manual r offset
+	{0x3e, 0x00},	//manual b offset
+	{0x3f, 0x00},	//manual g2 offset
+	///////////gain////////
+	{0x50, 0x14},	//10  //global gain
+
+	{0x53, 0x80},	//G
+	{0x54, 0x80},	//R channel gain
+	{0x55, 0x80},	//B channel gain
+	{0x56, 0x80},
+	/////////////////////////////////////////////////////////
+	//////////////// LSC_t    ////////////////////////////////
+	//////////////////////////////////////////////////////////
+	{0x8b, 0x20},	//r2
+	{0x8c, 0x20},	//g2
+	{0x8d, 0x20},	//b2
+	{0x8e, 0x14},	//r4
+	{0x8f, 0x10},	//g4
+	{0x90, 0x14},	//b4
+	{0x91, 0x3c},	//[7]singed4 [6:0]row_cneter
+	{0x92, 0x50},	//col_center
+	{0x5d, 0x12},	//decrease 1
+	{0x5e, 0x1a},	//decrease 2
+	{0x5f, 0x24},	//decrease 3
+	//////////////////////////////////////////////////////////
+	//////////////// DNDD_t    ///////////////////////////////
+	//////////////////////////////////////////////////////////
+	{0x60, 0x07},	//[4]zero weight mode
+	//[3]share mode
+	//[,]c weight mode
+	//[,]lsc decrease mode
+	//[,]b mode
+	{0x61, 0x15},	//[7:6]na
+	//[5:4]c weight adap ratio
+	//[,:2]dn lsc ratio
+	//[,:0]b ratio
+	{0x62, 0x08},	//b base
+	//0x63,0x02}//b increase RO
+	{0x64, 0x03},	//[7:4]n base [3:0]c weight
+	//0x65,  ,//[7:4]n increase [3:0]c coeff
+	{0x66, 0xe8},	//dark_th ,bright_th
+	{0x67, 0x86},	//flat high, flat low
+	{0x68, 0xa2},	//[7:4]dd limit [1:0]dd ratio
+	//////////////////////////////////////////////////////////
+	//////////////// asde_t    ///////////////////////////////
+	//////////////////////////////////////////////////////////
+	{0x69, 0x18},	//gain high th
+	{0x6a, 0x0f},	//[7:4]dn_c slop          //[3]use post_gain [2]use pre_gain [1]use global gain [0]use col gain
+	{0x6b, 0x00},	//[7:4]dn_b slop [3:0]dn_n slop
+	{0x6c, 0x5f},	//[7:4]bright_th start [3:0]bright_th slop
+	{0x6d, 0x8f},	//[7:4]dd_limit_start[3:0]dd_limit slop
+	{0x6e, 0x55},	//[7:4]ee1 effect start [3:0]slope  broad
+	{0x6f, 0x38},	//[7:4]ee2 effect start [3:0]slope  narrow
+	{0x70, 0x15},	//saturation dec slope
+	{0x71, 0x33},	//[7:4]low limit,[3:0]saturation slope
+	/////////////////////////////////////////////////////////
+	/////////////// eeintp_t    ///////////////////////////////
+	/////////////////////////////////////////////////////////
+	{0x72, 0xdc},	//[7]edge_add_mode [6]new edge mode [5]edge2_mode [4]HP_mode
+	//[3]lp intp en [2]lp edge en [1:0]lp edge mode
+
+	{0x73, 0x80},	//[7]edge_add_mode2 [6]NA [5]only 2direction [4]fixed direction th
+	//[3]only defect map [2]intp_map dir [1]HP_acc [0]only edge map
+	//////for high resolution in light scene
+	{0x74, 0x02},	//direction th1
+	{0x75, 0x3f},	//direction th2
+	{0x76, 0x02},	//direction diff th      h>v+diff ; h>th1 ; v<th2
+	{0x77, 0x36},	//[7:4]edge1_effect [3:0]edge2_effect
+	{0x78, 0x88},	//[7:4]edge_pos_ratio  [3:0]edge neg ratio
+	{0x79, 0x81},	//edge1_max,edge1_min
+	{0x7a, 0x81},	//edge2_max,edge2_min
+	{0x7b, 0x22},	//edge1_th,edge2_th
+	{0x7c, 0xff},	//pos_edge_max,neg_edge_max
+	//////for high resolution in light scene
+	///cct
+	{0x93, 0x48},	// <--40
+	{0x94, 0x02},
+	{0x95, 0x07},
+	{0x96, 0xe0},
+	{0x97, 0x40},
+	{0x98, 0xf0},
+	//ycpt
+	{0xb1, 0x40},	//manual cb
+	{0xb2, 0x40},	//manual cr
+	{0xb3, 0x40},
+	{0xb6, 0xe0},
+	{0xbd, 0x38},
+	{0xbe, 0x36},	// [5:4]gray mode 00:4&8  01:4&12 10:4&20  11:8$16   [3:0] auto_gray
+
+	////AECT
+	{0xd0, 0xcb},	// exp is gc mode
+	{0xd1, 0x10},	//every N
+	{0xd2, 0x90},	// 7 aec enable 5 clore y mode 4skin weight 3 weight drop mode
+	{0xd3, 0x48},	//Y_target and low pixel thd high X4 low X2
+	{0xd5, 0xf2},	//lhig
+	{0xd6, 0x16},	// ignore mode
+	{0xdb, 0x92},
+	{0xdc, 0xa5},	//fast_margin  fast_ratio
+	{0xdf, 0x23},	// I_fram D_ratio
+
+	{0xd9, 0x00},	// colore offset in CAL ,now is too dark so set zero
+	{0xda, 0x00},	// GB offset
+	{0xe0, 0x09},
+
+	{0xed, 0x04},	//minimum exposure low 8  bits
+	{0xee, 0xa0},	//max_post_dg_gain
+	{0xef, 0x40},	//max_pre_dg_gain
+	{0x80, 0x03},
+	////abbt
+	{0x80, 0x03},
+	////RGBgama_m5
+	{0x9F, 0x10},
+	{0xA0, 0x20},
+	{0xA1, 0x38},
+	{0xA2, 0x4E},
+	{0xA3, 0x63},
+	{0xA4, 0x76},
+	{0xA5, 0x87},
+	{0xA6, 0xA2},
+	{0xA7, 0xB8},
+	{0xA8, 0xCA},
+	{0xA9, 0xD8},
+	{0xAA, 0xE3},
+	{0xAB, 0xEB},
+	{0xAC, 0xF0},
+	{0xAD, 0xF8},
+	{0xAE, 0xFD},
+	{0xAF, 0xFF},
+	///wint
+	///Y_gamma
+	{0xc0, 0x00},	//Y_gamma_0
+	{0xc1, 0x10},	//Y_gamma_1
+	{0xc2, 0x1C},	//Y_gamma_2
+	{0xc3, 0x30},	//Y_gamma_3
+	{0xc4, 0x43},	//Y_gamma_4
+	{0xc5, 0x54},	//Y_gamma_5
+	{0xc6, 0x65},	//Y_gamma_6
+	{0xc7, 0x75},	//Y_gamma_7
+	{0xc8, 0x93},	//Y_gamma_8
+	{0xc9, 0xB0},	//Y_gamma_9
+	{0xca, 0xCB},	//Y_gamma_10
+	{0xcb, 0xE6},	//Y_gamma_11
+	{0xcc, 0xFF},	//Y_gamma_12
+	/////ABS
+	{0xf0, 0x02},
+	{0xf1, 0x01},
+	{0xf2, 0x02},//manual stretch K
+	{0xf3, 0x30},//the limit of Y_stretch
+	{0xf7, 0x12},
+	{0xf8, 0x0a},
+	{0xf9, 0x9f},
+	{0xfa, 0x78},
+
+	////AWB
+	{0xfe, 0x01},
+	{0x00, 0xf5},	//high_low limit
+	{0x02, 0x20},	//y2c
+	{0x04, 0x10},
+	{0x05, 0x08},
+	{0x06, 0x20},
+	{0x08, 0x0a},
+	{0x0a, 0xa0},	// number limit
+	{0x0b, 0x60},	// skip_mode
+	{0x0c, 0x08},
+	{0x0e, 0x44},	// width step
+	{0x0f, 0x32},	// height step
+	{0x10, 0x41},
+	{0x11, 0x37},	// 0x3f
+	{0x12, 0x22},
+	{0x13, 0x19},	//13//smooth 2
+	{0x14, 0x44},	//R_5k_gain_base
+	{0x15, 0x44},	//B_5k_gain_base
+	{0x16, 0xc2},	//c2//sinT
+	{0x17, 0xa8},	//ac//a8//a8//a8//cosT
+	{0x18, 0x18},	//X1 thd
+	{0x19, 0x50},	//X2 thd
+	{0x1a, 0xd8},	//e4//d0//Y1 thd
+	{0x1b, 0xf5},	//Y2 thd
+	{0x70, 0x40},	// A R2G low
+	{0x71, 0x58},	// A R2G high
+	{0x72, 0x30},	// A B2G low
+	{0x73, 0x48},	// A B2G high
+	{0x74, 0x20},	// A G low
+	{0x75, 0x60},	// A G high
+	{0x77, 0x20},
+	{0x78, 0x32},
+
+	///hsp
+	{0x30, 0x03},	//[1]HSP_en [0]sa_curve_en
+	{0x31, 0x40},
+	{0x32, 0x10},
+	{0x33, 0xe0},
+	{0x34, 0xe0},
+	{0x35, 0x00},
+	{0x36, 0x80},
+	{0x37, 0x00},
+	{0x38, 0x04},	//sat1, at8
+	{0x39, 0x09},
+	{0x3a, 0x12},
+	{0x3b, 0x1C},
+	{0x3c, 0x28},
+	{0x3d, 0x31},
+	{0x3e, 0x44},
+	{0x3f, 0x57},
+	{0x40, 0x6C},
+	{0x41, 0x81},
+	{0x42, 0x94},
+	{0x43, 0xA7},
+	{0x44, 0xB8},
+	{0x45, 0xD6},
+	{0x46, 0xEE},	//sat15,at224
+	{0x47, 0x0d},	//blue_edge_dec_ratio
+	///out
+	{0xfe, 0x00},
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client0;
+static char sensor0_inited = 0;
+#ifndef DISALBE_READ_ID
+__u8 sensor0_read_gc0308(__u8 uRegAddr)
+{
+	u8 val;
+	//printk("sensor_read_gc0308 i2c_smbus_read_byte uRegAddr=0x%x\n",uRegAddr);
+	i2c_smbus_write_byte(save_client0, uRegAddr);
+	//printk("sensor_read_gc0308 i2c_smbus_write_byte\n");
+	val = i2c_smbus_read_byte(save_client0);
+	return val;
+}
+#endif
+
+static int32_t sensor0_write_gc0308(__u8 uRegAddr, __u8 uData)
+{
+	int ret;
+	ret=i2c_smbus_write_byte_data(save_client0, uRegAddr, uData);
+	return ret;
+}
+
+static int sensor0_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap0_gc0308.i2c_id || client->addr != 0x21)
+		return -ENODEV;
+	sensor0_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client0 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor0_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap0_gc0308_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap0_gc0308 = {
+	.i2c_id = 2,
+	.name = "cap0_gc0308",
+	.init = &cap0_gc0308_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_LO | HSP_HI | PCLKP_HI),
+	.cropstart = ( 0 | 2<<16 ),	/*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format	 = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin0_probe_gc0308(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[1];
+#endif
+	struct GC_RegValue *psRegValue;
+	ENTRY();
+	nuvoton_vin0_attach_sensor(cam, &cap0_gc0308);
+
+	// if i2c module isn't loaded at this time
+	if(!sensor0_inited)
+		return -1;
+
+	psRegValue=RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor0_write_gc0308((psRegValue->uRegAddr), (psRegValue->uValue));
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+		}
+	}
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	SensorID[0]=sensor0_read_gc0308(0x00);  /* PID 0x77 */
+	printk("Sensor PID = 0x%02x(0x9B)\n", SensorID[0]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+static const struct i2c_device_id sensor0_id[] = {
+	{ "cap0_gc0308", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor0_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap0_gc0308_match_table[] = {
+	{ .compatible = "nuvoton,cap0-gc0308",},
+	{},
+};
+#else
+#define cap0_gc0308_match_table NULL
+#endif
+
+
+static struct i2c_driver sensor0_i2c_driver = {
+	.driver = {
+		.name  = "cap0_gc0308",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap0_gc0308_match_table),
+	},
+	.probe    = sensor0_probe,
+	.remove   = sensor0_remove,
+	.id_table = sensor0_id,
+};
+module_i2c_driver(sensor0_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_nt99050.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_nt99050.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_nt99050.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_nt99050.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,239 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap0_nt99050;
+
+struct OV_RegValue {
+	__u16   uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct OV_RegValue)
+/* NT99141, VGA, YUV422 */
+static struct OV_RegValue Init_RegValue[] = {
+	//[InitialSetting]
+	{0x3021, 0x01},
+#if 0 /* BT656 */
+	{0x32F0, 0x61},{0x32F1, 0x10},
+#else
+	{0x32F0, 0x01},
+#endif
+	{0x3024, 0x00}, {0x3270, 0x00}, //[Gamma_MDR]
+	{0x3271, 0x0D}, {0x3272, 0x19}, {0x3273, 0x2A}, {0x3274, 0x3C}, {0x3275, 0x4D},
+	{0x3276, 0x67}, {0x3277, 0x81}, {0x3278, 0x98}, {0x3279, 0xAD}, {0x327A, 0xCE},
+	{0x327B, 0xE0}, {0x327C, 0xED}, {0x327D, 0xFF}, {0x327E, 0xFF}, {0x3060, 0x01},
+	{0x3210, 0x04}, //LSC //D
+	{0x3211, 0x04}, //F
+	{0x3212, 0x04}, //D
+	{0x3213, 0x04}, //D
+	{0x3214, 0x04}, {0x3215, 0x05}, {0x3216, 0x04}, {0x3217, 0x04}, {0x321C, 0x04},
+	{0x321D, 0x05}, {0x321E, 0x04}, {0x321F, 0x03}, {0x3220, 0x00}, {0x3221, 0xA0},
+	{0x3222, 0x00}, {0x3223, 0xA0}, {0x3224, 0x00}, {0x3225, 0xA0}, {0x3226, 0x80},
+	{0x3227, 0x88}, {0x3228, 0x88}, {0x3229, 0x30}, {0x322A, 0xCF}, {0x322B, 0x07},
+	{0x322C, 0x04}, {0x322D, 0x02}, {0x3302, 0x00},//[CC: Saturation:100%]
+	{0x3303, 0x1C}, {0x3304, 0x00}, {0x3305, 0xC8}, {0x3306, 0x00}, {0x3307, 0x1C},
+	{0x3308, 0x07}, {0x3309, 0xE9}, {0x330A, 0x06}, {0x330B, 0xDF}, {0x330C, 0x01},
+	{0x330D, 0x38}, {0x330E, 0x00}, {0x330F, 0xC6}, {0x3310, 0x07}, {0x3311, 0x3F},
+	{0x3312, 0x07}, {0x3313, 0xFC}, {0x3257, 0x50}, //CA Setting
+	{0x3258, 0x10}, {0x3251, 0x01}, {0x3252, 0x50}, {0x3253, 0x9A}, {0x3254, 0x00},
+	{0x3255, 0xd8}, {0x3256, 0x60}, {0x32C4, 0x38}, {0x32F6, 0xCF}, {0x3363, 0x37},
+	{0x3331, 0x08}, {0x3332, 0x6C}, // 60
+	{0x3360, 0x10}, {0x3361, 0x30}, {0x3362, 0x70}, {0x3367, 0x40}, {0x3368, 0x32}, //20
+	{0x3369, 0x24}, //1D
+	{0x336A, 0x1A}, {0x336B, 0x20}, {0x336E, 0x1A}, {0x336F, 0x16}, {0x3370, 0x0c},
+	{0x3371, 0x12}, {0x3372, 0x1d}, {0x3373, 0x24}, {0x3374, 0x30}, {0x3375, 0x0A},
+	{0x3376, 0x18}, {0x3377, 0x20}, {0x3378, 0x30}, {0x3340, 0x1C}, {0x3326, 0x03}, //Eext_DIV
+	{0x3200, 0x3E}, //1E
+	{0x3201, 0x3F}, {0x3109, 0x82}, //LDO Open
+	{0x3106, 0x07}, {0x303F, 0x02}, {0x3040, 0xFF}, {0x3041, 0x01}, {0x3051, 0xE0},
+	{0x3060, 0x01},
+
+	{0x32BF, 0x04}, {0x32C0, 0x6A}, {0x32C1, 0x6A}, {0x32C2, 0x6A}, {0x32C3, 0x00},
+	{0x32C4, 0x20}, {0x32C5, 0x20}, {0x32C6, 0x20}, {0x32C7, 0x00}, {0x32C8, 0x95},
+	{0x32C9, 0x6A}, {0x32CA, 0x8A}, {0x32CB, 0x8A}, {0x32CC, 0x8A}, {0x32CD, 0x8A},
+	{0x32D0, 0x01}, {0x3200, 0x3E}, {0x3201, 0x0F}, {0x302A, 0x00}, {0x302B, 0x09},
+	{0x302C, 0x00}, {0x302D, 0x04}, {0x3022, 0x24}, {0x3023, 0x24}, {0x3002, 0x00},
+	{0x3003, 0x00}, {0x3004, 0x00}, {0x3005, 0x00}, {0x3006, 0x02}, {0x3007, 0x83},
+	{0x3008, 0x01}, {0x3009, 0xE3},
+
+	{0x300A, 0x03}, {0x300B, 0x28}, {0x300C, 0x01}, {0x300D, 0xF4},
+
+	{0x300E, 0x02}, {0x300F, 0x84}, {0x3010, 0x01}, {0x3011, 0xE4}, {0x32B8, 0x3B},
+	{0x32B9, 0x2D}, {0x32BB, 0x87}, {0x32BC, 0x34}, {0x32BD, 0x38}, {0x32BE, 0x30},
+	{0x3201, 0x3F}, {0x320A, 0x01}, {0x3021, 0x06}, {0x3060, 0x01},
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client0;
+static char sensor0_inited = 0;
+#ifndef DISALBE_READ_ID
+static int sensor0_read_nt99050(u16 reg,u8 *val)
+{
+	int ret;
+	/* We have 16-bit i2c addresses - care for endianess */
+	unsigned char data[2] = { reg >> 8, reg & 0xff };
+
+	ret = i2c_master_send(save_client0, data, 2);
+	if (ret < 2) {
+		dev_err(&save_client0->dev, "%s: i2c read error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	ret = i2c_master_recv(save_client0, val, 1);
+	if (ret < 1) {
+		dev_err(&save_client0->dev, "%s: i2c read error, reg: 0x%x\n",__func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+	return 0;
+}
+#endif
+static int sensor0_write_nt99050(u16 reg, u8 val)
+{
+	int ret;
+	unsigned char data[3] = { reg >> 8, reg & 0xff, val };
+
+	ret = i2c_master_send(save_client0, data, 3);
+	if (ret < 3) {
+		dev_err(&save_client0->dev, "%s: i2c write error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	return 0;
+}
+
+static int sensor0_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap0_nt99050.i2c_id || client->addr != 0x21)
+		return -ENODEV;
+	sensor0_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client0 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor0_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap0_nt99050_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap0_nt99050 = {
+	.i2c_id = 2,
+	.name = "cap0_nt99050",
+	.init = &cap0_nt99050_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_LO | HSP_LO | PCLKP_HI),
+	.cropstart = ( 0 | 0<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin0_probe_nt99050(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[2];
+#endif
+	struct OV_RegValue *psRegValue;
+	ENTRY();
+
+	nuvoton_vin0_attach_sensor(cam, &cap0_nt99050);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor0_inited)
+		return -1;
+
+	psRegValue=Init_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Init_RegValue); i++, psRegValue++) {
+		printk(".");
+		ret = sensor0_write_nt99050((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+	}
+
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	sensor0_read_nt99050(0x3000,&SensorID[0]);  /* Chip_Version_H 0x14 */
+	sensor0_read_nt99050(0x3001,&SensorID[1]);  /* Chip_Version_L 0x10 */
+	printk("\nSensor Chip_Version_H = 0x%02x(0x05) Chip_Version_L = 0x%02x(0x00)\n", SensorID[0],SensorID[1]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+static const struct i2c_device_id sensor0_id[] = {
+	{ "cap0_nt99050", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor0_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap0_nt99050_match_table[] = {
+	{ .compatible = "nuvoton,cap0-nt99050",},
+	{},
+};
+#else
+#define cap0_nt99050_match_table NULL
+#endif
+
+
+static struct i2c_driver sensor0_i2c_driver = {
+	.driver = {
+		.name  = "cap0_nt99050",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap0_nt99050_match_table),
+	},
+	.probe    = sensor0_probe,
+	.remove   = sensor0_remove,
+	.id_table = sensor0_id,
+};
+module_i2c_driver(sensor0_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_nt99141.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_nt99141.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_nt99141.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_nt99141.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,241 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap0_nt99141;
+
+struct OV_RegValue {
+	__u16   uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct OV_RegValue)
+/* NT99141, VGA, YUV422 */
+static struct OV_RegValue Init_RegValue[] = {
+	//{0x3021, 0x60},
+#if 1
+	/* [Inti] */
+	{0x3109, 0x04},{0x3040, 0x04},{0x3041, 0x02},{0x3042, 0xFF},{0x3043, 0x08},
+	{0x3052, 0xE0},{0x305F, 0x33},{0x3100, 0x07},{0x3106, 0x03},
+	{0x3108, 0x00},{0x3110, 0x22},{0x3111, 0x57},{0x3112, 0x22},{0x3113, 0x55},
+	{0x3114, 0x05},{0x3135, 0x00},{0x32F0, 0x01},{0x306a,0x01},
+	// Initial AWB Gain */
+	{0x3290, 0x01},{0x3291, 0x80},{0x3296, 0x01},{0x3297, 0x73},
+	/* CA Ratio */
+	{0x3250, 0x80},{0x3251, 0x03},{0x3252, 0xFF},{0x3253, 0x00},{0x3254, 0x03},
+	{0x3255, 0xFF},{0x3256, 0x00},{0x3257, 0x50},
+	/* Gamma */
+	{0x3270, 0x00},{0x3271, 0x0C},{0x3272, 0x18},{0x3273, 0x32},{0x3274, 0x44},
+	{0x3275, 0x54},{0x3276, 0x70},{0x3277, 0x88},{0x3278, 0x9D},{0x3279, 0xB0},
+	{0x327A, 0xCF},{0x327B, 0xE2},{0x327C, 0xEF},{0x327D, 0xF7},{0x327E, 0xFF},
+	/* Color Correction */
+	{0x3302, 0x00},{0x3303, 0x40},{0x3304, 0x00},{0x3305, 0x96},{0x3306, 0x00},
+	{0x3307, 0x29},{0x3308, 0x07},{0x3309, 0xBA},{0x330A, 0x06},{0x330B, 0xF5},
+	{0x330C, 0x01},{0x330D, 0x51},{0x330E, 0x01},{0x330F, 0x30},{0x3310, 0x07},
+	{0x3311, 0x16},{0x3312, 0x07},{0x3313, 0xBA},
+	/* EExt */
+	{0x3326, 0x02},{0x32F6, 0x0F},{0x32F9, 0x42},{0x32FA, 0x24},{0x3325, 0x4A},
+	{0x3330, 0x00},{0x3331, 0x0A},{0x3332, 0xFF},{0x3338, 0x30},{0x3339, 0x84},
+	{0x333A, 0x48},{0x333F, 0x07},
+	/* Auto Function */
+	{0x3360, 0x10},{0x3361, 0x18},{0x3362, 0x1f},{0x3363, 0x37},{0x3364, 0x80},
+	{0x3365, 0x80},{0x3366, 0x68},{0x3367, 0x60},{0x3368, 0x30},{0x3369, 0x28},
+	{0x336A, 0x20},{0x336B, 0x10},{0x336C, 0x00},{0x336D, 0x20},{0x336E, 0x1C},
+	{0x336F, 0x18},{0x3370, 0x10},{0x3371, 0x38},{0x3372, 0x3C},{0x3373, 0x3F},
+	{0x3374, 0x3F},{0x338A, 0x34},{0x338B, 0x7F},{0x338C, 0x10},{0x338D, 0x23},
+	{0x338E, 0x7F},{0x338F, 0x14},{0x3375, 0x0A},{0x3376, 0x0C},{0x3377, 0x10},
+	{0x3378, 0x14},
+	{0x3012, 0x02},{0x3013, 0xD0},{0x3060, 0x01},
+#endif
+	/* [YUYV_640x480_25_Fps]---MCLK:12M hz PCLK:24M hz */
+	{0x32BF, 0x60},{0x32C0, 0x60},{0x32C1, 0x60},{0x32C2, 0x60},{0x32C3, 0x00},
+	{0x32C4, 0x20},{0x32C5, 0x20},{0x32C6, 0x20},{0x32C7, 0x00},{0x32C8, 0xB3},
+	{0x32C9, 0x60},{0x32CA, 0x80},{0x32CB, 0x80},{0x32CC, 0x80},{0x32CD, 0x80},
+	{0x32DB, 0x76},{0x32E0, 0x02},{0x32E1, 0x80},{0x32E2, 0x01},{0x32E3, 0xE0},
+	{0x32E4, 0x00},{0x32E5, 0x80},{0x32E6, 0x00},{0x32E7, 0x80},{0x3200, 0x3E},
+	{0x3201, 0x0F},{0x3028, 0x07},{0x3029, 0x00},{0x302A, 0x14},{0x3022, 0x25},
+	{0x3023, 0x24},{0x3002, 0x00},{0x3003, 0xA4},{0x3004, 0x00},{0x3005, 0x04},
+	{0x3006, 0x04},{0x3007, 0x63},{0x3008, 0x02},{0x3009, 0xD3},{0x300A, 0x05},
+	{0x300B, 0x3C},{0x300C, 0x02},{0x300D, 0xE1},{0x300E, 0x03},{0x300F, 0xC0},
+	{0x3010, 0x02},{0x3011, 0xD0},{0x32B8, 0x3F},{0x32B9, 0x31},{0x32BB, 0x87},
+	{0x32BC, 0x38},{0x32BD, 0x3C},{0x32BE, 0x34},{0x3201, 0x7F},{0x3021, 0x06},
+	{0x3060, 0x01},//{0x302A, 0x04},{0x3021, 0x00},{0x3021, 0x66},
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client0;
+static char sensor0_inited = 0;
+#ifndef DISALBE_READ_ID
+static int sensor0_read_nt99141(u16 reg,u8 *val)
+{
+	int ret;
+	/* We have 16-bit i2c addresses - care for endianess */
+	unsigned char data[2] = { reg >> 8, reg & 0xff };
+
+	ret = i2c_master_send(save_client0, data, 2);
+	if (ret < 2) {
+		dev_err(&save_client0->dev, "%s: i2c read error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	ret = i2c_master_recv(save_client0, val, 1);
+	if (ret < 1) {
+		dev_err(&save_client0->dev, "%s: i2c read error, reg: 0x%x\n",__func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+	return 0;
+}
+#endif
+static int sensor0_write_nt99141(u16 reg, u8 val)
+{
+	int ret;
+	unsigned char data[3] = { reg >> 8, reg & 0xff, val };
+
+	ret = i2c_master_send(save_client0, data, 3);
+	if (ret < 3) {
+		dev_err(&save_client0->dev, "%s: i2c write error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	return 0;
+}
+
+static int sensor0_probe(struct i2c_client *client,const struct i2c_device_id *id)
+{
+	ENTRY();
+	printk("============>sensor0 id=%d, addr %x\n",i2c_adapter_id(client->adapter),client->addr);
+	if(i2c_adapter_id(client->adapter) != cap0_nt99141.i2c_id || client->addr != 0x2a)
+		return -ENODEV;
+	sensor0_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client0 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor0_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap0_nt99141_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap0_nt99141 = {
+	.i2c_id = 2,
+	.name = "cap0_nt99141",
+	.init = &cap0_nt99141_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_LO | HSP_LO | PCLKP_HI),
+	.cropstart = ( 0 | 0<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin0_probe_nt99141(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[2];
+#endif
+	struct OV_RegValue *psRegValue;
+
+	ENTRY();
+
+
+	nuvoton_vin0_attach_sensor(cam, &cap0_nt99141);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor0_inited)
+		return -1;
+
+	psRegValue=Init_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Init_RegValue); i++, psRegValue++) {
+		printk(".");
+		ret = sensor0_write_nt99141((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+	}
+
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	sensor0_read_nt99141(0x3000,&SensorID[0]);  /* Chip_Version_H 0x14 */
+	sensor0_read_nt99141(0x3001,&SensorID[1]);  /* Chip_Version_L 0x10 */
+	printk("\nSensor Chip_Version_H = 0x%02x(0x14) Chip_Version_L = 0x%02x(0x10)\n", SensorID[0],SensorID[1]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+static const struct i2c_device_id sensor0_id[] = {
+	{ "cap0_nt99141", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor0_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap0_nt99141_match_table[] = {
+	{ .compatible = "nuvoton,cap0-nt99141",},
+	{},
+};
+#else
+#define cap0_nt99141_match_table NULL
+#endif
+
+
+static struct i2c_driver sensor0_i2c_driver = {
+	.driver = {
+		.name = "cap0_nt99141",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap0_nt99141_match_table),
+	},
+	.probe    = sensor0_probe,
+	.remove   = sensor0_remove,
+	.id_table = sensor0_id,
+};
+module_i2c_driver(sensor0_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_ov5640.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_ov5640.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_ov5640.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_ov5640.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,315 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap0_ov5640;
+
+struct OV_RegValue {
+	__u16   uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct OV_RegValue)
+
+static struct OV_RegValue Init_RegValue[] = {
+	{0x3103, 0x11},{0x3008, 0x82},{0x3008, 0x42},{0x3103, 0x03},{0x3017, 0xff},
+	{0x3018, 0xff},{0x3034, 0x1a},{0x3035, 0x11},{0x3036, 0x46},
+	{0x3037, 0x03},  //PLL div=1,2,3,4,6,8
+	{0x3108, 0x01},{0x3630, 0x2e},{0x3632, 0xe2},{0x3633, 0x23},{0x3621, 0xe0},
+	{0x3704, 0xa0},{0x3703, 0x5a},{0x3715, 0x78},{0x3717, 0x01},{0x370b, 0x60},
+	{0x3705, 0x1a},{0x3905, 0x02},{0x3906, 0x10},{0x3901, 0x0a},{0x3731, 0x12},
+	{0x3600, 0x08},{0x3601, 0x33},{0x302d, 0x60},{0x3620, 0x52},{0x371b, 0x20},
+	{0x471c, 0x50},{0x3a18, 0x00},{0x3a19, 0xf8},{0x3635, 0x1c},{0x3634, 0x40},
+	{0x3622, 0x01},{0x3c01, 0x34},{0x3c04, 0x28},{0x3c05, 0x98},{0x3c06, 0x00},
+	{0x3c07, 0x08},{0x3c08, 0x00},{0x3c09, 0x1c},{0x3c0a, 0x9c},{0x3c0b, 0x40},
+	{0x3820, 0x41},{0x3821, 0x07},{0x3814, 0x31},{0x3815, 0x31},{0x3800, 0x00},
+	{0x3801, 0x00},{0x3802, 0x00},{0x3803, 0x04},{0x3804, 0x0a},{0x3805, 0x3f},
+	{0x3806, 0x07},{0x3807, 0x9b},{0x3808, 0x02}, // width
+	{0x3809, 0x80},{0x380a, 0x01}, // height
+	{0x380b, 0xe0},{0x380c, 0x07},{0x380d, 0x68},{0x380e, 0x03},{0x380f, 0xd8},
+	{0x3810, 0x00},{0x3811, 0x10},{0x3812, 0x00},{0x3813, 0x06},{0x3618, 0x00},
+	{0x3612, 0x29},{0x3708, 0x62},{0x3709, 0x52},{0x370c, 0x03},{0x3a02, 0x03},
+	{0x3a03, 0xd8},{0x3a08, 0x01},{0x3a09, 0x27},{0x3a0a, 0x00},{0x3a0b, 0xf6},
+	{0x3a0e, 0x03},{0x3a0d, 0x04},{0x3a14, 0x03},{0x3a15, 0xd8},{0x4001, 0x02},
+	{0x4004, 0x02},{0x3000, 0x00},{0x3002, 0x1c},{0x3004, 0xff},{0x3006, 0xc3},
+	{0x300e, 0x58},{0x302e, 0x00},{0x4300, 0x30},{0x501f, 0x00},{0x4713, 0x03},
+	{0x4407, 0x04},{0x460b, 0x35},{0x460c, 0x22},{0x3824, 0x02},{0x5000, 0xa7},
+	{0x5001, 0xa3},{0x5180, 0xff},{0x5181, 0xf2},{0x5182, 0x00},{0x5183, 0x14},
+	{0x5184, 0x25},{0x5185, 0x24},{0x5186, 0x09},{0x5187, 0x09},{0x5188, 0x09},
+	{0x5189, 0x75},{0x518a, 0x54},{0x518b, 0xe0},{0x518c, 0xb2},{0x518d, 0x42},
+	{0x518e, 0x3d},{0x518f, 0x56},{0x5190, 0x46},{0x5191, 0xf8},{0x5192, 0x04},
+	{0x5193, 0x70},{0x5194, 0xf0},{0x5195, 0xf0},{0x5196, 0x03},{0x5197, 0x01},
+	{0x5198, 0x04},{0x5199, 0x12},{0x519a, 0x04},{0x519b, 0x00},{0x519c, 0x06},
+	{0x519d, 0x82},{0x519e, 0x38},{0x5381, 0x1c},{0x5382, 0x5a},{0x5383, 0x06},
+	{0x5384, 0x0a},{0x5385, 0x7e},{0x5386, 0x88},{0x5387, 0x7c},{0x5388, 0x6c},
+	{0x5389, 0x10},{0x538a, 0x01},{0x538b, 0x98},{0x5300, 0x08},{0x5301, 0x30},
+	{0x5302, 0x10},{0x5303, 0x00},{0x5304, 0x08},{0x5305, 0x30},{0x5306, 0x08},
+	{0x5307, 0x16},{0x5309, 0x08},{0x530a, 0x30},{0x530b, 0x04},{0x530c, 0x06},
+	{0x5480, 0x01},{0x5481, 0x08},{0x5482, 0x14},{0x5483, 0x28},{0x5484, 0x51},
+	{0x5485, 0x65},{0x5486, 0x71},{0x5487, 0x7d},{0x5488, 0x87},{0x5489, 0x91},
+	{0x548a, 0x9a},{0x548b, 0xaa},{0x548c, 0xb8},{0x548d, 0xcd},{0x548e, 0xdd},
+	{0x548f, 0xea},{0x5490, 0x1d},{0x5580, 0x02},{0x5583, 0x40},{0x5584, 0x10},
+	{0x5589, 0x10},{0x558a, 0x00},{0x558b, 0xf8},{0x5800, 0x23},{0x5801, 0x15},
+	{0x5802, 0x10},{0x5803, 0x10},{0x5804, 0x15},{0x5805, 0x23},{0x5806, 0x0c},
+	{0x5807, 0x08},{0x5808, 0x05},{0x5809, 0x05},{0x580a, 0x08},{0x580b, 0x0c},
+	{0x580c, 0x07},{0x580d, 0x03},{0x580e, 0x00},{0x580f, 0x00},{0x5810, 0x03},
+	{0x5811, 0x07},{0x5812, 0x07},{0x5813, 0x03},{0x5814, 0x00},{0x5815, 0x00},
+	{0x5816, 0x03},{0x5817, 0x07},{0x5818, 0x0b},{0x5819, 0x08},{0x581a, 0x05},
+	{0x581b, 0x05},{0x581c, 0x07},{0x581d, 0x0b},{0x581e, 0x2a},{0x581f, 0x16},
+	{0x5820, 0x11},{0x5821, 0x11},{0x5822, 0x15},{0x5823, 0x29},{0x5824, 0xbf},
+	{0x5825, 0xaf},{0x5826, 0x9f},{0x5827, 0xaf},{0x5828, 0xdf},{0x5829, 0x6f},
+	{0x582a, 0x8e},{0x582b, 0xab},{0x582c, 0x9e},{0x582d, 0x7f},{0x582e, 0x4f},
+	{0x582f, 0x89},{0x5830, 0x86},{0x5831, 0x98},{0x5832, 0x6f},{0x5833, 0x4f},
+	{0x5834, 0x6e},{0x5835, 0x7b},{0x5836, 0x7e},{0x5837, 0x6f},{0x5838, 0xde},
+	{0x5839, 0xbf},{0x583a, 0x9f},{0x583b, 0xbf},{0x583c, 0xec},{0x5025, 0x00},
+	{0x3a0f, 0x30},{0x3a10, 0x28},{0x3a1b, 0x30},{0x3a1e, 0x26},{0x3a11, 0x60},
+	{0x3a1f, 0x14},{0x3008, 0x02},
+};
+
+static struct OV_RegValue VGA_RegValue[] = {
+	{0x3035, 0x11},{0x3036, 0x69},{0x3C07, 0x07},{0x3820, 0x41},{0x3821, 0x07},
+	{0x3814, 0x31},{0x3815, 0x31},{0x3800, 0x00},{0x3801, 0x00},{0x3802, 0x00},
+	{0x3803, 0x00},{0x3804, 0x0a},{0x3805, 0x3f},{0x3806, 0x07},{0x3807, 0x9f},
+	{0x3808, 0x02}, // width
+	{0x3809, 0x80},
+	{0x380A, 0x01}, // height
+	{0x380B, 0xE1},{0x380C, 0x0B},{0x380D, 0x1C},{0x380E, 0x07},{0x380F, 0x9F},
+	{0x3810, 0x00},{0x3811, 0x10},{0x3812, 0x00},{0x3813, 0x06},{0x3618, 0x00},
+	{0x3612, 0x29},{0x3708, 0x64}, //{0x3708, 0x62},
+	{0x3709, 0x52},{0x370C, 0x03},
+	{0x3A02, 0x03}, //{0x3A02, 0x02},
+	{0x3A03, 0xd8}, //{0x3A03, 0xe4},
+	{0x3A0E, 0x01},
+	{0x3A0D, 0x04}, //{0x3A0D, 0x02},
+	{0x3A14, 0x03}, //{0x3A14, 0x02},
+	{0x3A15, 0xd8}, //{0x3A15, 0xe4},
+	{0x4004, 0x02},
+	{0x4713, 0x03}, //{0x4713, 0x02},
+	{0x4407, 0x04},
+	{0x460B, 0x35}, //{0x460B, 0x37},
+	{0x460C, 0x22}, //{0x460C, 0x20},
+	{0x3824, 0x02}, //{0x3824, 0x04},
+	{0x5001, 0xa3},{0x5180, 0xff},{0x5181, 0xf2},{0x5182, 0x00},{0x5183, 0x14},
+	{0x5184, 0x25},{0x5185, 0x24},{0x5186, 0x09},{0x5187, 0x09},{0x5188, 0x09},
+	{0x5189, 0x75},{0x518a ,0x54},{0x518b, 0xe0},{0x518c, 0xb2},{0x518d, 0x42},
+	{0x518e, 0x3d},{0x518f, 0x56},{0x3008, 0x02},{0x3035, 0x31},{0x3821, 0x07},
+	{0x3002, 0x1c},{0x3006, 0xc3},{0x4713, 0x02},{0x4407, 0x04},{0x460b, 0x37},
+	{0x460c, 0x20},{0x3824, 0x04},{0x4003, 0x08},
+	// Gamma
+	{0x5481, 0x0F},{0x5482, 0x1E},{0x5483, 0x3A},{0x5484, 0x62},{0x5485, 0x74},
+	{0x5486, 0x82},{0x5487, 0x8E},{0x5488, 0x98},{0x5489, 0xA0},{0x548a, 0xA7},
+	{0x548b, 0xB5},{0x548c, 0xC0},{0x548d, 0xD2},{0x548e, 0xE1},{0x548f, 0xED},
+	{0x5490, 0x19},
+	// Color Matrix
+	{0x5381, 0x1c},{0x5382, 0x5a},{0x5383, 0x06},{0x5384, 0x20},{0x5385, 0x80},
+	{0x5386, 0xa0},{0x5387, 0xa2},{0x5388, 0xa0},{0x5389, 0x02},{0x538b, 0x98},
+	{0x538a, 0x01},
+	// Saturation
+	{0x5001, 0xa3},{0x5583, 0x30},{0x5584, 0x30},{0x5580, 0x02},{0x5588, 0x41},
+	// AEC
+	{0x3a0f, 0x40},{0x3a10, 0x38},{0x3a11, 0x71},{0x3a1b, 0x40},{0x3a1e, 0x38},
+	{0x3a1f, 0x10},
+	// AEC Weight
+//  {0x5688, 0x11}, // Zone 1/Zone 0 weight
+//  {0x5689, 0x11}, // Zone 3/Zone 2 weight
+//  {0x569a, 0x31}, // Zone 5/Zone 4 weight
+//  {0x569b, 0x13}, // Zone 7/Zone 6 weight
+//  {0x569c, 0x31}, // Zone 9/Zone 8 weight
+//  {0x569d, 0x13}, // Zone b/Zone a weight
+//  {0x569e, 0x11}, // Zone d/Zone c weight
+//  {0x569f, 0x11}, // Zone f/Zone e weight
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client0;
+static char sensor0_inited = 0;
+#ifndef DISALBE_READ_ID
+static int sensor0_read_ov5640(u16 reg,u8 *val)
+{
+	int ret;
+	/* We have 16-bit i2c addresses - care for endianess */
+	unsigned char data[2] = { reg >> 8, reg & 0xff };
+
+	ret = i2c_master_send(save_client0, data, 2);
+	if (ret < 2) {
+		dev_err(&save_client0->dev, "%s: i2c read error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	ret = i2c_master_recv(save_client0, val, 1);
+	if (ret < 1) {
+		dev_err(&save_client0->dev, "%s: i2c read error, reg: 0x%x\n",__func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+	return 0;
+}
+#endif
+
+static int sensor0_write_ov5640(u16 reg, u8 val)
+{
+	int ret;
+	unsigned char data[3] = { reg >> 8, reg & 0xff, val };
+
+	ret = i2c_master_send(save_client0, data, 3);
+	if (ret < 3) {
+		dev_err(&save_client0->dev, "%s: i2c write error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	return 0;
+}
+
+static int sensor0_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap0_ov5640.i2c_id || client->addr != 0x3c)
+		return -ENODEV;
+	sensor0_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client0 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor0_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap0_ov5640_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap0_ov5640 = {
+	.i2c_id = 2,
+	.name = "cap0_ov5640",
+	.init = &cap0_ov5640_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_HI | HSP_LO | PCLKP_HI),
+	.cropstart = ( 1 | 0<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin0_probe_ov5640(struct nuvoton_vin_device* cam)
+{
+	int i,j,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[1];
+#endif
+	struct OV_RegValue *psRegValue;
+	struct OV_RegValue *psRegValue1;
+	ENTRY();
+
+
+	nuvoton_vin0_attach_sensor(cam, &cap0_ov5640);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor0_inited)
+		return -1;
+	psRegValue=Init_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Init_RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor0_write_ov5640((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+		if(psRegValue->uRegAddr==0x3008  && psRegValue->uValue==0x82) {
+			for(j=0; j<0x20000; j++);
+			VDEBUG("Delay A loop for Reset Device\n");
+		}
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+		}
+	}
+
+	psRegValue1=VGA_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(VGA_RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor0_write_ov5640((psRegValue1->uRegAddr), (psRegValue1->uValue));
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue1->uRegAddr), (psRegValue1->uValue), ret);
+		}
+	}
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	sensor0_read_ov5640(0x302A,SensorID);  /* Chip Version 0xB0 */
+	printk("Chip Version = 0x%02X(0xB0) \n", SensorID[0]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+static const struct i2c_device_id sensor0_id[] = {
+	{ "cap0_ov5640", 0 },
+
+};
+MODULE_DEVICE_TABLE(i2c, sensor0_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap0_ov5640_match_table[] = {
+	{ .compatible = "nuvoton,cap0-ov5640",},
+	{},
+};
+#else
+#define cap0_ov5640_match_table NULL
+#endif
+
+
+static struct i2c_driver sensor0_i2c_driver = {
+	.driver = {
+		.name  = "cap0_ov5640",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap0_ov5640_match_table),
+	},
+	.probe    = sensor0_probe,
+	.remove   = sensor0_remove,
+	.id_table = sensor0_id,
+};
+
+module_i2c_driver(sensor0_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_ov7725.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_ov7725.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_ov7725.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_ov7725.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,193 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap0_ov7725;
+
+struct OV_RegValue {
+	__u8    uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct OV_RegValue)
+
+static struct OV_RegValue RegValue[] = {
+	{0x12, 0x80}, {0x12, 0x00}, {0x3D, 0x03}, {0x17, 0x22}, {0x18, 0xA4},
+	{0x19, 0x07}, {0x1A, 0xF0}, {0x32, 0x02}, {0x29, 0xA0}, {0x2C, 0xF0},
+	{0x2A, 0x02}, {0x65, 0x20}, {0x11, 0x01}, {0x42, 0x7F}, {0x63, 0xE0},
+	{0x64, 0xFF}, {0x66, 0x00}, {0x67, 0x48}, {0x0D, 0x41}, {0x0E, 0x01},
+	{0x0F, 0xC5}, {0x14, 0x11}, {0x22, 0x7F}, {0x23, 0x03}, {0x24, 0x40},
+	{0x25, 0x30}, {0x26, 0xA1}, {0x2B, 0x00}, {0x6B, 0xAA}, {0x13, 0xEF},
+	{0x90, 0x05}, {0x91, 0x01}, {0x92, 0x03}, {0x93, 0x00}, {0x94, 0x90},
+	{0x95, 0x8A}, {0x96, 0x06}, {0x97, 0x0B}, {0x98, 0x95}, {0x99, 0xA0},
+	{0x9A, 0x1E}, {0x9B, 0x08}, {0x9C, 0x20}, {0x9E, 0x81}, {0xA6, 0x04},
+	{0x7E, 0x0C}, {0x7F, 0x24}, {0x80, 0x3A}, {0x81, 0x60}, {0x82, 0x70},
+	{0x83, 0x7E}, {0x84, 0x8A}, {0x85, 0x94}, {0x86, 0x9E}, {0x87, 0xA8},
+	{0x88, 0xB4}, {0x89, 0xBE}, {0x8A, 0xCA}, {0x8B, 0xD8}, {0x8C, 0xE2},
+	{0x8D, 0x28}, {0x46, 0x05}, {0x47, 0x00}, {0x48, 0x00}, {0x49, 0x12},
+	{0x4A, 0x00}, {0x4B, 0x13}, {0x4C, 0x21}, {0x0C, 0x10}, {0x09, 0x00},
+	{0xFF, 0xFF}, {0xFF, 0xFF}
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client0;
+static char sensor0_inited = 0;
+#ifndef DISALBE_READ_ID
+__u8 sensor0_read_ov7725(__u8 uRegAddr)
+{
+	u8 val;
+	//printk("sensor_read_ov7725 i2c_smbus_read_byte uRegAddr=0x%x\n",uRegAddr);
+	i2c_smbus_write_byte(save_client0, uRegAddr);
+	//printk("sensor_read_ov7725 i2c_smbus_write_byte\n");
+	val = i2c_smbus_read_byte(save_client0);
+	return val;
+}
+#endif
+
+static int32_t sensor0_write_ov7725(__u8 uRegAddr, __u8 uData)
+{
+	int ret;
+	ret=i2c_smbus_write_byte_data(save_client0, uRegAddr, uData);
+	return ret;
+}
+
+static int sensor0_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap0_ov7725.i2c_id || client->addr != 0x21)
+		return -ENODEV;
+	sensor0_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client0 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor0_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap0_ov7725_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap0_ov7725 = {
+	.i2c_id = 2,
+	.name = "cap0_ov7725",
+	.init = &cap0_ov7725_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_HI | HSP_LO | PCLKP_HI),
+	.cropstart = ( 0 | 2<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin0_probe_ov7725(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[4];
+#endif
+	struct OV_RegValue *psRegValue;
+	ENTRY();
+
+
+	nuvoton_vin0_attach_sensor(cam, &cap0_ov7725);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor0_inited)
+		return -1;
+
+	psRegValue=RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor0_write_ov7725((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+		}
+	}
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	SensorID[0]=sensor0_read_ov7725(0x0A);  /* PID 0x77 */
+	SensorID[1]=sensor0_read_ov7725(0x0B);  /* VER 0x21 */
+	SensorID[2]=sensor0_read_ov7725(0x1C);  /* Manufacturer ID Byte - High  0x7F */
+	SensorID[3]=sensor0_read_ov7725(0x1D);  /* Manufacturer ID Byte - Low   0xA2 */
+	printk("Sensor PID = 0x%02x(0x77) VER = 0x%02x(0x21) MIDH = 0x%02x(0x7F) MIDL = 0x%02x(0xA2)\n", SensorID[0],SensorID[1],SensorID[2],SensorID[3]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+
+static const struct i2c_device_id sensor0_id[] = {
+	{ "cap0_ov7725", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor0_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap0_ov7725_match_table[] = {
+	{ .compatible = "nuvoton,cap0-ov7725",},
+	{},
+};
+#else
+#define cap0_ov7725_match_table NULL
+#endif
+
+
+static struct i2c_driver sensor0_i2c_driver = {
+	.driver = {
+		.name  = "cap0_ov7725",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap0_ov7725_match_table),
+	},
+	.probe    = sensor0_probe,
+	.remove   = sensor0_remove,
+	.id_table = sensor0_id,
+};
+module_i2c_driver(sensor0_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_tw9912.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_tw9912.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_tw9912.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor0_tw9912.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,281 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap0_tw9912;
+
+struct TW_RegValue {
+	__u8    uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct TW_RegValue)
+
+static struct TW_RegValue Init_RegValue[] = {
+	//NTSC INIT
+	{0x88, 0x14},{0x02, 0x48},//From YIN2
+	{0x03, 0x20},{0x05, 0x01},{0x07, 0x02},{0x08, 0x12},{0x09, 0xF0},
+	{0x0A, 0x14},{0x0B, 0xD0},{0x0C, 0xCC},{0x11, 0x64},{0x1C, 0x0F},
+	{0x1E, 0x08},{0x27, 0x38},{0x30, 0x00},{0x37, 0x28},{0x38, 0xAF},
+	{0xC0, 0x01},{0xC2, 0x01},{0xC3, 0x03},{0xC4, 0x5A},{0xC5, 0x00},
+	{0xC6, 0x20},{0xCB, 0x30},{0xCC, 0x00},{0xD7, 0x70},{0xD9, 0x04},
+	{0xE1, 0x05},{0xE2, 0xD9},{0xE6, 0x00},{0xE8, 0x0F},{0xE9, 0x00},
+};
+
+static struct TW_RegValue Output_RegValue[] = {
+#if 1 //NTSC PRO
+	{0x88, 0x02},
+	{0x02, 0x48},//From YIN2
+	{0x03, 0x20},//add
+	{0x04, 0x00},{0x05, 0x1E},{0x06, 0x03},
+	//{0x08, 0x0A},//{0x08, 0x12},
+	//{0x08, 0x17},
+#if 0
+	{0x07, 0x12},//{0x07, 0x02},                    /* Fix insufficient 480 horizontal line */
+	{0x09, 0x05},//{0x09, 0xFC},//{0x09, 0xF0},     /* Fix insufficient 480 horizontal line */
+#else
+	//{0x07, 0x12},//{0x07, 0x02},                  /* Fix insufficient 480 horizontal line */
+	//{0x09, 0x40},//{0x09, 0xFC},//{0x09, 0xF0},       /* Fix insufficient 480 horizontal line */
+	//D1 TRY
+	//{0x07, 0x03},
+	//{0x09, 0xF0},
+#endif
+	//{0x0A, 0x49},
+	//{0x0B, 0x34},
+	//{0x0C, 0xCC},
+	{0x07, 0x02},{0x08, 0x14},{0x09, 0xF9},{0x0A, 0x2b},{0x0B, 0xf4},
+	{0x0C, 0xDC},{0x0D, 0x15},{0x11, 0x64},{0x12, 0x11},{0x13, 0x80},
+	{0x14, 0x80},{0x15, 0x00},{0x17, 0x30},{0x18, 0x44},{0x1A, 0x10},
+	{0x1B, 0x00},{0x1C, 0x0F},{0x1D, 0x7F},{0x1E, 0x08},{0x1F, 0x00},
+	{0x20, 0x50},{0x21, 0x42},{0x22, 0xF0},{0x23, 0xD8},{0x24, 0xBC},
+	{0x25, 0xB8},{0x26, 0x44},{0x27, 0x38},{0x28, 0x00},{0x29, 0x00},
+	{0x2A, 0x78},{0x2B, 0x44},{0x2C, 0x30},{0x2D, 0x14},{0x2E, 0xA5},
+	{0x2F, 0x26},{0x30, 0x00},{0x31, 0x10},{0x32, 0x00},{0x33, 0x05},
+	{0x34, 0x1A},{0x35, 0x00},{0x36, 0xe2},
+	{0x37, 0x01}, //D1
+	//{0x37, 0x2D}, //VGA
+	{0x38, 0x01},{0x40, 0x00},{0x41, 0x80},{0x42, 0x00},{0xC0, 0x01},
+	{0xC1, 0x07},{0xC2, 0x01},{0xC3, 0x03},{0xC4, 0x5A},{0xC5, 0x00},
+	{0xC6, 0x20},{0xC7, 0x04},{0xC8, 0x00},{0xC9, 0x06},{0xCA, 0x06},
+	{0xCB, 0x30},{0xCC, 0x00},{0xCD, 0x54},{0xD0, 0x00},{0xD1, 0xF0},
+	{0xD2, 0xF0},{0xD3, 0xF0},{0xD4, 0x00},{0xD5, 0x00},{0xD6, 0x10},
+	{0xD7, 0x70},{0xD8, 0x00},{0xD9, 0x04},{0xDA, 0x80},{0xDB, 0x80},
+	{0xDC, 0x20},{0xE0, 0x00},{0xE1, 0x49},{0xE2, 0xD9},{0xE3, 0x00},
+	{0xE4, 0x00},{0xE5, 0x00},{0xE6, 0x00},{0xE7, 0x2A},{0xE8, 0x0F},
+	{0xE9, 0x6D},//{0xE9, 0x61},
+//  {0x2F, 0x8B} /* test mode force blue */
+
+#else //PAL
+
+	{0xFF, 0x00},//Page 0
+	//{0x88, 0x02}, //mark by paul's new sensor table
+	{0x01, 0x79},{0x02, 0x48},//From YIN2
+	//{0x02, 0x40},//From YIN0
+	{0x03, 0x20},//add
+	{0x04, 0x00},{0x05, 0x1E},{0x06, 0x03},
+	//D1 TRY
+	{0x07, 0x12},{0x08, 0x14},{0x09, 0x20},{0x0A, 0x26},{0x0B, 0xFE},
+//  {0x07, 0x12},
+//  {0x08, 0x14},
+//  {0x09, 0x20},
+//  {0x0A, 0x0E},
+//  {0x0B, 0xD0},
+	{0x0C, 0xCC},{0x0D, 0x15},{0x11, 0x64},{0x12, 0x11},{0x13, 0x80},
+	{0x14, 0x80},{0x15, 0x00},{0x17, 0x30},{0x18, 0x44},{0x1A, 0x10},
+	{0x1B, 0x00},{0x1C, 0x1F},//{0x1C, 0x0F},
+	{0x1D, 0x7F},{0x1E, 0x18},//{0x1E, 0x08},
+	{0x1F, 0x00},{0x20, 0x50},{0x21, 0x42},{0x22, 0xF0},{0x23, 0xD8},
+	{0x24, 0xBC},{0x25, 0xB8},{0x26, 0x44},{0x27, 0x38},{0x28, 0x00},
+	{0x29, 0x00},{0x2A, 0x78},{0x2B, 0x44},{0x2C, 0x30},{0x2D, 0x14},
+	{0x2E, 0xA5},{0x2F, 0x26},{0x30, 0x00},{0x31, 0x10},{0x32, 0x00},
+	{0x33, 0x05},{0x34, 0x1A},{0x35, 0x00},{0x36, 0xe2},
+//  {0x37, 0x2D},//VGA
+	{0x37, 0x01},//D1
+	{0x38, 0x01},{0x40, 0x00},{0x41, 0x80},{0x42, 0x00},{0xC0, 0x01},
+	{0xC1, 0x07},{0xC2, 0x01},{0xC3, 0x03},{0xC4, 0x5A},{0xC5, 0x00},
+	{0xC6, 0x20},{0xC7, 0x04},{0xC8, 0x00},{0xC9, 0x06},{0xCA, 0x06},
+	{0xCB, 0x30},{0xCC, 0x00},{0xCD, 0x54},{0xD0, 0x00},{0xD1, 0xF0},
+	{0xD2, 0xF0},{0xD3, 0xF0},{0xD4, 0x00},{0xD5, 0x00},{0xD6, 0x10},
+	{0xD7, 0x70},{0xD8, 0x00},{0xD9, 0x04},{0xDA, 0x80},{0xDB, 0x80},
+	{0xDC, 0x20},{0xE0, 0x00},{0xE1, 0x49},{0xE2, 0xD9},{0xE3, 0x00},
+	{0xE4, 0x00},{0xE5, 0x00},{0xE6, 0x00},{0xE8, 0x0F},{0xE9, 0x6D},
+	//{0xE9, 0x61},
+	//{0xff, 0xff}
+#endif
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client0;
+static char sensor0_inited = 0;
+#ifndef DISALBE_READ_ID
+__u8 sensor0_read_tw9912(__u8 uRegAddr)
+{
+	u8 val;
+	//printk("sensor_read_tw9912 i2c_smbus_read_byte uRegAddr=0x%x\n",uRegAddr);
+	i2c_smbus_write_byte(save_client0, uRegAddr);
+	//printk("sensor_read_tw9912 i2c_smbus_write_byte\n");
+	val = i2c_smbus_read_byte(save_client0);
+	return val;
+}
+#endif
+static int32_t sensor0_write_tw9912(__u8 uRegAddr, __u8 uData)
+{
+	int ret;
+	ret=i2c_smbus_write_byte_data(save_client0, uRegAddr, uData);
+	return ret;
+}
+
+static int sensor0_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap0_tw9912.i2c_id)
+		return -ENODEV;
+	sensor0_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client0 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor0_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap0_tw9912_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+#if 1 //NTSC
+#define CROP_START_X    0x24
+#define CROP_START_Y    0x28
+#endif
+static struct nuvoton_vin_sensor cap0_tw9912 = {
+	.i2c_id = 2,
+	.name = "cap0_tw9912",
+	.init = &cap0_tw9912_init,
+	.infmtord = (INORD_YVYU | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_LO | HSP_LO | PCLKP_HI),
+	.cropstart = ( CROP_START_Y | CROP_START_X<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = CROP_START_X,
+			.top = CROP_START_Y,
+			.width = 720,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 720,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin0_probe_tw9912(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[1];
+#endif
+	struct TW_RegValue *psRegValue;
+	struct TW_RegValue *psRegValue1;
+	ENTRY();
+
+
+	nuvoton_vin0_attach_sensor(cam, &cap0_tw9912);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor0_inited)
+		return -1;
+
+	psRegValue=Init_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Init_RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor0_write_tw9912((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+			printk("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+		}
+	}
+	printk("\n");
+
+	psRegValue1=Output_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Output_RegValue); i++, psRegValue1++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor0_write_tw9912((psRegValue1->uRegAddr), (psRegValue1->uValue));
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue1->uRegAddr), (psRegValue1->uValue), ret);
+		}
+	}
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	SensorID[0]=sensor0_read_tw9912(0x00);  /* ID 0x60 */
+	printk("Chip Version = 0x%02X(0x60) \n", SensorID[0]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+
+static const struct i2c_device_id sensor0_id[] = {
+	{ "cap0_tw9912", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor0_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap0_tw9912_match_table[] = {
+	{ .compatible = "nuvoton,cap0-tw9912",},
+	{},
+};
+#else
+#define cap0_tw9912_match_table NULL
+#endif
+
+
+static struct i2c_driver sensor0_i2c_driver = {
+	.driver = {
+		.name  = "cap0_tw9912",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap0_tw9912_match_table),
+	},
+	.probe    = sensor0_probe,
+	.remove   = sensor0_remove,
+	.id_table = sensor0_id,
+};
+module_i2c_driver(sensor0_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_gc0308.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_gc0308.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_gc0308.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_gc0308.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,470 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap1_gc0308;
+
+struct GC_RegValue {
+	__u8	uRegAddr;
+	__u8	uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName)	sizeof(nTableName)/sizeof(struct GC_RegValue)
+#define __60HZ__
+static struct GC_RegValue RegValue[] = {
+	{0xfe,0x00},
+#ifdef __60HZ__
+	{0x01, 0x6a},	//HB
+	{0x02, 0x0C}, 	//VB
+	{0x0f, 0x00},
+
+	{0xe2, 0x00},
+	{0xe3, 0x7d}, //Flicker Step = 1/120s
+	{0xe4, 0x01},
+	{0xe5, 0xF4},
+	{0xe6, 0x03},
+	{0xe7, 0xe8},
+	{0xe8, 0x05},
+	{0xe9, 0xdc},
+	{0xea, 0x07},
+	{0xeb, 0xd0},
+	{0xec, 0x00}, //fps 30f/s
+#endif
+
+#ifdef __50HZ__
+	{0x01, 0x6a},	//HB
+	{0x02, 0x0C}, 	//VB
+	{0x0f, 0x00},
+
+	{0xe2, 0x00},
+	{0xe3, 0x96}, //Flicker Step = 1/100s
+	{0xe4, 0x01},
+	{0xe5, 0xC2},
+	{0xe6, 0x03},
+	{0xe7, 0x84},
+	{0xe8, 0x05},
+	{0xe9, 0xdc},
+	{0xea, 0x07},
+	{0xeb, 0x9e},
+	{0xec, 0x00}, //fps 30f/s
+#endif
+
+	{0x05, 0x00},	// row_start_high
+	{0x06, 0x00},	// row_start_low
+	{0x07, 0x00},	// col_start_high
+	{0x08, 0x00},	// col_start_low
+	{0x09, 0x01},	//[8]cis_win_height  488
+	{0x0a, 0xe8},	//[7:0]cis_win_height
+	{0x0b, 0x02}	,//[9:8]cis_win_width 648
+	{0x0c, 0x88},	//[7:0]cis_win_width
+	{0x0d, 0x02},	//vs_st
+	{0x0e, 0x02},	//vs_et
+	{0x10, 0x26},	//[7:4]restg_width, [3:0]sh_width
+	{0x11, 0x0d},	//fd//[7:4]tx_width, [3:0]space width,*2
+	{0x12, 0x2a},	//sh_delay
+	{0x13, 0x00},	//[3:0] row_tail_width
+	{0x14, 0x12},	//[7]hsync_always ,[6] NA,  [5:4] CFA sequence
+	// [3:2]NA,  [1]upside_down,  [0] mirror
+	{0x15, 0x0a},	//[7:6]output_mode,,[5:4]restg_mode,[3:2]sdark_mode, [1]new exposure,[0]badframe_en
+	{0x16, 0x05},	//[7:5]NA, [4]capture_ad_data_edge, [3:0]Number of A/D pipe stages
+	{0x17, 0x01},	//[7:6]analog_opa_r,[5]coltest_en, [4]ad_test_enable,
+	//[3]tx_allow,[2]black sun correction,[1:0]black sun control reg
+	{0x18, 0x44},	//[7]NA,  [6:4]column gain ee, [3]NA, [2:0]column gain eo
+	{0x19, 0x44},	//[7]NA,  [6:4]column gain oe, [3]NA, [2:0]column gain oo
+	{0x1a, 0x2a},	//1e//[7]rsv1,[6]rsv0, [5:4]coln_r,
+	//[3:2]colg_r column gain opa bias current, [1]clk_delay, [0] apwd
+	{0x1b, 0x00},	//[7:2]NA, [1:0]BIN4 AND BIN2
+	{0x1c, 0x49},	//c1//[7]hrst_enbale, [6:4]da_rsg, [3]tx high enable, [2]NA, [1:0]da18_r
+	{0x1d, 0x9a},	//08//[7]vref_en, [6:4]da_vef, [3]da25_en, [2]NA, [1:0]da25_r,set da25 voltage
+	{0x1e, 0x61},	//60//[7]LP_MTD,[6:5]opa_r,ADC's operating current,  [4:2]NA, [1:0]sref
+	{0x1f, 0x15},	//[7:6]NA, [5:4]sync_drv, [3:2]data_drv, [1:0]pclk_drv
+
+	{0x20, 0xff},	//[7]bks[6]gamma[5]cc[4]ee[3]intp[2]dn[1]dd[0]lsc
+	{0x21, 0xf8},	//[7]na[6]na[5]skin_ee[4]cbcr_hue_en[3]y_as_en[2]auto_gray_en[1]y_gamma_en[0]na
+	{0x22, 0x57},	//[7]na [6]auto_dndd [5]auto_ee [4]auto_sa [3]na [2]abs [1]awb  [0]na
+	{0x24, 0xa2},	//YCbYcr //a0
+	{0x25, 0x0f},
+	//output sync_mode
+	{0x26, 0x01},	//02
+	{0x2f, 0x01},	//debug mode3
+	//////////////////////////////////////////////////////////////
+	///////////////////// grab     ////////////////////////////////
+	///////////////////////////////////////////////////////////////
+	{0x30, 0xf7},	//blk mode [7]dark current mode:1 use exp rated dark ,0 use ndark row calculated
+	//[1]dark_current_en//[0]offset_en
+	{0x31, 0x50},	//blk_value limit.64 low align to 11bits;8 for 256 range
+	{0x32, 0x00},	//global offset
+	{0x39, 0x04},	// exp_ate_darkc
+	{0x3a, 0x20},	//{7:6}offset submode {5:0}offset ratio
+	{0x3b, 0x20},	//{7:6}darkc submode {5:0}dark current ratio
+	{0x3c, 0x00},	//manual g1 offset
+	{0x3d, 0x00},	//manual r offset
+	{0x3e, 0x00},	//manual b offset
+	{0x3f, 0x00},	//manual g2 offset
+	///////////gain////////
+	{0x50, 0x14},	//10  //global gain
+
+	{0x53, 0x80},	//G
+	{0x54, 0x80},	//R channel gain
+	{0x55, 0x80},	//B channel gain
+	{0x56, 0x80},
+	/////////////////////////////////////////////////////////
+	//////////////// LSC_t    ////////////////////////////////
+	//////////////////////////////////////////////////////////
+	{0x8b, 0x20},	//r2
+	{0x8c, 0x20},	//g2
+	{0x8d, 0x20},	//b2
+	{0x8e, 0x14},	//r4
+	{0x8f, 0x10},	//g4
+	{0x90, 0x14},	//b4
+	{0x91, 0x3c},	//[7]singed4 [6:0]row_cneter
+	{0x92, 0x50},	//col_center
+	{0x5d, 0x12},	//decrease 1
+	{0x5e, 0x1a},	//decrease 2
+	{0x5f, 0x24},	//decrease 3
+	//////////////////////////////////////////////////////////
+	//////////////// DNDD_t    ///////////////////////////////
+	//////////////////////////////////////////////////////////
+	{0x60, 0x07},	//[4]zero weight mode
+	//[3]share mode
+	//[,]c weight mode
+	//[,]lsc decrease mode
+	//[,]b mode
+	{0x61, 0x15},	//[7:6]na
+	//[5:4]c weight adap ratio
+	//[,:2]dn lsc ratio
+	//[,:0]b ratio
+	{0x62, 0x08},	//b base
+	//0x63,0x02}//b increase RO
+	{0x64, 0x03},	//[7:4]n base [3:0]c weight
+	//0x65,  ,//[7:4]n increase [3:0]c coeff
+	{0x66, 0xe8},	//dark_th ,bright_th
+	{0x67, 0x86},	//flat high, flat low
+	{0x68, 0xa2},	//[7:4]dd limit [1:0]dd ratio
+	//////////////////////////////////////////////////////////
+	//////////////// asde_t    ///////////////////////////////
+	//////////////////////////////////////////////////////////
+	{0x69, 0x18},	//gain high th
+	{0x6a, 0x0f},	//[7:4]dn_c slop          //[3]use post_gain [2]use pre_gain [1]use global gain [0]use col gain
+	{0x6b, 0x00},	//[7:4]dn_b slop [3:0]dn_n slop
+	{0x6c, 0x5f},	//[7:4]bright_th start [3:0]bright_th slop
+	{0x6d, 0x8f},	//[7:4]dd_limit_start[3:0]dd_limit slop
+	{0x6e, 0x55},	//[7:4]ee1 effect start [3:0]slope  broad
+	{0x6f, 0x38},	//[7:4]ee2 effect start [3:0]slope  narrow
+	{0x70, 0x15},	//saturation dec slope
+	{0x71, 0x33},	//[7:4]low limit,[3:0]saturation slope
+	/////////////////////////////////////////////////////////
+	/////////////// eeintp_t    ///////////////////////////////
+	/////////////////////////////////////////////////////////
+	{0x72, 0xdc},	//[7]edge_add_mode [6]new edge mode [5]edge2_mode [4]HP_mode
+	//[3]lp intp en [2]lp edge en [1:0]lp edge mode
+
+	{0x73, 0x80},	//[7]edge_add_mode2 [6]NA [5]only 2direction [4]fixed direction th
+	//[3]only defect map [2]intp_map dir [1]HP_acc [0]only edge map
+	//////for high resolution in light scene
+	{0x74, 0x02},	//direction th1
+	{0x75, 0x3f},	//direction th2
+	{0x76, 0x02},	//direction diff th      h>v+diff ; h>th1 ; v<th2
+	{0x77, 0x36},	//[7:4]edge1_effect [3:0]edge2_effect
+	{0x78, 0x88},	//[7:4]edge_pos_ratio  [3:0]edge neg ratio
+	{0x79, 0x81},	//edge1_max,edge1_min
+	{0x7a, 0x81},	//edge2_max,edge2_min
+	{0x7b, 0x22},	//edge1_th,edge2_th
+	{0x7c, 0xff},	//pos_edge_max,neg_edge_max
+	//////for high resolution in light scene
+	///cct
+	{0x93, 0x48},	// <--40
+	{0x94, 0x02},
+	{0x95, 0x07},
+	{0x96, 0xe0},
+	{0x97, 0x40},
+	{0x98, 0xf0},
+	//ycpt
+	{0xb1, 0x40},	//manual cb
+	{0xb2, 0x40},	//manual cr
+	{0xb3, 0x40},
+	{0xb6, 0xe0},
+	{0xbd, 0x38},
+	{0xbe, 0x36},	// [5:4]gray mode 00:4&8  01:4&12 10:4&20  11:8$16   [3:0] auto_gray
+
+	////AECT
+	{0xd0, 0xcb},	// exp is gc mode
+	{0xd1, 0x10},	//every N
+	{0xd2, 0x90},	// 7 aec enable 5 clore y mode 4skin weight 3 weight drop mode
+	{0xd3, 0x48},	//Y_target and low pixel thd high X4 low X2
+	{0xd5, 0xf2},	//lhig
+	{0xd6, 0x16},	// ignore mode
+	{0xdb, 0x92},
+	{0xdc, 0xa5},	//fast_margin  fast_ratio
+	{0xdf, 0x23},	// I_fram D_ratio
+
+	{0xd9, 0x00},	// colore offset in CAL ,now is too dark so set zero
+	{0xda, 0x00},	// GB offset
+	{0xe0, 0x09},
+
+	{0xed, 0x04},	//minimum exposure low 8  bits
+	{0xee, 0xa0},	//max_post_dg_gain
+	{0xef, 0x40},	//max_pre_dg_gain
+	{0x80, 0x03},
+	////abbt
+	{0x80, 0x03},
+	////RGBgama_m5
+	{0x9F, 0x10},
+	{0xA0, 0x20},
+	{0xA1, 0x38},
+	{0xA2, 0x4E},
+	{0xA3, 0x63},
+	{0xA4, 0x76},
+	{0xA5, 0x87},
+	{0xA6, 0xA2},
+	{0xA7, 0xB8},
+	{0xA8, 0xCA},
+	{0xA9, 0xD8},
+	{0xAA, 0xE3},
+	{0xAB, 0xEB},
+	{0xAC, 0xF0},
+	{0xAD, 0xF8},
+	{0xAE, 0xFD},
+	{0xAF, 0xFF},
+	///wint
+	///Y_gamma
+	{0xc0, 0x00},	//Y_gamma_0
+	{0xc1, 0x10},	//Y_gamma_1
+	{0xc2, 0x1C},	//Y_gamma_2
+	{0xc3, 0x30},	//Y_gamma_3
+	{0xc4, 0x43},	//Y_gamma_4
+	{0xc5, 0x54},	//Y_gamma_5
+	{0xc6, 0x65},	//Y_gamma_6
+	{0xc7, 0x75},	//Y_gamma_7
+	{0xc8, 0x93},	//Y_gamma_8
+	{0xc9, 0xB0},	//Y_gamma_9
+	{0xca, 0xCB},	//Y_gamma_10
+	{0xcb, 0xE6},	//Y_gamma_11
+	{0xcc, 0xFF},	//Y_gamma_12
+	/////ABS
+	{0xf0, 0x02},
+	{0xf1, 0x01},
+	{0xf2, 0x02},//manual stretch K
+	{0xf3, 0x30},//the limit of Y_stretch
+	{0xf7, 0x12},
+	{0xf8, 0x0a},
+	{0xf9, 0x9f},
+	{0xfa, 0x78},
+
+	////AWB
+	{0xfe, 0x01},
+	{0x00, 0xf5},	//high_low limit
+	{0x02, 0x20},	//y2c
+	{0x04, 0x10},
+	{0x05, 0x08},
+	{0x06, 0x20},
+	{0x08, 0x0a},
+	{0x0a, 0xa0},	// number limit
+	{0x0b, 0x60},	// skip_mode
+	{0x0c, 0x08},
+	{0x0e, 0x44},	// width step
+	{0x0f, 0x32},	// height step
+	{0x10, 0x41},
+	{0x11, 0x37},	// 0x3f
+	{0x12, 0x22},
+	{0x13, 0x19},	//13//smooth 2
+	{0x14, 0x44},	//R_5k_gain_base
+	{0x15, 0x44},	//B_5k_gain_base
+	{0x16, 0xc2},	//c2//sinT
+	{0x17, 0xa8},	//ac//a8//a8//a8//cosT
+	{0x18, 0x18},	//X1 thd
+	{0x19, 0x50},	//X2 thd
+	{0x1a, 0xd8},	//e4//d0//Y1 thd
+	{0x1b, 0xf5},	//Y2 thd
+	{0x70, 0x40},	// A R2G low
+	{0x71, 0x58},	// A R2G high
+	{0x72, 0x30},	// A B2G low
+	{0x73, 0x48},	// A B2G high
+	{0x74, 0x20},	// A G low
+	{0x75, 0x60},	// A G high
+	{0x77, 0x20},
+	{0x78, 0x32},
+
+	///hsp
+	{0x30, 0x03},	//[1]HSP_en [0]sa_curve_en
+	{0x31, 0x40},
+	{0x32, 0x10},
+	{0x33, 0xe0},
+	{0x34, 0xe0},
+	{0x35, 0x00},
+	{0x36, 0x80},
+	{0x37, 0x00},
+	{0x38, 0x04},	//sat1, at8
+	{0x39, 0x09},
+	{0x3a, 0x12},
+	{0x3b, 0x1C},
+	{0x3c, 0x28},
+	{0x3d, 0x31},
+	{0x3e, 0x44},
+	{0x3f, 0x57},
+	{0x40, 0x6C},
+	{0x41, 0x81},
+	{0x42, 0x94},
+	{0x43, 0xA7},
+	{0x44, 0xB8},
+	{0x45, 0xD6},
+	{0x46, 0xEE},	//sat15,at224
+	{0x47, 0x0d},	//blue_edge_dec_ratio
+	///out
+	{0xfe, 0x00},
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client1;
+static char sensor1_inited = 0;
+#ifndef DISALBE_READ_ID
+__u8 sensor1_read_gc0308(__u8 uRegAddr)
+{
+	u8 val;
+	//printk("sensor_read_gc0308 i2c_smbus_read_byte uRegAddr=0x%x\n",uRegAddr);
+	i2c_smbus_write_byte(save_client1, uRegAddr);
+	//printk("sensor_read_gc0308 i2c_smbus_write_byte\n");
+	val = i2c_smbus_read_byte(save_client1);
+	return val;
+}
+#endif
+
+static int32_t sensor1_write_gc0308(__u8 uRegAddr, __u8 uData)
+{
+	int ret;
+	ret=i2c_smbus_write_byte_data(save_client1, uRegAddr, uData);
+	return ret;
+}
+
+static int sensor1_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap1_gc0308.i2c_id || client->addr != 0x21)
+		return -ENODEV;
+	sensor1_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client1 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor1_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap1_gc0308_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap1_gc0308 = {
+	.i2c_id = 1,
+	.name = "cap1_gc0308",
+	.init = &cap1_gc0308_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_LO | HSP_HI | PCLKP_HI),
+	.cropstart = ( 0 | 2<<16 ),	/*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format	 = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin1_probe_gc0308(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[1];
+#endif
+	struct GC_RegValue *psRegValue;
+	ENTRY();
+	nuvoton_vin1_attach_sensor(cam, &cap1_gc0308);
+
+	// if i2c module isn't loaded at this time
+	if(!sensor1_inited)
+		return -1;
+
+	psRegValue=RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor1_write_gc0308((psRegValue->uRegAddr), (psRegValue->uValue));
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+		}
+	}
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	SensorID[0]=sensor1_read_gc0308(0x00);  /* PID 0x77 */
+	printk("Sensor PID = 0x%02x(0x9B)\n", SensorID[0]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+static const struct i2c_device_id sensor1_id[] = {
+	{ "cap1_gc0308", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor1_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap1_gc0308_match_table[] = {
+	{ .compatible = "nuvoton,cap1-gc0308",},
+	{},
+};
+#else
+#define cap1_gc0308_match_table NULL
+#endif
+
+
+static struct i2c_driver sensor1_i2c_driver = {
+	.driver = {
+		.name  = "cap1_gc0308",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap1_gc0308_match_table),
+	},
+	.probe    = sensor1_probe,
+	.remove   = sensor1_remove,
+	.id_table = sensor1_id,
+};
+module_i2c_driver(sensor1_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_nt99050.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_nt99050.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_nt99050.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_nt99050.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,240 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap1_nt99050;
+
+struct OV_RegValue {
+	__u16   uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct OV_RegValue)
+/* NT99141, VGA, YUV422 */
+static struct OV_RegValue Init_RegValue[] = {
+	//[InitialSetting]
+	{0x3021, 0x01},
+#if 0 /* BT656 */
+	{0x32F0, 0x61},{0x32F1, 0x10},
+#else
+	{0x32F0, 0x01},
+#endif
+	{0x3024, 0x00}, {0x3270, 0x00}, //[Gamma_MDR]
+	{0x3271, 0x0D}, {0x3272, 0x19}, {0x3273, 0x2A}, {0x3274, 0x3C}, {0x3275, 0x4D},
+	{0x3276, 0x67}, {0x3277, 0x81}, {0x3278, 0x98}, {0x3279, 0xAD}, {0x327A, 0xCE},
+	{0x327B, 0xE0}, {0x327C, 0xED}, {0x327D, 0xFF}, {0x327E, 0xFF}, {0x3060, 0x01},
+	{0x3210, 0x04}, //LSC //D
+	{0x3211, 0x04}, //F
+	{0x3212, 0x04}, //D
+	{0x3213, 0x04}, //D
+	{0x3214, 0x04}, {0x3215, 0x05}, {0x3216, 0x04}, {0x3217, 0x04}, {0x321C, 0x04},
+	{0x321D, 0x05}, {0x321E, 0x04}, {0x321F, 0x03}, {0x3220, 0x00}, {0x3221, 0xA0},
+	{0x3222, 0x00}, {0x3223, 0xA0}, {0x3224, 0x00}, {0x3225, 0xA0}, {0x3226, 0x80},
+	{0x3227, 0x88}, {0x3228, 0x88}, {0x3229, 0x30}, {0x322A, 0xCF}, {0x322B, 0x07},
+	{0x322C, 0x04}, {0x322D, 0x02}, {0x3302, 0x00},//[CC: Saturation:100%]
+	{0x3303, 0x1C}, {0x3304, 0x00}, {0x3305, 0xC8}, {0x3306, 0x00}, {0x3307, 0x1C},
+	{0x3308, 0x07}, {0x3309, 0xE9}, {0x330A, 0x06}, {0x330B, 0xDF}, {0x330C, 0x01},
+	{0x330D, 0x38}, {0x330E, 0x00}, {0x330F, 0xC6}, {0x3310, 0x07}, {0x3311, 0x3F},
+	{0x3312, 0x07}, {0x3313, 0xFC}, {0x3257, 0x50}, //CA Setting
+	{0x3258, 0x10}, {0x3251, 0x01}, {0x3252, 0x50}, {0x3253, 0x9A}, {0x3254, 0x00},
+	{0x3255, 0xd8}, {0x3256, 0x60}, {0x32C4, 0x38}, {0x32F6, 0xCF}, {0x3363, 0x37},
+	{0x3331, 0x08}, {0x3332, 0x6C}, // 60
+	{0x3360, 0x10}, {0x3361, 0x30}, {0x3362, 0x70}, {0x3367, 0x40}, {0x3368, 0x32}, //20
+	{0x3369, 0x24}, //1D
+	{0x336A, 0x1A}, {0x336B, 0x20}, {0x336E, 0x1A}, {0x336F, 0x16}, {0x3370, 0x0c},
+	{0x3371, 0x12}, {0x3372, 0x1d}, {0x3373, 0x24}, {0x3374, 0x30}, {0x3375, 0x0A},
+	{0x3376, 0x18}, {0x3377, 0x20}, {0x3378, 0x30}, {0x3340, 0x1C}, {0x3326, 0x03}, //Eext_DIV
+	{0x3200, 0x3E}, //1E
+	{0x3201, 0x3F}, {0x3109, 0x82}, //LDO Open
+	{0x3106, 0x07}, {0x303F, 0x02}, {0x3040, 0xFF}, {0x3041, 0x01}, {0x3051, 0xE0},
+	{0x3060, 0x01},
+
+	{0x32BF, 0x04}, {0x32C0, 0x6A}, {0x32C1, 0x6A}, {0x32C2, 0x6A}, {0x32C3, 0x00},
+	{0x32C4, 0x20}, {0x32C5, 0x20}, {0x32C6, 0x20}, {0x32C7, 0x00}, {0x32C8, 0x95},
+	{0x32C9, 0x6A}, {0x32CA, 0x8A}, {0x32CB, 0x8A}, {0x32CC, 0x8A}, {0x32CD, 0x8A},
+	{0x32D0, 0x01}, {0x3200, 0x3E}, {0x3201, 0x0F}, {0x302A, 0x00}, {0x302B, 0x09},
+	{0x302C, 0x00}, {0x302D, 0x04}, {0x3022, 0x24}, {0x3023, 0x24}, {0x3002, 0x00},
+	{0x3003, 0x00}, {0x3004, 0x00}, {0x3005, 0x00}, {0x3006, 0x02}, {0x3007, 0x83},
+	{0x3008, 0x01}, {0x3009, 0xE3},
+
+	{0x300A, 0x03}, {0x300B, 0x28}, {0x300C, 0x01}, {0x300D, 0xF4},
+
+	{0x300E, 0x02}, {0x300F, 0x84}, {0x3010, 0x01}, {0x3011, 0xE4}, {0x32B8, 0x3B},
+	{0x32B9, 0x2D}, {0x32BB, 0x87}, {0x32BC, 0x34}, {0x32BD, 0x38}, {0x32BE, 0x30},
+	{0x3201, 0x3F}, {0x320A, 0x01}, {0x3021, 0x06}, {0x3060, 0x01},
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client1;
+static char sensor1_inited = 0;
+#ifndef DISALBE_READ_ID
+static int sensor1_read_nt99050(u16 reg,u8 *val)
+{
+	int ret;
+	/* We have 16-bit i2c addresses - care for endianess */
+	unsigned char data[2] = { reg >> 8, reg & 0xff };
+
+	ret = i2c_master_send(save_client1, data, 2);
+	if (ret < 2) {
+		dev_err(&save_client1->dev, "%s: i2c read error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	ret = i2c_master_recv(save_client1, val, 1);
+	if (ret < 1) {
+		dev_err(&save_client1->dev, "%s: i2c read error, reg: 0x%x\n",__func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+	return 0;
+}
+#endif
+
+static int sensor1_write_nt99050(u16 reg, u8 val)
+{
+	int ret;
+	unsigned char data[3] = { reg >> 8, reg & 0xff, val };
+
+	ret = i2c_master_send(save_client1, data, 3);
+	if (ret < 3) {
+		dev_err(&save_client1->dev, "%s: i2c write error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	return 0;
+}
+
+static int sensor1_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap1_nt99050.i2c_id || client->addr != 0x21)
+		return -ENODEV;
+	sensor1_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client1 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor1_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap1_nt99050_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap1_nt99050 = {
+	.i2c_id = 1,
+	.name = "cap1_nt99050",
+	.init = &cap1_nt99050_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_LO | HSP_LO | PCLKP_HI),
+	.cropstart = ( 0 | 0<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin1_probe_nt99050(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[2];
+#endif
+	struct OV_RegValue *psRegValue;
+	ENTRY();
+
+	nuvoton_vin1_attach_sensor(cam, &cap1_nt99050);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor1_inited)
+		return -1;
+
+	psRegValue=Init_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Init_RegValue); i++, psRegValue++) {
+		printk(".");
+		ret = sensor1_write_nt99050((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+	}
+
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	sensor1_read_nt99050(0x3000,&SensorID[0]);  /* Chip_Version_H 0x14 */
+	sensor1_read_nt99050(0x3001,&SensorID[1]);  /* Chip_Version_L 0x10 */
+	printk("\nSensor Chip_Version_H = 0x%02x(0x05) Chip_Version_L = 0x%02x(0x00)\n", SensorID[0],SensorID[1]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+
+static const struct i2c_device_id sensor1_id[] = {
+	{ "nt99050", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor1_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap1_nt99050_match_table[] = {
+	{ .compatible = "nuvoton,cap1-nt99050",},
+	{},
+};
+#else
+#define cap1_nt99050_match_table NULL
+#endif
+
+static struct i2c_driver sensor1_i2c_driver = {
+	.driver = {
+		.name  = "cap1_nt99050",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap1_nt99050_match_table),
+	},
+	.probe    = sensor1_probe,
+	.remove   = sensor1_remove,
+	.id_table = sensor1_id,
+};
+module_i2c_driver(sensor1_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_nt99141.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_nt99141.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_nt99141.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_nt99141.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,239 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap1_nt99141;
+
+struct OV_RegValue {
+	__u16   uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct OV_RegValue)
+/* NT99141, VGA, YUV422 */
+static struct OV_RegValue Init_RegValue[] = {
+	//{0x3021, 0x60},
+#if 1
+	/* [Inti] */
+	{0x3109, 0x04},{0x3040, 0x04},{0x3041, 0x02},{0x3042, 0xFF},{0x3043, 0x08},
+	{0x3052, 0xE0},{0x305F, 0x33},{0x3100, 0x07},{0x3106, 0x03},
+	{0x3108, 0x00},{0x3110, 0x22},{0x3111, 0x57},{0x3112, 0x22},{0x3113, 0x55},
+	{0x3114, 0x05},{0x3135, 0x00},{0x32F0, 0x01},{0x306a,0x01},
+	// Initial AWB Gain */
+	{0x3290, 0x01},{0x3291, 0x80},{0x3296, 0x01},{0x3297, 0x73},
+	/* CA Ratio */
+	{0x3250, 0x80},{0x3251, 0x03},{0x3252, 0xFF},{0x3253, 0x00},{0x3254, 0x03},
+	{0x3255, 0xFF},{0x3256, 0x00},{0x3257, 0x50},
+	/* Gamma */
+	{0x3270, 0x00},{0x3271, 0x0C},{0x3272, 0x18},{0x3273, 0x32},{0x3274, 0x44},
+	{0x3275, 0x54},{0x3276, 0x70},{0x3277, 0x88},{0x3278, 0x9D},{0x3279, 0xB0},
+	{0x327A, 0xCF},{0x327B, 0xE2},{0x327C, 0xEF},{0x327D, 0xF7},{0x327E, 0xFF},
+	/* Color Correction */
+	{0x3302, 0x00},{0x3303, 0x40},{0x3304, 0x00},{0x3305, 0x96},{0x3306, 0x00},
+	{0x3307, 0x29},{0x3308, 0x07},{0x3309, 0xBA},{0x330A, 0x06},{0x330B, 0xF5},
+	{0x330C, 0x01},{0x330D, 0x51},{0x330E, 0x01},{0x330F, 0x30},{0x3310, 0x07},
+	{0x3311, 0x16},{0x3312, 0x07},{0x3313, 0xBA},
+	/* EExt */
+	{0x3326, 0x02},{0x32F6, 0x0F},{0x32F9, 0x42},{0x32FA, 0x24},{0x3325, 0x4A},
+	{0x3330, 0x00},{0x3331, 0x0A},{0x3332, 0xFF},{0x3338, 0x30},{0x3339, 0x84},
+	{0x333A, 0x48},{0x333F, 0x07},
+	/* Auto Function */
+	{0x3360, 0x10},{0x3361, 0x18},{0x3362, 0x1f},{0x3363, 0x37},{0x3364, 0x80},
+	{0x3365, 0x80},{0x3366, 0x68},{0x3367, 0x60},{0x3368, 0x30},{0x3369, 0x28},
+	{0x336A, 0x20},{0x336B, 0x10},{0x336C, 0x00},{0x336D, 0x20},{0x336E, 0x1C},
+	{0x336F, 0x18},{0x3370, 0x10},{0x3371, 0x38},{0x3372, 0x3C},{0x3373, 0x3F},
+	{0x3374, 0x3F},{0x338A, 0x34},{0x338B, 0x7F},{0x338C, 0x10},{0x338D, 0x23},
+	{0x338E, 0x7F},{0x338F, 0x14},{0x3375, 0x0A},{0x3376, 0x0C},{0x3377, 0x10},
+	{0x3378, 0x14},
+	{0x3012, 0x02},{0x3013, 0xD0},{0x3060, 0x01},
+#endif
+	/* [YUYV_640x480_25_Fps]---MCLK:12M hz PCLK:24M hz */
+	{0x32BF, 0x60},{0x32C0, 0x60},{0x32C1, 0x60},{0x32C2, 0x60},{0x32C3, 0x00},
+	{0x32C4, 0x20},{0x32C5, 0x20},{0x32C6, 0x20},{0x32C7, 0x00},{0x32C8, 0xB3},
+	{0x32C9, 0x60},{0x32CA, 0x80},{0x32CB, 0x80},{0x32CC, 0x80},{0x32CD, 0x80},
+	{0x32DB, 0x76},{0x32E0, 0x02},{0x32E1, 0x80},{0x32E2, 0x01},{0x32E3, 0xE0},
+	{0x32E4, 0x00},{0x32E5, 0x80},{0x32E6, 0x00},{0x32E7, 0x80},{0x3200, 0x3E},
+	{0x3201, 0x0F},{0x3028, 0x07},{0x3029, 0x00},{0x302A, 0x14},{0x3022, 0x25},
+	{0x3023, 0x24},{0x3002, 0x00},{0x3003, 0xA4},{0x3004, 0x00},{0x3005, 0x04},
+	{0x3006, 0x04},{0x3007, 0x63},{0x3008, 0x02},{0x3009, 0xD3},{0x300A, 0x05},
+	{0x300B, 0x3C},{0x300C, 0x02},{0x300D, 0xE1},{0x300E, 0x03},{0x300F, 0xC0},
+	{0x3010, 0x02},{0x3011, 0xD0},{0x32B8, 0x3F},{0x32B9, 0x31},{0x32BB, 0x87},
+	{0x32BC, 0x38},{0x32BD, 0x3C},{0x32BE, 0x34},{0x3201, 0x7F},{0x3021, 0x06},
+	{0x3060, 0x01},//{0x302A, 0x04},{0x3021, 0x00},{0x3021, 0x66},
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client1;
+static char sensor1_inited = 0;
+
+#ifndef DISALBE_READ_ID
+static int sensor1_read_nt99141(u16 reg,u8 *val)
+{
+	int ret;
+	/* We have 16-bit i2c addresses - care for endianess */
+	unsigned char data[2] = { reg >> 8, reg & 0xff };
+
+	ret = i2c_master_send(save_client1, data, 2);
+	if (ret < 2) {
+		dev_err(&save_client1->dev, "%s: i2c read error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	ret = i2c_master_recv(save_client1, val, 1);
+	if (ret < 1) {
+		dev_err(&save_client1->dev, "%s: i2c read error, reg: 0x%x\n",__func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+	return 0;
+}
+#endif
+
+static int sensor1_write_nt99141(u16 reg, u8 val)
+{
+	int ret;
+	unsigned char data[3] = { reg >> 8, reg & 0xff, val };
+
+	ret = i2c_master_send(save_client1, data, 3);
+	if (ret < 3) {
+		dev_err(&save_client1->dev, "%s: i2c write error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	return 0;
+}
+
+static int sensor1_probe(struct i2c_client *client,const struct i2c_device_id *id)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap1_nt99141.i2c_id || client->addr != 0x2a)
+		return -ENODEV;
+	sensor1_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client1 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor1_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap1_nt99141_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap1_nt99141 = {
+	.i2c_id = 1,
+	.name = "cap1_nt99141",
+	.init = &cap1_nt99141_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_LO | HSP_LO | PCLKP_HI),
+	.cropstart = ( 0 | 0<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin1_probe_nt99141(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[2];
+#endif
+	struct OV_RegValue *psRegValue;
+
+	ENTRY();
+
+	nuvoton_vin1_attach_sensor(cam, &cap1_nt99141);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor1_inited)
+		return -1;
+
+	psRegValue=Init_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Init_RegValue); i++, psRegValue++) {
+		printk(".");
+		ret = sensor1_write_nt99141((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+	}
+
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	sensor1_read_nt99141(0x3000,&SensorID[0]);  /* Chip_Version_H 0x14 */
+	sensor1_read_nt99141(0x3001,&SensorID[1]);  /* Chip_Version_L 0x10 */
+	printk("\nSensor Chip_Version_H = 0x%02x(0x14) Chip_Version_L = 0x%02x(0x10)\n", SensorID[0],SensorID[1]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+static const struct i2c_device_id sensor1_id[] = {
+	{ "cap1_nt99141", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor1_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap1_nt99141_match_table[] = {
+	{ .compatible = "nuvoton,cap1-nt99141",},
+	{},
+};
+#else
+#define cap1_nt99141_match_table NULL
+#endif
+
+static struct i2c_driver sensor1_i2c_driver = {
+	.driver = {
+		.name = "cap1_nt99141",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap1_nt99141_match_table),
+	},
+	.probe    = sensor1_probe,
+	.remove   = sensor1_remove,
+	.id_table = sensor1_id,
+};
+module_i2c_driver(sensor1_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_ov5640.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_ov5640.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_ov5640.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_ov5640.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,316 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap1_ov5640;
+
+struct OV_RegValue {
+	__u16   uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct OV_RegValue)
+
+static struct OV_RegValue Init_RegValue[] = {
+	{0x3103, 0x11},{0x3008, 0x82},{0x3008, 0x42},{0x3103, 0x03},{0x3017, 0xff},
+	{0x3018, 0xff},{0x3034, 0x1a},{0x3035, 0x11},{0x3036, 0x46},
+	{0x3037, 0x03},  //PLL div=1,2,3,4,6,8
+	{0x3108, 0x01},{0x3630, 0x2e},{0x3632, 0xe2},{0x3633, 0x23},{0x3621, 0xe0},
+	{0x3704, 0xa0},{0x3703, 0x5a},{0x3715, 0x78},{0x3717, 0x01},{0x370b, 0x60},
+	{0x3705, 0x1a},{0x3905, 0x02},{0x3906, 0x10},{0x3901, 0x0a},{0x3731, 0x12},
+	{0x3600, 0x08},{0x3601, 0x33},{0x302d, 0x60},{0x3620, 0x52},{0x371b, 0x20},
+	{0x471c, 0x50},{0x3a18, 0x00},{0x3a19, 0xf8},{0x3635, 0x1c},{0x3634, 0x40},
+	{0x3622, 0x01},{0x3c01, 0x34},{0x3c04, 0x28},{0x3c05, 0x98},{0x3c06, 0x00},
+	{0x3c07, 0x08},{0x3c08, 0x00},{0x3c09, 0x1c},{0x3c0a, 0x9c},{0x3c0b, 0x40},
+	{0x3820, 0x41},{0x3821, 0x07},{0x3814, 0x31},{0x3815, 0x31},{0x3800, 0x00},
+	{0x3801, 0x00},{0x3802, 0x00},{0x3803, 0x04},{0x3804, 0x0a},{0x3805, 0x3f},
+	{0x3806, 0x07},{0x3807, 0x9b},{0x3808, 0x02}, // width
+	{0x3809, 0x80},{0x380a, 0x01}, // height
+	{0x380b, 0xe0},{0x380c, 0x07},{0x380d, 0x68},{0x380e, 0x03},{0x380f, 0xd8},
+	{0x3810, 0x00},{0x3811, 0x10},{0x3812, 0x00},{0x3813, 0x06},{0x3618, 0x00},
+	{0x3612, 0x29},{0x3708, 0x62},{0x3709, 0x52},{0x370c, 0x03},{0x3a02, 0x03},
+	{0x3a03, 0xd8},{0x3a08, 0x01},{0x3a09, 0x27},{0x3a0a, 0x00},{0x3a0b, 0xf6},
+	{0x3a0e, 0x03},{0x3a0d, 0x04},{0x3a14, 0x03},{0x3a15, 0xd8},{0x4001, 0x02},
+	{0x4004, 0x02},{0x3000, 0x00},{0x3002, 0x1c},{0x3004, 0xff},{0x3006, 0xc3},
+	{0x300e, 0x58},{0x302e, 0x00},{0x4300, 0x30},{0x501f, 0x00},{0x4713, 0x03},
+	{0x4407, 0x04},{0x460b, 0x35},{0x460c, 0x22},{0x3824, 0x02},{0x5000, 0xa7},
+	{0x5001, 0xa3},{0x5180, 0xff},{0x5181, 0xf2},{0x5182, 0x00},{0x5183, 0x14},
+	{0x5184, 0x25},{0x5185, 0x24},{0x5186, 0x09},{0x5187, 0x09},{0x5188, 0x09},
+	{0x5189, 0x75},{0x518a, 0x54},{0x518b, 0xe0},{0x518c, 0xb2},{0x518d, 0x42},
+	{0x518e, 0x3d},{0x518f, 0x56},{0x5190, 0x46},{0x5191, 0xf8},{0x5192, 0x04},
+	{0x5193, 0x70},{0x5194, 0xf0},{0x5195, 0xf0},{0x5196, 0x03},{0x5197, 0x01},
+	{0x5198, 0x04},{0x5199, 0x12},{0x519a, 0x04},{0x519b, 0x00},{0x519c, 0x06},
+	{0x519d, 0x82},{0x519e, 0x38},{0x5381, 0x1c},{0x5382, 0x5a},{0x5383, 0x06},
+	{0x5384, 0x0a},{0x5385, 0x7e},{0x5386, 0x88},{0x5387, 0x7c},{0x5388, 0x6c},
+	{0x5389, 0x10},{0x538a, 0x01},{0x538b, 0x98},{0x5300, 0x08},{0x5301, 0x30},
+	{0x5302, 0x10},{0x5303, 0x00},{0x5304, 0x08},{0x5305, 0x30},{0x5306, 0x08},
+	{0x5307, 0x16},{0x5309, 0x08},{0x530a, 0x30},{0x530b, 0x04},{0x530c, 0x06},
+	{0x5480, 0x01},{0x5481, 0x08},{0x5482, 0x14},{0x5483, 0x28},{0x5484, 0x51},
+	{0x5485, 0x65},{0x5486, 0x71},{0x5487, 0x7d},{0x5488, 0x87},{0x5489, 0x91},
+	{0x548a, 0x9a},{0x548b, 0xaa},{0x548c, 0xb8},{0x548d, 0xcd},{0x548e, 0xdd},
+	{0x548f, 0xea},{0x5490, 0x1d},{0x5580, 0x02},{0x5583, 0x40},{0x5584, 0x10},
+	{0x5589, 0x10},{0x558a, 0x00},{0x558b, 0xf8},{0x5800, 0x23},{0x5801, 0x15},
+	{0x5802, 0x10},{0x5803, 0x10},{0x5804, 0x15},{0x5805, 0x23},{0x5806, 0x0c},
+	{0x5807, 0x08},{0x5808, 0x05},{0x5809, 0x05},{0x580a, 0x08},{0x580b, 0x0c},
+	{0x580c, 0x07},{0x580d, 0x03},{0x580e, 0x00},{0x580f, 0x00},{0x5810, 0x03},
+	{0x5811, 0x07},{0x5812, 0x07},{0x5813, 0x03},{0x5814, 0x00},{0x5815, 0x00},
+	{0x5816, 0x03},{0x5817, 0x07},{0x5818, 0x0b},{0x5819, 0x08},{0x581a, 0x05},
+	{0x581b, 0x05},{0x581c, 0x07},{0x581d, 0x0b},{0x581e, 0x2a},{0x581f, 0x16},
+	{0x5820, 0x11},{0x5821, 0x11},{0x5822, 0x15},{0x5823, 0x29},{0x5824, 0xbf},
+	{0x5825, 0xaf},{0x5826, 0x9f},{0x5827, 0xaf},{0x5828, 0xdf},{0x5829, 0x6f},
+	{0x582a, 0x8e},{0x582b, 0xab},{0x582c, 0x9e},{0x582d, 0x7f},{0x582e, 0x4f},
+	{0x582f, 0x89},{0x5830, 0x86},{0x5831, 0x98},{0x5832, 0x6f},{0x5833, 0x4f},
+	{0x5834, 0x6e},{0x5835, 0x7b},{0x5836, 0x7e},{0x5837, 0x6f},{0x5838, 0xde},
+	{0x5839, 0xbf},{0x583a, 0x9f},{0x583b, 0xbf},{0x583c, 0xec},{0x5025, 0x00},
+	{0x3a0f, 0x30},{0x3a10, 0x28},{0x3a1b, 0x30},{0x3a1e, 0x26},{0x3a11, 0x60},
+	{0x3a1f, 0x14},{0x3008, 0x02},
+};
+
+static struct OV_RegValue VGA_RegValue[] = {
+	{0x3035, 0x11},{0x3036, 0x69},{0x3C07, 0x07},{0x3820, 0x41},{0x3821, 0x07},
+	{0x3814, 0x31},{0x3815, 0x31},{0x3800, 0x00},{0x3801, 0x00},{0x3802, 0x00},
+	{0x3803, 0x00},{0x3804, 0x0a},{0x3805, 0x3f},{0x3806, 0x07},{0x3807, 0x9f},
+	{0x3808, 0x02}, // width
+	{0x3809, 0x80},
+	{0x380A, 0x01}, // height
+	{0x380B, 0xE1},{0x380C, 0x0B},{0x380D, 0x1C},{0x380E, 0x07},{0x380F, 0x9F},
+	{0x3810, 0x00},{0x3811, 0x10},{0x3812, 0x00},{0x3813, 0x06},{0x3618, 0x00},
+	{0x3612, 0x29},{0x3708, 0x64}, //{0x3708, 0x62},
+	{0x3709, 0x52},{0x370C, 0x03},
+	{0x3A02, 0x03}, //{0x3A02, 0x02},
+	{0x3A03, 0xd8}, //{0x3A03, 0xe4},
+	{0x3A0E, 0x01},
+	{0x3A0D, 0x04}, //{0x3A0D, 0x02},
+	{0x3A14, 0x03}, //{0x3A14, 0x02},
+	{0x3A15, 0xd8}, //{0x3A15, 0xe4},
+	{0x4004, 0x02},
+	{0x4713, 0x03}, //{0x4713, 0x02},
+	{0x4407, 0x04},
+	{0x460B, 0x35}, //{0x460B, 0x37},
+	{0x460C, 0x22}, //{0x460C, 0x20},
+	{0x3824, 0x02}, //{0x3824, 0x04},
+	{0x5001, 0xa3},{0x5180, 0xff},{0x5181, 0xf2},{0x5182, 0x00},{0x5183, 0x14},
+	{0x5184, 0x25},{0x5185, 0x24},{0x5186, 0x09},{0x5187, 0x09},{0x5188, 0x09},
+	{0x5189, 0x75},{0x518a ,0x54},{0x518b, 0xe0},{0x518c, 0xb2},{0x518d, 0x42},
+	{0x518e, 0x3d},{0x518f, 0x56},{0x3008, 0x02},{0x3035, 0x31},{0x3821, 0x07},
+	{0x3002, 0x1c},{0x3006, 0xc3},{0x4713, 0x02},{0x4407, 0x04},{0x460b, 0x37},
+	{0x460c, 0x20},{0x3824, 0x04},{0x4003, 0x08},
+	// Gamma
+	{0x5481, 0x0F},{0x5482, 0x1E},{0x5483, 0x3A},{0x5484, 0x62},{0x5485, 0x74},
+	{0x5486, 0x82},{0x5487, 0x8E},{0x5488, 0x98},{0x5489, 0xA0},{0x548a, 0xA7},
+	{0x548b, 0xB5},{0x548c, 0xC0},{0x548d, 0xD2},{0x548e, 0xE1},{0x548f, 0xED},
+	{0x5490, 0x19},
+	// Color Matrix
+	{0x5381, 0x1c},{0x5382, 0x5a},{0x5383, 0x06},{0x5384, 0x20},{0x5385, 0x80},
+	{0x5386, 0xa0},{0x5387, 0xa2},{0x5388, 0xa0},{0x5389, 0x02},{0x538b, 0x98},
+	{0x538a, 0x01},
+	// Saturation
+	{0x5001, 0xa3},{0x5583, 0x30},{0x5584, 0x30},{0x5580, 0x02},{0x5588, 0x41},
+	// AEC
+	{0x3a0f, 0x40},{0x3a10, 0x38},{0x3a11, 0x71},{0x3a1b, 0x40},{0x3a1e, 0x38},
+	{0x3a1f, 0x10},
+	// AEC Weight
+//  {0x5688, 0x11}, // Zone 1/Zone 0 weight
+//  {0x5689, 0x11}, // Zone 3/Zone 2 weight
+//  {0x569a, 0x31}, // Zone 5/Zone 4 weight
+//  {0x569b, 0x13}, // Zone 7/Zone 6 weight
+//  {0x569c, 0x31}, // Zone 9/Zone 8 weight
+//  {0x569d, 0x13}, // Zone b/Zone a weight
+//  {0x569e, 0x11}, // Zone d/Zone c weight
+//  {0x569f, 0x11}, // Zone f/Zone e weight
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client1;
+static char sensor1_inited = 0;
+#ifndef DISALBE_READ_ID
+static int sensor1_read_ov5640(u16 reg,u8 *val)
+{
+	int ret;
+	/* We have 16-bit i2c addresses - care for endianess */
+	unsigned char data[2] = { reg >> 8, reg & 0xff };
+
+	ret = i2c_master_send(save_client1, data, 2);
+	if (ret < 2) {
+		dev_err(&save_client1->dev, "%s: i2c read error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	ret = i2c_master_recv(save_client1, val, 1);
+	if (ret < 1) {
+		dev_err(&save_client1->dev, "%s: i2c read error, reg: 0x%x\n",__func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+	return 0;
+}
+#endif
+
+static int sensor1_write_ov5640(u16 reg, u8 val)
+{
+	int ret;
+	unsigned char data[3] = { reg >> 8, reg & 0xff, val };
+
+	ret = i2c_master_send(save_client1, data, 3);
+	if (ret < 3) {
+		dev_err(&save_client1->dev, "%s: i2c write error, reg: 0x%x\n",
+		        __func__, reg);
+		return ret < 0 ? ret : -EIO;
+	}
+
+	return 0;
+}
+
+static int sensor1_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap1_ov5640.i2c_id || client->addr != 0x3C)
+		return -ENODEV;
+	sensor1_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client1 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor1_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap1_ov5640_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap1_ov5640 = {
+	.i2c_id = 1,
+	.name = "cap1_ov5640",
+	.init = &cap1_ov5640_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_HI | HSP_LO | PCLKP_HI),
+	.cropstart = ( 1 | 0<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin1_probe_ov5640(struct nuvoton_vin_device* cam)
+{
+	int i,j,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[1];
+#endif
+	struct OV_RegValue *psRegValue;
+	struct OV_RegValue *psRegValue1;
+	ENTRY();
+
+
+	nuvoton_vin1_attach_sensor(cam, &cap1_ov5640);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor1_inited)
+		return -1;
+	psRegValue=Init_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Init_RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor1_write_ov5640((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+		if(psRegValue->uRegAddr==0x3008  && psRegValue->uValue==0x82) {
+			for(j=0; j<0x20000; j++);
+			VDEBUG("Delay A loop for Reset Device\n");
+		}
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+		}
+	}
+
+	psRegValue1=VGA_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(VGA_RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor1_write_ov5640((psRegValue1->uRegAddr), (psRegValue1->uValue));
+		udelay(200);
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue1->uRegAddr), (psRegValue1->uValue), ret);
+		}
+	}
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	sensor1_read_ov5640(0x302A,SensorID);  /* Chip Version 0xB0 */
+	printk("Chip Version = 0x%02X(0xB0) \n", SensorID[0]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+
+static const struct i2c_device_id sensor1_id[] = {
+	{ "cap1_ov5640", 0 },
+
+};
+MODULE_DEVICE_TABLE(i2c, sensor1_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap1_ov5640_match_table[] = {
+	{ .compatible = "nuvoton,cap1-ov5640",},
+	{},
+};
+#else
+#define cap1_ov5640_match_table NULL
+#endif
+
+
+static struct i2c_driver sensor1_i2c_driver = {
+	.driver = {
+		.name  = "cap1_ov5640",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap1_ov5640_match_table),
+	},
+	.probe    = sensor1_probe,
+	.remove   = sensor1_remove,
+	.id_table = sensor1_id,
+};
+module_i2c_driver(sensor1_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_ov7725.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_ov7725.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_ov7725.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_ov7725.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,191 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap1_ov7725;
+
+struct OV_RegValue {
+	__u8    uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct OV_RegValue)
+
+static struct OV_RegValue RegValue[] = {
+	{0x12, 0x80}, {0x12, 0x00}, {0x3D, 0x03}, {0x17, 0x22}, {0x18, 0xA4},
+	{0x19, 0x07}, {0x1A, 0xF0}, {0x32, 0x02}, {0x29, 0xA0}, {0x2C, 0xF0},
+	{0x2A, 0x02}, {0x65, 0x20}, {0x11, 0x01}, {0x42, 0x7F}, {0x63, 0xE0},
+	{0x64, 0xFF}, {0x66, 0x00}, {0x67, 0x48}, {0x0D, 0x41}, {0x0E, 0x01},
+	{0x0F, 0xC5}, {0x14, 0x11}, {0x22, 0x7F}, {0x23, 0x03}, {0x24, 0x40},
+	{0x25, 0x30}, {0x26, 0xA1}, {0x2B, 0x00}, {0x6B, 0xAA}, {0x13, 0xEF},
+	{0x90, 0x05}, {0x91, 0x01}, {0x92, 0x03}, {0x93, 0x00}, {0x94, 0x90},
+	{0x95, 0x8A}, {0x96, 0x06}, {0x97, 0x0B}, {0x98, 0x95}, {0x99, 0xA0},
+	{0x9A, 0x1E}, {0x9B, 0x08}, {0x9C, 0x20}, {0x9E, 0x81}, {0xA6, 0x04},
+	{0x7E, 0x0C}, {0x7F, 0x24}, {0x80, 0x3A}, {0x81, 0x60}, {0x82, 0x70},
+	{0x83, 0x7E}, {0x84, 0x8A}, {0x85, 0x94}, {0x86, 0x9E}, {0x87, 0xA8},
+	{0x88, 0xB4}, {0x89, 0xBE}, {0x8A, 0xCA}, {0x8B, 0xD8}, {0x8C, 0xE2},
+	{0x8D, 0x28}, {0x46, 0x05}, {0x47, 0x00}, {0x48, 0x00}, {0x49, 0x12},
+	{0x4A, 0x00}, {0x4B, 0x13}, {0x4C, 0x21}, {0x0C, 0x10}, {0x09, 0x00},
+	{0xFF, 0xFF}, {0xFF, 0xFF}
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client1;
+static char sensor1_inited = 0;
+#ifndef DISALBE_READ_ID
+__u8 sensor1_read_ov7725(__u8 uRegAddr)
+{
+	u8 val;
+	//printk("sensor_read_ov7725 i2c_smbus_read_byte uRegAddr=0x%x\n",uRegAddr);
+	i2c_smbus_write_byte(save_client1, uRegAddr);
+	//printk("sensor_read_ov7725 i2c_smbus_write_byte\n");
+	val = i2c_smbus_read_byte(save_client1);
+	return val;
+}
+#endif
+
+static int32_t sensor_write_ov7725(__u8 uRegAddr, __u8 uData)
+{
+	int ret;
+	ret=i2c_smbus_write_byte_data(save_client1, uRegAddr, uData);
+	return ret;
+}
+
+static int sensor1_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap1_ov7725.i2c_id || client->addr != 0x21)
+		return -ENODEV;
+	sensor1_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client1 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor1_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap1_ov7725_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+static struct nuvoton_vin_sensor cap1_ov7725 = {
+	.i2c_id = 1,
+	.name = "cap1_ov7725",
+	.init = &cap1_ov7725_init,
+	.infmtord = (INORD_YUYV | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_HI | HSP_LO | PCLKP_HI),
+	.cropstart = ( 0 | 2<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = 0,
+			.top = 0,
+			.width = 640,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 640,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin1_probe_ov7725(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[4];
+#endif
+	struct OV_RegValue *psRegValue;
+	ENTRY();
+
+	nuvoton_vin1_attach_sensor(cam, &cap1_ov7725);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor1_inited)
+		return -1;
+
+	psRegValue=RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor_write_ov7725((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+		}
+	}
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	SensorID[0]=sensor1_read_ov7725(0x0A);  /* PID 0x77 */
+	SensorID[1]=sensor1_read_ov7725(0x0B);  /* VER 0x21 */
+	SensorID[2]=sensor1_read_ov7725(0x1C);  /* Manufacturer ID Byte - High  0x7F */
+	SensorID[3]=sensor1_read_ov7725(0x1D);  /* Manufacturer ID Byte - Low   0xA2 */
+	printk("Sensor PID = 0x%02x(0x77) VER = 0x%02x(0x21) MIDH = 0x%02x(0x7F) MIDL = 0x%02x(0xA2)\n", SensorID[0],SensorID[1],SensorID[2],SensorID[3]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+
+static const struct i2c_device_id sensor1_id[] = {
+	{ "cap1_ov7725", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor1_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap1_ov7725_match_table[] = {
+	{ .compatible = "nuvoton,cap1-ov7725",},
+	{},
+};
+#else
+#define cap1_ov7725_match_table NULL
+#endif
+
+static struct i2c_driver sensor1_i2c_driver = {
+	.driver = {
+		.name  = "cap1_ov7725",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap1_ov7725_match_table),
+	},
+	.probe    = sensor1_probe,
+	.remove   = sensor1_remove,
+	.id_table = sensor1_id,
+};
+module_i2c_driver(sensor1_i2c_driver);
diff -uprN linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_tw9912.c NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_tw9912.c
--- linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_tw9912.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/media/i2c/nuvoton/sensor1_tw9912.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,280 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include "nuc980_cap.h"
+
+//#define DISALBE_READ_ID
+
+static struct nuvoton_vin_sensor cap1_tw9912;
+
+struct TW_RegValue {
+	__u8    uRegAddr;
+	__u8    uValue;
+};
+
+#define _REG_TABLE_SIZE(nTableName) sizeof(nTableName)/sizeof(struct TW_RegValue)
+
+static struct TW_RegValue Init_RegValue[] = {
+	//NTSC INIT
+	{0x88, 0x14},{0x02, 0x48},//From YIN2
+	{0x03, 0x20},{0x05, 0x01},{0x07, 0x02},{0x08, 0x12},{0x09, 0xF0},
+	{0x0A, 0x14},{0x0B, 0xD0},{0x0C, 0xCC},{0x11, 0x64},{0x1C, 0x0F},
+	{0x1E, 0x08},{0x27, 0x38},{0x30, 0x00},{0x37, 0x28},{0x38, 0xAF},
+	{0xC0, 0x01},{0xC2, 0x01},{0xC3, 0x03},{0xC4, 0x5A},{0xC5, 0x00},
+	{0xC6, 0x20},{0xCB, 0x30},{0xCC, 0x00},{0xD7, 0x70},{0xD9, 0x04},
+	{0xE1, 0x05},{0xE2, 0xD9},{0xE6, 0x00},{0xE8, 0x0F},{0xE9, 0x00},
+};
+
+static struct TW_RegValue Output_RegValue[] = {
+#if 1 //NTSC PRO
+	{0x88, 0x02},
+	{0x02, 0x48},//From YIN2
+	{0x03, 0x20},//add
+	{0x04, 0x00},{0x05, 0x1E},{0x06, 0x03},
+	//{0x08, 0x0A},//{0x08, 0x12},
+	//{0x08, 0x17},
+#if 0
+	{0x07, 0x12},//{0x07, 0x02},                    /* Fix insufficient 480 horizontal line */
+	{0x09, 0x05},//{0x09, 0xFC},//{0x09, 0xF0},     /* Fix insufficient 480 horizontal line */
+#else
+	//{0x07, 0x12},//{0x07, 0x02},                  /* Fix insufficient 480 horizontal line */
+	//{0x09, 0x40},//{0x09, 0xFC},//{0x09, 0xF0},       /* Fix insufficient 480 horizontal line */
+	//D1 TRY
+	//{0x07, 0x03},
+	//{0x09, 0xF0},
+#endif
+	//{0x0A, 0x49},
+	//{0x0B, 0x34},
+	//{0x0C, 0xCC},
+	{0x07, 0x02},{0x08, 0x14},{0x09, 0xF9},{0x0A, 0x2b},{0x0B, 0xf4},
+	{0x0C, 0xDC},{0x0D, 0x15},{0x11, 0x64},{0x12, 0x11},{0x13, 0x80},
+	{0x14, 0x80},{0x15, 0x00},{0x17, 0x30},{0x18, 0x44},{0x1A, 0x10},
+	{0x1B, 0x00},{0x1C, 0x0F},{0x1D, 0x7F},{0x1E, 0x08},{0x1F, 0x00},
+	{0x20, 0x50},{0x21, 0x42},{0x22, 0xF0},{0x23, 0xD8},{0x24, 0xBC},
+	{0x25, 0xB8},{0x26, 0x44},{0x27, 0x38},{0x28, 0x00},{0x29, 0x00},
+	{0x2A, 0x78},{0x2B, 0x44},{0x2C, 0x30},{0x2D, 0x14},{0x2E, 0xA5},
+	{0x2F, 0x26},{0x30, 0x00},{0x31, 0x10},{0x32, 0x00},{0x33, 0x05},
+	{0x34, 0x1A},{0x35, 0x00},{0x36, 0xe2},
+	{0x37, 0x01}, //D1
+	//{0x37, 0x2D}, //VGA
+	{0x38, 0x01},{0x40, 0x00},{0x41, 0x80},{0x42, 0x00},{0xC0, 0x01},
+	{0xC1, 0x07},{0xC2, 0x01},{0xC3, 0x03},{0xC4, 0x5A},{0xC5, 0x00},
+	{0xC6, 0x20},{0xC7, 0x04},{0xC8, 0x00},{0xC9, 0x06},{0xCA, 0x06},
+	{0xCB, 0x30},{0xCC, 0x00},{0xCD, 0x54},{0xD0, 0x00},{0xD1, 0xF0},
+	{0xD2, 0xF0},{0xD3, 0xF0},{0xD4, 0x00},{0xD5, 0x00},{0xD6, 0x10},
+	{0xD7, 0x70},{0xD8, 0x00},{0xD9, 0x04},{0xDA, 0x80},{0xDB, 0x80},
+	{0xDC, 0x20},{0xE0, 0x00},{0xE1, 0x49},{0xE2, 0xD9},{0xE3, 0x00},
+	{0xE4, 0x00},{0xE5, 0x00},{0xE6, 0x00},{0xE7, 0x2A},{0xE8, 0x0F},
+	{0xE9, 0x6D},//{0xE9, 0x61},
+//  {0x2F, 0x8B} /* test mode force blue */
+
+#else //PAL
+
+	{0xFF, 0x00},//Page 0
+	//{0x88, 0x02}, //mark by paul's new sensor table
+	{0x01, 0x79},{0x02, 0x48},//From YIN2
+	//{0x02, 0x40},//From YIN0
+	{0x03, 0x20},//add
+	{0x04, 0x00},{0x05, 0x1E},{0x06, 0x03},
+	//D1 TRY
+	{0x07, 0x12},{0x08, 0x14},{0x09, 0x20},{0x0A, 0x26},{0x0B, 0xFE},
+//  {0x07, 0x12},
+//  {0x08, 0x14},
+//  {0x09, 0x20},
+//  {0x0A, 0x0E},
+//  {0x0B, 0xD0},
+	{0x0C, 0xCC},{0x0D, 0x15},{0x11, 0x64},{0x12, 0x11},{0x13, 0x80},
+	{0x14, 0x80},{0x15, 0x00},{0x17, 0x30},{0x18, 0x44},{0x1A, 0x10},
+	{0x1B, 0x00},{0x1C, 0x1F},//{0x1C, 0x0F},
+	{0x1D, 0x7F},{0x1E, 0x18},//{0x1E, 0x08},
+	{0x1F, 0x00},{0x20, 0x50},{0x21, 0x42},{0x22, 0xF0},{0x23, 0xD8},
+	{0x24, 0xBC},{0x25, 0xB8},{0x26, 0x44},{0x27, 0x38},{0x28, 0x00},
+	{0x29, 0x00},{0x2A, 0x78},{0x2B, 0x44},{0x2C, 0x30},{0x2D, 0x14},
+	{0x2E, 0xA5},{0x2F, 0x26},{0x30, 0x00},{0x31, 0x10},{0x32, 0x00},
+	{0x33, 0x05},{0x34, 0x1A},{0x35, 0x00},{0x36, 0xe2},
+//  {0x37, 0x2D},//VGA
+	{0x37, 0x01},//D1
+	{0x38, 0x01},{0x40, 0x00},{0x41, 0x80},{0x42, 0x00},{0xC0, 0x01},
+	{0xC1, 0x07},{0xC2, 0x01},{0xC3, 0x03},{0xC4, 0x5A},{0xC5, 0x00},
+	{0xC6, 0x20},{0xC7, 0x04},{0xC8, 0x00},{0xC9, 0x06},{0xCA, 0x06},
+	{0xCB, 0x30},{0xCC, 0x00},{0xCD, 0x54},{0xD0, 0x00},{0xD1, 0xF0},
+	{0xD2, 0xF0},{0xD3, 0xF0},{0xD4, 0x00},{0xD5, 0x00},{0xD6, 0x10},
+	{0xD7, 0x70},{0xD8, 0x00},{0xD9, 0x04},{0xDA, 0x80},{0xDB, 0x80},
+	{0xDC, 0x20},{0xE0, 0x00},{0xE1, 0x49},{0xE2, 0xD9},{0xE3, 0x00},
+	{0xE4, 0x00},{0xE5, 0x00},{0xE6, 0x00},{0xE8, 0x0F},{0xE9, 0x6D},
+	//{0xE9, 0x61},
+	//{0xff, 0xff}
+#endif
+};
+
+/************  I2C  *****************/
+static struct i2c_client *save_client1;
+static char sensor1_inited = 0;
+#ifndef DISALBE_READ_ID
+__u8 sensor_read_tw9912(__u8 uRegAddr)
+{
+	u8 val;
+	//printk("sensor_read_tw9912 i2c_smbus_read_byte uRegAddr=0x%x\n",uRegAddr);
+	i2c_smbus_write_byte(save_client1, uRegAddr);
+	//printk("sensor_read_tw9912 i2c_smbus_write_byte\n");
+	val = i2c_smbus_read_byte(save_client1);
+	return val;
+}
+#endif
+
+static int32_t sensor_write_tw9912(__u8 uRegAddr, __u8 uData)
+{
+	int ret;
+	ret=i2c_smbus_write_byte_data(save_client1, uRegAddr, uData);
+	return ret;
+}
+
+static int sensor1_probe(struct i2c_client *client,const struct i2c_device_id *did)
+{
+	ENTRY();
+	if(i2c_adapter_id(client->adapter) != cap1_tw9912.i2c_id)
+		return -ENODEV;
+	sensor1_inited = 1;
+	client->flags = I2C_CLIENT_SCCB;
+	save_client1 = client;
+	LEAVE();
+	return 0;
+}
+static int sensor1_remove(struct i2c_client *client)
+{
+	ENTRY();
+	LEAVE();
+	return 0;
+}
+
+static int cap1_tw9912_init(struct nuvoton_vin_device* cam)
+{
+	int err = 0;
+	ENTRY();
+	LEAVE();
+	return err;
+}
+
+#if 1 //NTSC
+#define CROP_START_X    0x24
+#define CROP_START_Y    0x28
+#endif
+static struct nuvoton_vin_sensor cap1_tw9912 = {
+	.i2c_id = 1,
+	.name = "cap1_tw9912",
+	.init = &cap1_tw9912_init,
+	.infmtord = (INORD_YVYU | INFMT_YCbCr | INTYPE_CCIR601),
+	.polarity = (VSP_LO | HSP_LO | PCLKP_HI),
+	.cropstart = ( CROP_START_Y | CROP_START_X<<16 ), /*( Vertical | Horizontal<<16 ) */
+	.cropcap = {
+		.bounds = {
+			.left = CROP_START_X,
+			.top = CROP_START_Y,
+			.width = 720,
+			.height = 480,
+		},
+		.defrect = {
+			.left = 0,
+			.top = 0,
+			.width = 800,
+			.height = 480,
+		},
+	},
+	.pix_format  = {
+		.width = 720,
+		.height = 480,
+		.pixelformat = V4L2_PIX_FMT_YUYV,
+		.priv = 16,
+		.colorspace = V4L2_COLORSPACE_JPEG,
+	},
+};
+
+int nuvoton_vin1_probe_tw9912(struct nuvoton_vin_device* cam)
+{
+	int i,ret = 0;
+#ifndef DISALBE_READ_ID
+	__u8 SensorID[1];
+#endif
+	struct TW_RegValue *psRegValue;
+	struct TW_RegValue *psRegValue1;
+	ENTRY();
+
+	nuvoton_vin1_attach_sensor(cam, &cap1_tw9912);
+
+
+	// if i2c module isn't loaded at this time
+	if(!sensor1_inited)
+		return -1;
+
+	psRegValue=Init_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Init_RegValue); i++, psRegValue++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor_write_tw9912((psRegValue->uRegAddr), (psRegValue->uValue));
+		udelay(200);
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+			printk("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue->uRegAddr), (psRegValue->uValue), ret);
+		}
+	}
+	printk("\n");
+
+	psRegValue1=Output_RegValue;
+	for(i=0; i<_REG_TABLE_SIZE(Output_RegValue); i++, psRegValue1++) {
+		int32_t ret;
+		printk(".");
+		ret = sensor_write_tw9912((psRegValue1->uRegAddr), (psRegValue1->uValue));
+		if(ret<0) {
+			VDEBUG("Wrong to write register addr = 0x%x, write data = 0x%x , ret = %d\n", (psRegValue1->uRegAddr), (psRegValue1->uValue), ret);
+		}
+	}
+	//----------Read sensor id-------------------------------------
+#ifndef DISALBE_READ_ID
+	SensorID[0]=sensor_read_tw9912(0x00);  /* ID 0x60 */
+	printk("Chip Version = 0x%02X(0x60) \n", SensorID[0]);
+#endif
+	//-------------------------------------------------------------
+	printk("\n");
+	if(ret>=0)
+		printk("driver i2c initial done\n");
+	else
+		printk("driver i2c initial fail\n");
+	LEAVE();
+	return ret;
+}
+
+
+static const struct i2c_device_id sensor1_id[] = {
+	{ "cap1_tw9912", 0 },
+};
+MODULE_DEVICE_TABLE(i2c, sensor1_id);
+
+#ifdef CONFIG_USE_OF
+static struct of_device_id cap1_tw9912_match_table[] = {
+	{ .compatible = "nuvoton,cap1-tw9912",},
+	{},
+};
+#else
+#define cap1_tw9912_match_table NULL
+#endif
+
+static struct i2c_driver sensor1_i2c_driver = {
+	.driver = {
+		.name  = "cap1_tw9912",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(cap1_tw9912_match_table),
+	},
+	.probe    = sensor1_probe,
+	.remove   = sensor1_remove,
+	.id_table = sensor1_id,
+};
+module_i2c_driver(sensor1_i2c_driver);
diff -uprN linux-4.4.194/drivers/misc/Kconfig NUC980-linux-4.4.194/drivers/misc/Kconfig
--- linux-4.4.194/drivers/misc/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/misc/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -516,6 +516,354 @@ config SRAM
 	  the genalloc API. It is supposed to be used for small on-chip SRAM
 	  areas found on many SoCs.
 
+config NUC980_ETIMER
+        tristate "NUC980 Enhance Timer (ETIMER) support"
+        depends on ARCH_NUC980
+        help
+          Enhance timer dirver Nuvoton NUC980 Series processor. This timer also supports capture function.
+
+          To compile this driver as a module, choose M here: the module
+          will be called nuc980-etimer.
+
+config NUC980_TIMER_WKUP
+	tristate "NUC980 Enhance Timer (ETIMER) wake-up support"
+        depends on NUC980_ETIMER
+
+choice
+	prompt "NUC980 ETIMER channel 0 event count pin"
+	default NUC980_TIMER0_ECNT_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 0 event count pin.
+
+	config NUC980_TIMER0_ECNT_NONE
+		bool "No output"
+	config NUC980_TIMER0_ECNT_PA0
+		bool "Output to PA0"
+	config NUC980_TIMER0_ECNT_PD6
+		bool "Output to PD6"
+	config NUC980_TIMER0_ECNT_PF0
+		bool "Output to PF0"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 0 toggle output pin"
+	default NUC980_TIMER0_TGL_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 0 toggle output pin.
+
+	config NUC980_TIMER0_TGL_NONE
+		bool "No output"
+	config NUC980_TIMER0_TGL_PB3
+		bool "Output to PB3"
+	config NUC980_TIMER0_TGL_PC0
+		bool "Output to PC0"
+	config NUC980_TIMER0_TGL_PB9
+		bool "Output to PB9"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 0 capture input pin"
+	default NUC980_TIMER0_CAP_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 0 capture input pin.
+
+	config NUC980_TIMER0_CAP_NONE
+		bool "No input"
+	config NUC980_TIMER0_CAP_PB1
+		bool "Input from PB1"
+	config NUC980_TIMER0_CAP_PB8
+		bool "Input from PB8"
+	config NUC980_TIMER0_CAP_PB10
+		bool "Input from PB10"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 1 event count pin"
+	default NUC980_TIMER1_ECNT_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 1 event count pin.
+
+	config NUC980_TIMER1_ECNT_NONE
+		bool "No output"
+	config NUC980_TIMER1_ECNT_PA1
+		bool "Output to PA1"
+	config NUC980_TIMER1_ECNT_PD7
+		bool "Output to PD7"
+	config NUC980_TIMER1_ECNT_PF1
+		bool "Output to PF1"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 1 toggle output pin"
+	default NUC980_TIMER1_TGL_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 1 toggle output pin.
+
+	config NUC980_TIMER1_TGL_NONE
+		bool "No output"
+	config NUC980_TIMER1_TGL_PA14
+		bool "Output to PA14"
+	config NUC980_TIMER1_TGL_PD0
+		bool "Output to PD0"
+	config NUC980_TIMER1_TGL_PG11
+		bool "Output to PG11"
+	config NUC980_TIMER1_TGL_PF8
+		bool "Output to PF8"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 1 capture input pin"
+	default NUC980_TIMER1_CAP_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 1 capture input pin.
+
+	config NUC980_TIMER1_CAP_NONE
+		bool "No input"
+	config NUC980_TIMER1_CAP_PA13
+		bool "Input from PA13"
+	config NUC980_TIMER1_CAP_PD1
+		bool "Input from PD1"
+	config NUC980_TIMER1_CAP_PG12
+		bool "Input from PG12"
+	config NUC980_TIMER1_CAP_PF9
+		bool "Input from PF9"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 2 event count pin"
+	default NUC980_TIMER2_ECNT_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 2 event count pin.
+
+	config NUC980_TIMER2_ECNT_NONE
+		bool "No output"
+	config NUC980_TIMER2_ECNT_PA2
+		bool "Output to PA2"
+	config NUC980_TIMER2_ECNT_PD8
+		bool "Output to PD8"
+	config NUC980_TIMER2_ECNT_PF2
+		bool "Output to PF2"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 2 toggle output pin"
+	default NUC980_TIMER2_TGL_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 2 toggle output pin.
+
+	config NUC980_TIMER2_TGL_NONE
+		bool "No output"
+	config NUC980_TIMER2_TGL_PA10
+		bool "Output to PA10"
+	config NUC980_TIMER2_TGL_PB12
+		bool "Output to PB12"
+	config NUC980_TIMER2_TGL_PD12
+		bool "Output to PD12"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 2 capture input pin"
+	default NUC980_TIMER2_CAP_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 2 capture input pin.
+
+	config NUC980_TIMER2_CAP_NONE
+		bool "No input"
+	config NUC980_TIMER2_CAP_PA9
+		bool "Input from PA9"
+	config NUC980_TIMER2_CAP_PB11
+		bool "Input from PB11"
+	config NUC980_TIMER2_CAP_PD13
+		bool "Input from PD13"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 3 event count pin"
+	default NUC980_TIMER3_ECNT_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 3 event count pin.
+
+	config NUC980_TIMER3_ECNT_NONE
+		bool "No output"
+	config NUC980_TIMER3_ECNT_PA3
+		bool "Output to PA3"
+	config NUC980_TIMER3_ECNT_PD9
+		bool "Output to PD9"
+	config NUC980_TIMER3_ECNT_PF3
+		bool "Output to PF3"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 3 toggle output pin"
+	default NUC980_TIMER3_TGL_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 3 toggle output pin.
+
+	config NUC980_TIMER3_TGL_NONE
+		bool "No output"
+	config NUC980_TIMER3_TGL_PA8
+		bool "Output to PA8"
+	config NUC980_TIMER3_TGL_PD14
+		bool "Output to PD14"
+endchoice
+
+choice
+	prompt "NUC980 ETIMER channel 3 capture input pin"
+	default NUC980_TIMER3_CAP_NONE
+	depends on NUC980_ETIMER
+	help
+	  Select ETIMER channel 3 capture input pin.
+
+	config NUC980_TIMER3_CAP_NONE
+		bool "No input"
+	config NUC980_TIMER3_CAP_PA7
+		bool "Input from PA7"
+	config NUC980_TIMER3_CAP_PD15
+		bool "Input from PD15"
+endchoice
+
+config NUC980_QSPI0_SLAVE
+        tristate "NUC980 QSPI0 slave mode support"
+        depends on ARCH_NUC980
+        help
+          QSPI0 slave mode for NUC980.
+
+          To compile this driver as a module, choose M here: the module
+          will be called nuc980-qspi0-slave.
+
+choice
+        prompt "QSPI0 pin selection by transfer mode"
+        default SPI_NUC970_QSPI0_NORMAL
+        depends on NUC980_QSPI0_SLAVE
+        help
+          Select QSPI0 multi-function pin.
+          Can be PD2 ~ PD5 or additional PD6 and PD7 for quad mode.
+
+        config SPI_NUC980_QSPI0_SLAVE_NORMAL
+                bool "Normal mode"
+        config SPI_NUC980_QSPI0_SLAVE_QUAD
+                bool "Quad mode"
+endchoice
+
+config NUC980_SPI0_SLAVE
+        tristate "NUC980 SPI0 slave mode support"
+        depends on ARCH_NUC980
+        help
+          SPI0 slave mode for NUC980.
+
+          To compile this driver as a module, choose M here: the module
+          will be called nuc980-spi0-slave.
+
+config NUC980_SPI1_SLAVE
+        tristate "NUC980 SPI1 slave mode support"
+        depends on ARCH_NUC980
+        help
+          SPI1 slave mode for NUC980.
+
+          To compile this driver as a module, choose M here: the module
+          will be called nuc980-spi1-slave.
+
+
+
+config NUC980_SC
+	tristate "NUC970 Smartcard Interface support"
+	depends on ARCH_NUC980
+	help
+	 Smartcard card interface support for NUC980 series processor.
+	 This driver comply with EMV2000 and supports T0 and T1 transfer.
+
+config EMV_CHECK
+	bool "Perform EMV check"
+	depends on NUC980_SC
+
+config	NUC980_SC0
+	bool "NUC980 SC0 support"
+	depends on NUC980_SC && !USE_OF
+
+choice
+	prompt "NUC980 SC0 pin selection"
+	default NUC980_SC0_PA
+	depends on NUC980_SC0
+	help
+	  Select SC0 multi function pin.
+
+	config NUC980_SC0_PG
+		bool "Use port A"
+	config NUC980_SC0_PC
+		bool "Use port C"
+endchoice
+
+
+choice
+	prompt "NUC980 SC0 CD pin config"
+	default NUC980_SC0_CDLV_H
+	depends on NUC980_SC0
+	help
+	  Select SC0 card detect level.
+
+	config NUC980_SC0_CDLV_H
+		bool "CD high as card insert"
+	config NUC980_SC0_CDLV_L
+		bool "CD low as card insert"
+	config NUC980_SC0_CD_IGNORE
+		bool "Ignore CD signal"
+endchoice
+
+config	NUC980_SC0_PWRINV
+	bool "Inverse SC0 power pin level"
+	depends on NUC980_SC0
+
+
+config	NUC980_SC1
+	bool "NUC980 SC1 support"
+	depends on NUC980_SC && !USE_OF
+	help
+	 Enabe this option will configure SC1 MFP
+
+choice
+	prompt "NUC980 SC1 pin selection"
+	default NUC980_SC1_PC
+	depends on NUC980_SC1
+	help
+	  Select SC1 multi function pin.
+
+	config NUC980_SC1_PC
+		bool "Use port C"
+	config NUC980_SC1_PF
+		bool "Use port F"
+endchoice
+
+choice
+	prompt "NUC980 SC1 CD pin config"
+	default NUC980_SC1_CDLV_H
+	depends on NUC980_SC1
+	help
+	  Select SC1 card detect level.
+
+	config NUC980_SC1_CDLV_H
+		bool "CD high as card insert"
+	config NUC980_SC1_CDLV_L
+		bool "CD low as card insert"
+	config NUC980_SC1_CD_IGNORE
+		bool "Ignore CD signal"
+endchoice
+
+config	NUC980_SC1_PWRINV
+	bool "Inverse SC1 power pin level"
+	depends on NUC980_SC1
+
+
 config VEXPRESS_SYSCFG
 	bool "Versatile Express System Configuration driver"
 	depends on VEXPRESS_CONFIG
@@ -525,6 +873,39 @@ config VEXPRESS_SYSCFG
 	  bus. System Configuration interface is one of the possible means
 	  of generating transactions on this bus.
 
+config NUC980_EBI
+	bool "NUC980 EBI driver"
+	depends on ARCH_NUC980
+	select GENERIC_ALLOCATOR
+	help
+	  Driver for NUC980 EBI controller.
+	  Used to configure the EBI (external bus interface) when the device-
+	  tree is used. This bus supports external ethernet controller,
+	  SRAMs etc.
+
+choice
+	prompt "NUC980 EBI Timing Setting"
+	default NUC980_EBI_TIMING_SLOWEST
+	depends on NUC980_EBI
+	help
+	  Select EBI Timing configuration.
+
+	config NUC980_EBI_TIMING_FASTEST
+		bool "Timing Fastest"
+	config NUC980_EBI_TIMING_VERYFAST
+		bool "Timing Veryfast"
+	config NUC980_EBI_TIMING_FAST
+		bool "Timing Fast"
+	config NUC980_EBI_TIMING_NORMAL
+		bool "Timing Normal"
+	config NUC980_EBI_TIMING_SLOW
+		bool "Timing Slow"
+	config NUC980_EBI_TIMING_VERYSLOW
+		bool "Timing Very slow"
+	config NUC980_EBI_TIMING_SLOWEST
+		bool "Timing Slowest"
+endchoice
+
 source "drivers/misc/c2port/Kconfig"
 source "drivers/misc/eeprom/Kconfig"
 source "drivers/misc/cb710/Kconfig"
diff -uprN linux-4.4.194/drivers/misc/Makefile NUC980-linux-4.4.194/drivers/misc/Makefile
--- linux-4.4.194/drivers/misc/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/misc/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -56,3 +56,9 @@ obj-$(CONFIG_GENWQE)		+= genwqe/
 obj-$(CONFIG_ECHO)		+= echo/
 obj-$(CONFIG_VEXPRESS_SYSCFG)	+= vexpress-syscfg.o
 obj-$(CONFIG_CXL_BASE)		+= cxl/
+obj-$(CONFIG_NUC980_EBI)        += nuc980-ebi.o
+obj-$(CONFIG_NUC980_ETIMER)     += nuc980-etimer.o
+obj-$(CONFIG_NUC980_SC)         += nuc980-sc.o sc-util.o sc-t0.o sc-t1.o
+obj-$(CONFIG_NUC980_QSPI0_SLAVE)        += nuc980-qspi0-slave.o
+obj-$(CONFIG_NUC980_SPI0_SLAVE) += nuc980-spi0-slave.o
+obj-$(CONFIG_NUC980_SPI1_SLAVE) += nuc980-spi1-slave.o
diff -uprN linux-4.4.194/drivers/misc/nuc980-ebi.c NUC980-linux-4.4.194/drivers/misc/nuc980-ebi.c
--- linux-4.4.194/drivers/misc/nuc980-ebi.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/misc/nuc980-ebi.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,299 @@
+/* linux/driver/misc/nuc980-ebi.c
+ *
+ * Copyright (c) 2018 Nuvoton technology corporation
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+#if 0
+#define ENTRY()                                 printk("[%-20s] : Enter...\n", __FUNCTION__)
+#define LEAVE()                                 printk("[%-20s] : Leave...\n", __FUNCTION__)
+#else
+#define ENTRY()
+#define LEAVE()
+#endif
+
+#if 0
+#define DEBUG(fmt, args...)     printk(fmt, ##args)
+#else
+#define DEBUG(fmt, args...)     do {} while (0)
+#endif
+
+
+
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/slab.h>
+#include <linux/miscdevice.h>
+#include <linux/device.h>
+#include <linux/spinlock.h>
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/clk.h>
+#include <linux/platform_device.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-ebi.h>
+#include <linux/dma-mapping.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/of.h>
+
+
+#define SRAM_GRANULARITY	32
+
+struct ebi_dev {
+	int minor;	// dynamic minor num, so we need this to distinguish between channels
+	struct pinctrl *pinctrl;
+	struct clk *clk;
+	struct clk *hclk;
+	unsigned long base_addr[4];
+	int bank;
+};
+
+static struct ebi_dev *ebi;
+
+static long ebi_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	struct nuc980_set_ebi *pebi,sebi;
+	struct ebi_dev *nuc980_ebi = (struct ebi_dev *)filp->private_data;
+	pebi=&sebi;
+	switch(cmd) {
+	case EBI_IOC_SET:
+		if(copy_from_user((void *)&sebi, (const void *)arg, sizeof(struct nuc980_set_ebi)))
+			return -EFAULT;
+		//pebi=(struct nuc980_set_ebi *)(arg);
+		DEBUG("set bank=%d\n",pebi->bank);
+
+#ifdef CONFIG_NUC980_EBI_TIMING_FASTEST
+		pebi->timing = EBI_TIMING_FASTEST;
+#endif
+#ifdef CONFIG_NUC980_EBI_TIMING_VERYFAST
+		pebi->timing = EBI_TIMING_VERYFAST;
+#endif
+#ifdef CONFIG_NUC980_EBI_TIMING_FAST
+		pebi->timing =EBI_TIMING_FAST;
+#endif
+#ifdef CONFIG_NUC980_EBI_TIMING_NORMAL
+		pebi->timing = EBI_TIMING_NORMAL;
+#endif
+#ifdef CONFIG_NUC980_EBI_TIMING_SLOW
+		pebi->timing = EBI_TIMING_SLOW;
+#endif
+#ifdef CONFIG_NUC980_EBI_TIMING_VERYSLOW
+		pebi->timing = EBI_TIMING_VERYSLOW;
+#endif
+#ifdef CONFIG_NUC980_EBI_TIMING_SLOWEST
+		pebi->timing = EBI_TIMING_SLOWEST;
+#endif
+
+		nuc980_set_ebi_ctl(pebi->bank, pebi->width, pebi->timing, pebi->busmode, pebi->CSActiveLevel);
+		nuc980_ebi->bank = pebi->bank;
+		nuc980_ebi->base_addr[nuc980_ebi->bank] = pebi->base;
+
+		DEBUG("bank[%d]: width=%d, timing=0x%x, busmode=%d, CSActiveLevel=%d, base=0x%x\n",pebi->bank, pebi->width, pebi->timing, pebi->busmode, pebi->CSActiveLevel, pebi->base);
+		// DEBUG("REG_EBI_CTL=0x%08x\n",__raw_readl(REG_EBI_CTL(nuc980_ebi->bank)));
+		// DEBUG("REG_EBI_TCTL=0x%08x\n",__raw_readl(REG_EBI_TCTL(nuc980_ebi->bank)));
+		break;
+	}
+	return 0;
+}
+static int ebi_open(struct inode *inode, struct file *filp)
+{
+#ifndef CONFIG_USE_OF
+	struct pinctrl_state *s=NULL;
+	int ret;
+#endif
+
+	ENTRY();
+	filp->private_data = ebi;
+	ebi->hclk = clk_get(NULL, "ebi_hclk");
+	if (IS_ERR(ebi->hclk)) {
+		printk("failed to get ebi clock mux\n");
+		return -EAGAIN;
+	}
+	clk_prepare(ebi->hclk);
+	clk_enable(ebi->hclk);
+
+#ifndef CONFIG_USE_OF
+	switch(ebi->bank) {
+	case 0:
+		s = pinctrl_lookup_state(ebi->pinctrl, "ebi-16bit-0");  //ebi 16bit cs0
+		break;
+	case 1:
+		s = pinctrl_lookup_state(ebi->pinctrl, "ebi-16bit-4");  //ebi 16bit cs1
+		break;
+	case 2:
+		s = pinctrl_lookup_state(ebi->pinctrl, "ebi-16bit-8");  //ebi 16bit cs2
+		break;
+	};
+	if (IS_ERR(s)) {
+		printk("pinctrl_lookup_state err\n");
+		return -EPERM;
+	}
+
+	if((ret = pinctrl_select_state(ebi->pinctrl, s)) < 0) {
+		printk("pinctrl_select_state err\n");
+		return ret;
+	}
+#endif
+
+	LEAVE();
+	return 0;
+}
+//static unsigned int ebi_poll(struct file *filp, poll_table *wait){return 0;}
+static ssize_t ebi_read(struct file *filp, char __user *buf, size_t count, loff_t *f_pos)
+{
+	return 0;
+}
+static int ebi_release(struct inode *inode, struct file *filp)
+{
+	ENTRY();
+	clk_disable(ebi->hclk);
+	clk_put(ebi->hclk);
+	filp->private_data = NULL;
+	LEAVE();
+	return 0;
+}
+static int ebi_mmap(struct file *filp, struct vm_area_struct * vma);
+struct file_operations ebi_fops = {
+	.owner		= THIS_MODULE,
+	.open		= ebi_open,
+	.release	= ebi_release,
+	.read		= ebi_read,
+	.mmap = ebi_mmap,
+	.unlocked_ioctl	= ebi_ioctl,
+};
+
+static struct miscdevice ebi_dev[] = {
+	[0] = {
+		.minor = MISC_DYNAMIC_MINOR,
+		.name = "ebi",
+		.fops = &ebi_fops,
+	},
+};
+
+;
+static int ebi_mmap(struct file *filp, struct vm_area_struct * vma)
+{
+	struct ebi_dev *nuc980_ebi = (struct ebi_dev *)filp->private_data;
+	unsigned long pageFrameNo = 0, size;
+
+#if 0
+	unsigned long virt_addr,phys_addr;
+	static unsigned int physical_address;
+	static unsigned int virtual_address;
+	size = vma->vm_end - vma->vm_start;
+	ENTRY();
+	virt_addr = (unsigned long)dma_alloc_writecombine(NULL, size,
+	            (unsigned int *) &phys_addr,
+	            GFP_KERNEL);
+	pageFrameNo = __phys_to_pfn(phys_addr);
+	if (!virt_addr) {
+		printk(KERN_INFO "kmalloc() failed !\n");
+		return -EINVAL;
+	}
+	DEBUG("MMAP_KMALLOC : virt addr = 0x%08x, size = %d, %d\n",virt_addr, size, __LINE__);
+#else
+	DEBUG("mmap: nuc980_ebi->bank=0x%08x\n",nuc980_ebi->bank);
+	DEBUG("nuc980_ebi->base_addr=0x%08x\n",(unsigned int)nuc980_ebi->base_addr[nuc980_ebi->bank]);
+	pageFrameNo = __phys_to_pfn(nuc980_ebi->base_addr[nuc980_ebi->bank]);
+	ENTRY();
+#endif
+
+	size = vma->vm_end - vma->vm_start;
+	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+	vma->vm_flags |= (VM_DONTEXPAND | VM_DONTDUMP);
+	if (remap_pfn_range(vma, vma->vm_start, pageFrameNo,size, vma->vm_page_prot)) {
+		printk(KERN_INFO "nuc980_mem_mmap() : remap_pfn_range() failed !\n");
+		return -EINVAL;
+	}
+
+	printk("EBI_BANK%d\n", nuc980_ebi->bank);
+	DEBUG("REG_EBI_CTL=0x%08x\n",__raw_readl(REG_EBI_CTL(nuc980_ebi->bank)));
+	DEBUG("REG_EBI_TCTL=0x%08x\n",__raw_readl(REG_EBI_TCTL(nuc980_ebi->bank)));
+	DEBUG("REG_MFP_GPA_H=0x%08x  REG_MFP_GPA_L=0x%08x\n",__raw_readl(REG_MFP_GPA_H),__raw_readl(REG_MFP_GPA_L));
+	DEBUG("REG_MFP_GPG_H=0x%08x  REG_MFP_GPG_L=0x%08x\n",__raw_readl(REG_MFP_GPG_H),__raw_readl(REG_MFP_GPG_L));
+	DEBUG("REG_MFP_GPC_H=0x%08x  REG_MFP_GPC_L=0x%08x\n",__raw_readl(REG_MFP_GPC_H),__raw_readl(REG_MFP_GPC_L));
+	LEAVE();
+	return 0;
+}
+
+static int nuc980_ebi_probe(struct platform_device *pdev)
+{
+	struct ebi_dev *nuc980_ebi;
+	ENTRY();
+	DEBUG("%s - pdev = %s\n", __func__, pdev->name);
+	nuc980_ebi = devm_kzalloc(&pdev->dev, sizeof(*nuc980_ebi), GFP_KERNEL);
+	if (!nuc980_ebi)
+		return -ENOMEM;
+
+	//nuc980_ebi->clk = devm_clk_get(&pdev->dev, NULL);
+	nuc980_ebi->clk = devm_clk_get(&pdev->dev, "ebi_hclk");
+	if (IS_ERR(nuc980_ebi->clk))
+		nuc980_ebi->clk = NULL;
+	else
+		clk_prepare_enable(nuc980_ebi->clk);
+
+	misc_register(&ebi_dev[0]);
+	nuc980_ebi->pinctrl = devm_pinctrl_get(&pdev->dev);
+	nuc980_ebi->minor = MINOR(ebi_dev[0].minor);
+
+#ifdef CONFIG_OF
+	{
+		struct pinctrl *pinctrl;
+		pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+		if (IS_ERR(pinctrl)) {
+			return PTR_ERR(pinctrl);
+		}
+	}
+#endif
+
+	DEBUG("nuc980_ebi->minor=%d\n",nuc980_ebi->minor);
+	ebi=nuc980_ebi;
+	platform_set_drvdata(pdev, nuc980_ebi);
+
+	LEAVE();
+	return 0;
+}
+
+static int nuc980_ebi_remove(struct platform_device *pdev)
+{
+	//struct ebi_dev *nuc980_ebi = platform_get_drvdata(pdev);
+	ENTRY();
+	misc_deregister(&ebi_dev[0]);
+	LEAVE();
+	return 0;
+}
+
+static const struct of_device_id nuc980_ebi_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-ebi" },
+	{},
+};
+
+static struct platform_driver nuc980_ebi_driver = {
+	.driver = {
+		.name = "nuc980-ebi",
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_ebi_of_match),
+	},
+	.probe = nuc980_ebi_probe,
+	.remove = nuc980_ebi_remove,
+};
+
+module_platform_driver(nuc980_ebi_driver);
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_ALIAS("platform:nuc980-ebi");
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/misc/nuc980-etimer.c NUC980-linux-4.4.194/drivers/misc/nuc980-etimer.c
--- linux-4.4.194/drivers/misc/nuc980-etimer.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/misc/nuc980-etimer.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1104 @@
+/* linux/driver/char/nuc980-etimer.c
+ *
+ * Copyright (c) 2018 Nuvoton technology corporation
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/slab.h>
+#include <linux/miscdevice.h>
+#include <linux/device.h>
+#include <linux/spinlock.h>
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/of_irq.h>
+#include <linux/platform_device.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-timer.h>
+#include <mach/nuc980-timer.h>
+
+#define ETIMER_CH	4
+#define ETIMER_OPMODE_NONE		0
+//#define ETIMER_OPMODE_ONESHOT		1
+#define ETIMER_OPMODE_PERIODIC	2
+//#define ETIMER_OPMODE_CONTINUOUS	3
+#define ETIMER_OPMODE_TOGGLE		4
+#define ETIMER_OPMODE_TRIGGER_COUNTING	5
+#define ETIMER_OPMODE_FREE_COUNTING	6
+#define ETIMER_OPMODE_EVENT_COUNTING 7
+
+#define ETIMER_CTL_TWAKE_EN		0x00000004
+#define ETIMER_CTL_ETMR_EN		0x00000001
+#define ETIMER_CTL_ONESHOT		0x00000000
+#define ETIMER_CTL_PERIODIC		0x00000010
+#define ETIMER_CTL_TOGGLE		0x00000020
+#define ETIMER_CTL_CONTINUOUS	0x00000030
+#define ETIMER_CTL_EVENT_COUNTING	0x00001000
+#define ETIMER_CTL_TCAP_EN		0x00010000
+#define ETIMER_CTL_FREE_COUNTING    0x00000000
+#define ETIMER_CTL_TRIGGER_COUNTING	0x00100000
+#define ETIMER_IER_TCAP_IE		0x00000002
+
+
+#define ETIMER_TRIGGER_COUNTING 	(ETIMER_CTL_TRIGGER_COUNTING |\
+                                     ETIMER_CTL_TCAP_EN |\
+                                     ETIMER_CTL_PERIODIC |\
+                                     ETIMER_CTL_ETMR_EN)
+
+#define ETIMER_FREE_COUNTING 		(ETIMER_CTL_FREE_COUNTING |\
+                                     ETIMER_CTL_TCAP_EN |\
+                                     ETIMER_CTL_PERIODIC |\
+                                     ETIMER_CTL_ETMR_EN)
+
+#define ETIMER_TOGGLE			(ETIMER_CTL_TOGGLE | ETIMER_CTL_ETMR_EN)
+
+#define ETIMER_EVENT_COUNTER	(ETIMER_CTL_EVENT_COUNTING | ETIMER_CTL_ETMR_EN)
+
+struct nuc980_etimer {
+	spinlock_t lock;
+	struct pinctrl *pinctrl;
+	struct clk *clk;
+	struct clk *eclk;
+	wait_queue_head_t wq;
+	int minor;	// dynamic minor num, so we need this to distinguish between channels
+	u32 cap;	// latest capture data
+	u32 cnt;	// latest timer up-counter value
+	int irq;	// interrupt number
+	u8 ch;		// timer channel. 0~3
+	u8 mode;	// Current OP mode. Counter, free counting, trigger counting...
+	u8 occupied;	// device opened
+	u8 update;	// new capture data available
+};
+
+
+static struct nuc980_etimer *etmr[ETIMER_CH];
+#ifdef CONFIG_NUC980_TIMER_WKUP
+static uint8_t gu8_ch;
+#endif
+static uint32_t gu32_cnt;
+
+static irqreturn_t nuc980_etimer_interrupt(int irq, void *dev_id)
+{
+	struct nuc980_etimer *t = (struct nuc980_etimer *)dev_id;
+	static int cnt = 0;
+	static uint32_t t0, t1;
+	void __iomem *TMRBaseAddr = TIMER0;
+	unsigned long flag = 0;
+
+	int ch = t->ch;
+
+	switch (ch) {
+	case 0:
+		TMRBaseAddr = TIMER0;
+		break;
+	case 1:
+		TMRBaseAddr = TIMER1;
+		break;
+	case 2:
+		TMRBaseAddr = TIMER2;
+		break;
+	case 3:
+		TMRBaseAddr = TIMER3;
+		break;
+	}
+	spin_lock(&t->lock);
+
+	flag = __raw_readl(REG_TIMER_ISR(TMRBaseAddr));
+	if( flag & 0x10 ) {
+		__raw_writel((0x100 << ch), REG_WKUPSSR0); // clear system wake up source flag
+		__raw_writel(0x10, REG_TIMER_ISR(TMRBaseAddr));  // clear Timer Wake-up Status
+	}
+
+	if(flag & 0x1) {
+		t->cnt = gu32_cnt++;
+		__raw_writel(__raw_readl(REG_TIMER_ISR(TMRBaseAddr)) & 0x1, REG_TIMER_ISR(TMRBaseAddr)); // clear Timer Interrupt Status
+		t->update = 1;
+	}
+
+	if(flag & 0x2) {
+		if(t->mode == ETIMER_OPMODE_FREE_COUNTING) {
+			if(cnt == 0) {
+				/* Gets the Timer capture data */
+				t0 =  __raw_readl(REG_TIMER_TCAP(TMRBaseAddr));
+				cnt++;
+
+			} else if(cnt == 1) {
+				/* Gets the Timer capture data */
+				t1 =  __raw_readl(REG_TIMER_TCAP(TMRBaseAddr));
+				cnt++;
+
+				if(t0 > t1) {
+					/* over run, drop this data and do nothing */
+
+				} else {
+					/* Display the measured input frequency */
+					t->cap =  12000000 / (t1 - t0);
+					t->update = 1;
+
+				}
+			} else {
+				cnt = 0;
+			}
+
+		} else {
+			t->cap = __raw_readl(REG_TIMER_TCAP(TMRBaseAddr));
+			t->update = 1;
+		}
+
+		__raw_writel(__raw_readl(REG_TIMER_ISR(TMRBaseAddr)) & 0x2, REG_TIMER_ISR(TMRBaseAddr)); // clear Timer capture Interrupt Status
+
+	}
+
+	wake_up_interruptible(&t->wq);
+	spin_unlock(&t->lock);
+
+	return IRQ_HANDLED;
+}
+
+static void etimer_SwitchClkSrc(int flag, struct nuc980_etimer *t)
+{
+	struct clk *clkmux, *clklxt;
+	struct clk ;
+	int ch;
+	void __iomem *TMRBaseAddr = TIMER0;
+
+	clkmux = clk_get(NULL, "timer0_eclk_mux");
+
+	ch = t->ch;
+	switch (ch) {
+	case 0:
+		TMRBaseAddr = TIMER0;
+		break;
+	case 1:
+		TMRBaseAddr = TIMER1;
+		break;
+	case 2:
+		TMRBaseAddr = TIMER2;
+		break;
+	case 3:
+		TMRBaseAddr = TIMER3;
+		break;
+	}
+
+	if(flag==1) {
+		clklxt = clk_get(NULL, "xin32k");
+		// timer clock is 32kHz, set prescaler to 1 - 1.
+		__raw_writel(0, REG_TIMER_PRECNT(TMRBaseAddr));
+		pr_debug("ch = %d, xin32k \n", ch);
+	} else {
+		clklxt = clk_get(NULL, "xin");
+		// timer clock is 12MHz, set prescaler to 12 - 1.
+		__raw_writel(11, REG_TIMER_PRECNT(TMRBaseAddr));
+		pr_debug("ch = %d, xin12M \n", ch);
+	}
+
+	if (IS_ERR(clklxt)) {
+		pr_debug("failed to get 32k clk\n");
+		return;
+	}
+	if(ch == 0) {
+		clkmux = clk_get(NULL, "timer0_eclk_mux");
+	} else if (ch == 1) {
+		clkmux = clk_get(NULL, "timer1_eclk_mux");
+	} else if (ch == 2) {
+		clkmux = clk_get(NULL, "timer2_eclk_mux");
+	} else if (ch == 3) {
+		clkmux = clk_get(NULL, "timer3_eclk_mux");
+	}
+	if (IS_ERR(clkmux)) {
+		pr_debug("failed to get etimer clock mux\n");
+		return;
+	}
+	clk_set_parent(clkmux, clklxt);
+
+	if(ch == 0) {
+		etmr[ch]->clk = clk_get(NULL, "timer0");
+		etmr[ch]->eclk = clk_get(NULL, "timer0_eclk");
+	} else if(ch == 1) {
+		etmr[ch]->clk = clk_get(NULL, "timer1");
+		etmr[ch]->eclk = clk_get(NULL, "timer1_eclk");
+	} else if(ch == 2) {
+		etmr[ch]->clk = clk_get(NULL, "timer2");
+		etmr[ch]->eclk = clk_get(NULL, "timer2_eclk");
+	} else if(ch == 3) {
+		etmr[ch]->clk = clk_get(NULL, "timer3");
+		etmr[ch]->eclk = clk_get(NULL, "timer3_eclk");
+	}
+
+
+	if (IS_ERR(etmr[ch]->clk)) {
+		printk("failed to get etmr clock\n");
+		return;
+	}
+
+
+	if (IS_ERR(etmr[ch]->eclk)) {
+		printk("failed to get etmr eclock\n");
+		return;
+	}
+
+	clk_prepare(etmr[ch]->clk);
+	clk_enable(etmr[ch]->clk);
+	clk_prepare(etmr[ch]->eclk);
+	clk_enable(etmr[ch]->eclk);
+}
+
+
+static void stop_timer(struct nuc980_etimer *t)
+{
+	unsigned long flag;
+	void __iomem *TMRBaseAddr = TIMER0;
+
+	switch (t->ch) {
+	case 0:
+		TMRBaseAddr = TIMER0;
+		break;
+	case 1:
+		TMRBaseAddr = TIMER1;
+		break;
+	case 2:
+		TMRBaseAddr = TIMER2;
+		break;
+	case 3:
+		TMRBaseAddr = TIMER3;
+		break;
+	}
+
+	spin_lock_irqsave(&t->lock, flag);
+	// stop timer
+	__raw_writel(0, REG_TIMER_CTL(TMRBaseAddr));
+	// disable interrupt
+	__raw_writel(0, REG_TIMER_IER(TMRBaseAddr));
+	// clear interrupt flag if any
+	__raw_writel(0xFFFFFFFF, REG_TIMER_ISR(TMRBaseAddr));
+	t->mode = ETIMER_OPMODE_NONE;
+	t->update = 0;
+	spin_unlock_irqrestore(&t->lock, flag);
+}
+
+static ssize_t etimer_read(struct file *filp, char __user *buf, size_t count, loff_t *f_pos)
+{
+	unsigned long flag;
+	struct nuc980_etimer *t = (struct nuc980_etimer *)filp->private_data;
+	int ret = 0;
+
+	spin_lock_irqsave(&t->lock, flag);
+	if(t->mode != ETIMER_OPMODE_TRIGGER_COUNTING &&
+	   t->mode != ETIMER_OPMODE_FREE_COUNTING    &&
+	   t->mode != ETIMER_OPMODE_PERIODIC         &&
+	   t->mode != ETIMER_OPMODE_EVENT_COUNTING) {
+		ret = -EPERM;
+
+		goto out;
+	}
+
+	if(t->update) {
+
+		if(t->mode == ETIMER_OPMODE_TRIGGER_COUNTING ||
+		   t->mode == ETIMER_OPMODE_FREE_COUNTING) {
+
+			if(copy_to_user(buf, &t->cap, sizeof(unsigned int)))
+				ret = -EFAULT;
+			else
+				ret = 4;	// size of int.
+		} else if(t->mode == ETIMER_OPMODE_PERIODIC ||
+		          t->mode == ETIMER_OPMODE_EVENT_COUNTING) {
+			if(copy_to_user(buf, &t->cnt, sizeof(unsigned int)))
+				ret = -EFAULT;
+			else
+				ret = 4;	// size of int.
+		}
+		t->update = 0;
+
+		goto out;
+	} else {
+		spin_unlock_irqrestore(&t->lock, flag);
+		wait_event_interruptible(t->wq, t->update != 0);
+		if(t->mode == ETIMER_OPMODE_TRIGGER_COUNTING ||
+		   t->mode == ETIMER_OPMODE_FREE_COUNTING) {
+
+			if(copy_to_user(buf, &t->cap, sizeof(unsigned int)))
+				ret = -EFAULT;
+			else
+				ret = 4;	// size of int.
+		} else if(t->mode == ETIMER_OPMODE_PERIODIC ||
+		          t->mode == ETIMER_OPMODE_EVENT_COUNTING) {
+			if(copy_to_user(buf, &t->cnt, sizeof(unsigned int)))
+				ret = -EFAULT;
+			else
+				ret = 4;	// size of int.
+		}
+		t->update = 0;
+
+		return ret;
+	}
+
+out:
+	spin_unlock_irqrestore(&t->lock, flag);
+
+	return ret;
+}
+
+
+static int etimer_release(struct inode *inode, struct file *filp)
+{
+	struct nuc980_etimer *t = (struct nuc980_etimer *)filp->private_data;
+	int ch = t->ch;
+	unsigned long flag;
+
+	stop_timer(t);
+
+	// free irq
+	free_irq(etmr[ch]->irq, etmr[ch]);
+	// disable clk
+	clk_disable(etmr[ch]->clk);
+	clk_disable(etmr[ch]->eclk);
+	clk_put(etmr[ch]->clk);
+	clk_put(etmr[ch]->eclk);
+
+	spin_lock_irqsave(&etmr[ch]->lock, flag);
+	etmr[ch]->occupied = 0;
+	spin_unlock_irqrestore(&etmr[ch]->lock, flag);
+	filp->private_data = NULL;
+
+	return(0);
+}
+
+static int etimer_open(struct inode *inode, struct file *filp)
+{
+	int i, ret, ch = 0;
+	unsigned long flag;
+	struct clk *clkmux, *clkhxt;
+
+	for(i = 0; i < ETIMER_CH; i++)
+		if(MINOR(inode->i_rdev) == etmr[i]->minor) {
+			ch = i;
+			break;
+		}
+
+	spin_lock_irqsave(&etmr[ch]->lock, flag);
+	if(etmr[ch]->occupied) {
+		spin_unlock_irqrestore(&etmr[ch]->lock, flag);
+		pr_debug("-EBUSY error\n");
+		return -EBUSY;
+	}
+
+	etmr[ch]->occupied = 1;
+	spin_unlock_irqrestore(&etmr[ch]->lock, flag);
+
+	if (request_irq(etmr[ch]->irq, nuc980_etimer_interrupt,
+	                IRQF_NO_SUSPEND, "nuc980-timer", etmr[ch])) {
+		pr_debug("register irq failed %d\n", etmr[ch]->irq);
+		ret = -EAGAIN;
+		goto out2;
+	}
+
+	filp->private_data = etmr[ch];
+
+	// configure engine clock
+	clkhxt = clk_get(NULL, "xin");
+	if (IS_ERR(clkhxt)) {
+		pr_debug("failed to get xin clk\n");
+		ret = PTR_ERR(clkhxt);
+		goto out1;
+	}
+	if(ch == 0) {
+		clkmux = clk_get(NULL, "timer0_eclk_mux");
+	} else if (ch == 1) {
+		clkmux = clk_get(NULL, "timer1_eclk_mux");
+	} else if (ch == 2) {
+		clkmux = clk_get(NULL, "timer2_eclk_mux");
+	} else if (ch == 3) {
+		clkmux = clk_get(NULL, "timer3_eclk_mux");
+	}
+	if (IS_ERR(clkmux)) {
+		pr_debug("failed to get etimer clock mux\n");
+		ret = PTR_ERR(clkmux);
+		goto out1;
+	}
+	clk_set_parent(clkmux, clkhxt);
+
+	if(ch == 0) {
+		etmr[ch]->clk = clk_get(NULL, "timer0");
+		etmr[ch]->eclk = clk_get(NULL, "timer0_eclk");
+	} else if(ch == 1) {
+		etmr[ch]->clk = clk_get(NULL, "timer1");
+		etmr[ch]->eclk = clk_get(NULL, "timer1_eclk");
+	} else if(ch == 2) {
+		etmr[ch]->clk = clk_get(NULL, "timer2");
+		etmr[ch]->eclk = clk_get(NULL, "timer2_eclk");
+	} else if(ch == 3) {
+		etmr[ch]->clk = clk_get(NULL, "timer3");
+		etmr[ch]->eclk = clk_get(NULL, "timer3_eclk");
+	}
+
+	if (IS_ERR(etmr[ch]->clk)) {
+		pr_debug("failed to get etmr clock\n");
+		ret = PTR_ERR(etmr[ch]->clk);
+		goto out1;
+	}
+
+
+	if (IS_ERR(etmr[ch]->eclk)) {
+		pr_debug("failed to get etmr eclock\n");
+		ret = PTR_ERR(etmr[ch]->eclk);
+		goto out1;
+	}
+
+	clk_prepare(etmr[ch]->clk);
+	clk_enable(etmr[ch]->clk);
+	clk_prepare(etmr[ch]->eclk);
+	clk_enable(etmr[ch]->eclk);
+
+	return 0;
+
+
+out1:
+
+	free_irq(etmr[ch]->irq, etmr[ch]);
+out2:
+	spin_lock_irqsave(&etmr[ch]->lock, flag);
+	etmr[ch]->occupied = 0;
+	spin_unlock_irqrestore(&etmr[ch]->lock, flag);
+
+	return ret;
+
+}
+
+static long etimer_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	unsigned long flag;
+	struct nuc980_etimer *t = (struct nuc980_etimer *)filp->private_data;
+	int ch = t->ch;
+	int unsigned param;
+	u32 clksrc;
+	void __iomem *TMRBaseAddr = TIMER0;
+#ifndef CONFIG_USE_OF
+	struct pinctrl_state *s;
+	int ret;
+#endif
+
+	// stop timer before we do any change
+	stop_timer(t);
+
+	// init time-out counts
+	gu32_cnt = 1;
+	t->cnt = gu32_cnt;
+
+	// check clock source
+	clksrc = __raw_readl(REG_CLK_DIV8);
+
+	switch (ch) {
+	case 0:
+		TMRBaseAddr = TIMER0;
+		break;
+	case 1:
+		TMRBaseAddr = TIMER1;
+		break;
+	case 2:
+		TMRBaseAddr = TIMER2;
+		break;
+	case 3:
+		TMRBaseAddr = TIMER3;
+		break;
+	}
+
+	switch(cmd) {
+	case TMR_IOC_CLKLXT:
+		etimer_SwitchClkSrc(1, t);
+		break;
+
+	case TMR_IOC_CLKHXT:
+		etimer_SwitchClkSrc(0, t);
+		break;
+
+	case TMR_IOC_STOP:
+		//timer stopped
+		break;
+
+	case TMR_IOC_PERIODIC:
+
+		if(copy_from_user((void *)&param, (const void *)arg, sizeof(unsigned int)))
+			return -EFAULT;
+
+		// compare register is 24-bit width
+		if(param > 0xFFFFFF)
+			return -EPERM;
+
+		spin_lock_irqsave(&t->lock, flag);
+
+		// timer clock is 12MHz, set prescaler to 12 - 1.
+		__raw_writel(11, REG_TIMER_PRECNT(TMRBaseAddr));
+		__raw_writel(param, REG_TIMER_CMPR(TMRBaseAddr));
+
+		// enable timeout interrupt
+		__raw_writel(0x1, REG_TIMER_IER(TMRBaseAddr));
+		__raw_writel(ETIMER_CTL_PERIODIC | ETIMER_CTL_ETMR_EN, REG_TIMER_CTL(TMRBaseAddr));
+
+		t->mode = ETIMER_OPMODE_PERIODIC;
+		spin_unlock_irqrestore(&t->lock, flag);
+
+		break;
+
+#ifdef CONFIG_NUC980_TIMER_WKUP
+	case TMR_IOC_PERIODIC_FOR_WKUP:
+
+		if(copy_from_user((void *)&param, (const void *)arg, sizeof(unsigned int)))
+			return -EFAULT;
+
+		// compare register is 24-bit width
+		if(param > 0xFFFFFF)
+			return -EPERM;
+
+		// check clock, power down mode using 32kHz
+		clksrc = __raw_readl(REG_CLK_DIV8);
+		if ( ((clksrc >> ((16 + (ch * 2)))) & 0x3) != 0x3 ) {
+			printk("Power down mode clock need to switch to 32k.\n");
+			return -1;
+		}
+		// gu8_wkflag = 0;
+		gu8_ch = ch;
+		spin_lock_irqsave(&t->lock, flag);
+		__raw_writel(param, REG_TIMER_CMPR(TMRBaseAddr));
+
+		// enable timeout interrupt
+		__raw_writel(0x1, REG_TIMER_IER(TMRBaseAddr));
+		__raw_writel(ETIMER_CTL_PERIODIC  | ETIMER_CTL_ETMR_EN, REG_TIMER_CTL(TMRBaseAddr));
+
+
+		t->mode = ETIMER_OPMODE_PERIODIC;
+		spin_unlock_irqrestore(&t->lock, flag);
+
+		break;
+#endif
+
+	case TMR_IOC_TOGGLE:
+		// get output duty in us
+		if(copy_from_user((void *)&param, (const void *)arg, sizeof(unsigned int)))
+			return -EFAULT;
+		// divide by 2 because a duty cycle is high + low
+		param >>= 1;
+		// compare register is 24-bit width
+		if(param > 0xFFFFFF)
+			return -EPERM;
+
+#ifndef CONFIG_USE_OF
+		// set pin function
+		if(t->ch == 0) {
+#if defined (CONFIG_NUC980_TIMER0_TGL_PB3)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-tgl-PB3");
+#elif defined (CONFIG_NUC980_TIMER0_TGL_PC0)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-tgl-PC0");
+#elif defined (CONFIG_NUC980_TIMER0_TGL_PB9)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-tgl-PB9");
+#elif defined (CONFIG_NUC980_TIMER0_TGL_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 1) {
+#if defined (CONFIG_NUC980_TIMER1_TGL_PA14)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-tgl-PA14");
+#elif defined (CONFIG_NUC980_TIMER1_TGL_PD0)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-tgl-PD0");
+#elif defined (CONFIG_NUC980_TIMER1_TGL_PG11)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-tgl-PG11");
+#elif defined (CONFIG_NUC980_TIMER1_TGL_PF8)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-tgl-PF8");
+#elif defined (CONFIG_NUC980_TIMER1_TGL_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 2) {
+#if defined (CONFIG_NUC980_TIMER2_TGL_PA10)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-tgl-PA10");
+#elif defined (CONFIG_NUC980_TIMER2_TGL_PB12)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-tgl-PB12");
+#elif defined (CONFIG_NUC980_TIMER2_TGL_PD12)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-tgl-PD12");
+#elif defined (CONFIG_NUC980_TIMER2_TGL_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 3) {
+#if defined (CONFIG_NUC980_TIMER3_TGL_PA8)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer3-tgl-PA8");
+#elif defined (CONFIG_NUC980_TIMER3_TGL_PD14)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer3-tgl-PD14");
+#elif defined (CONFIG_NUC980_TIMER3_TGL_NONE)
+			return -EPERM;
+#endif
+		}
+
+		if (IS_ERR(s)) {
+			pr_debug("pinctrl_lookup_state err\n");
+			return -EPERM;
+		}
+
+		if((ret = pinctrl_select_state(t->pinctrl, s)) < 0) {
+			pr_debug("pinctrl_select_state err\n");
+			return ret;
+		}
+#endif
+
+		spin_lock_irqsave(&t->lock, flag);
+		// timer clock is 12MHz, set prescaler to 12 - 1.
+		__raw_writel(11, REG_TIMER_PRECNT(TMRBaseAddr));
+		__raw_writel(param, REG_TIMER_CMPR(TMRBaseAddr));
+		__raw_writel(ETIMER_TOGGLE, REG_TIMER_CTL(TMRBaseAddr));
+		t->mode = ETIMER_OPMODE_TOGGLE;
+		pr_debug("Toggle REG_TIMER_CTL(%d)=0x%08x\n",ch, __raw_readl(REG_TIMER_CTL(TMRBaseAddr)));
+		spin_unlock_irqrestore(&t->lock, flag);
+
+		break;
+
+	case TMR_IOC_EVENT_COUNTING:
+
+		// get capture setting
+		if(copy_from_user((void *)&param, (const void *)arg, sizeof(unsigned int)))
+			return -EFAULT;
+
+#ifndef CONFIG_USE_OF
+		// set pin function
+		if(t->ch == 0) {
+#if defined (CONFIG_NUC980_TIMER0_ECNT_PA0)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-ecnt-PA0");
+#elif defined (CONFIG_NUC980_TIMER0_ECNT_PD6)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-ecnt-PD6");
+#elif defined (CONFIG_NUC980_TIMER0_ECNT_PF0)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-ecnt-PF0");
+#elif defined (CONFIG_NUC980_TIMER0_ECNT_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 1) {
+#if defined (CONFIG_NUC980_TIMER1_ECNT_PA1)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-ecnt-PA1");
+#elif defined (CONFIG_NUC980_TIMER1_ECNT_PD7)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-ecnt-PD7");
+#elif defined (CONFIG_NUC980_TIMER1_ECNT_PF1)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-ecnt-PF1");
+#elif defined (CONFIG_NUC980_TIMER1_ECNT_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 2) {
+#if defined (CONFIG_NUC980_TIMER2_ECNT_PA2)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-ecnt-PA2");
+#elif defined (CONFIG_NUC980_TIMER2_ECNT_PD8)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-ecnt-PD8");
+#elif defined (CONFIG_NUC980_TIMER2_ECNT_PF2)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-ecnt-PF2");
+#elif defined (CONFIG_NUC980_TIMER2_ECNT_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 3) {
+#if defined (CONFIG_NUC980_TIMER3_ECNT_PA3)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer3-ecnt-PA3");
+#elif defined (CONFIG_NUC980_TIMER3_ECNT_PD9)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer3-ecnt-PD9");
+#elif defined (CONFIG_NUC980_TIMER3_ECNT_PF3)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer3-ecnt-PF3");
+#elif defined (CONFIG_NUC980_TIMER3_ECNT_NONE)
+			return -EPERM;
+#endif
+		}
+
+		if (IS_ERR(s)) {
+			pr_debug("pinctrl_lookup_state err\n");
+			return -EPERM;
+		}
+		if((ret = pinctrl_select_state(t->pinctrl, s)) < 0) {
+			pr_debug("pinctrl_select_state err\n");
+			return ret;
+		}
+#endif
+
+		spin_lock_irqsave(&t->lock, flag);
+		// timer clock is 12MHz, set prescaler to 12 - 1.
+		__raw_writel(0, REG_TIMER_PRECNT(TMRBaseAddr));
+		__raw_writel(param, REG_TIMER_CMPR(TMRBaseAddr));
+		// enable timeout interrupt
+		__raw_writel(0x1, REG_TIMER_IER(TMRBaseAddr));
+		__raw_writel(ETIMER_EVENT_COUNTER | ETIMER_CTL_PERIODIC | TMR_EXTCNT_EDGE_FF, REG_TIMER_CTL(TMRBaseAddr));
+		t->mode = ETIMER_OPMODE_EVENT_COUNTING;
+		spin_unlock_irqrestore(&t->lock, flag);
+
+		break;
+
+	case TMR_IOC_FREE_COUNTING:
+
+		// get capture setting
+		if(copy_from_user((void *)&param, (const void *)arg, sizeof(unsigned int)))
+			return -EFAULT;
+
+#ifndef CONFIG_USE_OF
+		// set pin function
+		if(t->ch == 0) {
+#if defined (CONFIG_NUC980_TIMER0_CAP_PB1)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-cap-PB1");
+#elif defined (CONFIG_NUC980_TIMER0_CAP_PB8)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-cap-PB8");
+#elif defined (CONFIG_NUC980_TIMER0_CAP_PB10)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-cap-PB10");
+#elif defined (CONFIG_NUC980_TIMER0_CAP_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 1) {
+#if defined (CONFIG_NUC980_TIMER1_CAP_PA13)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-cap-PA13");
+#elif defined (CONFIG_NUC980_TIMER1_CAP_PD1)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-cap-PD1");
+#elif defined (CONFIG_NUC980_TIMER1_CAP_PG12)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-cap-PG12");
+#elif defined (CONFIG_NUC980_TIMER1_CAP_PF9)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-cap-PF9");
+#elif defined (CONFIG_NUC980_TIMER1_CAP_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 2) {
+#if defined (CONFIG_NUC980_TIMER2_CAP_PA9)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-cap-PA9");
+#elif defined (CONFIG_NUC980_TIMER2_CAP_PB11)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-cap-PB11");
+#elif defined (CONFIG_NUC980_TIMER2_CAP_PD13)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-cap-PD13");
+#elif defined (CONFIG_NUC980_TIMER2_CAP_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 3) {
+#if defined (CONFIG_NUC980_TIMER3_CAP_PA7)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer3-cap-PA7");
+#elif defined (CONFIG_NUC980_TIMER3_CAP_PD15)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer3-cap-PD15");
+#elif defined (CONFIG_NUC980_TIMER3_CAP_NONE)
+			return -EPERM;
+#endif
+		}
+
+		if (IS_ERR(s)) {
+			pr_debug("pinctrl_lookup_state err\n");
+			return -EPERM;
+		}
+		if((ret = pinctrl_select_state(t->pinctrl, s)) < 0) {
+			pr_debug("pinctrl_select_state err\n");
+			return ret;
+		}
+#endif
+
+		spin_lock_irqsave(&t->lock, flag);
+		// timer clock is 12MHz.
+		__raw_writel(0, REG_TIMER_PRECNT(TMRBaseAddr));
+		__raw_writel(0xFFFFFF, REG_TIMER_CMPR(TMRBaseAddr));
+		// enable capture interrupt
+		__raw_writel(ETIMER_IER_TCAP_IE, REG_TIMER_IER(TMRBaseAddr));
+		__raw_writel(param | ETIMER_FREE_COUNTING, REG_TIMER_CTL(TMRBaseAddr));
+
+		t->mode = ETIMER_OPMODE_FREE_COUNTING;
+		spin_unlock_irqrestore(&t->lock, flag);
+
+		break;
+
+	case TMR_IOC_TRIGGER_COUNTING:
+		// get capture setting
+		if(copy_from_user((void *)&param, (const void *)arg, sizeof(unsigned int)))
+			return -EFAULT;
+
+
+#ifndef CONFIG_USE_OF
+		// set pin function
+		if(t->ch == 0) {
+#if defined (CONFIG_NUC980_TIMER0_CAP_PB1)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-cap-PB1");
+#elif defined (CONFIG_NUC980_TIMER0_CAP_PB8)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-cap-PB8");
+#elif defined (CONFIG_NUC980_TIMER0_CAP_PB10)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer0-cap-PB10");
+#elif defined (CONFIG_NUC980_TIMER0_CAP_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 1) {
+#if defined (CONFIG_NUC980_TIMER1_CAP_PA13)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-cap-PA13");
+#elif defined (CONFIG_NUC980_TIMER1_CAP_PD1)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-cap-PD1");
+#elif defined (CONFIG_NUC980_TIMER1_CAP_PG12)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-cap-PG12");
+#elif defined (CONFIG_NUC980_TIMER1_CAP_PF9)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer1-cap-PF9");
+#elif defined (CONFIG_NUC980_TIMER1_CAP_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 2) {
+#if defined (CONFIG_NUC980_TIMER2_CAP_PA9)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-cap-PA9");
+#elif defined (CONFIG_NUC980_TIMER2_CAP_PB11)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-cap-PB11");
+#elif defined (CONFIG_NUC980_TIMER2_CAP_PD13)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer2-cap-PD13");
+#elif defined (CONFIG_NUC980_TIMER2_CAP_NONE)
+			return -EPERM;
+#endif
+		} else if(t->ch == 3) {
+#if defined (CONFIG_NUC980_TIMER3_CAP_PA7)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer3-cap-PA7");
+#elif defined (CONFIG_NUC980_TIMER3_CAP_PD15)
+			s = pinctrl_lookup_state(t->pinctrl, "etimer3-cap-PD15");
+#elif defined (CONFIG_NUC980_TIMER3_CAP_NONE)
+			return -EPERM;
+#endif
+		}
+
+		if (IS_ERR(s)) {
+			pr_debug("pinctrl_lookup_state err\n");
+			return -EPERM;
+		}
+		if((ret = pinctrl_select_state(t->pinctrl, s)) < 0) {
+			pr_debug("pinctrl_select_state err\n");
+			return ret;
+		}
+#endif
+
+		spin_lock_irqsave(&t->lock, flag);
+		// timer clock is 12MHz.
+		__raw_writel(11, REG_TIMER_PRECNT(TMRBaseAddr));
+		__raw_writel(0xFFFFFF, REG_TIMER_CMPR(TMRBaseAddr));
+		// enable capture interrupt
+		__raw_writel(ETIMER_IER_TCAP_IE, REG_TIMER_IER(TMRBaseAddr));
+		__raw_writel((u32)(param | ETIMER_TRIGGER_COUNTING), REG_TIMER_CTL(TMRBaseAddr));
+		t->mode = ETIMER_OPMODE_TRIGGER_COUNTING;
+		spin_unlock_irqrestore(&t->lock, flag);
+		break;
+
+	default:
+		return -ENOTTY;
+
+
+	}
+	return 0;
+}
+
+static unsigned int etimer_poll(struct file *filp, poll_table *wait)
+{
+	struct nuc980_etimer *t = (struct nuc980_etimer *)filp->private_data;
+	unsigned int mask = 0;
+
+	poll_wait(filp, &t->wq, wait);
+	if(t->update)
+		mask |= POLLIN | POLLRDNORM;
+	return mask;
+}
+
+struct file_operations etimer_fops = {
+	.owner		= THIS_MODULE,
+	.open		= etimer_open,
+	.release	= etimer_release,
+	.read		= etimer_read,
+	.unlocked_ioctl	= etimer_ioctl,
+	.poll		= etimer_poll,
+};
+
+static struct miscdevice etimer_dev[] = {
+	[0] = {
+		.minor = MISC_DYNAMIC_MINOR,
+		.name = "timer0",
+		.fops = &etimer_fops,
+	},
+	[1] = {
+		.minor = MISC_DYNAMIC_MINOR,
+		.name = "timer1",
+		.fops = &etimer_fops,
+	},
+	[2] = {
+		.minor = MISC_DYNAMIC_MINOR,
+		.name = "timer2",
+		.fops = &etimer_fops,
+	},
+	[3] = {
+		.minor = MISC_DYNAMIC_MINOR,
+		.name = "timer3",
+		.fops = &etimer_fops,
+	},
+
+};
+
+static int nuc980_etimer_probe(struct platform_device *pdev)
+{
+	int ch = pdev->id;
+
+	//printk("nuc980_etimer_probe    %s - pdev = %s  \n", __func__, pdev->name);
+
+#ifdef CONFIG_USE_OF
+	struct pinctrl *pinctrl;
+	u32   val32[2];
+
+	//printk("nuc980_etimer_probe    %s - pdev = %s  \n", __func__, pdev->name);
+
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+	if (IS_ERR(pinctrl)) {
+		return PTR_ERR(pinctrl);
+	}
+
+	if (of_property_read_u32_array(pdev->dev.of_node, "port-number", val32, 1) != 0) {
+		printk("%s can not get port-number!\n", __func__);
+		return -EINVAL;
+	}
+
+	ch = val32[0];
+
+#endif
+
+	//printk("etimer %d  \n\n", ch);
+
+	etmr[ch] = devm_kzalloc(&pdev->dev, sizeof(struct nuc980_etimer), GFP_KERNEL);
+	if (etmr[ch] == NULL) {
+		dev_err(&pdev->dev, "failed to allocate memory for etimer device\n");
+		return -ENOMEM;
+	}
+
+
+	misc_register(&etimer_dev[ch]);
+
+	etmr[ch]->pinctrl = devm_pinctrl_get(&pdev->dev);
+	etmr[ch]->minor = MINOR(etimer_dev[ch].minor);
+	etmr[ch]->ch = ch;
+	spin_lock_init(&etmr[ch]->lock);
+
+#ifdef CONFIG_USE_OF
+	etmr[ch]->irq = platform_get_irq(pdev, 0);
+#else
+	etmr[ch]->irq = platform_get_irq(pdev, ch);
+#endif
+
+	//printk("etimer%d(pdev->id=%d), platform_get_irq - %d\n", ch, pdev->id, etmr[ch]->irq);
+
+	init_waitqueue_head(&etmr[ch]->wq);
+
+
+	platform_set_drvdata(pdev, etmr[ch]);
+
+
+	return(0);
+}
+
+static int nuc980_etimer_remove(struct platform_device *pdev)
+{
+	struct nuc980_etimer *t = platform_get_drvdata(pdev);
+	int ch = t->ch;
+
+	misc_deregister(&etimer_dev[ch]);
+
+
+	return 0;
+}
+
+
+#ifdef CONFIG_NUC980_TIMER_WKUP
+static int nuc980_etimer_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct nuc980_etimer *t = platform_get_drvdata(pdev);
+
+	void __iomem *TMRBaseAddr = TIMER0;
+
+	switch (t->ch) {
+	case 0:
+		TMRBaseAddr = TIMER0;
+		break;
+	case 1:
+		TMRBaseAddr = TIMER1;
+		break;
+	case 2:
+		TMRBaseAddr = TIMER2;
+		break;
+	case 3:
+		TMRBaseAddr = TIMER3;
+		break;
+	}
+
+	//pr_debug("******* nuc980_etimer_suspend pdev->id = %d, gu8_ch= %d, t->ch =%d \n", pdev->id, gu8_ch,  t->ch);
+	if(t->ch == gu8_ch) {
+		__raw_writel(__raw_readl(REG_WKUPSER0)| (0x100<<(gu8_ch)),REG_WKUPSER0);
+
+		__raw_writel(ETIMER_CTL_PERIODIC | ETIMER_CTL_ETMR_EN | ETIMER_CTL_TWAKE_EN, REG_TIMER_CTL(TMRBaseAddr));
+
+
+		enable_irq_wake(t->irq);
+	}
+
+	return 0;
+}
+
+static int nuc980_etimer_resume(struct platform_device *pdev)
+{
+	struct nuc980_etimer *t = platform_get_drvdata(pdev);
+	void __iomem *TMRBaseAddr = TIMER0;
+
+	switch (t->ch) {
+	case 0:
+		TMRBaseAddr = TIMER0;
+		break;
+	case 1:
+		TMRBaseAddr = TIMER1;
+		break;
+	case 2:
+		TMRBaseAddr = TIMER2;
+		break;
+	case 3:
+		TMRBaseAddr = TIMER3;
+		break;
+	}
+
+	//pr_debug("======== nuc980_etimer_resume pdev->id = %d, gu8_ch= %d, t->ch =%d \n", pdev->id, gu8_ch,  t->ch);
+	if(t->ch == gu8_ch) {
+		__raw_writel(__raw_readl(REG_WKUPSER0)& ~(0x100<<(gu8_ch)),REG_WKUPSER0);
+
+		__raw_writel(ETIMER_CTL_PERIODIC | ETIMER_CTL_ETMR_EN, REG_TIMER_CTL(TMRBaseAddr));
+
+		disable_irq_wake(t->irq);
+	}
+
+	return 0;
+}
+
+#else
+#define nuc980_etimer_suspend 	NULL
+#define nuc980_etimer_resume	NULL
+#endif
+
+static const struct of_device_id nuc980_etimer_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-timer" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_etimer_of_match);
+
+static struct platform_driver nuc980_etimer_driver = {
+	.driver		= {
+		.owner	= THIS_MODULE,
+		.name	= "nuc980-timer",
+		.of_match_table = of_match_ptr(nuc980_etimer_of_match),
+	},
+	.probe		= nuc980_etimer_probe,
+	.remove		= nuc980_etimer_remove,
+	.suspend	= nuc980_etimer_suspend,
+	.resume		= nuc980_etimer_resume,
+};
+
+
+module_platform_driver(nuc980_etimer_driver);
+
+
+
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_ALIAS("platform:nuc980-timer");
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/misc/nuc980-qspi0-slave.c NUC980-linux-4.4.194/drivers/misc/nuc980-qspi0-slave.c
--- linux-4.4.194/drivers/misc/nuc980-qspi0-slave.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/misc/nuc980-qspi0-slave.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,881 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/gpio.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+
+#include <linux/spi/spi.h>
+#include <linux/spi/spi_bitbang.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/spi-nuc980.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/map.h>
+#include <asm/mach/irq.h>
+#include <asm/irq.h>
+
+#include <mach/hardware.h>
+#include <mach/regs-gcr.h>
+
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <mach/regs-pdma.h>
+
+#include <linux/platform_data/dma-nuc980.h>
+
+/* spi registers offset */
+#define REG_CTL		0x00
+#define REG_CLKDIV	0x04
+#define REG_SSCTL	0x08
+#define REG_PDMACTL	0x0C
+#define REG_FIFOCTL	0x10
+#define REG_STATUS	0x14
+#define REG_TX		0x20
+#define REG_RX		0x30
+
+/* spi register bit */
+#define UNITIEN		(0x01 << 17)
+#define TXNEG		(0x01 << 2)
+#define RXNEG		(0x01 << 1)
+#define SLAVE		(0x01 << 18)
+#define LSB		(0x01 << 13)
+#define SELECTLEV	(0x01 << 2)
+#define SELECTPOL	(0x01 << 3)
+#define SSACTIEN	(0x01 << 12)
+#define SELECTSLAVE0	0x01
+#define SELECTSLAVE1	0x02
+#define SPIEN		0x01
+#define TXTHIEN		(0x01 << 3)
+#define RXTHIEN		(0x01 << 2)
+#define SSINAIEN	(0x01 << 13)
+#define SSACTIF		(0x01 << 2)
+#define SSINAIF		(0x01 << 3)
+#define RXTHIF		(0x01 << 10)
+#define TXTHIF		(0x01 << 18)
+#define TXUFIF		(0x01 << 19)
+
+#ifdef CONFIG_SPI_NUC980_QSPI0
+# error Do not enable CONFIG_SPI_NUC980_QSPI0 and CONFIG_NUC980_QSPI0_SLAVE at the same time!
+#endif
+
+static volatile int slave_done_state=0;
+static DECLARE_WAIT_QUEUE_HEAD(slave_done);
+
+static int QSPI0_SlaveDataLen = 256;
+static int QSPI0_SlaveData[256];
+static int TransmittedCnt = 0;
+static int InTransmitted = 0;
+
+struct nuc980_spi {
+	struct spi_bitbang	bitbang;
+	struct completion	done;
+	void __iomem		*regs;
+	int			irq;
+	unsigned int 		len;
+	unsigned int		count;
+	const void		*tx;
+	void			*rx;
+	struct clk		*clk;
+	struct resource		*ioarea;
+	struct spi_master	*master;
+	struct spi_device	*curdev;
+	struct device		*dev;
+	struct nuc980_spi_info *pdata;
+	spinlock_t		lock;
+	struct resource		*res;
+};
+
+
+static inline struct nuc980_qspi0 *to_hw(struct spi_device *sdev) {
+	return spi_master_get_devdata(sdev->master);
+}
+
+static inline void nuc980_slave_select(struct spi_device *spi, unsigned int ssr)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int val;
+	unsigned int cs = spi->mode & SPI_CS_HIGH ? 1 : 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_SSCTL);
+
+	if (!cs)
+		val &= ~SELECTLEV;
+	else
+		val |= SELECTLEV;
+
+	if(spi->chip_select == 0) {
+		if (!ssr)
+			val &= ~SELECTSLAVE0;
+		else
+			val |= SELECTSLAVE0;
+	} else {
+		if (!ssr)
+			val &= ~SELECTSLAVE1;
+		else
+			val |= SELECTSLAVE1;
+	}
+
+	__raw_writel(val, hw->regs + REG_SSCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_qspi0_chipsel(struct spi_device *spi, int value)
+{
+	switch (value) {
+	case BITBANG_CS_INACTIVE:
+		nuc980_slave_select(spi, 0);
+		break;
+
+	case BITBANG_CS_ACTIVE:
+		nuc980_slave_select(spi, 1);
+		break;
+	}
+}
+
+static inline void nuc980_qspi0_setup_txbitlen(struct nuc980_spi *hw,
+                unsigned int txbitlen)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+	val &= ~0x1f00;
+	if(txbitlen != 32)
+		val |= (txbitlen << 8);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_set_clock_polarity(struct nuc980_spi *hw, unsigned int polarity)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (polarity)
+		val |= SELECTPOL;
+	else
+		val &= ~SELECTPOL;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_tx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= TXNEG;
+	else
+		val &= ~TXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_rx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= RXNEG;
+	else
+		val &= ~RXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_send_first(struct nuc980_spi *hw, unsigned int lsb)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (lsb)
+		val |= LSB;
+	else
+		val &= ~LSB;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_enable_slave(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	val |= SLAVE;
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_set_sleep(struct nuc980_spi *hw, unsigned int sleep)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	val &= ~(0x0f << 4);
+
+	if (sleep)
+		val |= (sleep << 4);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+
+static inline void nuc980_set_divider(struct nuc980_spi *hw)
+{
+	__raw_writel(hw->pdata->divider, hw->regs + REG_CLKDIV);
+}
+
+static int nuc980_qspi0_update_state(struct spi_device *spi,
+                                     struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int clk;
+	unsigned int div;
+	unsigned int bpw;
+	unsigned int hz;
+	unsigned char spimode;
+
+	bpw = t ? t->bits_per_word : spi->bits_per_word;
+	hz  = t ? t->speed_hz : spi->max_speed_hz;
+
+	if(hw->pdata->txbitlen != bpw)
+		hw->pdata->txbitlen = bpw;
+
+	if(hw->pdata->hz != hz) {
+		clk = clk_get_rate(hw->clk);
+		div = DIV_ROUND_UP(clk, hz) - 1;
+		hw->pdata->hz = hz;
+		hw->pdata->divider = div;
+	}
+
+	//Mode 0: CPOL=0, CPHA=0; active high
+	//Mode 1: CPOL=0, CPHA=1 ;active low
+	//Mode 2: CPOL=1, CPHA=0 ;active low
+	//Mode 3: POL=1, CPHA=1;active high
+	if (spi->mode & SPI_CPOL)
+		hw->pdata->clkpol = 1;
+	else
+		hw->pdata->clkpol = 0;
+
+	spimode = spi->mode & 0xff; //remove dual/quad bit
+
+	if ((spimode == SPI_MODE_0) || (spimode == SPI_MODE_2)) {
+		hw->pdata->txneg = 1;
+		hw->pdata->rxneg = 0;
+	} else {
+		hw->pdata->txneg = 0;
+		hw->pdata->rxneg = 1;
+	}
+
+	if (spi->mode & SPI_LSB_FIRST)
+		hw->pdata->lsb = 1;
+	else
+		hw->pdata->lsb = 0;
+
+	return 0;
+}
+
+static int nuc980_qspi0_setupxfer(struct spi_device *spi,
+                                  struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_qspi0_update_state(spi, t);
+	if (ret)
+		return ret;
+
+	nuc980_qspi0_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_divider(hw);
+
+	return 0;
+}
+
+static int nuc980_qspi0_setup(struct spi_device *spi)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_qspi0_update_state(spi, NULL);
+	if (ret)
+		return ret;
+
+	spin_lock(&hw->bitbang.lock);
+	if (!hw->bitbang.busy) {
+		nuc980_set_divider(hw);
+		nuc980_slave_select(spi, 0);
+	}
+	spin_unlock(&hw->bitbang.lock);
+
+	return 0;
+}
+
+static inline void nuc980_enable_rxth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val = (val & ~0x7000000) | 0x0000000; /* set RXTH = 0 */
+	val |= RXTHIEN; /* enable RXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_disable_rxth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val &= ~RXTHIEN; /* disable RXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_enable_txth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val = (val & ~0x70000000) | 0x30000000; /* set TXTH = 3 */
+	val |= TXTHIEN; /* enable TXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_disable_txth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val &= ~TXTHIEN; /* disable TXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_enable_ssinact_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_SSCTL);
+
+	val |= SSINAIEN; /* enable SSINAIEN */
+
+	__raw_writel(val, hw->regs + REG_SSCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static irqreturn_t nuc980_qspi0_irq(int irq, void *dev)
+{
+	struct nuc980_spi *hw = dev;
+	unsigned int val, status;
+
+	status = __raw_readl(hw->regs + REG_STATUS);
+	__raw_writel(status, hw->regs + REG_STATUS);
+
+	if (status & RXTHIF) {
+		if (InTransmitted == 0) {
+			nuc980_disable_rxth_int(hw);
+			slave_done_state = 1;
+			wake_up_interruptible(&slave_done);
+			InTransmitted = 1;
+		}
+	}
+	if (status & TXTHIF) {
+		while(!(__raw_readl(hw->regs + REG_STATUS) & 0x20000)) {//TXFULL
+			__raw_writel(QSPI0_SlaveData[TransmittedCnt++], hw->regs + REG_TX);
+			if (TransmittedCnt >= QSPI0_SlaveDataLen) {
+				nuc980_disable_txth_int(hw);
+				InTransmitted = 0;
+				TransmittedCnt = 0;
+				break;
+			}
+		}
+	}
+	if (status & SSINAIF) {
+		/* Check if transmition complete */
+		if (InTransmitted == 1) {
+			int i;
+			printk("Master pull SS high, but slave TX doesn't complete!\n");
+			__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //TXRX reset
+			while (__raw_readl(hw->regs + REG_STATUS) & (1<<23)); //TXRXRST
+			nuc980_enable_rxth_int(hw);
+			InTransmitted = 0;
+			TransmittedCnt = 0;
+			for (i = 0; i < QSPI0_SlaveDataLen; i++)
+				QSPI0_SlaveData[i] = 0;
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+
+static void nuc980_init_spi(struct nuc980_spi *hw)
+{
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	spin_lock_init(&hw->lock);
+
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_sleep(hw, hw->pdata->sleep);
+	nuc980_qspi0_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_set_divider(hw);
+	nuc980_enable_slave(hw);
+	nuc980_enable_rxth_int(hw);
+	nuc980_enable_ssinact_int(hw);
+}
+
+#ifdef CONFIG_OF
+static struct nuc980_spi_info *nuc980_qspi0_parse_dt(struct device *dev) {
+	struct nuc980_spi_info *sci;
+	u32 temp;
+
+	sci = devm_kzalloc(dev, sizeof(*sci), GFP_KERNEL);
+	if (!sci) {
+		dev_err(dev, "memory allocation for spi_info failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	if (of_property_read_u32(dev->of_node, "num_cs", &temp)) {
+		dev_warn(dev, "can't get num_cs from dt\n");
+		sci->num_cs = 2;
+	} else {
+		sci->num_cs = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "lsb", &temp)) {
+		dev_warn(dev, "can't get lsb from dt\n");
+		sci->lsb = 0;
+	} else {
+		sci->lsb = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txneg", &temp)) {
+		dev_warn(dev, "can't get txneg from dt\n");
+		sci->txneg = 1;
+	} else {
+		sci->txneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "clkpol", &temp)) {
+		dev_warn(dev, "can't get clkpol from dt\n");
+		sci->clkpol = 0;
+	} else {
+		sci->clkpol = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "rxneg", &temp)) {
+		dev_warn(dev, "can't get rxneg from dt\n");
+		sci->rxneg = 0;
+	} else {
+		sci->rxneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "divider", &temp)) {
+		dev_warn(dev, "can't get divider from dt\n");
+		sci->divider = 4;
+	} else {
+		sci->divider = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "sleep", &temp)) {
+		dev_warn(dev, "can't get sleep from dt\n");
+		sci->sleep = 0;
+	} else {
+		sci->sleep = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txbitlen", &temp)) {
+		dev_warn(dev, "can't get txbitlen from dt\n");
+		sci->txbitlen = 8;
+	} else {
+		sci->txbitlen = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "bus_num", &temp)) {
+		dev_warn(dev, "can't get bus_num from dt\n");
+		sci->bus_num = 0;
+	} else {
+		sci->bus_num = temp;
+	}
+
+	return sci;
+}
+#else
+static struct nuc980_spi_info *nuc980_qspi0_parse_dt(struct device *dev) {
+	return dev->platform_data;
+}
+#endif
+
+/* In Thread, only prepare data and enable TXTHIEN.
+   The data will be transmitted in IRQ
+ */
+static int QSPI0_Slave_Thread_TXRX(struct nuc980_spi *hw)
+{
+	unsigned char rx;
+	unsigned long flags;
+	int i;
+
+	while(1) {
+
+		wait_event_interruptible(slave_done, (slave_done_state != 0));
+		rx = __raw_readl(hw->regs + REG_RX);
+		//printk("Receive [0x%x] \n", rx);
+
+		switch (rx) {
+		case 0x9f:
+			for (i = 0; i < QSPI0_SlaveDataLen; i++)
+				QSPI0_SlaveData[i] = i;
+
+			nuc980_enable_txth_int(hw);
+			break;
+		default:
+			break;
+		}
+
+		InTransmitted = 0;
+		slave_done_state = 0;
+		nuc980_enable_rxth_int(hw);
+	}
+
+	return 0;
+}
+
+static int nuc980_qspi0_slave_probe(struct platform_device *pdev)
+{
+	struct nuc980_spi *hw;
+	struct spi_master *master;
+	int err = 0;
+	struct pinctrl *p;
+
+	master = spi_alloc_master(&pdev->dev, sizeof(struct nuc980_spi));
+	if (master == NULL) {
+		dev_err(&pdev->dev, "No memory for spi_master\n");
+		err = -ENOMEM;
+		goto err_nomem;
+	}
+
+	hw = spi_master_get_devdata(master);
+	hw->master = spi_master_get(master);
+	hw->pdata = nuc980_qspi0_parse_dt(&pdev->dev);
+	hw->dev = &pdev->dev;
+
+	if (hw->pdata == NULL) {
+		dev_err(&pdev->dev, "No platform data supplied\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+	platform_set_drvdata(pdev, hw);
+	init_completion(&hw->done);
+#if defined(SPI_NUC980_QSPI0_SLAVE_NORMAL)
+	master->mode_bits          = (SPI_MODE_0 | SPI_CS_HIGH | SPI_LSB_FIRST | SPI_CPHA | SPI_CPOL);
+#elif defined(SPI_NUC980_QSPI0_SLAVE_QUAD)
+	master->mode_bits          = (SPI_MODE_0 | SPI_TX_DUAL | SPI_RX_DUAL | SPI_TX_QUAD | SPI_RX_QUAD | SPI_CS_HIGH | SPI_LSB_FIRST | SPI_CPHA | SPI_CPOL);
+#endif
+	master->dev.of_node        = pdev->dev.of_node;
+	master->num_chipselect     = hw->pdata->num_cs;
+	master->bus_num            = hw->pdata->bus_num;
+	hw->bitbang.master         = hw->master;
+	hw->bitbang.setup_transfer = nuc980_qspi0_setupxfer;
+	hw->bitbang.chipselect     = nuc980_qspi0_chipsel;
+	hw->bitbang.master->setup  = nuc980_qspi0_setup;
+
+	hw->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (hw->res == NULL) {
+		dev_err(&pdev->dev, "Cannot get IORESOURCE_MEM\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+#if defined(CONFIG_OF)
+	hw->regs = devm_ioremap_resource(&pdev->dev, hw->res);
+#else
+	hw->ioarea = request_mem_region(hw->res->start,
+	                                resource_size(hw->res), pdev->name);
+
+	if (hw->ioarea == NULL) {
+		dev_err(&pdev->dev, "Cannot reserve region\n");
+		err = -ENXIO;
+		goto err_pdata;
+	}
+
+	hw->regs = ioremap(hw->res->start, resource_size(hw->res));
+	if (hw->regs == NULL) {
+		dev_err(&pdev->dev, "Cannot map IO\n");
+		err = -ENXIO;
+		goto err_iomap;
+	}
+#endif
+
+	hw->irq = platform_get_irq(pdev, 0);
+	if (hw->irq < 0) {
+		dev_err(&pdev->dev, "No IRQ specified\n");
+		err = -ENOENT;
+		goto err_irq;
+	}
+
+	err = request_irq(hw->irq, nuc980_qspi0_irq, 0, pdev->name, hw);
+	if (err) {
+		dev_err(&pdev->dev, "Cannot claim IRQ\n");
+		goto err_irq;
+	}
+
+	hw->clk = clk_get(NULL, "qspi0_eclk");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	hw->clk = clk_get(NULL, "qspi0");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+#if defined(CONFIG_OF)
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+	/*
+#if defined(CONFIG_SPI_NUC980_P0_NORMAL) && !defined(CONFIG_SPI_NUC980_P0_SS1)
+		p = devm_pinctrl_get_select(&pdev->dev, "qspi0");
+#elif defined(CONFIG_SPI_NUC980_P0_NORMAL) && defined(CONFIG_SPI_NUC980_P0_SS1_PB0)
+		p = devm_pinctrl_get_select(&pdev->dev, "qspi0-ss1-PB");
+#elif defined(CONFIG_SPI_NUC980_P0_NORMAL) && defined(CONFIG_SPI_NUC980_P0_SS1_PH12)
+		p = devm_pinctrl_get_select(&pdev->dev, "qspi0-ss1-PH");
+#elif defined(CONFIG_SPI_NUC980_P0_QUAD) && !defined(CONFIG_SPI_NUC980_P0_SS1)
+		p = devm_pinctrl_get_select(&pdev->dev, "qspi0-quad");
+#elif defined(CONFIG_SPI_NUC980_P0_QUAD) && defined(CONFIG_SPI_NUC980_P0_SS1_PB0)
+		p = devm_pinctrl_get_select(&pdev->dev, "qspi0-quad-ss1-PB");
+#elif defined(CONFIG_SPI_NUC980_P0_QUAD) && defined(CONFIG_SPI_NUC980_P0_SS1_PH12)
+		p = devm_pinctrl_get_select(&pdev->dev, "qspi0-quad-ss1-PB");
+#endif
+	*/
+	/*TODO : use pinctrl*/
+	__raw_writel(0x11111100, REG_MFP_GPD_L);
+#endif
+	if(IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve spi pin by mode\n");
+		err = PTR_ERR(p);
+		goto err_register;
+	}
+
+	nuc980_init_spi(hw);
+
+	__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //CWWeng : RXRST & TXRST
+	while (__raw_readl(hw->regs + REG_STATUS) & (1<<23)); //TXRXRST
+
+	__raw_writel(__raw_readl(hw->regs + REG_CTL) | SPIEN, hw->regs + REG_CTL); /* enable SPI */
+	while ((__raw_readl(hw->regs + REG_STATUS) & (1<<15)) == 0); //SPIENSTS
+
+	kthread_run(QSPI0_Slave_Thread_TXRX, hw, "QSPI0_SLAVE_THread_TXRX");
+
+	return 0;
+
+err_register:
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+err_clk:
+	free_irq(hw->irq, hw);
+err_irq:
+	iounmap(hw->regs);
+#ifndef CONFIG_OF
+err_iomap:
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#endif
+err_pdata:
+	spi_master_put(hw->master);
+
+err_nomem:
+	return err;
+}
+
+static int nuc980_qspi0_slave_remove(struct platform_device *dev)
+{
+	struct nuc980_spi *hw = platform_get_drvdata(dev);
+
+	free_irq(hw->irq, hw);
+	platform_set_drvdata(dev, NULL);
+	spi_bitbang_stop(&hw->bitbang);
+
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+
+	iounmap(hw->regs);
+
+#ifndef CONFIG_OF
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#else
+	kfree(hw->pdata);
+#endif
+
+	spi_master_put(hw->master);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_qspi0_suspend(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	while(__raw_readl(hw->regs + REG_CTL) & 0x1)
+		msleep(1);
+
+	// disable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) & ~0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static int nuc980_qspi0_resume(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	// enable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) | 0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_qspi0_pmops = {
+	.suspend    = nuc980_qspi0_suspend,
+	.resume     = nuc980_qspi0_resume,
+};
+
+#define NUC980_QSPI0_PMOPS (&nuc980_qspi0_pmops)
+
+#else
+#define NUC980_QSPI0_PMOPS NULL
+#endif
+
+#if defined(CONFIG_OF)
+static const struct of_device_id nuc980_qspi0_slave_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-qspi0-slave" },
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_qspi0_of_match);
+#endif
+
+static struct platform_driver nuc980_qspi0_slave_driver = {
+	.probe      = nuc980_qspi0_slave_probe,
+	.remove     = nuc980_qspi0_slave_remove,
+	.driver     = {
+		.name   = "nuc980-qspi0-slave",
+		.owner  = THIS_MODULE,
+		.pm	= NUC980_QSPI0_PMOPS,
+#if defined(CONFIG_OF)
+		.of_match_table = of_match_ptr(nuc980_qspi0_slave_of_match),
+#endif
+	},
+};
+module_platform_driver(nuc980_qspi0_slave_driver);
+
+MODULE_DESCRIPTION("nuc980 qspi0 slave driver!");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-qspi0-slave");
diff -uprN linux-4.4.194/drivers/misc/nuc980-sc.c NUC980-linux-4.4.194/drivers/misc/nuc980-sc.c
--- linux-4.4.194/drivers/misc/nuc980-sc.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/misc/nuc980-sc.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,994 @@
+/* linux/driver/misc/nuc980-sc.c
+ *
+ * Copyright (c) 2018 Nuvoton Technology Corporation
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/slab.h>
+#include <linux/miscdevice.h>
+#include <linux/device.h>
+#include <linux/mutex.h>
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/clk.h>
+#include <linux/wait.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-sc.h>
+#include <mach/nuc980-sc.h>
+
+extern int ATR_InitFromArray (ATR_t * atr, const char atr_buffer[ATR_MAX_SIZE], unsigned int length);
+extern int ATR_CheckIntegrity(ATR_t * atr, int type);
+extern int ATR_Parse(int intf);
+extern void CmdXfrT0(unsigned int reader_index,
+                     unsigned int snd_len, unsigned char snd_buf[], /*unsigned int *rcv_len,*/
+                     unsigned char rcv_buf[]);
+extern void CmdXfrT1(unsigned int reader_index,
+                     unsigned int snd_len, unsigned char snd_buf[], /*unsigned int *rcv_len,*/
+                     unsigned char rcv_buf[]);
+
+extern int t1_init(unsigned int intf);
+extern int t1_negotiate_ifsd(/*t1_state_t * t1*/unsigned int intf, unsigned int dad, int ifsd);
+
+struct nuc980_sc sc[SC_INTF];
+static int atr_remain_t, atr_remain, ifbyte_flag, tck; // variables for ATR processing
+
+
+static void reset_reader(struct nuc980_sc *sc)
+{
+	// stop all timers
+	__raw_writel((__raw_readl(sc->base + REG_SC_ALTCTL) & ~(SC_ALTCTL_CNTEN2 | SC_ALTCTL_CNTEN1 | SC_ALTCTL_CNTEN0)) |
+	             (SC_ALTCTL_TXRST | SC_ALTCTL_RXRST | SC_ALTCTL_ADACEN),
+	             sc->base + REG_SC_ALTCTL);
+
+	// Set Rx trigger level to 1 character, longest card detect debounce period, disable error retry (EMV ATR does not use error retry)
+	// Enable auto convention, and all three smartcard internal timers
+	__raw_writel((__raw_readl(sc->base + REG_SC_CTL) & ~(SC_CTL_RXTRGLV | SC_CTL_TXRTY | SC_CTL_RXRTY)) | (SC_CTL_AUTOCEN | SC_CTL_TMRSEL),
+	             sc->base + REG_SC_CTL);
+	__raw_writel(0, sc->base + REG_SC_TMRCTL0);
+	__raw_writel(0, sc->base + REG_SC_TMRCTL1);
+	__raw_writel(0, sc->base + REG_SC_TMRCTL2);
+	// Disable Rx timeout
+	__raw_writel(0, sc->base + REG_SC_RXTOUT);
+	// 372 clocks per ETU by default
+	__raw_writel(371, sc->base + REG_SC_ETUCTL);
+
+
+	/* Enable necessary interrupt for smartcard operation */
+	if(sc->cdlvl == 2) // Do not enable card detect interrupt if card present state ignore
+		__raw_writel(SC_INTEN_RDAIEN |
+		             SC_INTEN_TERRIEN |
+		             SC_INTEN_TMR0IEN |
+		             SC_INTEN_TMR1IEN |
+		             SC_INTEN_TMR2IEN |
+		             SC_INTEN_INITIEN |
+		             SC_INTEN_ACERRIEN, sc->base + REG_SC_INTEN);
+	else
+		__raw_writel(SC_INTEN_RDAIEN |
+		             SC_INTEN_TERRIEN |
+		             SC_INTEN_TMR0IEN |
+		             SC_INTEN_TMR1IEN |
+		             SC_INTEN_TMR2IEN |
+		             SC_INTEN_CDIEN |
+		             SC_INTEN_INITIEN |
+		             SC_INTEN_ACERRIEN, sc->base + REG_SC_INTEN);
+#ifdef CONFIG_EMV_CHECK
+	__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_INITSEL, sc->base + REG_SC_ALTCTL);
+#endif
+
+	return;
+}
+
+static void config_reader(struct nuc980_sc *sc)
+{
+	int GT = 12;
+	// Set ETU
+	__raw_writel(sc->F / sc->D, sc->base + REG_SC_ETUCTL);
+	// Calculate GT
+	if(sc->N == 255) {
+		if(sc->protocol == 1)
+			GT = 11;
+	} else if(sc->N != 0) {
+		GT = sc->N + 12;
+	}
+	// Set EGT and BGT
+	if(sc->protocol == 0) {
+		__raw_writel((__raw_readl(sc->base + REG_SC_CTL) & ~(SC_CTL_NSB |SC_CTL_BGT)) | ((16 - 1) << 8),
+		             sc->base + REG_SC_CTL);
+		__raw_writel(GT - 12, sc->base + REG_SC_EGT);
+	} else {
+		//printk("set EGT to %d\n", GT - 11);
+		__raw_writel((__raw_readl(sc->base + REG_SC_CTL) & ~SC_CTL_BGT) | SC_CTL_NSB | ((22 - 1) << 8),
+		             sc->base + REG_SC_CTL);
+		__raw_writel(GT - 11, sc->base + REG_SC_EGT);
+	}
+	// Set retry count
+	while(__raw_readl(sc->base + REG_SC_CTL) & SC_CTL_SYNC);
+	if(sc->protocol == 0) { // retry 4 times max for T0
+		//printk("set retry count %d\n", __raw_readl(sc->base + REG_SC_ETUCTL));
+		__raw_writel((__raw_readl(sc->base + REG_SC_CTL) & ~(SC_CTL_TXRTY | SC_CTL_RXRTY)) | SC_CTL_TXRTYEN | SC_CTL_RXRTYEN | 0x00330000,
+		             sc->base + REG_SC_CTL);
+		__raw_writel(SC_ALTCTL_RXRST | SC_ALTCTL_TXRST, sc->base + REG_SC_ALTCTL);
+
+	} else { // disable retry if T1
+		__raw_writel(__raw_readl(sc->base + REG_SC_CTL) & ~(SC_CTL_TXRTYEN | SC_CTL_RXRTYEN),
+		             sc->base + REG_SC_CTL);
+
+	}
+
+}
+
+// type 0: cold reset, 1: warm reset
+int parse_atr(struct nuc980_sc *sc, int type)
+{
+	int i;
+
+	//printk("parse\n");
+	if(ATR_InitFromArray(&sc->atr, sc->atrbuf, sc->atrlen) != 0)
+		return SC_ERR_ATR;
+#ifdef CONFIG_EMV_CHECK
+	if((i = ATR_CheckIntegrity(&sc->atr, type)) != 0)
+		return i;
+#endif
+	if((i = ATR_Parse(sc->intf)) != 0)
+		return i;
+
+	config_reader(sc);
+
+
+	return 0;
+
+}
+
+
+//XXX: make sure Tx/Rx pointer does not excees buffer size
+static irqreturn_t nuc980_sc_interrupt(int irq, void *dev_id)
+{
+	struct nuc980_sc *sc = (struct nuc980_sc *)dev_id;
+
+	u32 intsts = __raw_readl(sc->base + REG_SC_INTSTS);
+	u32 status = __raw_readl(sc->base + REG_SC_STATUS);
+	u32 inten = __raw_readl(sc->base + REG_SC_INTEN);
+
+	// Activate, warm reset, deactivate
+	if(intsts & SC_INTSTS_INITIF) {
+		__raw_writel(SC_INTSTS_INITIF, sc->base + REG_SC_INTSTS);
+		if(__raw_readl(sc->base + REG_SC_PINCTL) & SC_PINCTL_RSTSTS) {  // cold reset or warm reset
+			//printk("activate done\n");
+			sc->state = SC_OP_READ_ATR;
+		} else { // deactivate
+			sc->state = SC_OP_IDLE;
+			sc->act = -1;
+			//printk("deact done %d\n", sc->act);
+		}
+
+	}
+
+	// Check CD event
+	if(intsts & SC_INTSTS_CDIF) {
+
+		// don't care about latest CD status. As long as remove event trigger, stop everything...
+		if(status & SC_STATUS_CREMOVE) {
+			//printk("SC%d: Card Removed\n", intf);
+			/* Stop write operation */
+			__raw_writel(__raw_readl(sc->base + REG_SC_INTEN) & ~SC_INTEN_TBEIEN, sc->base + REG_SC_INTEN);
+			__raw_writel(SC_STATUS_CREMOVE, sc->base + REG_SC_STATUS);
+
+			sc->err = SC_ERR_CARD_REMOVED;
+			sc->state = SC_OP_IDLE;
+			sc->act = -1;
+			sc->atrlen = sc->protocol = 0;
+			memset(&sc->T0, 0, sizeof(sc->T0));
+			memset(&sc->T1, 0, sizeof(sc->T1));
+			memset(&sc->T0_dat, 0, sizeof(sc->T0_dat));
+			memset(&sc->T1_dat, 0, sizeof(sc->T1_dat));
+			memset(&sc->atr, 0, sizeof(sc->atr));
+
+			__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) & ~(SC_ALTCTL_CNTEN2 | SC_ALTCTL_CNTEN1 | SC_ALTCTL_CNTEN0),
+			             sc->base + REG_SC_ALTCTL);
+			__raw_writel(SC_ALTCTL_RXRST | SC_ALTCTL_TXRST, sc->base + REG_SC_ALTCTL);
+
+		} else if(status & SC_STATUS_CINSERT) {
+			__raw_writel(SC_STATUS_CINSERT, sc->base + REG_SC_STATUS);
+
+		}
+		// clear CD_IS bit
+		__raw_writel(SC_INTSTS_CDIF, sc->base + REG_SC_INTSTS);
+
+	}
+
+	// Check Timeout event
+	if(intsts & SC_INTSTS_TMR0IF) {
+		__raw_writel(SC_INTSTS_TMR0IF, sc->base + REG_SC_INTSTS);
+		sc->err = SC_ERR_TIME0OUT;
+		sc->state = SC_OP_IDLE;
+		__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc->base + REG_SC_ALTCTL);
+
+	}
+
+	if(intsts & SC_INTSTS_TMR1IF) {
+		__raw_writel(SC_INTSTS_TMR1IF, sc->base + REG_SC_INTSTS);
+		sc->err = SC_ERR_TIME1OUT;
+		sc->state = SC_OP_IDLE;
+		__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN1, sc->base + REG_SC_ALTCTL);
+	}
+
+	if(intsts & SC_INTSTS_TMR2IF) {
+		__raw_writel(SC_INTSTS_TMR2IF, sc->base + REG_SC_INTSTS);
+
+		if(atr_remain_t < 0) {
+			__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN2, sc->base + REG_SC_ALTCTL);
+			sc->err = SC_ERR_TIME2OUT;
+		} else {
+			atr_remain_t -= 256;
+		}
+
+	}
+
+	// Check Tx/Rx event
+	/* transmit buffer empty interrupt */
+	if(intsts & SC_INTSTS_TBEIF) {
+		if( sc->state == SC_OP_WRITE ) {
+			int len, i;
+			// We can push 4 bytes into FIFO at most due to FIFO depth limitation
+			if(sc->tcnt - sc->toffset > 3)
+				len = 4;
+			else
+				len = sc->tcnt - sc->toffset;
+			for(i = 0; i < len; i++) {
+				__raw_writel(sc->tbuf[sc->toffset++], sc->base + REG_SC_DAT);
+			}
+			if(sc->toffset == sc->tcnt) {
+				__raw_writel(__raw_readl(sc->base + REG_SC_INTEN) & ~SC_INTEN_TBEIEN, sc->base + REG_SC_INTEN);
+				sc->state = SC_OP_IDLE;
+			}
+		}
+	}
+
+	/* RDR data ready or Rx time out*/
+	if(intsts & (SC_INTSTS_RDAIF | SC_INTSTS_RXTOIF)) {
+
+		if(sc->state == SC_OP_READ) {
+			// [2011.11.25]
+			/* EMV Certification */
+			if(sc->protocol == SC_PROTOCOL_T1) {
+				// ISO 7816-3 11.4.3, CWT = (11 + 2^CWI)ETU
+				__raw_writel((sc->T1.CWT + 50) | SC_TMR_MODE_7, sc->base + REG_SC_TMRCTL0);
+				__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_CNTEN0, sc->base + REG_SC_ALTCTL);
+			}
+			if(intsts & SC_INTSTS_RDAIF) {
+				sc->rbuf[sc->rtail++] = __raw_readl(sc->base + REG_SC_DAT);
+
+			}
+		} else if(sc->state == SC_OP_READ_ATR) {  /* Read ATR ISR */
+			int volatile ii;
+			// stop checking timer & start to check waiting time 9600
+			__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc->base + REG_SC_ALTCTL);
+			for(ii = 0; ii < 10; ii++);
+			__raw_writel((9600+480) | SC_TMR_MODE_0, sc->base + REG_SC_TMRCTL0);
+			__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_CNTEN0, sc->base + REG_SC_ALTCTL);
+
+			if(sc->atrlen == 0) { // first byte received, start ticking...
+				/* start counting total time for ATR session */
+				__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN2, sc->base + REG_SC_ALTCTL);
+				for(ii = 0; ii < 10; ii++);
+				__raw_writel(255 | SC_TMR_MODE_4, sc->base + REG_SC_TMRCTL2);
+				__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_CNTEN2, sc->base + REG_SC_ALTCTL);
+
+				atr_remain_t = 20050;
+				atr_remain = 2;
+				ifbyte_flag = -1;
+				tck = 0;
+			}
+
+			if( (intsts & SC_INTSTS_RDAIF) && atr_remain) {
+				/*
+				* atr_len==0 : TS
+				* atr_len==1 : T0
+				*/
+				sc->atrbuf[sc->atrlen] = __raw_readl(sc->base + REG_SC_DAT);
+
+				atr_remain--;
+				ifbyte_flag--;
+
+				if(sc->atrlen == 1) {
+					atr_remain += (sc->atrbuf[sc->atrlen] & 0xf); // Historical byte
+					ifbyte_flag = 0; // T0 contains Y(x) as well\n
+				}
+
+				if( ifbyte_flag == 0 ) {
+					if(sc->atrbuf[sc->atrlen] & 0x10) {
+						++atr_remain;
+						++ifbyte_flag;
+					}
+					if(sc->atrbuf[sc->atrlen] & 0x20) {
+						++atr_remain;
+						++ifbyte_flag;
+					}
+					if(sc->atrbuf[sc->atrlen] & 0x40) {
+						++atr_remain;
+						++ifbyte_flag;
+					}
+					if(sc->atrbuf[sc->atrlen] & 0x80) {
+						++atr_remain;
+						++ifbyte_flag;
+						if((tck == 0) && (sc->atrlen != 1) && ((sc->atrbuf[sc->atrlen] & 0xf) != 0)) {
+							++atr_remain; //tck exist
+							tck = 1;
+						}
+					} else {
+						/* Here, it's special case for APDU test card */
+						if((tck == 0) && (sc->atrlen != 1) && ((sc->atrbuf[sc->atrlen] & 0xf) != 0)) {
+							++atr_remain; //tck exist
+							tck = 1;
+						}
+						ifbyte_flag = -1;
+					}
+				}
+
+				sc->atrlen++;   /* increase the length of ATR */
+
+			}
+
+			if(atr_remain == 0) {   /* receive ATR done */
+				// Stop timer
+				__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) & ~(SC_ALTCTL_CNTEN2 | SC_ALTCTL_CNTEN0),
+				             sc->base + REG_SC_ALTCTL);
+				sc->state = SC_OP_IDLE;
+
+			}
+		} else {
+			// also goes here if we cannot consume previously received data in time, not necessary a bug
+			sc->rbuf[sc->rtail++] = __raw_readl(sc->base + REG_SC_DAT);
+		}
+	}
+	// Check Transmit error
+	if(intsts & SC_INTSTS_ACERRIF) {
+		__raw_writel(SC_INTSTS_ACERRIF, sc->base + REG_SC_INTSTS);
+		sc->err = SC_ERR_AUTOCONVENTION;
+		sc->state = SC_OP_IDLE;
+	}
+
+	/* Transmit Error: break error, frame error, Rx/Tx over flow, parity error, invalid stop */
+	if((intsts & SC_INTSTS_TERRIF) && (inten & SC_INTEN_TERRIEN)) {
+		if(status & SC_STATUS_RXOV) {
+			__raw_writel(SC_STATUS_RXOV, sc->base + REG_SC_STATUS);
+			sc->err = SC_ERR_READ;
+			sc->state = SC_OP_IDLE;
+		}
+
+		if(status & SC_STATUS_TXOV) {
+			__raw_writel(SC_STATUS_TXOV, sc->base + REG_SC_STATUS);
+			sc->err = SC_ERR_WRITE;
+			sc->state = SC_OP_IDLE;
+		}
+
+		if(status & (SC_STATUS_PEF | SC_STATUS_BEF | SC_STATUS_FEF)) {
+
+			__raw_writel(SC_STATUS_PEF | SC_STATUS_BEF | SC_STATUS_FEF, sc->base + REG_SC_STATUS);
+			sc->err = SC_ERR_PARITY;
+			__raw_writel(SC_ALTCTL_RXRST, sc->base + REG_SC_ALTCTL);
+			if(sc->protocol == SC_PROTOCOL_T0) {
+				sc->state = SC_OP_IDLE;
+			}
+
+		}
+
+		if(status & SC_STATUS_TXOVERR) {
+			__raw_writel(__raw_readl(sc->base + REG_SC_INTEN) & ~SC_INTEN_TBEIEN, sc->base + REG_SC_INTEN);
+			__raw_writel(SC_STATUS_TXRERR | SC_STATUS_TXOVERR, sc->base + REG_SC_STATUS);
+			__raw_writel(SC_ALTCTL_TXRST, sc->base + REG_SC_ALTCTL);
+			sc->err = SC_ERR_WRITE;
+			sc->state = SC_OP_IDLE;
+		}
+
+		if(status & SC_STATUS_RXOVERR) {
+			__raw_writel(SC_STATUS_RXRERR | SC_STATUS_RXOVERR, sc->base + REG_SC_STATUS);
+			__raw_writel(SC_ALTCTL_RXRST, sc->base + REG_SC_ALTCTL);
+			sc->err = SC_ERR_READ;
+			sc->state = SC_OP_IDLE;
+		}
+	}
+	wake_up_interruptible(&sc->wq);  // wake on any event
+	return IRQ_HANDLED;
+}
+
+// This function does not block, transaction complete in write(), this API is only for user to read back card response.
+static ssize_t sc_read(struct file *filp, char __user *buf, size_t count, loff_t *f_pos)
+{
+
+	struct nuc980_sc *sc = (struct nuc980_sc *)filp->private_data;
+	int ret = 0;
+
+	if(unlikely((count == 0) || (sc->rhead == sc->rtail)))
+		goto out;
+
+	if(unlikely(count > MAX_LEN))
+		count = MAX_LEN;
+
+	if(count > sc->rtail - sc->rhead)
+		count = sc->rtail - sc->rhead;
+
+
+	mutex_lock(&sc->lock);
+
+	if(sc->err != 0) {
+		ret = -EFAULT;
+	} else {
+		if(copy_to_user(buf, &sc->rbuf[0], count))
+			ret = -EFAULT;
+		else {
+			ret = count;
+			sc->rhead += count;
+		}
+	}
+	mutex_unlock(&sc->lock);
+out:
+
+	return ret;
+}
+
+
+static ssize_t sc_write(struct file *filp, const char __user *buf, size_t count, loff_t *f_pos)
+{
+
+	struct nuc980_sc *sc = (struct nuc980_sc *)filp->private_data;
+	int intf = sc->intf;
+	int ret = 0;
+
+	mutex_lock(&sc->lock);
+	if(unlikely(count == 0))
+		goto out;
+	if(unlikely(sc->act != 1))
+		goto out;
+
+
+	if(unlikely(count > MAX_LEN))
+		sc->tcnt = MAX_LEN;
+	else
+		sc->tcnt = count;
+
+	sc->toffset = 0;
+	sc->err = 0;
+	sc->rhead = sc->rtail = 0; // this is a new transaction, drop old data
+	if (copy_from_user(sc->tbuf, buf, count)) {
+		ret = -EFAULT;
+		goto out;
+	}
+	if(sc->protocol == 0) {
+		CmdXfrT0(intf, sc->tcnt, sc->tbuf, sc->rbuf);
+	} else {  //T1
+		CmdXfrT1(intf, sc->tcnt, sc->tbuf, sc->rbuf);
+	}
+
+	if(sc->err != 0)
+		ret = -EFAULT;
+	else
+		ret = sc->tcnt; // transfer complete...
+out:
+	mutex_unlock(&sc->lock);
+	return ret;
+}
+
+static int sc_release(struct inode *inode, struct file *filp)
+{
+	struct nuc980_sc *sc = (struct nuc980_sc *)filp->private_data;
+	int ret = 0;
+	// free irq
+	mutex_lock(&sc->lock);
+
+	free_irq(sc->irq, (void *)sc);
+
+	// deactivate
+	__raw_writel(SC_INTSTS_INITIF, sc->base + REG_SC_INTSTS);
+	__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_DACTEN, sc->base + REG_SC_ALTCTL);
+	while(!(__raw_readl(sc->base + REG_SC_INTSTS) & SC_INTSTS_INITIF));
+
+	__raw_writel(0, sc->base + REG_SC_INTEN);
+	__raw_writel(0, sc->base + REG_SC_ALTCTL);
+	__raw_writel(0, sc->base + REG_SC_CTL);
+
+	sc->atrlen = 0;
+	sc->rtail = sc->rhead = 0;
+	sc->act = 0;
+	memset(&sc->T0, 0, sizeof(sc->T0));
+	memset(&sc->T1, 0, sizeof(sc->T1));
+	memset(&sc->T0_dat, 0, sizeof(sc->T0_dat));
+	memset(&sc->T1_dat, 0, sizeof(sc->T1_dat));
+	memset(&sc->atr, 0, sizeof(sc->atr));
+	// disable clk
+	clk_disable(sc->clk);
+	clk_disable(sc->eclk);
+	clk_put(sc->clk);
+	clk_put(sc->eclk);
+
+	filp->private_data = NULL;
+	sc->open = 0;
+
+	mutex_unlock(&sc->lock);
+	return(ret);
+}
+
+static int sc_open(struct inode *inode, struct file *filp)
+{
+
+	int ret, intf;
+
+	for(intf = 0; intf < SC_INTF; intf++)
+		if(MINOR(inode->i_rdev) == sc[intf].minor) {
+			break;
+		}
+	mutex_lock(&sc[intf].lock);
+	if(sc[intf].open == 1) {
+		mutex_unlock(&sc[intf].lock);
+		return -EBUSY;
+	}
+	filp->private_data = (void *)&sc[intf];
+
+	if(intf == 0) {
+		sc[intf].clk = clk_get(NULL, "smc0");
+		sc[intf].eclk = clk_get(NULL, "smc0_eclk");
+	} else {
+		sc[intf].clk = clk_get(NULL, "smc1");
+		sc[intf].eclk = clk_get(NULL, "smc1_eclk");
+	}
+
+
+	if (IS_ERR(sc[intf].clk)) {
+		printk("failed to get sc clock\n");
+		ret = PTR_ERR(sc[intf].clk);
+		goto out2;
+	}
+	if (IS_ERR(sc[intf].eclk)) {
+		printk("failed to get sc eclock\n");
+		ret = PTR_ERR(sc[intf].eclk);
+		goto out2;
+	}
+	clk_prepare(sc[intf].clk);
+	clk_enable(sc[intf].clk);
+	clk_prepare(sc[intf].eclk);
+	clk_enable(sc[intf].eclk);
+	clk_set_rate(sc[intf].eclk, 4000000);	// Set SC clock to 4MHz
+
+	if(sc[intf].pwrinv) {
+		__raw_writel(__raw_readl(sc[intf].base + REG_SC_PINCTL) | SC_PINCTL_PWRINV, sc[intf].base + REG_SC_PINCTL);
+	}
+	if(sc[intf].cdlvl == 0) {
+		__raw_writel(__raw_readl(sc[intf].base + REG_SC_CTL) | SC_CTL_CDLV, sc[intf].base + REG_SC_CTL);
+	}
+
+	// enable SC engine
+	__raw_writel(__raw_readl(sc[intf].base + REG_SC_CTL) | SC_CTL_SCEN, sc[intf].base + REG_SC_CTL);
+	if (request_irq(sc[intf].irq, nuc980_sc_interrupt,
+	                0x0, "nuc980-sc", (void *)&sc[intf])) {
+		printk("register irq failed %d\n", sc[intf].irq);
+		ret = -EAGAIN;
+		goto out1;
+	}
+	sc[intf].open = 1;
+	mutex_unlock(&sc[intf].lock);
+	return 0;
+
+
+out1:
+
+	free_irq(sc[intf].irq, (void *)&sc[intf]);
+out2:
+	mutex_unlock(&sc[intf].lock);
+	return ret;
+
+}
+
+static long sc_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	struct nuc980_sc *sc = (struct nuc980_sc *)filp->private_data;
+	int intf = sc->intf;
+	struct sc_transact sc_t;
+	struct sc_transact *psc_t = &sc_t;
+	unsigned int param;
+
+	mutex_lock(&sc->lock);
+
+	switch(cmd) {
+	case SC_IOC_ACTIVATE:
+		reset_reader(sc);
+
+		if(sc->act == 1) {
+			sc->act = 0;
+			sc->state = SC_OP_DEACTIVATE;
+			__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_DACTEN, sc->base + REG_SC_ALTCTL);
+			wait_event_interruptible(sc->wq, sc->state != SC_OP_DEACTIVATE);
+			memset(&sc->T0, 0, sizeof(sc->T0));
+			memset(&sc->T1, 0, sizeof(sc->T1));
+			memset(&sc->T0_dat, 0, sizeof(sc->T0_dat));
+			memset(&sc->T1_dat, 0, sizeof(sc->T1_dat));
+			// Delay 10ms before we cold reset the card. ISO 7816-3 6.2.4
+			schedule_timeout_interruptible(HZ/100);
+		}
+		sc->act = sc->atrlen = sc->rhead = sc->rtail = sc->err = 0;
+		sc->state = SC_OP_COLD_RESET;
+		sc->N = sc->D = sc->F = 0;
+		__raw_writel(((42000/372) + 1) | SC_TMR_MODE_3, sc->base + REG_SC_TMRCTL0);
+		__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_CNTEN0 | SC_ALTCTL_ACTEN, sc->base + REG_SC_ALTCTL);
+
+		wait_event_interruptible(sc->wq, (sc->state != SC_OP_READ_ATR) && (sc->state != SC_OP_COLD_RESET));
+
+		if(sc->err == 0)
+			sc->err = parse_atr(sc, 0);
+
+		if(sc->err == SC_ERR_PARAM) {
+			sc->err = sc->protocol =  0;
+			sc->atrlen = sc->act = 0;
+			sc->state = SC_OP_WARM_RESET;
+			sc->N = sc->D = sc->F = 0;
+			reset_reader(sc);
+			__raw_writel(((42000/372) + 1) | SC_TMR_MODE_3, sc->base + REG_SC_TMRCTL0);
+			__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_CNTEN0 | SC_ALTCTL_WARSTEN, sc->base + REG_SC_ALTCTL);
+
+			wait_event_interruptible(sc->wq, (sc->state != SC_OP_READ_ATR) && (sc->state != SC_OP_WARM_RESET));
+			if(sc->err == 0)
+				sc->err = parse_atr(sc, 1);
+		}
+
+		if(sc->err != 0) { // no matter what error, deactivate...
+			schedule_timeout_interruptible(HZ/100);
+			sc->act = 0;
+			__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_DACTEN, sc->base + REG_SC_ALTCTL);
+			wait_event_interruptible(sc->wq, (sc->act == -1) || (sc->err != 0));
+			memset(&sc->T0, 0, sizeof(sc->T0));
+			memset(&sc->T1, 0, sizeof(sc->T1));
+			memset(&sc->T0_dat, 0, sizeof(sc->T0_dat));
+			memset(&sc->T1_dat, 0, sizeof(sc->T1_dat));
+			mutex_unlock(&sc->lock);
+			return -EFAULT;
+		} else {
+			sc->act = 1;
+			mutex_unlock(&sc->lock);
+			return sc->atrlen;
+		}
+	case SC_IOC_READATR:
+		if(sc->act != 1) {
+			mutex_unlock(&sc->lock);
+			return -EFAULT;
+		}
+		if(copy_to_user((void *)arg, (const void *)sc->atrbuf, sc->atrlen)) {
+			mutex_unlock(&sc->lock);
+			return -EFAULT;
+		}
+		break;
+
+	case SC_IOC_DEACTIVATE:
+		if(__raw_readl(sc->base + REG_SC_PINCTL) & SC_PINCTL_RSTSTS) {
+			// only deactivate if card is activated
+			sc->state = SC_OP_DEACTIVATE;
+			__raw_writel(__raw_readl(sc->base + REG_SC_ALTCTL) | SC_ALTCTL_DACTEN, sc->base + REG_SC_ALTCTL);
+			wait_event_interruptible(sc->wq, sc->state != SC_OP_DEACTIVATE);
+		}
+		sc->atrlen = sc->protocol = 0;
+		sc->rtail = sc->rhead = 0;
+		sc->act = 0;
+		sc->err = 0;
+		memset(&sc->T0, 0, sizeof(sc->T0));
+		memset(&sc->T1, 0, sizeof(sc->T1));
+		memset(&sc->T0_dat, 0, sizeof(sc->T0_dat));
+		memset(&sc->T1_dat, 0, sizeof(sc->T1_dat));
+		memset(&sc->atr, 0, sizeof(sc->atr));
+		break;
+
+	case SC_IOC_GETSTATUS:
+		if(sc->cdlvl == 2) {
+			if(sc->act == 1) {
+				param = ICC_PRESENT_ACTIVE;
+			} else {
+				param =ICC_PRESENT_INACTIVE;
+			}
+		} else {
+			int status = __raw_readl(sc->base + REG_SC_STATUS);
+			int ctl = __raw_readl(sc->base + REG_SC_CTL);
+			if(sc->act == 1) {
+				param = ICC_PRESENT_ACTIVE;
+			} else if(sc->err == SC_ERR_CARD_REMOVED) { // card once removed, maybe insert now, but, must report this event to user app.
+				param = ICC_ABSENT;
+				sc->err = 0;
+			} else if(((status & SC_STATUS_CDPINSTS) >> 13) != ((ctl & SC_CTL_CDLV) >> 26)) { // card is currently removed
+				param = ICC_ABSENT;
+			} else {
+				param =ICC_PRESENT_INACTIVE;
+			}
+		}
+
+		if(copy_to_user((void *)arg, (const void *)&param, sizeof(unsigned int))) {
+			mutex_unlock(&sc->lock);
+			return -EFAULT;
+		}
+		break;
+
+	case SC_IOC_SETPARAM:
+		if(sc->protocol == 1) {
+			t1_init(sc->intf);
+			t1_negotiate_ifsd(sc->intf, 0, 0xFE); // EMV 9.2.4.3, this must be 0xFE
+		} else {// do nothing if T0
+			//printk("this is a T0 card\n");
+		}
+		break;
+	case SC_IOC_TRANSACT:
+		// First get tx length, and then get tx data
+		copy_from_user((void *)psc_t, (const void *)arg, sizeof(struct sc_transact));
+
+		// Although the pointer is for use space,we can still check here since NULL is 0
+		if(unlikely(psc_t->tx_buf == NULL || psc_t->rx_buf == NULL)) {
+			mutex_unlock(&sc->lock);
+			return -EFAULT;
+		}
+
+		if(unlikely(sc->act != 1)) {
+			mutex_unlock(&sc->lock);
+			return -EIO;
+		}
+
+		if(unlikely(psc_t->tx_len > MAX_LEN))
+			sc->tcnt = MAX_LEN;
+		else
+			sc->tcnt = psc_t->tx_len;
+
+		sc->toffset = 0;
+		sc->err = 0;
+		sc->rhead = sc->rtail = 0; // this is a new transaction, drop old data
+
+		if (copy_from_user((void *)sc->tbuf, (const void *)psc_t->tx_buf, psc_t->tx_len)) {
+			mutex_unlock(&sc->lock);
+			return -EFAULT;
+		}
+
+		if(sc->protocol == 0) {
+			CmdXfrT0(intf, sc->tcnt, sc->tbuf, sc->rbuf);
+		} else {  //T1
+			CmdXfrT1(intf, sc->tcnt, sc->tbuf, sc->rbuf);
+		}
+
+		if(sc->err != 0) {
+			mutex_unlock(&sc->lock);
+			return -EFAULT;
+		}
+
+
+		psc_t->rx_len = sc->rtail - sc->rhead;
+		// First copy data to user space
+		if(copy_to_user((void *)psc_t->rx_buf, (const void *)&sc->rbuf[0], psc_t->rx_len)) {
+			mutex_unlock(&sc->lock);
+			return -EFAULT;
+		}
+		// And then pass data length to userland
+		if(copy_to_user((void *)&((struct sc_transact *)arg)->rx_len, (const void *)&psc_t->rx_len, sizeof(u32))) {
+			mutex_unlock(&sc->lock);
+			return -EFAULT;
+		}
+
+		break;
+	default:
+		mutex_unlock(&sc->lock);
+		return -ENOTTY;
+
+
+	}
+	mutex_unlock(&sc->lock);
+	return 0;
+}
+
+
+struct file_operations sc_fops = {
+	.owner		= THIS_MODULE,
+	.open		= sc_open,
+	.release	= sc_release,
+	.read		= sc_read,
+	.write		= sc_write,
+	.unlocked_ioctl	= sc_ioctl,
+};
+
+static struct miscdevice sc_dev[] = {
+	[0] = {
+		.minor = MISC_DYNAMIC_MINOR,
+		.name = "sc0",
+		.fops = &sc_fops,
+	},
+	[1] = {
+		.minor = MISC_DYNAMIC_MINOR,
+		.name = "sc1",
+		.fops = &sc_fops,
+	},
+};
+
+
+static const struct of_device_id nuc980_sc_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-sc" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_sc_of_match);
+
+static int nuc980_sc_probe(struct platform_device *pdev)
+{
+	int intf;
+	struct resource *res;
+
+#ifdef CONFIG_USE_OF
+	if(!of_match_device(nuc980_sc_of_match, &pdev->dev)) {
+		dev_err(&pdev->dev, "Failed to find matching device\n");
+		return -EINVAL;
+	}
+
+	of_property_read_u32_array(pdev->dev.of_node, "port-number", &intf, 1);
+	memset(&sc[intf], 0, sizeof(struct nuc980_sc));
+	sc[intf].pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+	of_property_read_u32_array(pdev->dev.of_node, "cdlvl", &sc[intf].cdlvl, 1);
+	of_property_read_u32_array(pdev->dev.of_node, "pwrinv", &sc[intf].pwrinv, 1);
+
+#else
+	intf = pdev->id;
+	memset(&sc[intf], 0, sizeof(struct nuc980_sc));
+	if(intf == 0) {
+#	ifdef CONFIG_NUC980_SC0
+#		if defined (CONFIG_NUC980_SC0_PA)
+		sc[intf].pinctrl = devm_pinctrl_get_select(&pdev->dev, "sc0-PA");
+#		elif defined (CONFIG_NUC980_SC0_PC)
+		sc[intf].pinctrl = devm_pinctrl_get_select(&pdev->dev, "sc0-PC");
+#		endif
+#	endif
+#	if defined(CONFIG_NUC980_SC0_CD_IGNORE)
+		sc[intf].cdlvl = 2;
+#	elif defined(CONFIG_NUC980_SC0_CDLV_H)
+		sc[intf].cdlvl = 0;
+#	else
+		sc[intf].cdlvl = 1;
+#	endif
+#	ifdef CONFIG_NUC980_SC0_PWRINV
+		sc[intf].pwrinv = 1;
+#	else
+		sc[intf].pwrinv = 0;
+#	endif
+	} else {
+#	ifdef CONFIG_NUC980_SC1
+#		if defined (CONFIG_NUC980_SC1_PC)
+		sc[intf].pinctrl = devm_pinctrl_get_select(&pdev->dev, "sc1-PC");
+#		elif defined (CONFIG_NUC980_SC1_PF)
+		sc[intf].pinctrl = devm_pinctrl_get_select(&pdev->dev, "sc1-PF");
+#		endif
+#	endif
+#	if defined(CONFIG_NUC980_SC1_CD_IGNORE)
+		sc[intf].cdlvl = 2;
+#	elif defined(CONFIG_NUC980_SC1_CDLV_H)
+		sc[intf].cdlvl = 0;
+#	else
+		sc[intf].cdlvl = 1;
+#	endif
+#	ifdef CONFIG_NUC980_SC1_PWRINV
+		sc[intf].pwrinv = 1;
+#	else
+		sc[intf].pwrinv = 0;
+#	endif
+	}
+
+#endif
+	if(IS_ERR(sc[intf].pinctrl)) {
+		dev_err(&pdev->dev, "Unable to reserve SC%d pin", intf);
+		return PTR_ERR(sc[intf].pinctrl);
+	}
+
+	misc_register(&sc_dev[intf]);
+
+	sc[intf].minor = MINOR(sc_dev[intf].minor);
+	sc[intf].intf = intf;
+
+	mutex_init(&sc[intf].lock);
+
+	sc[intf].irq = platform_get_irq(pdev, 0);
+	res = (void __iomem *)platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	sc[intf].res = request_mem_region(res->start, resource_size(res), pdev->name);
+	sc[intf].base = ioremap(res->start, resource_size(res));
+	sc[intf].open = 0;
+	if (sc[intf].base == NULL) {
+		dev_err(&pdev->dev, "cannot request IO\n");
+		return -ENXIO;
+	}
+
+	init_waitqueue_head(&sc[intf].wq);
+	platform_set_drvdata(pdev, (void *)&sc[intf]);
+
+	return 0;
+}
+
+static int nuc980_sc_remove(struct platform_device *pdev)
+{
+	int intf = pdev->id;
+
+	misc_deregister(&sc_dev[intf]);
+
+	iounmap(sc[intf].base);
+	release_resource(sc[intf].res);
+
+	return 0;
+}
+
+
+#ifdef CONFIG_PM
+static int nuc980_sc_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct nuc980_sc *_sc = &sc[pdev->id];
+
+	// Holds the lock until wake up. Avoid application access the card.
+	mutex_lock(&_sc->lock);
+
+	if(_sc->open == 0)
+		goto out;
+	// Make sure the card enter deactivate state before system power down
+	if(__raw_readl(_sc->base + REG_SC_PINCTL) & SC_PINCTL_RSTSTS) {
+		// only deactivate if card is activated
+		_sc->state = SC_OP_DEACTIVATE;
+		__raw_writel(__raw_readl(_sc->base + REG_SC_ALTCTL) | SC_ALTCTL_DACTEN, _sc->base + REG_SC_ALTCTL);
+		wait_event_interruptible(_sc->wq, _sc->state != SC_OP_DEACTIVATE);
+	}
+	_sc->atrlen = _sc->protocol = 0;
+	_sc->rtail = _sc->rhead = 0;
+	_sc->act = 0;
+	_sc->err = 0;
+	memset(&_sc->T0, 0, sizeof(_sc->T0));
+	memset(&_sc->T1, 0, sizeof(_sc->T1));
+	memset(&_sc->T0_dat, 0, sizeof(_sc->T0_dat));
+	memset(&_sc->T1_dat, 0, sizeof(_sc->T1_dat));
+	memset(&_sc->atr, 0, sizeof(_sc->atr));
+out:
+	return 0;
+}
+
+static int nuc980_sc_resume(struct platform_device *pdev)
+{
+	struct nuc980_sc *_sc = &sc[pdev->id];
+
+	// Release the lock so application can start access the card.
+	mutex_unlock(&_sc->lock);
+	return 0;
+}
+
+#else
+#define nuc980_sc_suspend 	NULL
+#define nuc980_sc_resume	NULL
+#endif
+
+
+static struct platform_driver nuc980_sc_driver = {
+	.driver		= {
+		.owner	= THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_sc_of_match),
+		.name	= "nuc980-sc",
+	},
+	.probe		= nuc980_sc_probe,
+	.remove		= nuc980_sc_remove,
+	.suspend	= nuc980_sc_suspend,
+	.resume		= nuc980_sc_resume,
+};
+
+
+module_platform_driver(nuc980_sc_driver);
+
+
+
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_ALIAS("platform:nuc980-sc");
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/misc/nuc980-spi0-slave.c NUC980-linux-4.4.194/drivers/misc/nuc980-spi0-slave.c
--- linux-4.4.194/drivers/misc/nuc980-spi0-slave.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/misc/nuc980-spi0-slave.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,877 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/gpio.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+
+#include <linux/spi/spi.h>
+#include <linux/spi/spi_bitbang.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/spi-nuc980.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/map.h>
+#include <asm/mach/irq.h>
+#include <asm/irq.h>
+
+#include <mach/hardware.h>
+#include <mach/regs-gcr.h>
+
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <mach/regs-pdma.h>
+
+#include <linux/platform_data/dma-nuc980.h>
+
+/* spi registers offset */
+#define REG_CTL		0x00
+#define REG_CLKDIV	0x04
+#define REG_SSCTL	0x08
+#define REG_PDMACTL	0x0C
+#define REG_FIFOCTL	0x10
+#define REG_STATUS	0x14
+#define REG_TX		0x20
+#define REG_RX		0x30
+
+/* spi register bit */
+#define UNITIEN		(0x01 << 17)
+#define TXNEG		(0x01 << 2)
+#define RXNEG		(0x01 << 1)
+#define SLAVE		(0x01 << 18)
+#define LSB		(0x01 << 13)
+#define SELECTLEV	(0x01 << 2)
+#define SELECTPOL	(0x01 << 3)
+#define SSACTIEN	(0x01 << 12)
+#define SELECTSLAVE0	0x01
+#define SELECTSLAVE1	0x02
+#define SPIEN		0x01
+#define TXTHIEN		(0x01 << 3)
+#define RXTHIEN		(0x01 << 2)
+#define SSINAIEN	(0x01 << 13)
+#define SSACTIF		(0x01 << 2)
+#define SSINAIF		(0x01 << 3)
+#define RXTHIF		(0x01 << 10)
+#define TXTHIF		(0x01 << 18)
+#define TXUFIF		(0x01 << 19)
+
+#ifdef CONFIG_SPI_NUC980_SPI0
+# error Do not enable CONFIG_SPI_NUC980_SPI0 and CONFIG_NUC980_SPI0_SLAVE at the same time!
+#endif
+
+static volatile int slave_done_state=0;
+static DECLARE_WAIT_QUEUE_HEAD(slave_done);
+
+static int SPI0_SlaveDataLen = 256;
+static int SPI0_SlaveData[256];
+static int TransmittedCnt = 0;
+static int InTransmitted = 0;
+
+struct nuc980_spi {
+	struct spi_bitbang	bitbang;
+	struct completion	done;
+	void __iomem		*regs;
+	int			irq;
+	unsigned int 		len;
+	unsigned int		count;
+	const void		*tx;
+	void			*rx;
+	struct clk		*clk;
+	struct resource		*ioarea;
+	struct spi_master	*master;
+	struct spi_device	*curdev;
+	struct device		*dev;
+	struct nuc980_spi_info *pdata;
+	spinlock_t		lock;
+	struct resource		*res;
+};
+
+
+static inline struct nuc980_spi0 *to_hw(struct spi_device *sdev) {
+	return spi_master_get_devdata(sdev->master);
+}
+
+static inline void nuc980_slave_select(struct spi_device *spi, unsigned int ssr)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int val;
+	unsigned int cs = spi->mode & SPI_CS_HIGH ? 1 : 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_SSCTL);
+
+	if (!cs)
+		val &= ~SELECTLEV;
+	else
+		val |= SELECTLEV;
+
+	if(spi->chip_select == 0) {
+		if (!ssr)
+			val &= ~SELECTSLAVE0;
+		else
+			val |= SELECTSLAVE0;
+	} else {
+		if (!ssr)
+			val &= ~SELECTSLAVE1;
+		else
+			val |= SELECTSLAVE1;
+	}
+
+	__raw_writel(val, hw->regs + REG_SSCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_spi0_chipsel(struct spi_device *spi, int value)
+{
+	switch (value) {
+	case BITBANG_CS_INACTIVE:
+		nuc980_slave_select(spi, 0);
+		break;
+
+	case BITBANG_CS_ACTIVE:
+		nuc980_slave_select(spi, 1);
+		break;
+	}
+}
+
+static inline void nuc980_spi0_setup_txbitlen(struct nuc980_spi *hw,
+                unsigned int txbitlen)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+	val &= ~0x1f00;
+	if(txbitlen != 32)
+		val |= (txbitlen << 8);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_set_clock_polarity(struct nuc980_spi *hw, unsigned int polarity)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (polarity)
+		val |= SELECTPOL;
+	else
+		val &= ~SELECTPOL;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_tx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= TXNEG;
+	else
+		val &= ~TXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_rx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= RXNEG;
+	else
+		val &= ~RXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_send_first(struct nuc980_spi *hw, unsigned int lsb)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (lsb)
+		val |= LSB;
+	else
+		val &= ~LSB;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_enable_slave(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	val |= SLAVE;
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_set_sleep(struct nuc980_spi *hw, unsigned int sleep)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	val &= ~(0x0f << 4);
+
+	if (sleep)
+		val |= (sleep << 4);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+
+static inline void nuc980_set_divider(struct nuc980_spi *hw)
+{
+	__raw_writel(hw->pdata->divider, hw->regs + REG_CLKDIV);
+}
+
+static int nuc980_spi0_update_state(struct spi_device *spi,
+                                    struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int clk;
+	unsigned int div;
+	unsigned int bpw;
+	unsigned int hz;
+	unsigned char spimode;
+
+	bpw = t ? t->bits_per_word : spi->bits_per_word;
+	hz  = t ? t->speed_hz : spi->max_speed_hz;
+
+	if(hw->pdata->txbitlen != bpw)
+		hw->pdata->txbitlen = bpw;
+
+	if(hw->pdata->hz != hz) {
+		clk = clk_get_rate(hw->clk);
+		div = DIV_ROUND_UP(clk, hz) - 1;
+		hw->pdata->hz = hz;
+		hw->pdata->divider = div;
+	}
+
+	//Mode 0: CPOL=0, CPHA=0; active high
+	//Mode 1: CPOL=0, CPHA=1 ;active low
+	//Mode 2: CPOL=1, CPHA=0 ;active low
+	//Mode 3: POL=1, CPHA=1;active high
+	if (spi->mode & SPI_CPOL)
+		hw->pdata->clkpol = 1;
+	else
+		hw->pdata->clkpol = 0;
+
+	spimode = spi->mode & 0xff; //remove dual/quad bit
+
+	if ((spimode == SPI_MODE_0) || (spimode == SPI_MODE_2)) {
+		hw->pdata->txneg = 1;
+		hw->pdata->rxneg = 0;
+	} else {
+		hw->pdata->txneg = 0;
+		hw->pdata->rxneg = 1;
+	}
+
+	if (spi->mode & SPI_LSB_FIRST)
+		hw->pdata->lsb = 1;
+	else
+		hw->pdata->lsb = 0;
+
+	return 0;
+}
+
+static int nuc980_spi0_setupxfer(struct spi_device *spi,
+                                 struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_spi0_update_state(spi, t);
+	if (ret)
+		return ret;
+
+	nuc980_spi0_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_divider(hw);
+
+	return 0;
+}
+
+static int nuc980_spi0_setup(struct spi_device *spi)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_spi0_update_state(spi, NULL);
+	if (ret)
+		return ret;
+
+	spin_lock(&hw->bitbang.lock);
+	if (!hw->bitbang.busy) {
+		nuc980_set_divider(hw);
+		nuc980_slave_select(spi, 0);
+	}
+	spin_unlock(&hw->bitbang.lock);
+
+	return 0;
+}
+
+static inline void nuc980_enable_rxth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val = (val & ~0x7000000) | 0x0000000; /* set RXTH = 0 */
+	val |= RXTHIEN; /* enable RXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_disable_rxth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val &= ~RXTHIEN; /* disable RXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_enable_txth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val = (val & ~0x70000000) | 0x30000000; /* set TXTH = 3 */
+	val |= TXTHIEN; /* enable TXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_disable_txth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val &= ~TXTHIEN; /* disable TXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_enable_ssinact_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_SSCTL);
+
+	val |= SSINAIEN; /* enable SSINAIEN */
+
+	__raw_writel(val, hw->regs + REG_SSCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static irqreturn_t nuc980_spi0_irq(int irq, void *dev)
+{
+	struct nuc980_spi *hw = dev;
+	unsigned int val, status;
+
+	status = __raw_readl(hw->regs + REG_STATUS);
+	__raw_writel(status, hw->regs + REG_STATUS);
+
+	if (status & RXTHIF) {
+		if (InTransmitted == 0) {
+			nuc980_disable_rxth_int(hw);
+			slave_done_state = 1;
+			wake_up_interruptible(&slave_done);
+			InTransmitted = 1;
+		}
+	}
+	if (status & TXTHIF) {
+		while(!(__raw_readl(hw->regs + REG_STATUS) & 0x20000)) {//TXFULL
+			__raw_writel(SPI0_SlaveData[TransmittedCnt++], hw->regs + REG_TX);
+			if (TransmittedCnt >= SPI0_SlaveDataLen) {
+				nuc980_disable_txth_int(hw);
+				InTransmitted = 0;
+				TransmittedCnt = 0;
+				break;
+			}
+		}
+	}
+	if (status & SSINAIF) {
+		/* Check if transmition complete */
+		if (InTransmitted == 1) {
+			int i;
+			printk("Master pull SS high, but slave TX doesn't complete!\n");
+			__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //TXRX reset
+			while (__raw_readl(hw->regs + REG_STATUS) & (1<<23)); //TXRXRST
+			nuc980_enable_rxth_int(hw);
+			InTransmitted = 0;
+			TransmittedCnt = 0;
+			for (i = 0; i < SPI0_SlaveDataLen; i++)
+				SPI0_SlaveData[i] = 0;
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+
+static void nuc980_init_spi(struct nuc980_spi *hw)
+{
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	spin_lock_init(&hw->lock);
+
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_sleep(hw, hw->pdata->sleep);
+	nuc980_spi0_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_set_divider(hw);
+	nuc980_enable_slave(hw);
+	nuc980_enable_rxth_int(hw);
+	nuc980_enable_ssinact_int(hw);
+}
+
+#ifdef CONFIG_OF
+static struct nuc980_spi_info *nuc980_spi0_parse_dt(struct device *dev) {
+	struct nuc980_spi_info *sci;
+	u32 temp;
+
+	sci = devm_kzalloc(dev, sizeof(*sci), GFP_KERNEL);
+	if (!sci) {
+		dev_err(dev, "memory allocation for spi_info failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	if (of_property_read_u32(dev->of_node, "num_cs", &temp)) {
+		dev_warn(dev, "can't get num_cs from dt\n");
+		sci->num_cs = 2;
+	} else {
+		sci->num_cs = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "lsb", &temp)) {
+		dev_warn(dev, "can't get lsb from dt\n");
+		sci->lsb = 0;
+	} else {
+		sci->lsb = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txneg", &temp)) {
+		dev_warn(dev, "can't get txneg from dt\n");
+		sci->txneg = 1;
+	} else {
+		sci->txneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "clkpol", &temp)) {
+		dev_warn(dev, "can't get clkpol from dt\n");
+		sci->clkpol = 0;
+	} else {
+		sci->clkpol = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "rxneg", &temp)) {
+		dev_warn(dev, "can't get rxneg from dt\n");
+		sci->rxneg = 0;
+	} else {
+		sci->rxneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "divider", &temp)) {
+		dev_warn(dev, "can't get divider from dt\n");
+		sci->divider = 4;
+	} else {
+		sci->divider = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "sleep", &temp)) {
+		dev_warn(dev, "can't get sleep from dt\n");
+		sci->sleep = 0;
+	} else {
+		sci->sleep = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txbitlen", &temp)) {
+		dev_warn(dev, "can't get txbitlen from dt\n");
+		sci->txbitlen = 8;
+	} else {
+		sci->txbitlen = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "bus_num", &temp)) {
+		dev_warn(dev, "can't get bus_num from dt\n");
+		sci->bus_num = 0;
+	} else {
+		sci->bus_num = temp;
+	}
+
+	return sci;
+}
+#else
+static struct nuc980_spi_info *nuc980_spi0_parse_dt(struct device *dev) {
+	return dev->platform_data;
+}
+#endif
+
+/* In Thread, only prepare data and enable TXTHIEN.
+   The data will be transmitted in IRQ
+ */
+static int SPI0_Slave_Thread_TXRX(struct nuc980_spi *hw)
+{
+	unsigned char rx;
+	unsigned long flags;
+	int i;
+
+	while(1) {
+
+		wait_event_interruptible(slave_done, (slave_done_state != 0));
+		rx = __raw_readl(hw->regs + REG_RX);
+		//printk("Receive [0x%x] \n", rx);
+
+		switch (rx) {
+		case 0x9f:
+			for (i = 0; i < SPI0_SlaveDataLen; i++)
+				SPI0_SlaveData[i] = i;
+
+			nuc980_enable_txth_int(hw);
+			break;
+		default:
+			break;
+		}
+
+		InTransmitted = 0;
+		slave_done_state = 0;
+		nuc980_enable_rxth_int(hw);
+	}
+
+	return 0;
+}
+
+static int nuc980_spi0_slave_probe(struct platform_device *pdev)
+{
+	struct nuc980_spi *hw;
+	struct spi_master *master;
+	int err = 0;
+	struct pinctrl *p;
+
+	master = spi_alloc_master(&pdev->dev, sizeof(struct nuc980_spi));
+	if (master == NULL) {
+		dev_err(&pdev->dev, "No memory for spi_master\n");
+		err = -ENOMEM;
+		goto err_nomem;
+	}
+
+	hw = spi_master_get_devdata(master);
+	hw->master = spi_master_get(master);
+	hw->pdata = nuc980_spi0_parse_dt(&pdev->dev);
+	hw->dev = &pdev->dev;
+
+	if (hw->pdata == NULL) {
+		dev_err(&pdev->dev, "No platform data supplied\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+	platform_set_drvdata(pdev, hw);
+	init_completion(&hw->done);
+	master->mode_bits          = (SPI_MODE_0 | SPI_CS_HIGH | SPI_LSB_FIRST | SPI_CPHA | SPI_CPOL);
+	master->dev.of_node        = pdev->dev.of_node;
+	master->num_chipselect     = hw->pdata->num_cs;
+	master->bus_num            = hw->pdata->bus_num;
+	hw->bitbang.master         = hw->master;
+	hw->bitbang.setup_transfer = nuc980_spi0_setupxfer;
+	hw->bitbang.chipselect     = nuc980_spi0_chipsel;
+	hw->bitbang.master->setup  = nuc980_spi0_setup;
+
+	hw->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (hw->res == NULL) {
+		dev_err(&pdev->dev, "Cannot get IORESOURCE_MEM\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+#if defined(CONFIG_OF)
+	hw->regs = devm_ioremap_resource(&pdev->dev, hw->res);
+#else
+	hw->ioarea = request_mem_region(hw->res->start,
+	                                resource_size(hw->res), pdev->name);
+
+	if (hw->ioarea == NULL) {
+		dev_err(&pdev->dev, "Cannot reserve region\n");
+		err = -ENXIO;
+		goto err_pdata;
+	}
+
+	hw->regs = ioremap(hw->res->start, resource_size(hw->res));
+	if (hw->regs == NULL) {
+		dev_err(&pdev->dev, "Cannot map IO\n");
+		err = -ENXIO;
+		goto err_iomap;
+	}
+#endif
+
+	hw->irq = platform_get_irq(pdev, 0);
+	if (hw->irq < 0) {
+		dev_err(&pdev->dev, "No IRQ specified\n");
+		err = -ENOENT;
+		goto err_irq;
+	}
+
+	err = request_irq(hw->irq, nuc980_spi0_irq, 0, pdev->name, hw);
+	if (err) {
+		dev_err(&pdev->dev, "Cannot claim IRQ\n");
+		goto err_irq;
+	}
+
+	hw->clk = clk_get(NULL, "spi0_eclk");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	hw->clk = clk_get(NULL, "spi0");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+#if defined(CONFIG_OF)
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+	/*
+#if defined(CONFIG_SPI_NUC980_P0_NORMAL) && !defined(CONFIG_SPI_NUC980_P0_SS1)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi0");
+#elif defined(CONFIG_SPI_NUC980_P0_NORMAL) && defined(CONFIG_SPI_NUC980_P0_SS1_PB0)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi0-ss1-PB");
+#elif defined(CONFIG_SPI_NUC980_P0_NORMAL) && defined(CONFIG_SPI_NUC980_P0_SS1_PH12)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi0-ss1-PH");
+#elif defined(CONFIG_SPI_NUC980_P0_QUAD) && !defined(CONFIG_SPI_NUC980_P0_SS1)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi0-quad");
+#elif defined(CONFIG_SPI_NUC980_P0_QUAD) && defined(CONFIG_SPI_NUC980_P0_SS1_PB0)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi0-quad-ss1-PB");
+#elif defined(CONFIG_SPI_NUC980_P0_QUAD) && defined(CONFIG_SPI_NUC980_P0_SS1_PH12)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi0-quad-ss1-PB");
+#endif
+	*/
+	/*TODO : use pinctrl*/
+	__raw_writel((__raw_readl(REG_MFP_GPD_H) & ~0xFFFF) | 0x1111, REG_MFP_GPD_H);
+#endif
+	if(IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve spi pin by mode\n");
+		err = PTR_ERR(p);
+		goto err_register;
+	}
+
+	nuc980_init_spi(hw);
+
+	__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //CWWeng : RXRST & TXRST
+	while (__raw_readl(hw->regs + REG_STATUS) & (1<<23)); //TXRXRST
+
+	__raw_writel(__raw_readl(hw->regs + REG_CTL) | SPIEN, hw->regs + REG_CTL); /* enable SPI */
+	while ((__raw_readl(hw->regs + REG_STATUS) & (1<<15)) == 0); //SPIENSTS
+
+	kthread_run(SPI0_Slave_Thread_TXRX, hw, "SPI0_SLAVE_THread_TXRX");
+
+	return 0;
+
+err_register:
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+err_clk:
+	free_irq(hw->irq, hw);
+err_irq:
+	iounmap(hw->regs);
+#ifndef CONFIG_OF
+err_iomap:
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#endif
+err_pdata:
+	spi_master_put(hw->master);
+
+err_nomem:
+	return err;
+}
+
+static int nuc980_spi0_slave_remove(struct platform_device *dev)
+{
+	struct nuc980_spi *hw = platform_get_drvdata(dev);
+
+	free_irq(hw->irq, hw);
+	platform_set_drvdata(dev, NULL);
+	spi_bitbang_stop(&hw->bitbang);
+
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+
+	iounmap(hw->regs);
+
+#ifndef CONFIG_OF
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#else
+	kfree(hw->pdata);
+#endif
+
+	spi_master_put(hw->master);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_spi0_suspend(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	while(__raw_readl(hw->regs + REG_CTL) & 0x1)
+		msleep(1);
+
+	// disable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) & ~0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static int nuc980_spi0_resume(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	// enable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) | 0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_spi0_pmops = {
+	.suspend    = nuc980_spi0_suspend,
+	.resume     = nuc980_spi0_resume,
+};
+
+#define NUC980_SPI0_PMOPS (&nuc980_spi0_pmops)
+
+#else
+#define NUC980_SPI0_PMOPS NULL
+#endif
+
+#if defined(CONFIG_OF)
+static const struct of_device_id nuc980_spi0_slave_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-spi0-slave" },
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_spi0_of_match);
+#endif
+
+static struct platform_driver nuc980_spi0_slave_driver = {
+	.probe      = nuc980_spi0_slave_probe,
+	.remove     = nuc980_spi0_slave_remove,
+	.driver     = {
+		.name   = "nuc980-spi0-slave",
+		.owner  = THIS_MODULE,
+		.pm	= NUC980_SPI0_PMOPS,
+#if defined(CONFIG_OF)
+		.of_match_table = of_match_ptr(nuc980_spi0_slave_of_match),
+#endif
+	},
+};
+module_platform_driver(nuc980_spi0_slave_driver);
+
+MODULE_DESCRIPTION("nuc980 spi0 slave driver!");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-spi0-slave");
diff -uprN linux-4.4.194/drivers/misc/nuc980-spi1-slave.c NUC980-linux-4.4.194/drivers/misc/nuc980-spi1-slave.c
--- linux-4.4.194/drivers/misc/nuc980-spi1-slave.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/misc/nuc980-spi1-slave.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,877 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/gpio.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+
+#include <linux/spi/spi.h>
+#include <linux/spi/spi_bitbang.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/spi-nuc980.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/map.h>
+#include <asm/mach/irq.h>
+#include <asm/irq.h>
+
+#include <mach/hardware.h>
+#include <mach/regs-gcr.h>
+
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <mach/regs-pdma.h>
+
+#include <linux/platform_data/dma-nuc980.h>
+
+/* spi registers offset */
+#define REG_CTL		0x00
+#define REG_CLKDIV	0x04
+#define REG_SSCTL	0x08
+#define REG_PDMACTL	0x0C
+#define REG_FIFOCTL	0x10
+#define REG_STATUS	0x14
+#define REG_TX		0x20
+#define REG_RX		0x30
+
+/* spi register bit */
+#define UNITIEN		(0x01 << 17)
+#define TXNEG		(0x01 << 2)
+#define RXNEG		(0x01 << 1)
+#define SLAVE		(0x01 << 18)
+#define LSB		(0x01 << 13)
+#define SELECTLEV	(0x01 << 2)
+#define SELECTPOL	(0x01 << 3)
+#define SSACTIEN	(0x01 << 12)
+#define SELECTSLAVE0	0x01
+#define SELECTSLAVE1	0x02
+#define SPIEN		0x01
+#define TXTHIEN		(0x01 << 3)
+#define RXTHIEN		(0x01 << 2)
+#define SSINAIEN	(0x01 << 13)
+#define SSACTIF		(0x01 << 2)
+#define SSINAIF		(0x01 << 3)
+#define RXTHIF		(0x01 << 10)
+#define TXTHIF		(0x01 << 18)
+#define TXUFIF		(0x01 << 19)
+
+#ifdef CONFIG_SPI_NUC980_SPI1
+# error Do not enable CONFIG_SPI_NUC980_SPI1 and CONFIG_NUC980_SPI1_SLAVE at the same time!
+#endif
+
+static volatile int slave_done_state=0;
+static DECLARE_WAIT_QUEUE_HEAD(slave_done);
+
+static int SPI1_SlaveDataLen = 256;
+static int SPI1_SlaveData[256];
+static int TransmittedCnt = 0;
+static int InTransmitted = 0;
+
+struct nuc980_spi {
+	struct spi_bitbang	bitbang;
+	struct completion	done;
+	void __iomem		*regs;
+	int			irq;
+	unsigned int 		len;
+	unsigned int		count;
+	const void		*tx;
+	void			*rx;
+	struct clk		*clk;
+	struct resource		*ioarea;
+	struct spi_master	*master;
+	struct spi_device	*curdev;
+	struct device		*dev;
+	struct nuc980_spi_info *pdata;
+	spinlock_t		lock;
+	struct resource		*res;
+};
+
+
+static inline struct nuc980_spi1 *to_hw(struct spi_device *sdev) {
+	return spi_master_get_devdata(sdev->master);
+}
+
+static inline void nuc980_slave_select(struct spi_device *spi, unsigned int ssr)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int val;
+	unsigned int cs = spi->mode & SPI_CS_HIGH ? 1 : 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_SSCTL);
+
+	if (!cs)
+		val &= ~SELECTLEV;
+	else
+		val |= SELECTLEV;
+
+	if(spi->chip_select == 0) {
+		if (!ssr)
+			val &= ~SELECTSLAVE0;
+		else
+			val |= SELECTSLAVE0;
+	} else {
+		if (!ssr)
+			val &= ~SELECTSLAVE1;
+		else
+			val |= SELECTSLAVE1;
+	}
+
+	__raw_writel(val, hw->regs + REG_SSCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_spi1_chipsel(struct spi_device *spi, int value)
+{
+	switch (value) {
+	case BITBANG_CS_INACTIVE:
+		nuc980_slave_select(spi, 0);
+		break;
+
+	case BITBANG_CS_ACTIVE:
+		nuc980_slave_select(spi, 1);
+		break;
+	}
+}
+
+static inline void nuc980_spi1_setup_txbitlen(struct nuc980_spi *hw,
+                unsigned int txbitlen)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+	val &= ~0x1f00;
+	if(txbitlen != 32)
+		val |= (txbitlen << 8);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_set_clock_polarity(struct nuc980_spi *hw, unsigned int polarity)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (polarity)
+		val |= SELECTPOL;
+	else
+		val &= ~SELECTPOL;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_tx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= TXNEG;
+	else
+		val &= ~TXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_rx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= RXNEG;
+	else
+		val &= ~RXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_send_first(struct nuc980_spi *hw, unsigned int lsb)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (lsb)
+		val |= LSB;
+	else
+		val &= ~LSB;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_enable_slave(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	val |= SLAVE;
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_set_sleep(struct nuc980_spi *hw, unsigned int sleep)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	val &= ~(0x0f << 4);
+
+	if (sleep)
+		val |= (sleep << 4);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+
+static inline void nuc980_set_divider(struct nuc980_spi *hw)
+{
+	__raw_writel(hw->pdata->divider, hw->regs + REG_CLKDIV);
+}
+
+static int nuc980_spi1_update_state(struct spi_device *spi,
+                                    struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int clk;
+	unsigned int div;
+	unsigned int bpw;
+	unsigned int hz;
+	unsigned char spimode;
+
+	bpw = t ? t->bits_per_word : spi->bits_per_word;
+	hz  = t ? t->speed_hz : spi->max_speed_hz;
+
+	if(hw->pdata->txbitlen != bpw)
+		hw->pdata->txbitlen = bpw;
+
+	if(hw->pdata->hz != hz) {
+		clk = clk_get_rate(hw->clk);
+		div = DIV_ROUND_UP(clk, hz) - 1;
+		hw->pdata->hz = hz;
+		hw->pdata->divider = div;
+	}
+
+	//Mode 0: CPOL=0, CPHA=0; active high
+	//Mode 1: CPOL=0, CPHA=1 ;active low
+	//Mode 2: CPOL=1, CPHA=0 ;active low
+	//Mode 3: POL=1, CPHA=1;active high
+	if (spi->mode & SPI_CPOL)
+		hw->pdata->clkpol = 1;
+	else
+		hw->pdata->clkpol = 0;
+
+	spimode = spi->mode & 0xff; //remove dual/quad bit
+
+	if ((spimode == SPI_MODE_0) || (spimode == SPI_MODE_2)) {
+		hw->pdata->txneg = 1;
+		hw->pdata->rxneg = 0;
+	} else {
+		hw->pdata->txneg = 0;
+		hw->pdata->rxneg = 1;
+	}
+
+	if (spi->mode & SPI_LSB_FIRST)
+		hw->pdata->lsb = 1;
+	else
+		hw->pdata->lsb = 0;
+
+	return 0;
+}
+
+static int nuc980_spi1_setupxfer(struct spi_device *spi,
+                                 struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_spi1_update_state(spi, t);
+	if (ret)
+		return ret;
+
+	nuc980_spi1_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_divider(hw);
+
+	return 0;
+}
+
+static int nuc980_spi1_setup(struct spi_device *spi)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_spi1_update_state(spi, NULL);
+	if (ret)
+		return ret;
+
+	spin_lock(&hw->bitbang.lock);
+	if (!hw->bitbang.busy) {
+		nuc980_set_divider(hw);
+		nuc980_slave_select(spi, 0);
+	}
+	spin_unlock(&hw->bitbang.lock);
+
+	return 0;
+}
+
+static inline void nuc980_enable_rxth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val = (val & ~0x7000000) | 0x0000000; /* set RXTH = 0 */
+	val |= RXTHIEN; /* enable RXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_disable_rxth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val &= ~RXTHIEN; /* disable RXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_enable_txth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val = (val & ~0x70000000) | 0x30000000; /* set TXTH = 3 */
+	val |= TXTHIEN; /* enable TXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_disable_txth_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_FIFOCTL);
+
+	val &= ~TXTHIEN; /* disable TXTHIEN */
+
+	__raw_writel(val, hw->regs + REG_FIFOCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_enable_ssinact_int(struct nuc980_spi *hw)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_SSCTL);
+
+	val |= SSINAIEN; /* enable SSINAIEN */
+
+	__raw_writel(val, hw->regs + REG_SSCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static irqreturn_t nuc980_spi1_irq(int irq, void *dev)
+{
+	struct nuc980_spi *hw = dev;
+	unsigned int val, status;
+
+	status = __raw_readl(hw->regs + REG_STATUS);
+	__raw_writel(status, hw->regs + REG_STATUS);
+
+	if (status & RXTHIF) {
+		if (InTransmitted == 0) {
+			nuc980_disable_rxth_int(hw);
+			slave_done_state = 1;
+			wake_up_interruptible(&slave_done);
+			InTransmitted = 1;
+		}
+	}
+	if (status & TXTHIF) {
+		while(!(__raw_readl(hw->regs + REG_STATUS) & 0x20000)) {//TXFULL
+			__raw_writel(SPI1_SlaveData[TransmittedCnt++], hw->regs + REG_TX);
+			if (TransmittedCnt >= SPI1_SlaveDataLen) {
+				nuc980_disable_txth_int(hw);
+				InTransmitted = 0;
+				TransmittedCnt = 0;
+				break;
+			}
+		}
+	}
+	if (status & SSINAIF) {
+		/* Check if transmition complete */
+		if (InTransmitted == 1) {
+			int i;
+			printk("Master pull SS high, but slave TX doesn't complete!\n");
+			__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //TXRX reset
+			while (__raw_readl(hw->regs + REG_STATUS) & (1<<23)); //TXRXRST
+			nuc980_enable_rxth_int(hw);
+			InTransmitted = 0;
+			TransmittedCnt = 0;
+			for (i = 0; i < SPI1_SlaveDataLen; i++)
+				SPI1_SlaveData[i] = 0;
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+
+static void nuc980_init_spi(struct nuc980_spi *hw)
+{
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	spin_lock_init(&hw->lock);
+
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_sleep(hw, hw->pdata->sleep);
+	nuc980_spi1_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_set_divider(hw);
+	nuc980_enable_slave(hw);
+	nuc980_enable_rxth_int(hw);
+	nuc980_enable_ssinact_int(hw);
+}
+
+#ifdef CONFIG_OF
+static struct nuc980_spi_info *nuc980_spi1_parse_dt(struct device *dev) {
+	struct nuc980_spi_info *sci;
+	u32 temp;
+
+	sci = devm_kzalloc(dev, sizeof(*sci), GFP_KERNEL);
+	if (!sci) {
+		dev_err(dev, "memory allocation for spi_info failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	if (of_property_read_u32(dev->of_node, "num_cs", &temp)) {
+		dev_warn(dev, "can't get num_cs from dt\n");
+		sci->num_cs = 2;
+	} else {
+		sci->num_cs = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "lsb", &temp)) {
+		dev_warn(dev, "can't get lsb from dt\n");
+		sci->lsb = 0;
+	} else {
+		sci->lsb = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txneg", &temp)) {
+		dev_warn(dev, "can't get txneg from dt\n");
+		sci->txneg = 1;
+	} else {
+		sci->txneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "clkpol", &temp)) {
+		dev_warn(dev, "can't get clkpol from dt\n");
+		sci->clkpol = 0;
+	} else {
+		sci->clkpol = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "rxneg", &temp)) {
+		dev_warn(dev, "can't get rxneg from dt\n");
+		sci->rxneg = 0;
+	} else {
+		sci->rxneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "divider", &temp)) {
+		dev_warn(dev, "can't get divider from dt\n");
+		sci->divider = 4;
+	} else {
+		sci->divider = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "sleep", &temp)) {
+		dev_warn(dev, "can't get sleep from dt\n");
+		sci->sleep = 0;
+	} else {
+		sci->sleep = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txbitlen", &temp)) {
+		dev_warn(dev, "can't get txbitlen from dt\n");
+		sci->txbitlen = 8;
+	} else {
+		sci->txbitlen = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "bus_num", &temp)) {
+		dev_warn(dev, "can't get bus_num from dt\n");
+		sci->bus_num = 0;
+	} else {
+		sci->bus_num = temp;
+	}
+
+	return sci;
+}
+#else
+static struct nuc980_spi_info *nuc980_spi1_parse_dt(struct device *dev) {
+	return dev->platform_data;
+}
+#endif
+
+/* In Thread, only prepare data and enable TXTHIEN.
+   The data will be transmitted in IRQ
+ */
+static int SPI1_Slave_Thread_TXRX(struct nuc980_spi *hw)
+{
+	unsigned char rx;
+	unsigned long flags;
+	int i;
+
+	while(1) {
+
+		wait_event_interruptible(slave_done, (slave_done_state != 0));
+		rx = __raw_readl(hw->regs + REG_RX);
+		//printk("Receive [0x%x] \n", rx);
+
+		switch (rx) {
+		case 0x9f:
+			for (i = 0; i < SPI1_SlaveDataLen; i++)
+				SPI1_SlaveData[i] = i;
+
+			nuc980_enable_txth_int(hw);
+			break;
+		default:
+			break;
+		}
+
+		InTransmitted = 0;
+		slave_done_state = 0;
+		nuc980_enable_rxth_int(hw);
+	}
+
+	return 0;
+}
+
+static int nuc980_spi1_slave_probe(struct platform_device *pdev)
+{
+	struct nuc980_spi *hw;
+	struct spi_master *master;
+	int err = 0;
+	struct pinctrl *p;
+
+	master = spi_alloc_master(&pdev->dev, sizeof(struct nuc980_spi));
+	if (master == NULL) {
+		dev_err(&pdev->dev, "No memory for spi_master\n");
+		err = -ENOMEM;
+		goto err_nomem;
+	}
+
+	hw = spi_master_get_devdata(master);
+	hw->master = spi_master_get(master);
+	hw->pdata = nuc980_spi1_parse_dt(&pdev->dev);
+	hw->dev = &pdev->dev;
+
+	if (hw->pdata == NULL) {
+		dev_err(&pdev->dev, "No platform data supplied\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+	platform_set_drvdata(pdev, hw);
+	init_completion(&hw->done);
+	master->mode_bits          = (SPI_MODE_0 | SPI_CS_HIGH | SPI_LSB_FIRST | SPI_CPHA | SPI_CPOL);
+	master->dev.of_node        = pdev->dev.of_node;
+	master->num_chipselect     = hw->pdata->num_cs;
+	master->bus_num            = hw->pdata->bus_num;
+	hw->bitbang.master         = hw->master;
+	hw->bitbang.setup_transfer = nuc980_spi1_setupxfer;
+	hw->bitbang.chipselect     = nuc980_spi1_chipsel;
+	hw->bitbang.master->setup  = nuc980_spi1_setup;
+
+	hw->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (hw->res == NULL) {
+		dev_err(&pdev->dev, "Cannot get IORESOURCE_MEM\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+#if defined(CONFIG_OF)
+	hw->regs = devm_ioremap_resource(&pdev->dev, hw->res);
+#else
+	hw->ioarea = request_mem_region(hw->res->start,
+	                                resource_size(hw->res), pdev->name);
+
+	if (hw->ioarea == NULL) {
+		dev_err(&pdev->dev, "Cannot reserve region\n");
+		err = -ENXIO;
+		goto err_pdata;
+	}
+
+	hw->regs = ioremap(hw->res->start, resource_size(hw->res));
+	if (hw->regs == NULL) {
+		dev_err(&pdev->dev, "Cannot map IO\n");
+		err = -ENXIO;
+		goto err_iomap;
+	}
+#endif
+
+	hw->irq = platform_get_irq(pdev, 0);
+	if (hw->irq < 0) {
+		dev_err(&pdev->dev, "No IRQ specified\n");
+		err = -ENOENT;
+		goto err_irq;
+	}
+
+	err = request_irq(hw->irq, nuc980_spi1_irq, 0, pdev->name, hw);
+	if (err) {
+		dev_err(&pdev->dev, "Cannot claim IRQ\n");
+		goto err_irq;
+	}
+
+	hw->clk = clk_get(NULL, "spi1_eclk");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	hw->clk = clk_get(NULL, "spi1");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+#if defined(CONFIG_OF)
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+	/*
+#if defined(CONFIG_SPI_NUC980_P0_NORMAL) && !defined(CONFIG_SPI_NUC980_P0_SS1)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi1");
+#elif defined(CONFIG_SPI_NUC980_P0_NORMAL) && defined(CONFIG_SPI_NUC980_P0_SS1_PB0)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi1-ss1-PB");
+#elif defined(CONFIG_SPI_NUC980_P0_NORMAL) && defined(CONFIG_SPI_NUC980_P0_SS1_PH12)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi1-ss1-PH");
+#elif defined(CONFIG_SPI_NUC980_P0_QUAD) && !defined(CONFIG_SPI_NUC980_P0_SS1)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi1-quad");
+#elif defined(CONFIG_SPI_NUC980_P0_QUAD) && defined(CONFIG_SPI_NUC980_P0_SS1_PB0)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi1-quad-ss1-PB");
+#elif defined(CONFIG_SPI_NUC980_P0_QUAD) && defined(CONFIG_SPI_NUC980_P0_SS1_PH12)
+		p = devm_pinctrl_get_select(&pdev->dev, "spi1-quad-ss1-PB");
+#endif
+	*/
+	/*TODO : use pinctrl*/
+	__raw_writel((__raw_readl(REG_MFP_GPB_H) & ~0xFFFF0) | 0x55550, REG_MFP_GPB_H);
+#endif
+	if(IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve spi pin by mode\n");
+		err = PTR_ERR(p);
+		goto err_register;
+	}
+
+	nuc980_init_spi(hw);
+
+	__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //CWWeng : RXRST & TXRST
+	while (__raw_readl(hw->regs + REG_STATUS) & (1<<23)); //TXRXRST
+
+	__raw_writel(__raw_readl(hw->regs + REG_CTL) | SPIEN, hw->regs + REG_CTL); /* enable SPI */
+	while ((__raw_readl(hw->regs + REG_STATUS) & (1<<15)) == 0); //SPIENSTS
+
+	kthread_run(SPI1_Slave_Thread_TXRX, hw, "SPI1_SLAVE_THread_TXRX");
+
+	return 0;
+
+err_register:
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+err_clk:
+	free_irq(hw->irq, hw);
+err_irq:
+	iounmap(hw->regs);
+#ifndef CONFIG_OF
+err_iomap:
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#endif
+err_pdata:
+	spi_master_put(hw->master);
+
+err_nomem:
+	return err;
+}
+
+static int nuc980_spi1_slave_remove(struct platform_device *dev)
+{
+	struct nuc980_spi *hw = platform_get_drvdata(dev);
+
+	free_irq(hw->irq, hw);
+	platform_set_drvdata(dev, NULL);
+	spi_bitbang_stop(&hw->bitbang);
+
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+
+	iounmap(hw->regs);
+
+#ifndef CONFIG_OF
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#else
+	kfree(hw->pdata);
+#endif
+
+	spi_master_put(hw->master);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_spi1_suspend(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	while(__raw_readl(hw->regs + REG_CTL) & 0x1)
+		msleep(1);
+
+	// disable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) & ~0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static int nuc980_spi1_resume(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	// enable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) | 0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_spi1_pmops = {
+	.suspend    = nuc980_spi1_suspend,
+	.resume     = nuc980_spi1_resume,
+};
+
+#define NUC980_SPI1_PMOPS (&nuc980_spi1_pmops)
+
+#else
+#define NUC980_SPI1_PMOPS NULL
+#endif
+
+#if defined(CONFIG_OF)
+static const struct of_device_id nuc980_spi1_slave_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-spi1-slave" },
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_spi1_of_match);
+#endif
+
+static struct platform_driver nuc980_spi1_slave_driver = {
+	.probe      = nuc980_spi1_slave_probe,
+	.remove     = nuc980_spi1_slave_remove,
+	.driver     = {
+		.name   = "nuc980-spi1-slave",
+		.owner  = THIS_MODULE,
+		.pm	= NUC980_SPI1_PMOPS,
+#if defined(CONFIG_OF)
+		.of_match_table = of_match_ptr(nuc980_spi1_slave_of_match),
+#endif
+	},
+};
+module_platform_driver(nuc980_spi1_slave_driver);
+
+MODULE_DESCRIPTION("nuc980 spi1 slave driver!");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-spi1-slave");
diff -uprN linux-4.4.194/drivers/misc/sc-t0.c NUC980-linux-4.4.194/drivers/misc/sc-t0.c
--- linux-4.4.194/drivers/misc/sc-t0.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/misc/sc-t0.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,346 @@
+/* linux/driver/misc/sc-t0.c
+ *
+ * Copyright (c) 2015 Nuvoton technology corporation
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+// Based on:
+/*
+    commands.c: Commands sent to the card
+    Copyright (C) 2003-2010   Ludovic Rousseau
+    Copyright (C) 2005 Martin Paljak
+
+    This library is free software; you can redistribute it and/or
+    modify it under the terms of the GNU Lesser General Public
+    License as published by the Free Software Foundation; either
+    version 2.1 of the License, or (at your option) any later version.
+
+    This library is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+    Lesser General Public License for more details.
+
+	You should have received a copy of the GNU Lesser General Public License
+	along with this library; if not, write to the Free Software Foundation,
+	Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+*/
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/slab.h>
+#include <linux/miscdevice.h>
+#include <linux/device.h>
+#include <linux/spinlock.h>
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/wait.h>
+#include <linux/clk.h>
+#include <linux/platform_device.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-sc.h>
+#include <mach/nuc980-sc.h>
+
+
+extern struct nuc980_sc sc[SC_INTF];
+static char gRx[SC_INTF][300];
+static unsigned gRx_offset[SC_INTF];
+
+/*****************************************************************************
+ *
+ *					T0CmdParsing
+ *
+ ****************************************************************************/
+static int T0CmdParsing(unsigned char *cmd, unsigned int cmd_len, unsigned int *exp_len)
+{
+	int ret = 0;
+	*exp_len = 0;
+
+	if(cmd_len < 4)
+		return -1;
+	/* Ref: 7816-4 Annex A */
+	switch (cmd_len)
+	{
+		case 4:	/* Case 1 */
+			//printk("Case 1\n");
+			*exp_len = 2; /* SW1 and SW2 only */
+			break;
+
+		case 5: /* Case 2 */
+			if (cmd[4] != 0) {
+				//printk("Case 2, recv %d\n", cmd[4] + 2);
+				*exp_len = cmd[4] + 2;
+			} else {
+				//printk("Case 2, recv 258\n");
+				*exp_len = 256 + 2;
+			}
+			break;
+
+		default:
+			if (cmd_len == (unsigned int)(cmd[4] + 5)) {/* Case 3 */
+				//printk("Case 3\n");
+				*exp_len = 2; /* SW1 and SW2 only */
+			} else if (cmd_len == (unsigned int)(cmd[4] + 6)) {/* Case 4 */
+				//printk("Case 3\n");
+				*exp_len = 2; /* SW1 and SW2 only */
+				ret = 4;
+			}else
+				return -1;	/* situation not supported */
+			break;
+	}
+
+	return ret;
+} /* T0CmdParsing */
+
+unsigned char tmp_buf[512]; // move out from function. we have limited stack depth
+/*****************************************************************************
+ *
+ *					T0ProcACK
+ *
+ ****************************************************************************/
+static void T0ProcACK(unsigned int intf, unsigned int *in_len,
+	unsigned int proc_len, int is_rcv)
+{
+
+	unsigned int ret_len;
+
+	if (is_rcv == 1)
+	{	/* Receiving mode */
+		unsigned int remain_len;
+
+		/* There is no data in our tmp_buf,
+		* we have to read all data we needed */
+		remain_len = proc_len;
+
+		{
+			ret_len = remain_len;
+
+			sc[intf].rlen = ret_len;
+			sc[intf].state = SC_OP_READ;
+			wait_event_interruptible(sc[intf].wq, ((sc[intf].rtail - sc[intf].rhead) >= sc[intf].rlen) || sc[intf].err);
+			if(sc[intf].err)
+				return;
+			sc[intf].state = SC_OP_IDLE;
+
+			*in_len = ret_len;
+			memcpy(&gRx[intf][gRx_offset[intf]], &sc[intf].rbuf[sc[intf].rhead], ret_len);
+			gRx_offset[intf] += ret_len;
+			sc[intf].rhead += ret_len;
+
+		}
+
+	}
+	else
+	{	/* Sending mode */
+
+		sc[intf].tcnt += proc_len;
+		sc[intf].state = SC_OP_WRITE;
+		// enable tx interrupt
+		__raw_writel(__raw_readl(sc[intf].base + REG_SC_INTEN) | SC_INTEN_TBEIEN, sc[intf].base + REG_SC_INTEN);
+		wait_event_interruptible(sc[intf].wq, sc[intf].state == SC_OP_IDLE);
+	}
+
+	return;
+} /* T0ProcACK */
+
+
+/*****************************************************************************
+ *
+ *					T0ProcSW1
+ *
+ ****************************************************************************/
+static void T0ProcSW1(unsigned int intf,
+	unsigned char *rcv_buf,
+	unsigned char *in_buf, unsigned int in_len)
+{
+
+	rcv_buf++;
+	in_buf++;
+	/* store the SW2 */
+	if(1) {
+		sc[intf].rlen = 1;
+		sc[intf].state = SC_OP_READ;
+		wait_event_interruptible(sc[intf].wq, ((sc[intf].rtail - sc[intf].rhead) >= sc[intf].rlen) || sc[intf].err);
+
+		if(sc[intf].err) {
+			__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+			return;
+		}
+
+		in_buf = &sc[intf].rbuf[sc[intf].rtail - 1];
+
+	}
+	// all done, stop timer.
+	__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+	sc[intf].state = SC_OP_IDLE;
+
+	gRx[intf][gRx_offset[intf]++] = sc[intf].rbuf[sc[intf].rtail - 2];
+	gRx[intf][gRx_offset[intf]++] = sc[intf].rbuf[sc[intf].rtail - 1];
+	memcpy(sc[intf].rbuf, &gRx[intf][0], gRx_offset[intf]);
+	sc[intf].rtail = gRx_offset[intf];
+	sc[intf].rhead = 0;
+
+	return;
+} /* T0ProcSW1 */
+
+void CmdXfrT0(unsigned int intf,
+	unsigned int snd_len, unsigned char snd_buf[],
+	unsigned char rcv_buf[])
+{
+	int is_rcv;
+
+	unsigned int exp_len, in_len;
+	unsigned char ins, *in_buf = &sc[intf].rbuf[0];  // just give a address avoid un-init warning
+
+	int return_value = 0;
+
+	gRx_offset[intf] = 0;
+
+	if(0){
+		int ii;
+		for(ii = 0; ii < snd_len; ii ++) {
+			printk("%02x ", snd_buf[ii]);
+			if(ii % 0x10 == 15)
+				printk("\n");
+		}
+		printk("\n");
+	}
+
+	in_len = 0;
+	return_value = T0CmdParsing(snd_buf, snd_len, &exp_len);
+
+	if (return_value < 0)
+	{
+		sc[intf].err = SC_ERR_T0;
+
+		return ;
+	}
+
+	if(return_value == 4) {  // case 4, no need to send Le
+		snd_len--;
+	}
+
+	if (snd_len == 5 || snd_len == 4)
+		is_rcv = 1;
+	else
+		is_rcv = 0;
+
+	/* Command to send to the smart card (must be 5 bytes, from 7816 p.15) */
+	if (snd_len == 4)
+	{
+		snd_len -= 4;
+	}
+	else
+	{
+		snd_len -= 5;
+	}
+
+	/* Make sure this is a valid command by checking the INS field */
+	ins = snd_buf[1];
+	if ((ins & 0xF0) == 0x60 ||	/* 7816-3 8.3.2 */
+		(ins & 0xF0) == 0x90)
+	{
+		sc[intf].err = SC_ERR_T0;
+		return;
+	}
+
+	__raw_writel((sc[intf].T0.WT) | SC_TMR_MODE_7, sc[intf].base + REG_SC_TMRCTL0);
+	__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) | SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+
+	sc[intf].tcnt = 5;
+	sc[intf].state = SC_OP_WRITE;
+	// enable tx interrupt
+	__raw_writel(__raw_readl(sc[intf].base + REG_SC_INTEN) | SC_INTEN_TBEIEN, sc[intf].base + REG_SC_INTEN);
+	wait_event_interruptible(sc[intf].wq, sc[intf].state == SC_OP_IDLE);
+
+	if (sc[intf].err)
+		return;
+
+	while (1)
+	{
+		if (in_len == 0)
+		{
+			in_len = 1;
+
+			sc[intf].rlen = 1;
+			sc[intf].state = SC_OP_READ;
+			wait_event_interruptible(sc[intf].wq, ((sc[intf].rtail - sc[intf].rhead) >= sc[intf].rlen) || sc[intf].err);
+			if(sc[intf].err)
+			{
+				__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+				return;
+			}
+
+			in_buf = &sc[intf].rbuf[sc[intf].rhead];
+			in_len = return_value;
+			sc[intf].rhead++;  // this byte is will be process immediately and not pass to user
+		}
+
+		/* Start to process the procedure bytes */
+		if (*in_buf == 0x60)
+		{
+			in_len = 0;
+			continue;
+		}
+		else if (*in_buf == ins || *in_buf == (ins ^ 0x01))
+		{
+			/* ACK => To transfer all remaining data bytes */
+			in_len--;
+			if (is_rcv) {
+				T0ProcACK(intf, &in_len, exp_len - gRx_offset[intf], 1);
+			} else {
+				T0ProcACK(intf, &in_len, snd_len, 0);
+				in_len = 0;
+			}
+			if ((gRx_offset[intf] == exp_len) || (sc[intf].err != 0)) {
+				__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+				if(sc[intf].err == 0) {
+					if ((gRx[intf][gRx_offset[intf] - 2] & 0xF0) != 0x60 && (gRx[intf][gRx_offset[intf] - 2] & 0xF0) != 0x90)
+						sc[intf].err = SC_ERR_T0;
+					else {
+						sc[intf].rtail = gRx_offset[intf];
+						sc[intf].rhead = 0;
+						memcpy(sc[intf].rbuf, &gRx[intf][0], gRx_offset[intf]);
+					}
+				}
+				return;
+			}
+
+			continue;
+		}
+		else if (*in_buf == (ins ^ 0xFF) || *in_buf == (ins ^ 0xFE))
+		{
+			if(!is_rcv)
+				snd_len--;
+			T0ProcACK(intf, &in_len, 1, is_rcv);
+			if(sc[intf].err) {
+				__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+				return;
+			}
+			in_len = 0;
+			continue;
+		} else if ((*in_buf & 0xF0) == 0x60 || (*in_buf & 0xF0) == 0x90) {
+			/* SW1 */
+			return T0ProcSW1(intf, rcv_buf, in_buf, in_len);
+		} else {
+			sc[intf].err = SC_ERR_T0; // protocol error
+			/* Error, unrecognized situation found */
+			__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+
+			return;
+		}
+	}
+
+	return;
+} /* CmdXfrT0 */
diff -uprN linux-4.4.194/drivers/misc/sc-t1.c NUC980-linux-4.4.194/drivers/misc/sc-t1.c
--- linux-4.4.194/drivers/misc/sc-t1.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/misc/sc-t1.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1125 @@
+/* linux/driver/misc/sc-t1.c
+ *
+ * Copyright (c) 2015 Nuvoton technology corporation
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+// Original from
+/*
+ * Implementation of T=1
+ *
+ * Copyright (C) 2003, Olaf Kirch <okir@suse.de>
+ *
+ * improvements by:
+ * Copyright (C) 2004 Ludovic Rousseau <ludovic.rousseau@free.fr>
+ */
+/*
+ * Buffer handling functions
+ *
+ * Copyright (C) 2003, Olaf Kirch <okir@suse.de>
+ */
+ /*
+ * Checksum handling
+ *
+ * Copyright Matthias Bruestle 1999-2002
+ * For licensing, see the file LICENCE
+ */
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/slab.h>
+#include <linux/miscdevice.h>
+#include <linux/device.h>
+#include <linux/spinlock.h>
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/wait.h>
+#include <linux/clk.h>
+#include <linux/platform_device.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-sc.h>
+#include <mach/nuc980-sc.h>
+
+extern struct nuc980_sc sc[SC_INTF];
+
+/* T=1 protocol constants */
+#define T1_I_BLOCK		0x00
+#define T1_R_BLOCK		0x80
+#define T1_S_BLOCK		0xC0
+#define T1_MORE_BLOCKS		0x20
+
+enum {
+	IFD_PROTOCOL_RECV_TIMEOUT = 0x0000,
+	IFD_PROTOCOL_T1_BLOCKSIZE,
+	IFD_PROTOCOL_T1_CHECKSUM_CRC,
+	IFD_PROTOCOL_T1_CHECKSUM_LRC,
+	IFD_PROTOCOL_T1_IFSC,
+	IFD_PROTOCOL_T1_IFSD,
+	IFD_PROTOCOL_T1_STATE,
+	IFD_PROTOCOL_T1_MORE
+};
+
+#define T1_BUFFER_SIZE		(3 + 254 + 2)
+
+static char gTx[SC_INTF][300];
+static char gRx[SC_INTF][300];
+
+#define T1_I_SEQ_SHIFT		6
+
+#define T1_IS_ERROR(pcb)	((pcb) & 0x0F)
+#define T1_EDC_ERROR		0x01
+#define T1_OTHER_ERROR		0x02
+#define T1_R_SEQ_SHIFT		4
+
+#define T1_S_TYPE(pcb)		((pcb) & 0x0F)
+#define T1_S_RESPONSE		0x20
+#define T1_S_RESYNC		0x00
+#define T1_S_IFS		0x01
+#define T1_S_ABORT		0x02
+#define T1_S_WTX		0x03
+#define T1_S_IS_RESPONSE	((pcb) & T1_S_RESPONSE)
+
+#define NAD 0
+#define PCB 1
+#define LEN 2
+#define DATA 3
+
+#define swap_nibbles(x)	((x >> 4) | ((x & 0xF) << 4))
+
+/* see /usr/include/PCSC/ifdhandler.h for other values
+ * this one is for internal use only */
+#define IFD_PARITY_ERROR 699
+
+typedef struct {
+//	int		lun;
+	int		state;
+
+	unsigned char	ns;	/* reader side */
+	unsigned char	nr;	/* card side */
+	unsigned int	ifsc;
+	unsigned int	ifsd;
+
+	unsigned char	wtx;
+	unsigned int	retries;
+	unsigned int	rc_bytes;
+	unsigned int 	icc_has_more;
+
+	unsigned int	(*checksum)(const uint8_t *, size_t, unsigned char *);
+
+	char			more;	/* more data bit */
+	unsigned char	previous_block[4];	/* to store the last R-block */
+	unsigned char	previous_i_block[MAX_LEN];	/* to store the last I-block */
+} t1_state_t;
+
+t1_state_t t1_state[SC_INTF];
+
+/* ISO STD 3309 */
+/* From: medin@catbyte.b30.ingr.com (Dave Medin)
+ * Subject: CCITT checksums
+ * Newsgroups: sci.electronics
+ * Date: Mon, 7 Dec 1992 17:33:39 GMT
+ */
+
+/* Correct Table? */
+
+static unsigned short crctab[256] = {
+	0x0000, 0x1189, 0x2312, 0x329b, 0x4624, 0x57ad, 0x6536, 0x74bf,
+	0x8c48, 0x9dc1, 0xaf5a, 0xbed3, 0xca6c, 0xdbe5, 0xe97e, 0xf8f7,
+	0x1081, 0x0108, 0x3393, 0x221a, 0x56a5, 0x472c, 0x75b7, 0x643e,
+	0x9cc9, 0x8d40, 0xbfdb, 0xae52, 0xdaed, 0xcb64, 0xf9ff, 0xe876,
+	0x2102, 0x308b, 0x0210, 0x1399, 0x6726, 0x76af, 0x4434, 0x55bd,
+	0xad4a, 0xbcc3, 0x8e58, 0x9fd1, 0xeb6e, 0xfae7, 0xc87c, 0xd9f5,
+	0x3183, 0x200a, 0x1291, 0x0318, 0x77a7, 0x662e, 0x54b5, 0x453c,
+	0xbdcb, 0xac42, 0x9ed9, 0x8f50, 0xfbef, 0xea66, 0xd8fd, 0xc974,
+	0x4204, 0x538d, 0x6116, 0x709f, 0x0420, 0x15a9, 0x2732, 0x36bb,
+	0xce4c, 0xdfc5, 0xed5e, 0xfcd7, 0x8868, 0x99e1, 0xab7a, 0xbaf3,
+	0x5285, 0x430c, 0x7197, 0x601e, 0x14a1, 0x0528, 0x37b3, 0x263a,
+	0xdecd, 0xcf44, 0xfddf, 0xec56, 0x98e9, 0x8960, 0xbbfb, 0xaa72,
+	0x6306, 0x728f, 0x4014, 0x519d, 0x2522, 0x34ab, 0x0630, 0x17b9,
+	0xef4e, 0xfec7, 0xcc5c, 0xddd5, 0xa96a, 0xb8e3, 0x8a78, 0x9bf1,
+	0x7387, 0x620e, 0x5095, 0x411c, 0x35a3, 0x242a, 0x16b1, 0x0738,
+	0xffcf, 0xee46, 0xdcdd, 0xcd54, 0xb9eb, 0xa862, 0x9af9, 0x8b70,
+	0x8408, 0x9581, 0xa71a, 0xb693, 0xc22c, 0xd3a5, 0xe13e, 0xf0b7,
+	0x0840, 0x19c9, 0x2b52, 0x3adb, 0x4e64, 0x5fed, 0x6d76, 0x7cff,
+	0x9489, 0x8500, 0xb79b, 0xa612, 0xd2ad, 0xc324, 0xf1bf, 0xe036,
+	0x18c1, 0x0948, 0x3bd3, 0x2a5a, 0x5ee5, 0x4f6c, 0x7df7, 0x6c7e,
+	0xa50a, 0xb483, 0x8618, 0x9791, 0xe32e, 0xf2a7, 0xc03c, 0xd1b5,
+	0x2942, 0x38cb, 0x0a50, 0x1bd9, 0x6f66, 0x7eef, 0x4c74, 0x5dfd,
+	0xb58b, 0xa402, 0x9699, 0x8710, 0xf3af, 0xe226, 0xd0bd, 0xc134,
+	0x39c3, 0x284a, 0x1ad1, 0x0b58, 0x7fe7, 0x6e6e, 0x5cf5, 0x4d7c,
+	0xc60c, 0xd785, 0xe51e, 0xf497, 0x8028, 0x91a1, 0xa33a, 0xb2b3,
+	0x4a44, 0x5bcd, 0x6956, 0x78df, 0x0c60, 0x1de9, 0x2f72, 0x3efb,
+	0xd68d, 0xc704, 0xf59f, 0xe416, 0x90a9, 0x8120, 0xb3bb, 0xa232,
+	0x5ac5, 0x4b4c, 0x79d7, 0x685e, 0x1ce1, 0x0d68, 0x3ff3, 0x2e7a,
+	0xe70e, 0xf687, 0xc41c, 0xd595, 0xa12a, 0xb0a3, 0x8238, 0x93b1,
+	0x6b46, 0x7acf, 0x4854, 0x59dd, 0x2d62, 0x3ceb, 0x0e70, 0x1ff9,
+	0xf78f, 0xe606, 0xd49d, 0xc514, 0xb1ab, 0xa022, 0x92b9, 0x8330,
+	0x7bc7, 0x6a4e, 0x58d5, 0x495c, 0x3de3, 0x2c6a, 0x1ef1, 0x0f78
+};
+
+/*
+ * Returns LRC of data.
+ */
+unsigned int
+csum_lrc_compute(const uint8_t *in, size_t len, unsigned char *rc)
+{
+	unsigned char	lrc = 0;
+
+	while (len--)
+		lrc ^= *in++;
+
+	if (rc)
+		*rc = lrc;
+	return 1;
+}
+
+/*
+ * Compute CRC of data.
+ */
+unsigned int
+csum_crc_compute(const uint8_t * data, size_t len, unsigned char *rc)
+{
+	unsigned short v = 0xFFFF;
+
+	while (len--) {
+		v = ((v >> 8) & 0xFF) ^ crctab[(v ^ *data++) & 0xFF];
+	}
+
+	if (rc) {
+		rc[0] = (v >> 8) & 0xFF;
+		rc[1] = v & 0xFF;
+	}
+
+	return 2;
+}
+
+typedef struct ct_buf {
+	unsigned char *base;
+	unsigned int head, tail, size;
+	unsigned int overrun;
+} ct_buf_t;
+
+void
+ct_buf_init(ct_buf_t *bp, void *mem, size_t len)
+{
+	memset(bp, 0, sizeof(*bp));
+	bp->base = (unsigned char *) mem;
+	bp->size = len;
+}
+
+void
+ct_buf_set(ct_buf_t *bp, void *mem, size_t len)
+{
+	ct_buf_init(bp, mem, len);
+	bp->tail = len;
+}
+
+int
+ct_buf_get(ct_buf_t *bp, void *mem, size_t len)
+{
+	if (len > bp->tail - bp->head)
+		return -1;
+	if (mem)
+		memcpy(mem, bp->base + bp->head, len);
+	bp->head += len;
+	return len;
+}
+
+int
+ct_buf_put(ct_buf_t *bp, const void *mem, size_t len)
+{
+	if (len > bp->size - bp->tail) {
+		bp->overrun = 1;
+		return -1;
+	}
+	if (mem)
+		memcpy(bp->base + bp->tail, mem, len);
+	bp->tail += len;
+	return len;
+}
+
+int
+ct_buf_putc(ct_buf_t *bp, int byte)
+{
+	unsigned char	c = byte;
+
+	return ct_buf_put(bp, &c, 1);
+}
+
+unsigned int
+ct_buf_avail(ct_buf_t *bp)
+{
+	return bp->tail - bp->head;
+}
+
+void *
+ct_buf_head(ct_buf_t *bp)
+{
+	return bp->base + bp->head;
+}
+
+
+
+/* internal state, do not mess with it. */
+/* should be != DEAD after reset/init */
+enum {
+	SENDING, RECEIVING, RESYNCH, DEAD
+};
+
+static void t1_set_checksum(t1_state_t *, int);
+static unsigned int t1_block_type(unsigned char);
+static unsigned int t1_seq(unsigned char);
+static unsigned int t1_rebuild(unsigned int intf, unsigned char *block);
+static unsigned int t1_compute_checksum(t1_state_t *, unsigned char *, size_t);
+static int t1_verify_checksum(t1_state_t *, unsigned char *, size_t);
+static int t1_xcv(unsigned int, unsigned char *, size_t, size_t);
+unsigned int t1_build(unsigned int intf, unsigned char *block,
+	unsigned char dad, unsigned char pcb,
+	ct_buf_t *bp, size_t *lenp);
+/*
+ * Set default T=1 protocol parameters
+ */
+static void t1_set_defaults(t1_state_t * t1)
+{
+	t1->retries = 3;
+	/* This timeout is rather insane, but we need this right now
+	 * to support cryptoflex keygen */
+	t1->ifsc = 32;
+	t1->ifsd = 32;
+	t1->nr = 0;
+	t1->ns = 0;
+	t1->wtx = 0;
+}
+
+static void t1_set_checksum(t1_state_t * t1, int csum)
+{
+	switch (csum) {
+	case IFD_PROTOCOL_T1_CHECKSUM_LRC:
+		t1->rc_bytes = 1;
+		t1->checksum = csum_lrc_compute;
+		break;
+	case IFD_PROTOCOL_T1_CHECKSUM_CRC:
+		t1->rc_bytes = 2;
+		t1->checksum = csum_crc_compute;
+		break;
+	}
+}
+
+/*
+ * Get/set parmaters for T1 protocol
+ */
+int t1_set_param(t1_state_t * t1, int type, long value)
+{
+	switch (type) {
+	case IFD_PROTOCOL_T1_CHECKSUM_LRC:
+	case IFD_PROTOCOL_T1_CHECKSUM_CRC:
+		t1_set_checksum(t1, type);
+		break;
+	case IFD_PROTOCOL_T1_IFSC:
+		t1->ifsc = value;
+		break;
+	case IFD_PROTOCOL_T1_IFSD:
+		t1->ifsd = value;
+		break;
+	case IFD_PROTOCOL_T1_STATE:
+		t1->state = value;
+		break;
+	case IFD_PROTOCOL_T1_MORE:
+		t1->more = value;
+		break;
+	default:
+		//printk("Unsupported parameter %d", type);
+		return -1;
+	}
+
+	return 0;
+}
+
+
+/*
+ * Attach t1 protocol
+ */
+int t1_init(unsigned int intf)
+{
+	t1_state_t * t1 = &t1_state[intf];
+	t1_set_defaults(t1);
+	t1_set_param(t1, IFD_PROTOCOL_T1_CHECKSUM_LRC, 0);
+	t1_set_param(t1, IFD_PROTOCOL_T1_STATE, SENDING);
+	t1_set_param(t1, IFD_PROTOCOL_T1_MORE, 0);
+	return 0;
+}
+
+
+/*
+ * Send an APDU through T=1
+ */
+unsigned char sdata[T1_BUFFER_SIZE];
+int t1_transceive(unsigned int intf, unsigned int dad,
+		const void *snd_buf, size_t snd_len,
+		void *rcv_buf)
+{
+	ct_buf_t sbuf, rbuf, tbuf;
+	unsigned char sblk[5];
+	unsigned int slen, retries, resyncs;
+	size_t last_send = 0;
+	t1_state_t * t1 = &t1_state[intf];
+
+	if (snd_len == 0)
+		return -1;
+
+	/* we can't talk to a dead card / reader. Reset it! */
+	if (t1->state == DEAD)
+	{
+		printk("T=1 state machine is DEAD. Reset the card first.\n");
+		return -1;
+	}
+
+	t1->state = SENDING;
+	retries = t1->retries;
+	resyncs = 3;
+
+	t1->previous_block[0] = t1->previous_block[1] = t1->previous_block[2] = t1->previous_block[3] = 0;
+	t1->icc_has_more = 0;
+	/* Initialize send/recv buffer */
+	ct_buf_set(&sbuf, (void *)snd_buf, snd_len);
+	ct_buf_init(&rbuf, rcv_buf, T1_BUFFER_SIZE);
+
+	/* Send the first block */
+	slen = t1_build(intf, sdata, dad, T1_I_BLOCK, &sbuf, &last_send);
+
+	while (1) {
+		unsigned char pcb;
+		int n;
+
+
+		retries--;
+
+		n = t1_xcv(intf, sdata, slen, sizeof(sdata));
+
+		if (-2 == n || sc[intf].err == SC_ERR_PARITY || sc[intf].err == SC_ERR_CARD_REMOVED)
+		{
+			printk("Parity error\n");
+
+			/* ISO 7816-3 Rule 7.4.2 */
+			if (retries <= 0)
+				goto resync;
+
+			sc[intf].err = 0;
+
+			if(t1->icc_has_more)
+				slen = t1_build(intf, sdata,
+					dad, T1_R_BLOCK,
+					NULL, NULL);
+			else
+				slen = t1_build(intf, sdata,
+					dad, T1_R_BLOCK | T1_EDC_ERROR,
+					NULL, NULL);
+			continue;
+		}
+
+
+		if ((n < 0)) {
+			int err;
+
+			if(t1_block_type(t1->previous_block[PCB]) == T1_S_BLOCK) {
+				if(T1_S_TYPE(t1->previous_block[PCB]) == T1_S_ABORT)
+					goto error;
+
+			}
+
+			if (retries <= 0)
+				goto resync;
+
+			if(t1->icc_has_more)
+				slen = t1_build(intf, sdata,
+					dad, T1_R_BLOCK,
+					NULL, NULL);
+			else
+				slen = t1_build(intf, sdata,
+					dad, T1_R_BLOCK | T1_OTHER_ERROR,
+					NULL, NULL);
+			err = sc[intf].err;
+			sc[intf].err = 0;
+
+			continue;
+
+		}
+
+		if (!t1_verify_checksum(t1, sdata, n)) {
+
+			/* ISO 7816-3 Rule 7.4.2 */
+			if (retries <= 0)
+				goto resync;
+
+			if(t1->icc_has_more)
+				slen = t1_build(intf, sdata,
+					dad, T1_R_BLOCK,
+					NULL, NULL);
+			else
+				slen = t1_build(intf, sdata,
+					dad, T1_R_BLOCK | T1_EDC_ERROR,
+					NULL, NULL);
+			continue;
+		}
+
+
+		if ((sdata[NAD] != swap_nibbles(dad)) /* wrong NAD */
+			|| (sdata[LEN] == 0xFF))	/* length == 0xFF (illegal) */
+		{
+
+			/* ISO 7816-3 Rule 7.4.2 */
+			if (retries <= 0)
+				goto resync;
+
+			if(t1->icc_has_more)
+				slen = t1_build(intf, sdata,
+					dad, T1_R_BLOCK,
+					NULL, NULL);
+			else
+				slen = t1_build(intf, sdata,
+					dad, T1_R_BLOCK | T1_OTHER_ERROR,
+					NULL, NULL);
+			continue;
+		}
+
+		pcb = sdata[PCB];
+		switch (t1_block_type(pcb)) {
+		case T1_R_BLOCK:
+			if ((sdata[LEN] != 0x00)	/* length != 0x00 (illegal) */
+				|| (pcb & 0x20)			/* b6 of pcb is set */
+			   )
+			{
+				/* ISO 7816-3 Rule 7.4.2 */
+				if (retries <= 0)
+					goto resync;
+
+				if(t1->icc_has_more)
+					slen = t1_build(intf, sdata,
+						dad, T1_R_BLOCK,
+						NULL, NULL);
+				else
+					slen = t1_build(intf, sdata,
+							dad, T1_R_BLOCK | T1_OTHER_ERROR,
+							NULL, NULL);
+				continue;
+			}
+
+			if (((t1_seq(pcb) != t1->ns)	/* wrong sequence number & no bit more */
+					&& ! t1->more)
+			   )
+			{
+
+				/* ISO 7816-3 Rule 7.4.2 */
+				if (retries <= 0)
+					goto resync;
+
+
+				if(t1->icc_has_more)
+					slen = t1_build(intf, sdata,
+						dad, T1_R_BLOCK,
+						NULL, NULL);
+				else
+					slen = t1_build(intf, sdata,
+							dad, T1_R_BLOCK | T1_OTHER_ERROR,
+							NULL, NULL);
+				continue;
+			}
+
+			if (t1->state == RECEIVING) {
+				/* ISO 7816-3 Rule 7.2 */
+				if (T1_R_BLOCK == t1_block_type(t1->previous_block[1]))
+				{
+#ifndef CONFIG_EMV_CHECK
+					/* ISO 7816-3 Rule 7.4.2 */
+					if (retries <= 0)
+						goto resync;
+#endif
+					//printk("Rule 7.2 f\n");
+					slen = t1_rebuild(intf, sdata);
+					continue;
+				}
+
+				slen = t1_build(intf, sdata,
+						dad, T1_R_BLOCK,
+						NULL, NULL);
+				break;
+			}
+
+			/* If the card terminal requests the next
+			 * sequence number, it received the previous
+			 * block successfully */
+			if (t1_seq(pcb) != t1->ns) {
+				ct_buf_get(&sbuf, NULL, last_send);
+				last_send = 0;
+				t1->ns ^= 1;
+			}
+
+#ifdef CONFIG_EMV_CHECK
+			/* If there's no data available, the ICC
+			 * shouldn't be asking for more */
+			if (ct_buf_avail(&sbuf) == 0)
+				goto resync;
+#endif
+			if(T1_IS_ERROR(pcb)) {// this R block indicates an error
+				slen = t1_build(intf, sdata, dad, T1_I_BLOCK,
+						&sbuf, &last_send);
+
+				if (retries <= 0)
+					goto resync;
+
+				continue;
+
+			} else {
+				slen = t1_build(intf, sdata, dad, T1_I_BLOCK,
+						&sbuf, &last_send);
+
+			}
+			break;
+
+		case T1_I_BLOCK:
+			/* The first I-block sent by the ICC indicates
+			 * the last block we sent was received successfully. */
+			if (t1->state == SENDING) {
+				ct_buf_get(&sbuf, NULL, last_send);
+				last_send = 0;
+				t1->ns ^= 1;
+			}
+
+
+			if(t1->more) {  // while we're still sending chaining I blocks shouldn't receive I block from ICC
+
+				slen = t1_build(intf, sdata, dad,
+						T1_R_BLOCK | T1_OTHER_ERROR,
+						NULL, NULL);
+				continue;
+
+			}
+
+			t1->state = RECEIVING;
+
+			/* If the block sent by the card doesn't match
+			 * what we expected it to send, reply with
+			 * an R block */
+			if (t1_seq(pcb) != t1->nr) {
+				/* ISO 7816-3 Rule 7.4.2 */
+				if (retries <= 0)
+					goto resync;
+				if(t1->icc_has_more)
+					slen = t1_build(intf, sdata,
+						dad, T1_R_BLOCK,
+						NULL, NULL);
+				else
+					slen = t1_build(intf, sdata, dad,
+							T1_R_BLOCK | T1_OTHER_ERROR,
+							NULL, NULL);
+				continue;
+			}
+
+
+
+
+			t1->nr ^= 1;
+
+			if (ct_buf_put(&rbuf, sdata + 3, sdata[LEN]) < 0)
+			{
+				goto error;
+			}
+
+			if ((pcb & T1_MORE_BLOCKS) == 0) {
+				goto done;
+			}
+			// clear previous error stored in previous_block if any
+			if(T1_IS_ERROR(t1->previous_block[PCB]) != 0 && t1_block_type(t1->previous_block[PCB]) ==  T1_R_BLOCK) { // use first error code
+				t1->previous_block[PCB] = 0;
+
+			}
+			t1->icc_has_more = 1;
+			slen = t1_build(intf, sdata, dad, T1_R_BLOCK, NULL, NULL);
+			break;
+
+		case T1_S_BLOCK:
+			if (/*T1_S_IS_RESPONSE(pcb)*/(pcb & 0x20) && t1->state == RESYNCH) {
+				/* ISO 7816-3 Rule 6.2 */
+				if(T1_S_TYPE(pcb) != T1_S_RESYNC) {
+					goto resync;
+				}
+
+				/* ISO 7816-3 Rule 6.3 */
+				t1->state = SENDING;
+				last_send = 0;
+				resyncs = 3;
+				retries = t1->retries;
+				ct_buf_init(&rbuf, rcv_buf, T1_BUFFER_SIZE);
+				sbuf.head = 0;//==>
+				slen = t1_build(intf, sdata, dad, T1_I_BLOCK,
+						&sbuf, &last_send);
+
+				continue;
+			}
+
+			if (/*T1_S_IS_RESPONSE(pcb)*/ (pcb & 0x20))
+			{
+				/* ISO 7816-3 Rule 7.4.2 */
+				if (retries <= 0)
+					goto resync;
+
+				if(t1->icc_has_more)
+					slen = t1_build(intf, sdata,
+						dad, T1_R_BLOCK,
+						NULL, NULL);
+				else
+					slen = t1_build(intf, sdata,
+							dad, T1_R_BLOCK | T1_OTHER_ERROR,
+							NULL, NULL);
+				continue;
+			}
+
+			ct_buf_init(&tbuf, sblk, sizeof(sblk));
+
+			switch (T1_S_TYPE(pcb)) {
+			case T1_S_RESYNC:
+				if (sdata[LEN] != 0)
+				{
+
+					slen = t1_build(intf, sdata, dad,
+						T1_R_BLOCK | T1_OTHER_ERROR,
+						NULL, NULL);
+					continue;
+				}
+
+				/* the card is not allowed to send a resync. */
+				goto resync;
+
+			case T1_S_ABORT:
+				if (sdata[LEN] != 0)
+				{
+					slen = t1_build(intf, sdata, dad,
+						T1_R_BLOCK | T1_OTHER_ERROR,
+						NULL, NULL);
+					continue;
+				}
+
+				break;
+
+			case T1_S_IFS:
+				if (sdata[LEN] != 1)
+				{
+
+					slen = t1_build(intf, sdata, dad,
+						T1_R_BLOCK | T1_OTHER_ERROR,
+						NULL, NULL);
+					continue;
+				}
+				if(sdata[DATA] < 0x10 || sdata[DATA] == 0xFF) {
+
+					if (retries <= 0)
+						goto resync;
+
+					if(t1->icc_has_more)
+						slen = t1_build(intf, sdata,
+							dad, T1_R_BLOCK,
+							NULL, NULL);
+					else
+						slen = t1_build(intf, sdata, dad,
+							T1_R_BLOCK | T1_OTHER_ERROR,
+							NULL, NULL);
+					continue;
+				} //else
+					//printk("CT sent S-block with ifs=%u\n", sdata[DATA]);
+				if (sdata[DATA] == 0)
+					goto resync;
+				t1->ifsc = sdata[DATA];
+				ct_buf_putc(&tbuf, sdata[DATA]);
+				break;
+
+			case T1_S_WTX:
+				if (sdata[LEN] != 1)
+				{
+					if (retries <= 0)
+						goto resync;
+
+
+					if(t1->icc_has_more)
+						slen = t1_build(intf, sdata,
+							dad, T1_R_BLOCK,
+							NULL, NULL);
+					else
+						slen = t1_build(intf, sdata, dad,
+							T1_R_BLOCK | T1_OTHER_ERROR,
+							NULL, NULL);
+					continue;
+				}
+
+				t1->wtx = sdata[DATA];
+				sc[intf].T1.WTX = sdata[DATA];
+				ct_buf_putc(&tbuf, sdata[DATA]);
+				break;
+
+			default:
+
+				if (retries <= 0)
+					goto resync;
+				if(t1->icc_has_more)
+					slen = t1_build(intf, sdata,
+						dad, T1_R_BLOCK,
+						NULL, NULL);
+				else
+					slen = t1_build(intf, sdata, dad,
+						T1_R_BLOCK | T1_OTHER_ERROR,
+						NULL, NULL);
+				continue;
+				//goto resync;
+			}
+
+			slen = t1_build(intf, sdata, dad,
+				T1_S_BLOCK | T1_S_RESPONSE | T1_S_TYPE(pcb),
+				&tbuf, NULL);
+		}
+
+		/* Everything went just splendid */
+		retries = t1->retries;
+		continue;
+
+resync:
+		/* the number or resyncs is limited, too */
+		/* ISO 7816-3 Rule 6.4 */
+		if (resyncs == 0)
+			goto error;
+
+		/* ISO 7816-3 Rule 6 */
+		resyncs--;
+		t1->ns = 0;
+		t1->nr = 0;
+		sc[intf].err = 0;
+		slen = t1_build(intf, sdata, dad, T1_S_BLOCK | T1_S_RESYNC, NULL,
+				NULL);
+		t1->state = RESYNCH;
+		t1->more = 0;
+		retries = 1;
+		continue;
+	}
+
+done:
+	return ct_buf_avail(&rbuf);
+
+error:
+	t1->state = DEAD;
+	return -1;
+}
+
+static unsigned t1_block_type(unsigned char pcb)
+{
+	switch (pcb & 0xC0) {
+	case T1_R_BLOCK:
+		return T1_R_BLOCK;
+	case T1_S_BLOCK:
+		return T1_S_BLOCK;
+	default:
+		return T1_I_BLOCK;
+	}
+}
+
+static unsigned int t1_seq(unsigned char pcb)
+{
+	switch (pcb & 0xC0) {
+	case T1_R_BLOCK:
+		return (pcb >> T1_R_SEQ_SHIFT) & 1;
+	case T1_S_BLOCK:
+		return 0;
+	default:
+		return (pcb >> T1_I_SEQ_SHIFT) & 1;
+	}
+}
+
+unsigned int t1_build(unsigned int intf, unsigned char *block,
+	unsigned char dad, unsigned char pcb,
+	ct_buf_t *bp, size_t *lenp)
+{
+	unsigned int len;
+	char more = 0;
+	t1_state_t * t1 = &t1_state[intf];
+	len = bp ? ct_buf_avail(bp) : 0;
+
+	if (len > t1->ifsc) {
+		pcb |= T1_MORE_BLOCKS;
+		len = t1->ifsc;
+		more = 1;
+	}
+
+
+	/* Add the sequence number */
+	switch (t1_block_type(pcb)) {
+	case T1_R_BLOCK:
+		if(T1_IS_ERROR(t1->previous_block[PCB]) != 0 && t1_block_type(t1->previous_block[PCB]) ==  T1_R_BLOCK) { // use first error code
+			pcb = T1_R_BLOCK | T1_IS_ERROR(t1->previous_block[PCB]);
+		}
+		pcb |= t1->nr << T1_R_SEQ_SHIFT;
+		break;
+	case T1_I_BLOCK:
+		pcb |= t1->ns << T1_I_SEQ_SHIFT;
+		t1->more = more;
+		break;
+	}
+
+	block[0] = dad;
+	block[1] = pcb;
+	block[2] = len;
+
+	if (len)
+		memcpy(block + 3, ct_buf_head(bp), len);
+	if (lenp)
+		*lenp = len;
+
+	len = t1_compute_checksum(t1, block, len + 3);
+
+	/* memorize the last sent block */
+	/* only 4 bytes since we are only interesed in R-blocks */  //==> this is probably wrong, and makes erro handling difficult
+	memcpy(t1->previous_block, block, 4);
+	if(t1_block_type(pcb) == T1_I_BLOCK) {
+		memcpy(t1->previous_i_block, block, len + 4);
+	}
+	return len;
+}
+
+static unsigned int
+t1_rebuild(unsigned int intf, unsigned char *block)
+{
+	t1_state_t * t1 = &t1_state[intf];
+	unsigned char pcb = t1 -> previous_block[1];
+	unsigned char pcb1 = t1 -> previous_i_block[1];
+
+	if(T1_I_BLOCK == t1_block_type(pcb1)) {
+		if(t1_seq(pcb1) == t1_seq(sdata[PCB]) /*&& (T1_R_BLOCK == t1_block_type(sdata[PCB]))*/) {
+			memcpy(block, t1 -> previous_i_block, t1 -> previous_i_block[2] + 4);
+			return (t1 -> previous_i_block[2] + 4);
+		} else {
+			memcpy(block, t1 -> previous_block, 4);
+			return 4;
+		}
+	} else
+	/* copy the last sent block */
+	if (T1_R_BLOCK == t1_block_type(pcb)) {
+		memcpy(block, t1 -> previous_block, 4);
+		return 4;
+	} else
+	{
+		return 0;
+	}
+}
+
+/*
+ * Build/verify checksum
+ */
+static unsigned int t1_compute_checksum(t1_state_t * t1,
+	unsigned char *data, size_t len)
+{
+	return len + t1->checksum(data, len, data + len);
+}
+
+static int t1_verify_checksum(t1_state_t * t1, unsigned char *rbuf,
+	size_t len)
+{
+	unsigned char csum[2];
+	int m, n;
+
+	m = len - t1->rc_bytes;
+	n = t1->rc_bytes;
+
+	if (m < 0)
+		return 0;
+
+	t1->checksum(rbuf, m, csum);
+	if (!memcmp(rbuf + m, csum, n))
+		return 1;
+
+	return 0;
+}
+
+/*
+ * Send/receive block
+ */
+static int t1_xcv(unsigned int intf, unsigned char *block, size_t slen,
+	size_t rmax)
+{
+#if 0
+	printk("TX:\n");
+	{
+		int i;
+		for(i = 0; i < slen; i++)
+			printk("%02x ", block[i]);
+		printk("\n");
+	}
+#endif
+	sc[intf].rhead = sc[intf].rtail = 0;
+	sc[intf].state = SC_OP_WRITE;
+	memcpy(sc[intf].tbuf, block, slen);
+	sc[intf].toffset = 0;
+	sc[intf].tcnt = slen;
+
+
+	if(!sc[intf].T1.WTX)  {
+		__raw_writel((sc[intf].T1.BWT + 2400 * sc[intf].D) | SC_TMR_MODE_7, sc[intf].base + REG_SC_TMRCTL0);
+	} else {
+		__raw_writel((sc[intf].T1.BWT * sc[intf].T1.WTX + 2400 * sc[intf].D) | SC_TMR_MODE_7, sc[intf].base + REG_SC_TMRCTL0);
+	}
+	__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) | SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+	sc[intf].T1.WTX = 0;  // WTX only valid for 1 packet.
+
+
+	// enable tx interrupt
+	__raw_writel(__raw_readl(sc[intf].base + REG_SC_INTEN) | SC_INTEN_TBEIEN, sc[intf].base + REG_SC_INTEN);
+	wait_event_interruptible(sc[intf].wq, sc[intf].state == SC_OP_IDLE);
+	if (sc[intf].err) {
+		return -1;
+	}
+
+
+	// 1. read prologue, get the block length
+	sc[intf].rlen = 3;
+	sc[intf].state = SC_OP_READ;
+	wait_event_interruptible(sc[intf].wq, /*sc[intf].state == SC_OP_IDLE*/(sc[intf].rtail > 3) || (sc[intf].err != 0));
+	if((sc[intf].err != 0) && (sc[intf].err != SC_ERR_PARITY)) {
+		goto out;
+	}
+	// 2. read rest of the block
+	sc[intf].rlen += sc[intf].rbuf[2] + (sc[intf].T1.EDC == SC_CHKSUM_LRC ? 1 : 2);
+	sc[intf].state = SC_OP_READ;
+	wait_event_interruptible(sc[intf].wq, (sc[intf].rtail == sc[intf].rlen) || (sc[intf].err != 0));
+	if(sc[intf].err == SC_ERR_PARITY) {
+		sc[intf].state = SC_OP_READ;
+		sc[intf].err = 0;
+		wait_event_interruptible(sc[intf].wq, (sc[intf].rtail == sc[intf].rlen) || (sc[intf].err != 0));
+		sc[intf].err = SC_ERR_PARITY;  // to see if there's remaining data...
+		__raw_writel(SC_ALTCTL_RXRST, sc[intf].base + REG_SC_ALTCTL);
+	}
+
+out:
+	__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+	sc[intf].state = SC_OP_IDLE;
+
+	if(!sc[intf].err) {
+#if 0
+		printk("RX:\n");
+		{
+			int i;
+			for(i = 0; i < sc[intf].rlen; i++)
+				printk("%02x ", sc[intf].rbuf[i]);
+			printk("\n");
+		}
+#endif
+		memcpy(block, sc[intf].rbuf, sc[intf].rlen);
+		return sc[intf].rlen;
+	} else if(sc[intf].err == SC_ERR_PARITY) {
+		//printk("parity err\n");
+		return -2;
+	} else {
+		//printk("other err\n");
+		return -1;
+	}
+}
+
+int t1_negotiate_ifsd(unsigned int intf, unsigned int dad, int ifsd)
+{
+	ct_buf_t sbuf;
+	unsigned char sdata[T1_BUFFER_SIZE];
+	unsigned int slen;
+	unsigned int retries;
+	size_t snd_len;
+	int n;
+	unsigned char snd_buf[1];
+	t1_state_t * t1 = &t1_state[intf];
+
+	retries = t1->retries;
+
+	if(sc[intf].T1.EDC == SC_CHKSUM_LRC)
+		t1_set_param(t1, IFD_PROTOCOL_T1_CHECKSUM_LRC, 0);
+	else
+		t1_set_param(t1, IFD_PROTOCOL_T1_CHECKSUM_CRC, 0);
+
+	t1_set_param(t1, IFD_PROTOCOL_T1_IFSC, sc[intf].T1.IFSC);
+	/* S-block IFSD request */
+	snd_buf[0] = ifsd;
+	snd_len = 1;
+
+	/* Initialize send/recv buffer */
+	ct_buf_set(&sbuf, (void *)snd_buf, snd_len);
+
+	while (1)
+	{
+		/* Build the block */
+		slen = t1_build(intf, sdata, 0, T1_S_BLOCK | T1_S_IFS, &sbuf, NULL);
+
+		/* Send the block */
+		n = t1_xcv(intf, sdata, slen, sizeof(sdata));
+
+		retries--;
+		/* ISO 7816-3 Rule 7.4.2 */
+		if (retries <= 0)
+			goto error;
+
+		if (-1 == n)
+		{
+			//printk("fatal: transmit/receive failed\n");
+			if(sc[intf].err == SC_ERR_TIME0OUT) {
+				sc[intf].err = 0;
+				continue;
+			}
+			goto error;
+		}
+
+		if ((-2 == n)								/* Parity error */
+			|| (sdata[DATA] != ifsd)				/* Wrong ifsd received */
+			|| (sdata[NAD] != swap_nibbles(dad))	/* wrong NAD */
+			|| (!t1_verify_checksum(t1, sdata, n))	/* checksum failed */
+			|| (n != 4 + (int)t1->rc_bytes)				/* wrong frame length */
+			|| (sdata[LEN] != 1)					/* wrong data length */
+			|| (sdata[PCB] != (T1_S_BLOCK | T1_S_RESPONSE | T1_S_IFS))) {/* wrong PCB */
+			sc[intf].err = 0;
+			continue;
+		}
+		/* no more error */
+		goto done;
+	}
+
+done:
+	return n;
+
+error:
+	t1->state = DEAD;
+	return -1;
+}
+
+
+int CmdXfrT1(unsigned int intf,
+	unsigned int tx_length, unsigned char tx_buffer[], unsigned char rx_buffer[])
+{
+	int return_value = 0;
+	int ret;
+
+	memcpy(&gTx[intf][0], tx_buffer, tx_length);
+	ret = t1_transceive(intf, 0,
+		&gTx[intf][0], tx_length, &gRx[intf][0]);
+
+	printk("out %d\n", ret);
+	if (ret < 0)
+		return_value = SC_ERR_T1;
+
+	//copy data from temp buffer to rbuf
+	sc[intf].rhead = 0;
+	sc[intf].rtail = ret;
+	memcpy(rx_buffer, &gRx[intf][0], ret);
+
+	return return_value;
+} /* CmdXfrT1 */
diff -uprN linux-4.4.194/drivers/misc/sc-util.c NUC980-linux-4.4.194/drivers/misc/sc-util.c
--- linux-4.4.194/drivers/misc/sc-util.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/misc/sc-util.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,648 @@
+/* linux/driver/misc/sc-util.c
+ *
+ * Copyright (c) 2015 Nuvoton technology corporation
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+// This file is based on atr.c and pps.c from a project start by Towitoko
+/*
+    atr.c
+    ISO 7816 ICC's answer to reset abstract data type implementation
+
+    This file is part of the Unix driver for Towitoko smartcard readers
+    Copyright (C) 2000 Carlos Prados <cprados@yahoo.com>
+
+    This library is free software; you can redistribute it and/or
+    modify it under the terms of the GNU Lesser General Public
+    License as published by the Free Software Foundation; either
+    version 2 of the License, or (at your option) any later version.
+
+    This library is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+    Lesser General Public License for more details.
+
+	You should have received a copy of the GNU Lesser General Public License
+	along with this library; if not, write to the Free Software Foundation,
+	Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+*/
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/slab.h>
+#include <linux/miscdevice.h>
+#include <linux/device.h>
+#include <linux/spinlock.h>
+#include <linux/wait.h>
+#include <linux/poll.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/wait.h>
+#include <linux/clk.h>
+#include <linux/platform_device.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-sc.h>
+#include <mach/nuc980-sc.h>
+
+extern struct nuc980_sc sc[SC_INTF];
+
+/*
+ * Not exported variables definition
+ */
+
+static unsigned int atr_num_ib_table[16] = {0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4};
+
+/*
+ * Exported variables definition
+ */
+
+static unsigned int atr_f_table[16] = {
+	372, 372, 558, 744, 1116, 1488, 1860, 0, 0, 512, 768, 1024, 1536, 2048, 0, 0
+};
+
+static unsigned int atr_d_table[16] = {0, 1, 2, 4, 8, 16, 32, 64, 12, 20, 0, 0, 0, 0, 0, 0};
+
+//static unsigned int atr_i_table[4] = {25, 50, 100, 0};
+
+/*
+ * Exported functions definition
+ */
+
+int ATR_InitFromArray (ATR_t * atr, const char atr_buffer[ATR_MAX_SIZE], unsigned int length)
+{
+	char TDi, tck = 0;
+	unsigned int pointer = 0, pn = 0;
+
+
+	/* Check size of buffer */
+	if (length < 2)
+		return (SC_ERR_ATR);
+
+	/* Store T0 and TS */
+	atr->TS = atr_buffer[0];
+
+	atr->T0 = TDi = atr_buffer[1];
+	pointer = 1;
+
+	/* Store number of historical bytes */
+	atr->hbn = TDi & 0x0F;
+
+	/* TCK is not present by default */
+	(atr->TCK).present = 0;
+
+	/* Extract interface bytes */
+	while (pointer < length) {
+		/* Check buffer is long enought */
+		if (pointer + atr_num_ib_table[(0xF0 & TDi) >> 4] >= length) {
+			return (SC_ERR_ATR);
+		}
+		/* Check TAi is present */
+		if ((TDi | 0xEF) == 0xFF) {
+			pointer++;
+			atr->ib[pn][ATR_INTERFACE_BYTE_TA].value = atr_buffer[pointer];
+			atr->ib[pn][ATR_INTERFACE_BYTE_TA].present = 1;
+		} else
+			atr->ib[pn][ATR_INTERFACE_BYTE_TA].present = 0;
+		/* Check TBi is present */
+		if ((TDi | 0xDF) == 0xFF) {
+			pointer++;
+			atr->ib[pn][ATR_INTERFACE_BYTE_TB].value = atr_buffer[pointer];
+			atr->ib[pn][ATR_INTERFACE_BYTE_TB].present = 1;
+		} else
+			atr->ib[pn][ATR_INTERFACE_BYTE_TB].present = 0;
+
+		/* Check TCi is present */
+		if ((TDi | 0xBF) == 0xFF) {
+			pointer++;
+			atr->ib[pn][ATR_INTERFACE_BYTE_TC].value = atr_buffer[pointer];
+			atr->ib[pn][ATR_INTERFACE_BYTE_TC].present = 1;
+		} else
+			atr->ib[pn][ATR_INTERFACE_BYTE_TC].present = 0;
+
+		/* Read TDi if present */
+		if ((TDi | 0x7F) == 0xFF) {
+			pointer++;
+			TDi = atr->ib[pn][ATR_INTERFACE_BYTE_TD].value = atr_buffer[pointer];
+			atr->ib[pn][ATR_INTERFACE_BYTE_TD].present = 1;
+			(atr->TCK).present = ((TDi & 0x0F) != ATR_PROTOCOL_TYPE_T0);
+			pn++;
+			if (pn >= ATR_MAX_PROTOCOLS)
+				return (SC_ERR_ATR);
+		} else {
+			atr->ib[pn][ATR_INTERFACE_BYTE_TD].present = 0;
+			break;
+		}
+	}
+
+	/* Store number of protocols */
+	atr->pn = pn + 1;
+
+	/* Store historical bytes */
+	if (pointer + atr->hbn >= length)
+		return (SC_ERR_ATR);
+
+	memcpy (atr->hb, atr_buffer + pointer + 1, atr->hbn);
+	pointer += (atr->hbn);
+
+	/* Store TCK  */
+	if ((atr->TCK).present) {
+		int i;
+		for(i = 1; i < length; i++)
+			tck ^= atr_buffer[i];
+
+		if (pointer + 1 >= length)
+			return (SC_ERR_ATR);
+		if(tck != 0)
+			return (SC_ERR_ATR);
+
+		pointer++;
+
+		(atr->TCK).value = atr_buffer[pointer];
+
+	}
+
+	atr->length = pointer + 1;
+	return (0);
+}
+
+int ATR_GetIntegerValue (ATR_t * atr, int name, char * value)
+{
+	int ret;
+
+	if (name == ATR_INTEGER_VALUE_FI) {
+		if (atr->ib[0][ATR_INTERFACE_BYTE_TA].present) {
+			(*value) = (atr->ib[0][ATR_INTERFACE_BYTE_TA].value & 0xF0) >> 4;
+			ret = 0;
+		} else
+			ret = ATR_NOT_FOUND;
+	}
+
+	else if (name == ATR_INTEGER_VALUE_DI) {
+		if (atr->ib[0][ATR_INTERFACE_BYTE_TA].present) {
+			(*value) = (atr->ib[0][ATR_INTERFACE_BYTE_TA].value & 0x0F);
+			ret = 0;
+		} else
+			ret = ATR_NOT_FOUND;
+	}
+
+	else if (name == ATR_INTEGER_VALUE_II) {
+		if (atr->ib[0][ATR_INTERFACE_BYTE_TB].present) {
+			(*value) = (atr->ib[0][ATR_INTERFACE_BYTE_TB].value & 0x60) >> 5;
+			ret = 0;
+		} else
+			ret = ATR_NOT_FOUND;
+	}
+
+	else if (name == ATR_INTEGER_VALUE_PI1) {
+		if (atr->ib[0][ATR_INTERFACE_BYTE_TB].present) {
+			(*value) = (atr->ib[0][ATR_INTERFACE_BYTE_TB].value & 0x1F);
+			ret = 0;
+		} else
+			ret = ATR_NOT_FOUND;
+	}
+
+	else if (name == ATR_INTEGER_VALUE_PI2) {
+		if (atr->ib[1][ATR_INTERFACE_BYTE_TB].present) {
+			(*value) = atr->ib[1][ATR_INTERFACE_BYTE_TB].value;
+			ret = 0;
+		} else
+			ret = ATR_NOT_FOUND;
+	}
+
+	else if (name == ATR_INTEGER_VALUE_N) {
+		if (atr->ib[0][ATR_INTERFACE_BYTE_TC].present) {
+			(*value) = atr->ib[0][ATR_INTERFACE_BYTE_TC].value;
+			ret = 0;
+		} else
+			ret = ATR_NOT_FOUND;
+	} else
+		ret = ATR_NOT_FOUND;
+
+	return ret;
+}
+
+int ATR_GetParameter (ATR_t * atr, int name, int *parameter)
+{
+	unsigned char FI, DI, /*II, PI1, PI2,*/ N;
+
+	if (name == ATR_PARAMETER_F) {
+		if (ATR_GetIntegerValue (atr, ATR_INTEGER_VALUE_FI, &FI) == 0)
+			*parameter = (int)atr_f_table[FI];
+		else
+			(*parameter) = ATR_DEFAULT_F;
+		return (0);
+	}
+
+	else if (name == ATR_PARAMETER_D) {
+		if (ATR_GetIntegerValue (atr, ATR_INTEGER_VALUE_DI, &DI) == 0)
+			*parameter = (int)atr_d_table[DI];
+		else
+			(*parameter) = ATR_DEFAULT_D;
+		return (0);
+	}
+	else if (name == ATR_PARAMETER_N) {
+		if (ATR_GetIntegerValue (atr, ATR_INTEGER_VALUE_N, &N) == 0)
+			(*parameter) = N;
+		else
+			(*parameter) = ATR_DEFAULT_N;
+		return (0);
+	}
+
+	return (ATR_NOT_FOUND);
+}
+
+/*
+ * This function was greatly inspired by ATRDecodeAtr() and
+ * PHGetDefaultProtocol() from pcsc-lite
+ *
+ * It was rewritten by Ludovic Rousseau, 2004
+ */
+#define PROTOCOL_UNSET -1
+int ATR_GetDefaultProtocol(ATR_t * atr, int *protocol, int *availableProtocols)
+{
+	int i;
+
+	/* default value */
+	*protocol = PROTOCOL_UNSET;
+	if (availableProtocols)
+		*availableProtocols = 0;
+
+	for (i=0; i<ATR_MAX_PROTOCOLS; i++)
+		if (atr->ib[i][ATR_INTERFACE_BYTE_TD].present) {
+			int T = atr->ib[i][ATR_INTERFACE_BYTE_TD].value & 0x0F;
+
+			//printk("T=%d Protocol Found\n", T);
+			if (availableProtocols)
+				*availableProtocols |= 1 << T;
+
+			if (PROTOCOL_UNSET == *protocol) {
+				/* set to the first protocol byte found */
+				*protocol = T;
+				//printk("default protocol: T=%d\n", *protocol);
+			}
+		}
+
+	/* specific mode if TA2 present */
+	if (atr->ib[1][ATR_INTERFACE_BYTE_TA].present) {
+		*protocol = atr->ib[1][ATR_INTERFACE_BYTE_TA].value & 0x0F;
+		if (availableProtocols)
+			*availableProtocols = 1 << *protocol;
+		//printk("specific mode found: T=%d\n", *protocol);
+	}
+
+	if (PROTOCOL_UNSET == *protocol) {
+		//printk("no default protocol found in ATR. Using T=0\n");
+		*protocol = ATR_PROTOCOL_TYPE_T0;
+		if (availableProtocols)
+			*availableProtocols = 1 << *protocol;
+	}
+
+	return 0;
+}
+
+#ifdef CONFIG_EMV_CHECK
+// For EMV
+int ATR_CheckIntegrity(ATR_t * atr, int type)
+{
+	int i, j, proto, availableproto;
+
+        if(atr->ib[0][ATR_INTERFACE_BYTE_TA].present == 1) {
+            if(atr->ib[0][ATR_INTERFACE_BYTE_TA].value < 0x11 || atr->ib[0][ATR_INTERFACE_BYTE_TA].value > 0x13)
+                return SC_ERR_PARAM;
+        }
+
+        /* In response to the cold-reset, TB1 only could be 0x00 */
+        if(type == 0) { // cold reset
+            if(atr->ib[0][ATR_INTERFACE_BYTE_TB].present == 1)
+                if(atr->ib[0][ATR_INTERFACE_BYTE_TB].value != 0x00)
+                    return SC_ERR_PARAM;
+            if(atr->ib[0][ATR_INTERFACE_BYTE_TB].present == 0)
+                return SC_ERR_PARAM;
+        }
+
+        /* Reject ATR containing TB2 */
+        if(atr->ib[1][ATR_INTERFACE_BYTE_TB].present == 1)
+            return SC_ERR_PARAM;
+
+        /* Bit [5] of TA2 must be equal to 0x0 */
+        if(atr->ib[1][ATR_INTERFACE_BYTE_TA].present == 1) {
+            if((atr->ib[1][ATR_INTERFACE_BYTE_TA].value & 0x10) == 0x10)
+                return SC_ERR_PARAM;
+        }
+
+        /* Reject an ATR that TC2 is equal to 0x00 */
+        if(atr->ib[1][ATR_INTERFACE_BYTE_TC].present == 1 && atr->ib[1][ATR_INTERFACE_BYTE_TC].value == 0x00)
+            return SC_ERR_PARAM;
+
+        /* TD1's l.s. nibble must be 0x0 or 0x1 */
+        if(atr->ib[0][ATR_INTERFACE_BYTE_TD].present == 1) {
+            if((atr->ib[0][ATR_INTERFACE_BYTE_TD].value & 0xF) > 0x1) {
+                return SC_ERR_PARAM;
+            }
+        }
+
+        /* TD2's l.s. nibble must be 0x1 or 0xE if TD1's l.s. nibble is 0x0 */
+        if(atr->ib[1][ATR_INTERFACE_BYTE_TD].present == 1) {
+            if((atr->ib[1][ATR_INTERFACE_BYTE_TD].value & 0xF)!=0x1 && (atr->ib[1][ATR_INTERFACE_BYTE_TD].value & 0xF) != 0xE)
+                return SC_ERR_PARAM;
+
+            if((atr->ib[1][ATR_INTERFACE_BYTE_TD].value & 0xF) == 0xE) {
+                if((atr->ib[0][ATR_INTERFACE_BYTE_TD].value & 0xF) != 0x0)
+                    return SC_ERR_PARAM;
+            }
+        }
+
+        /* Reject TA3 having a value in the range 0x0~0xF or 0xFF */
+        if(atr->ib[2][ATR_INTERFACE_BYTE_TA].present == 1) {
+            if(atr->ib[2][ATR_INTERFACE_BYTE_TA].value < 0x10 || atr->ib[2][ATR_INTERFACE_BYTE_TA].value == 0xFF) {
+                return SC_ERR_PARAM;
+            }
+
+        }
+
+	// Get default protocol first...
+	ATR_GetDefaultProtocol(atr, &proto, &availableproto);
+
+        /* Reject ATR not containing TB3 or BWI greater than 4 or CWI greater than 5 */
+        /* And reject ATR if fitting the formula : 2 to the power of CWI is equal or less than (N+1) */
+        if(proto == 1) {
+            if(atr->ib[2][ATR_INTERFACE_BYTE_TB].present == 1) {
+                if(((atr->ib[2][ATR_INTERFACE_BYTE_TB].value & 0xF0) >> 4) > 0x4)
+                    return SC_ERR_PARAM;
+
+                if((atr->ib[2][ATR_INTERFACE_BYTE_TB].value & 0xF) > 0x5)
+                    return SC_ERR_PARAM;
+
+                i = 1;
+                j = (atr->ib[2][ATR_INTERFACE_BYTE_TB].value & 0xF);
+                while(j--)
+                    i *= 2;
+                /* if TC1 is equal to 0xFF, N as -1 that is always valid */
+                if(atr->ib[0][ATR_INTERFACE_BYTE_TC].value != 0xFF)
+                    if( i <= (atr->ib[0][ATR_INTERFACE_BYTE_TC].value + 1))
+                        return SC_ERR_PARAM;
+
+            } else
+                return SC_ERR_PARAM;
+
+		/* ATR must contain TB3 in T=1 */
+		if(atr->ib[2][ATR_INTERFACE_BYTE_TB].present == 0)
+			return SC_ERR_PARAM;
+
+        }
+
+        /* Reject ATR if TC3 is not equal to 0x00 */
+        if(atr->ib[2][ATR_INTERFACE_BYTE_TC].present == 1) {
+            if(atr->ib[2][ATR_INTERFACE_BYTE_TC].value != 0x00) {
+                return SC_ERR_PARAM;
+            }
+        }
+
+        return 0;
+}
+#endif//ifdef CONFIG_EMV_CHECK
+
+// including PPS exchange
+int ATR_Parse(int intf)
+{
+	char pps[5] = {0x00, 0x00, 0x00, 0x00, 0x00};
+	ATR_t atr = sc[intf].atr;
+	char PCK;
+	int protocol, availableproto;
+
+
+	/* Set to zero buffer */
+	memset(pps, 0, sizeof(pps));
+
+	// Get default protocol first...
+	ATR_GetDefaultProtocol(&atr, &protocol, &availableproto);
+
+
+	if (0 == protocol)
+		pps[1] |= ATR_PROTOCOL_TYPE_T0;
+	else
+		if (1 == protocol)
+			pps[1] |= ATR_PROTOCOL_TYPE_T1;
+		else
+			return SC_ERR_ATR;
+
+	/* TA1 present */
+	if (atr.ib[0][ATR_INTERFACE_BYTE_TA].present)
+	{
+		unsigned int card_baudrate;
+		unsigned int default_baudrate;
+
+
+		(void)ATR_GetParameter(&atr, ATR_PARAMETER_D, &sc[intf].D);
+		(void)ATR_GetParameter(&atr, ATR_PARAMETER_F, &sc[intf].F);
+
+		/* may happen with non ISO cards */
+		if ((0 == sc[intf].F) || (0 == sc[intf].D))
+		{
+			/* values for TA1=11 */
+			sc[intf].F = 372;
+			sc[intf].D = 1;
+		}
+
+		/* Baudrate = f x D/F */
+		card_baudrate = (unsigned int) (4000000
+			* sc[intf].D / sc[intf].F);
+
+		default_baudrate = (unsigned int) (4000000
+			* ATR_DEFAULT_D / ATR_DEFAULT_F);
+
+		/* if the card does not try to lower the default speed */
+		if (card_baudrate > default_baudrate)
+		{
+			pps[1] |= 0x10; /* PTS1 presence */
+			pps[2] = atr.ib[0][ATR_INTERFACE_BYTE_TA].value;
+
+			printk("Set speed to %d bauds\n", card_baudrate);
+		}
+	} else { // assign default value
+		sc[intf].F = 372;
+		sc[intf].D = 1;
+
+	}
+
+#ifndef CONFIG_EMV_CHECK	// PPS not specified in EMV
+	/* Generate PPS */
+	pps[0] = 0xFF;
+	pps[3] = pps[0] ^ pps[1] ^ pps[2];
+
+	/* TA2 absent: negociable mode */
+	if ( ! atr.ib[1][ATR_INTERFACE_BYTE_TA].present)
+	{
+		int default_protocol;
+		//printk("prepare for pps\n");
+
+		ATR_GetDefaultProtocol(&atr, &default_protocol, NULL);
+
+		/* if the requested protocol is not the default one
+		 * or a TA1/PPS1 is present */
+		if (((pps[1] & 0x0F) != default_protocol) || (pps[2] != 0x00))
+		{
+			sc[intf].tbuf[0] = pps[0];
+			sc[intf].tbuf[1] = pps[1];
+			sc[intf].tbuf[2] = pps[2];
+			sc[intf].tbuf[3] = pps[3];
+			sc[intf].toffset = 0;
+			sc[intf].tcnt = 4;
+			sc[intf].state = SC_OP_WRITE;
+			sc[intf].rlen = 4;
+			sc[intf].rhead = sc[intf].rtail = 0;
+
+			__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) & ~(SC_ALTCTL_CNTEN2 | SC_ALTCTL_CNTEN0 | SC_ALTCTL_CNTEN0),
+						sc[intf].base + REG_SC_ALTCTL);
+			// Waiting time check, the waiting time of PPS is fixed at 9600 ETUs
+			__raw_writel((9600 - 1) | SC_TMR_MODE_7, sc[intf].base + REG_SC_TMRCTL0);
+			__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) | SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+
+			__raw_writel(__raw_readl(sc[intf].base + REG_SC_INTEN) | SC_INTEN_TBEIEN, sc[intf].base + REG_SC_INTEN);
+			wait_event_interruptible(sc[intf].wq, (sc[intf].state == SC_OP_IDLE) || (sc[intf].err != 0));
+			if(sc[intf].err != 0)
+				return SC_ERR_PPS;
+
+			sc[intf].state = SC_OP_READ;
+			wait_event_interruptible(sc[intf].wq, ((sc[intf].rtail == 4) || (sc[intf].err != 0)));
+			__raw_writel(__raw_readl(sc[intf].base + REG_SC_ALTCTL) & ~SC_ALTCTL_CNTEN0, sc[intf].base + REG_SC_ALTCTL);
+			if(sc[intf].err != 0)
+				return SC_ERR_PPS;
+
+			if(sc[intf].rbuf[0] != sc[intf].tbuf[0])   /* PPSS */
+				return SC_ERR_PPS;
+
+			PCK = sc[intf].rbuf[0];
+			if((sc[intf].rbuf[1]&0x0f) == (sc[intf].tbuf[1] &0x0f) &&
+				((sc[intf].rbuf[1] & 0xf0) == 0x10 ||(sc[intf].rbuf[1] & 0xf0) == 0x00)) {
+				PCK ^= sc[intf].rbuf[1];
+
+			} else
+				return SC_ERR_PPS;
+
+			if (sc[intf].rbuf[2] == sc[intf].tbuf[2])
+				PCK ^= sc[intf].rbuf[2];
+			else
+				return SC_ERR_PPS;
+
+			if (sc[intf].rbuf[3] != PCK)  /* PCK */
+				return SC_ERR_PPS;
+
+		}
+	}
+#else
+
+	if ( ! atr.ib[1][ATR_INTERFACE_BYTE_TA].present) {  // TA2 absent
+
+		if(atr.ib[0][ATR_INTERFACE_BYTE_TA].present) {	// TA1 present
+			sc[intf].F = 372;
+			sc[intf].D = 1;
+		}
+	}
+
+#endif
+	__raw_writel((sc[intf].F / sc[intf].D) - 1, sc[intf].base + REG_SC_ETUCTL);
+	printk("set etu to %d\n", (sc[intf].F / sc[intf].D));
+
+
+	/* TCi (i>2) indicates CRC instead of LRC */
+	if (SC_PROTOCOL_T1 == protocol)
+	{
+		//t1_state_t *t1 = &(reader -> t1);
+		int i;
+
+		/* TCi (i>2) present? */
+		for (i=2; i<ATR_MAX_PROTOCOLS; i++)
+			if (atr.ib[i][ATR_INTERFACE_BYTE_TC].present)
+			{
+				if (0 == atr.ib[i][ATR_INTERFACE_BYTE_TC].value)
+				{
+					//printk("Use LRC\n");
+					sc[intf].T1.EDC = SC_CHKSUM_LRC;
+				} else if (1 == atr.ib[i][ATR_INTERFACE_BYTE_TC].value) {
+					//printk("Use CRC\n");
+					sc[intf].T1.EDC = SC_CHKSUM_CRC;
+				}
+				/* only the first TCi (i>2) must be used */
+				break;
+			} else
+				sc[intf].T1.EDC = SC_CHKSUM_LRC;
+
+		for (i=2; i<ATR_MAX_PROTOCOLS; i++)
+			if (atr.ib[i][ATR_INTERFACE_BYTE_TB].present)
+			{
+				int j, k = 1;
+				sc[intf].T1.CWI = atr.ib[i][ATR_INTERFACE_BYTE_TB].value & 0xF;
+				for(j = 0; j < sc[intf].T1.CWI; j++)
+					k *= 2;
+				sc[intf].T1.CWT = k + 11;  // CWT = (11 + 2^CWI)
+				sc[intf].T1.BWI = atr.ib[i][ATR_INTERFACE_BYTE_TB].value >> 4;
+				k = 1;
+				for(j = 0; j < sc[intf].T1.BWI; j++)
+					k *= 2;
+				// ISO 7816-3 11.4.3
+				sc[intf].T1.BWT = 11 + (k * 960 * 372) / (__raw_readl(sc[intf].base + REG_SC_ETUCTL) + 1);
+				break;
+			}
+		if(i == ATR_MAX_PROTOCOLS) {  // set default
+			int i, j = 1;
+			sc[intf].T1.CWI = 13;
+			for(i = 0; i < 13; i++)
+				j *= 2;
+			sc[intf].T1.CWT = j + 11;
+			sc[intf].T1.BWI = 4;
+			j = 1;
+			for(i = 0; i < sc[intf].T1.BWI; i++)
+				j *= 2;
+			// ISO 7816-3 11.4.3
+			sc[intf].T1.BWT = 11 + (j * 960 * 372) / (__raw_readl(sc[intf].base + REG_SC_ETUCTL) + 1);
+		}
+
+		//printk("Set BWT to %d, CWT to %d\n", sc[intf].T1.BWT, sc[intf].T1.CWT);
+
+		for (i=2; i<ATR_MAX_PROTOCOLS; i++)
+			if (atr.ib[i][ATR_INTERFACE_BYTE_TA].present)
+			{
+				sc[intf].T1.IFSC = atr.ib[i][ATR_INTERFACE_BYTE_TA].value;
+				//printk("set IFSC to %d\n", sc[intf].T1.IFSC);
+				break;
+			}
+		if(i == ATR_MAX_PROTOCOLS) {
+			sc[intf].T1.IFSC = 32; // use default value
+		}
+	}
+
+
+
+#if 0
+	/* specific mode and implicit parameters? (b5 of TA2) */
+	if (atr.ib[1][ATR_INTERFACE_BYTE_TA].present
+		&& (atr.ib[1][ATR_INTERFACE_BYTE_TA].value & 0x10))
+		return SC_ERR_ATR;
+#endif
+
+	sc[intf].protocol = protocol;
+	(void)ATR_GetParameter(&atr, ATR_PARAMETER_N, &sc[intf].N);
+
+	if(atr.ib[1][ATR_INTERFACE_BYTE_TC].present == 1 ) { // TC2 present
+		//if(atr.ib[0][ATR_INTERFACE_BYTE_TD].value == 0)
+			sc[intf].T0.WI = atr.ib[1][ATR_INTERFACE_BYTE_TC].value;
+	} else {
+		sc[intf].T0.WI = 10;  // set default
+	}
+	sc[intf].T0.WT = (sc[intf].T0.WI * 960 * sc[intf].F) / (__raw_readl(sc[intf].base + REG_SC_ETUCTL) + 1) + 500 * sc[intf].D; // +500 for INQ
+
+	//printk("WT = %d\n", sc[intf].T0.WT);
+
+	return 0;
+}
diff -uprN linux-4.4.194/drivers/mmc/host/Kconfig NUC980-linux-4.4.194/drivers/mmc/host/Kconfig
--- linux-4.4.194/drivers/mmc/host/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/mmc/host/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -212,6 +212,10 @@ config MMC_SDHCI_TEGRA
 
 	  If unsure, say N.
 
+config MMC_NUC980_FMI
+	tristate "Nuvoton NUC980 FMI-SD support"
+	depends on MACH_NUC980 && NUC980_FMI_SD0
+
 config MMC_SDHCI_S3C
 	tristate "SDHCI support on Samsung S3C SoC"
 	depends on MMC_SDHCI && PLAT_SAMSUNG
@@ -494,6 +498,14 @@ config MMC_SPI
 
 	  If unsure, or if your system has no SPI master driver, say N.
 
+config MMC_NUC980_SD
+        tristate "Nuvoton NUC980 SD Card support"
+        depends on ARCH_NUC980
+
+config MMC_NUC980_FMI
+	tristate "Nuvoton NUC980 FMI-SD support"
+	depends on MACH_NUC980 && NUC980_FMI_SD0
+
 config MMC_S3C
 	tristate "Samsung S3C SD/MMC Card Interface support"
 	depends on ARCH_S3C24XX
diff -uprN linux-4.4.194/drivers/mmc/host/Makefile NUC980-linux-4.4.194/drivers/mmc/host/Makefile
--- linux-4.4.194/drivers/mmc/host/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/mmc/host/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -23,6 +23,8 @@ obj-$(CONFIG_MMC_AU1X)		+= au1xmmc.o
 obj-$(CONFIG_MMC_MTK)		+= mtk-sd.o
 obj-$(CONFIG_MMC_OMAP)		+= omap.o
 obj-$(CONFIG_MMC_OMAP_HS)	+= omap_hsmmc.o
+obj-$(CONFIG_MMC_NUC980_SD)	+= nuc980_sd.o
+obj-$(CONFIG_MMC_NUC980_FMI)	+= nuc980_fmi.o
 obj-$(CONFIG_MMC_ATMELMCI)	+= atmel-mci.o
 obj-$(CONFIG_MMC_TIFM_SD)	+= tifm_sd.o
 obj-$(CONFIG_MMC_MVSDIO)	+= mvsdio.o
diff -uprN linux-4.4.194/drivers/mmc/host/nuc980_fmi.c NUC980-linux-4.4.194/drivers/mmc/host/nuc980_fmi.c
--- linux-4.4.194/drivers/mmc/host/nuc980_fmi.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/mmc/host/nuc980_fmi.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1023 @@
+/*
+*  linux/drivers/mmc/host/nuc980_fmi.c - Nuvoton NUC980 FMI-SD Driver
+*
+* Copyright (c) 2018 Nuvoton Technology Corp.
+*
+* This program is free software; you can redistribute it and/or modify
+* it under the terms of the GNU General Public License as published by
+* the Free Software Foundation;version 2 of the License.
+*/
+
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/mutex.h>
+#include <linux/ioport.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/blkdev.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/dma-mapping.h>
+#include <linux/clk.h>
+#include <linux/atmel_pdc.h>
+#include <linux/gfp.h>
+#include <linux/freezer.h>
+#include <linux/of.h>
+
+#include <linux/mmc/host.h>
+
+#include <asm/io.h>
+#include <asm/irq.h>
+
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-fmi.h>
+
+#if 0
+#define ENTRY()                                 printk("[%-20s] : Enter...\n", __FUNCTION__)
+#define LEAVE()                                 printk("[%-20s] : Leave...\n", __FUNCTION__)
+#else
+#define ENTRY()
+#define LEAVE()
+#endif
+
+//#define nuc980_fmi_debug       printk
+#define nuc980_fmi_debug(...)
+
+#define DRIVER_NAME    "nuc980-fmi"
+
+#define FL_SENT_COMMAND (1 << 0)
+#define FL_SENT_STOP    (1 << 1)
+
+#define nuc980_fmi_read(reg)          __raw_readl(reg)
+#define nuc980_fmi_write(reg, val)    __raw_writel((val), (reg))
+
+#define MCI_BLKSIZE         512
+#define MCI_MAXBLKSIZE      4095
+#define MCI_BLKATONCE       255
+#define MCI_BUFSIZE         (MCI_BLKSIZE * MCI_BLKATONCE)
+
+/* Driver thread command */
+#define FMI_EVENT_NONE       0x00000000
+#define FMI_EVENT_CMD_OUT    0x00000001
+#define FMI_EVENT_RSP_IN     0x00000010
+#define FMI_EVENT_RSP2_IN    0x00000100
+#define FMI_EVENT_CLK_KEEP0  0x00001000
+#define FMI_EVENT_CLK_KEEP1  0x00010000
+
+/*
+ * Low level type for this driver
+ */
+struct nuc980_fmi_host {
+	struct mmc_host *mmc;
+	struct mmc_command *cmd;
+	struct mmc_request *request;
+
+//    void __iomem *sd_base;
+	int irq;
+
+	int present;
+	struct clk *fmi_clk, *upll_clk;
+	/*
+	 * Flag indicating when the command has been sent. This is used to
+	 * work out whether or not to send the stop
+	 */
+	unsigned int flags;
+	/* flag for current port */
+	u32 bus_mode;
+
+	/* DMA buffer used for transmitting */
+	unsigned int* buffer;
+	dma_addr_t physical_address;
+	unsigned int total_length;
+
+	/* Latest in the scatterlist that has been enabled for transfer, but not freed */
+	int in_use_index;
+
+	/* Latest in the scatterlist that has been enabled for transfer */
+	int transfer_index;
+
+	/* Timer for timeouts */
+	struct timer_list timer;
+};
+
+static volatile int fmi_event=0, fmi_state_xfer=0, fmi_ri_timeout=0;
+static DECLARE_WAIT_QUEUE_HEAD(fmi_wq_xfer);
+static int nuc980_fmi_event_thread(struct nuc980_fmi_host *fmi_host);
+
+/*
+ * Reset the controller and restore most of the state
+ */
+static void nuc980_fmi_reset_host(struct nuc980_fmi_host *host)
+{
+	unsigned long flags;
+	ENTRY();
+	local_irq_save(flags);
+
+	nuc980_fmi_write(REG_NAND_DMACCSR, DMACCSR_DMAC_EN | DMACCSR_SWRST); //enable DMAC for FMI
+	nuc980_fmi_write(REG_NAND_FMICSR, FMICSR_SWRST); /* Enable SD functionality of FMI */
+	nuc980_fmi_write(REG_NAND_FMICSR, FMICSR_EMMCEN);
+	local_irq_restore(flags);
+	LEAVE();
+}
+
+static void nuc980_fmi_timeout_timer(unsigned long data)
+{
+	struct nuc980_fmi_host *host;
+
+	host = (struct nuc980_fmi_host *)data;
+	ENTRY();
+	if (host->request) {
+		dev_err(host->mmc->parent, "Timeout waiting end of packet\n");
+
+		if (host->cmd && host->cmd->data) {
+			host->cmd->data->error = -ETIMEDOUT;
+		} else {
+			if (host->cmd)
+				host->cmd->error = -ETIMEDOUT;
+			else
+				host->request->cmd->error = -ETIMEDOUT;
+		}
+		nuc980_fmi_reset_host(host);
+		mmc_request_done(host->mmc, host->request);
+	}
+	LEAVE();
+}
+
+/*
+ * Copy from sg to a dma block - used for transfers
+ */
+static inline void nuc980_fmi_sg_to_dma(struct nuc980_fmi_host *host, struct mmc_data *data)
+{
+	unsigned int len, i, size;
+	unsigned *dmabuf = host->buffer;
+	ENTRY();
+	size = data->blksz * data->blocks;
+	len = data->sg_len;
+
+	/*
+	 * Just loop through all entries. Size might not
+	 * be the entire list though so make sure that
+	 * we do not transfer too much.
+	 */
+	for (i = 0; i < len; i++) {
+		struct scatterlist *sg;
+		int amount;
+		unsigned int *sgbuffer;
+
+		sg = &data->sg[i];
+
+		sgbuffer = kmap_atomic(sg_page(sg)) + sg->offset;
+		amount = min(size, sg->length);
+		size -= amount;
+		{
+			char *tmpv = (char *)dmabuf;
+			memcpy(tmpv, sgbuffer, amount);
+			tmpv += amount;
+			dmabuf = (unsigned *)tmpv;
+		}
+
+		kunmap_atomic(sgbuffer);
+		data->bytes_xfered += amount;
+
+		if (size == 0)
+			break;
+	}
+
+	/*
+	 * Check that we didn't get a request to transfer
+	 * more data than can fit into the SG list.
+	 */
+	BUG_ON(size != 0);
+	LEAVE();
+}
+
+/*
+ * Handle after a dma read
+ */
+static void nuc980_fmi_post_dma_read(struct nuc980_fmi_host *host)
+{
+	struct mmc_command *cmd;
+	struct mmc_data *data;
+	unsigned int len, i, size;
+	unsigned *dmabuf = host->buffer;
+	ENTRY();
+	cmd = host->cmd;
+	if (!cmd) {
+		nuc980_fmi_debug("no command\n");
+		return;
+	}
+
+	data = cmd->data;
+	if (!data) {
+		nuc980_fmi_debug("no data\n");
+		return;
+	}
+
+	size = data->blksz * data->blocks;
+	len = data->sg_len;
+
+	for (i = 0; i < len; i++) {
+		struct scatterlist *sg;
+		int amount;
+		unsigned int *sgbuffer;
+
+		sg = &data->sg[i];
+
+		sgbuffer = kmap_atomic(sg_page(sg)) + sg->offset;
+		amount = min(size, sg->length);
+		size -= amount;
+		{
+			char *tmpv = (char *)dmabuf;
+			memcpy(sgbuffer, tmpv, amount);
+			tmpv += amount;
+			dmabuf = (unsigned *)tmpv;
+		}
+		flush_kernel_dcache_page(sg_page(sg));
+		kunmap_atomic(sgbuffer);
+		data->bytes_xfered += amount;
+		if (size == 0)
+			break;
+	}
+	LEAVE();
+}
+
+/*
+ * Handle transmitted data
+ */
+static void nuc980_fmi_handle_transmitted(struct nuc980_fmi_host *host)
+{
+	ENTRY();
+	if (nuc980_fmi_read(REG_EMMCISR) & EMMCISR_CRC_IF)
+		nuc980_fmi_write(REG_EMMCISR, EMMCISR_CRC_IF);
+
+	/* check read/busy */
+	nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) | EMMCCSR_CLK_KEEP0);
+	LEAVE();
+}
+
+
+/*
+ * Update bytes tranfered count during a write operation
+ */
+static void nuc980_fmi_update_bytes_xfered(struct nuc980_fmi_host *host)
+{
+	struct mmc_data *data;
+	ENTRY();
+	/* always deal with the effective request (and not the current cmd) */
+	if (host->request->cmd && host->request->cmd->error != 0)
+		return;
+
+	if (host->request->data) {
+		data = host->request->data;
+		if (data->flags & MMC_DATA_WRITE) {
+			/* card is in IDLE mode now */
+			data->bytes_xfered = data->blksz * data->blocks;
+		}
+	}
+	LEAVE();
+}
+
+/*
+ * Enable the controller
+ */
+static void nuc980_fmi_enable(struct nuc980_fmi_host *host)
+{
+	ENTRY();
+	nuc980_fmi_write(REG_NAND_DMACCSR, DMACCSR_DMAC_EN);   // enable DMAC for FMI
+	nuc980_fmi_write(REG_NAND_FMICSR, FMICSR_EMMCEN);  /* Enable SD functionality of FMI */
+	nuc980_fmi_write(REG_EMMCISR, 0xffffffff);
+
+	nuc980_fmi_write(REG_EMMCIER, nuc980_fmi_read(REG_EMMCIER) | EMMCIER_CD0SRC);   // select GPIO detect
+	nuc980_fmi_write(REG_EMMCCSR, (nuc980_fmi_read(REG_EMMCCSR) & 0x9fffffff));
+	nuc980_fmi_write(REG_EMMCCSR, (nuc980_fmi_read(REG_EMMCCSR) & ~0xfff0000)|0x09010000);
+	LEAVE();
+}
+
+/*
+ * Disable the controller
+ */
+static void nuc980_fmi_disable(struct nuc980_fmi_host *host)
+{
+	ENTRY();
+	nuc980_fmi_write(REG_NAND_DMACCSR, DMACCSR_DMAC_EN | DMACCSR_SWRST); //enable DMAC for FMI
+	nuc980_fmi_write(REG_NAND_FMICSR, FMICSR_SWRST); /* Enable SD functionality of FMI */
+	nuc980_fmi_write(REG_EMMCISR, 0xffffffff);
+	nuc980_fmi_write(REG_NAND_FMICSR, nuc980_fmi_read(REG_NAND_FMICSR) & ~FMICSR_EMMCEN);
+	LEAVE();
+}
+
+/*
+ * Send a command
+ */
+static void nuc980_fmi_send_command(struct nuc980_fmi_host *host, struct mmc_command *cmd)
+{
+	unsigned int volatile csr;
+	unsigned int block_length;
+	struct mmc_data *data = cmd->data;
+	int clock_free_run_status = 0;
+	unsigned int blocks;
+	ENTRY();
+	host->cmd = cmd;
+
+	fmi_state_xfer = 0;
+
+	if (nuc980_fmi_read(REG_NAND_FMICSR) != FMICSR_EMMCEN)
+		nuc980_fmi_write(REG_NAND_FMICSR, FMICSR_EMMCEN);
+
+	csr = (nuc980_fmi_read(REG_EMMCCSR) & 0xff00c080) | 0x09010000; //schung20170811
+
+	clock_free_run_status = csr | 0x80; /* clock keep */
+	csr = csr & ~0x80;
+	csr = csr | (cmd->opcode << 8) | EMMCCSR_CO_EN;   // set command code and enable command out
+	fmi_event |= FMI_EVENT_CMD_OUT;
+
+	if (host->bus_mode == MMC_BUS_WIDTH_4)
+		csr |= EMMCCSR_DBW;
+
+	if (mmc_resp_type(cmd) != MMC_RSP_NONE) {
+		/* if a response is expected then allow maximum response latancy */
+		/* set 136 bit response for R2, 48 bit response otherwise */
+		if (mmc_resp_type(cmd) == MMC_RSP_R2) {
+			csr |= EMMCCSR_R2_EN;
+			fmi_event |= FMI_EVENT_RSP2_IN;
+		} else {
+			csr |= EMMCCSR_RI_EN;
+			fmi_event |= FMI_EVENT_RSP_IN;
+		}
+		nuc980_fmi_write(REG_EMMCISR, EMMCISR_RITO_IF);
+		fmi_ri_timeout = 0;
+		nuc980_fmi_write(REG_EMMCTMOUT, 0xffff);
+	}
+
+	if (data) {
+		nuc980_fmi_write(REG_EMMCIER, nuc980_fmi_read(REG_EMMCIER) | EMMCIER_BLKD_IE);  //Enable SD interrupt & select GPIO detect
+		block_length = data->blksz;
+		blocks = data->blocks;
+		nuc980_fmi_write(REG_EMMCBLEN, block_length-1);
+		if ((block_length > 512) || (blocks >= 256))
+			printk("ERROR: don't support read/write 256 blocks in on CMD\n");
+		else
+			csr = (csr & ~0x00ff0000) | (blocks << 16);
+	} else {
+		nuc980_fmi_write(REG_EMMCIER, nuc980_fmi_read(REG_EMMCIER) & ~EMMCIER_BLKD_IE); //disable SD interrupt & select GPIO detect
+		block_length = 0;
+		blocks = 0;
+	}
+
+	/*
+	 * Set the arguments and send the command
+	 */
+	nuc980_fmi_debug("Sending command %d as 0x%0X, arg = 0x%08X, blocks = %d, length = %d\n",
+	                 cmd->opcode, csr, cmd->arg, blocks, block_length);
+
+	if (data) {
+		data->bytes_xfered = 0;
+		host->transfer_index = 0;
+		host->in_use_index = 0;
+		if (data->flags & MMC_DATA_READ) {
+			/*
+			 * Handle a read
+			 */
+			nuc980_fmi_write(REG_EMMCTMOUT, 0x3fffff);  //schung20170810
+			host->total_length = 0;
+			nuc980_fmi_write(REG_NAND_DMACSAR, host->physical_address);
+			csr = csr | EMMCCSR_DI_EN;
+			nuc980_fmi_debug("FMI - Reading %d bytes [phy_addr = 0x%x]\n", block_length * blocks, host->physical_address);
+		} else if (data->flags & MMC_DATA_WRITE) {
+			host->total_length = block_length * blocks;
+			nuc980_fmi_sg_to_dma(host, data);
+			nuc980_fmi_debug("FMI - Transmitting %d bytes\n", host->total_length);
+			nuc980_fmi_write(REG_NAND_DMACSAR, host->physical_address);
+			csr = csr | EMMCCSR_DO_EN;
+		}
+	}
+	/*
+	 * Send the command and then enable the PDC - not the other way round as
+	 * the data sheet says
+	 */
+	nuc980_fmi_write(REG_EMMCARG, cmd->arg);
+	nuc980_fmi_write(REG_EMMCCSR, csr);
+	nuc980_fmi_event_thread(host);
+
+	if (data) {
+		if (data->flags & MMC_DATA_WRITE) {
+			while (!(nuc980_fmi_read(REG_EMMCISR) & EMMCISR_SDDAT0)) {
+				nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) | 0x40);   /* clk8_oe */
+				while (nuc980_fmi_read(REG_EMMCCSR) & 0x40);
+			}
+			nuc980_fmi_update_bytes_xfered(host);
+		}
+	}
+	if (clock_free_run_status) {
+		nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) | 0x80);   /* clock keep */
+	}
+	mmc_request_done(host->mmc, host->request);
+	LEAVE();
+}
+
+static void nuc980_fmi_send_stop(struct nuc980_fmi_host *host, struct mmc_command *cmd)
+{
+	unsigned int csr;
+	unsigned int block_length;
+	unsigned int blocks;
+	ENTRY();
+	host->cmd = cmd;
+
+	fmi_state_xfer = 0;
+
+	if (nuc980_fmi_read(REG_NAND_FMICSR) != FMICSR_EMMCEN)
+		nuc980_fmi_write(REG_NAND_FMICSR, FMICSR_EMMCEN);
+
+	csr = (nuc980_fmi_read(REG_EMMCCSR) & 0xff00c080) | 0x09010000; //schung20170811
+
+	csr = csr | (cmd->opcode << 8) | EMMCCSR_CO_EN;   // set command code and enable command out
+	fmi_event |= FMI_EVENT_CMD_OUT;
+
+	if (host->bus_mode == MMC_BUS_WIDTH_4)
+		csr |= EMMCCSR_DBW;
+
+	if (mmc_resp_type(cmd) != MMC_RSP_NONE) {
+		/* if a response is expected then allow maximum response latancy */
+
+		/* set 136 bit response for R2, 48 bit response otherwise */
+		if (mmc_resp_type(cmd) == MMC_RSP_R2) {
+			csr |= EMMCCSR_R2_EN;
+			fmi_event |= FMI_EVENT_RSP2_IN;
+		} else {
+			csr |= EMMCCSR_RI_EN;
+			fmi_event |= FMI_EVENT_RSP_IN;
+		}
+		nuc980_fmi_write(REG_EMMCISR, EMMCISR_RITO_IF);
+		fmi_ri_timeout = 0;
+		nuc980_fmi_write(REG_EMMCTMOUT, 0xffff);
+	}
+
+	nuc980_fmi_write(REG_EMMCIER, nuc980_fmi_read(REG_EMMCIER) & ~EMMCIER_BLKD_IE); //disable SD interrupt & select GPIO detect
+	block_length = 0;
+	blocks = 0;
+
+	nuc980_fmi_write(REG_EMMCARG, cmd->arg);
+	nuc980_fmi_write(REG_EMMCCSR, csr);
+	nuc980_fmi_event_thread(host);
+	mmc_request_done(host->mmc, host->request);
+	LEAVE();
+}
+
+
+/*
+ * Process the request
+ */
+static void nuc980_fmi_send_request(struct nuc980_fmi_host *host)
+{
+
+	ENTRY();
+
+	if (!(host->flags & FL_SENT_COMMAND)) {
+		host->flags |= FL_SENT_COMMAND;
+		nuc980_fmi_send_command(host, host->request->cmd);
+	} else if ((!(host->flags & FL_SENT_STOP)) && host->request->stop) {
+		host->flags |= FL_SENT_STOP;
+		nuc980_fmi_send_stop(host, host->request->stop);
+	} else {
+		del_timer(&host->timer);
+	}
+	LEAVE();
+}
+
+/*
+ * Handle a command that has been completed
+ */
+static void nuc980_fmi_completed_command(struct nuc980_fmi_host *host, unsigned int status)
+{
+	struct mmc_command *cmd = host->cmd;
+	struct mmc_data *data = cmd->data;
+	unsigned int i, j, tmp[5], err;
+	unsigned char *ptr;
+	ENTRY();
+	err = nuc980_fmi_read(REG_EMMCISR);
+	if ((err & EMMCISR_RITO_IF) || (cmd->error)) {
+		nuc980_fmi_write(REG_EMMCTMOUT, 0x0);
+		nuc980_fmi_write(REG_EMMCISR, EMMCISR_RITO_IF);
+		cmd->error = -ETIMEDOUT;
+		cmd->resp[0] = cmd->resp[1] = cmd->resp[2] = cmd->resp[3] = 0;
+	} else {
+		if (status & FMI_EVENT_RSP_IN) {
+			// if not R2
+			cmd->resp[0] = (nuc980_fmi_read(REG_EMMCRSP0) << 8)|(nuc980_fmi_read(REG_EMMCRSP1) & 0xff);
+			cmd->resp[1] = cmd->resp[2] = cmd->resp[3] = 0;
+		} else if (status & FMI_EVENT_RSP2_IN) {
+			// if R2
+			ptr = (unsigned char *)REG_NAND_FB0;
+			for (i=0, j=0; j<5; i+=4, j++)
+				tmp[j] = (*(ptr+i)<<24)|(*(ptr+i+1)<<16)|(*(ptr+i+2)<<8)|(*(ptr+i+3));
+			for (i=0; i<4; i++)
+				cmd->resp[i] = ((tmp[i] & 0x00ffffff)<<8)|((tmp[i+1] & 0xff000000)>>24);
+		}
+	}
+	//nuc980_fmi_debug("Event = 0x%0X [0x%08X 0x%08X] <0x%x>\n", status, cmd->resp[0], cmd->resp[1], err);
+
+	if (!cmd->error) {
+		if ((err & EMMCISR_CRC_7) == 0) {
+			if (!(mmc_resp_type(cmd) & MMC_RSP_CRC)) {
+				cmd->error = 0;
+				nuc980_fmi_write(REG_EMMCISR, EMMCISR_CRC_IF);
+			} else {
+				cmd->error = -EIO;
+				nuc980_fmi_debug("Error detected and set to %d/%d (cmd = %d, retries = %d)\n",
+				                 cmd->error, data ? data->error : 0, cmd->opcode, cmd->retries);
+			}
+		} else
+			cmd->error = 0;
+		if (data) {
+			data->bytes_xfered = 0;
+			host->transfer_index = 0;
+			host->in_use_index = 0;
+			if(host->request->cmd->data->flags ==MMC_DATA_WRITE &&
+			    host->request->cmd->opcode == 53 &&
+			    host->request->cmd->data->blksz  <=64) {
+				/* To Avoid CMD53 reading data than less 64 bytes will be worng */
+				while((nuc980_fmi_read(REG_EMMCISR)&0x70)!=0x20);
+				udelay(2);
+				nuc980_fmi_write(REG_NAND_DMACCSR, nuc980_fmi_read(REG_NAND_DMACCSR) | DMACCSR_SWRST);
+				while(nuc980_fmi_read(REG_NAND_DMACCSR)&0x2);
+				nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) | (1<<14));
+				while(nuc980_fmi_read(REG_EMMCCSR)&(1<<14));
+			} else {
+				if (wait_event_interruptible_timeout(fmi_wq_xfer, (fmi_state_xfer != 0), 20000) == 0) {
+					printk("SD time-out cmd=%d blksz=%d\n",host->request->cmd->opcode,host->request->cmd->data->blksz);
+					nuc980_fmi_write(REG_NAND_DMACCSR, nuc980_fmi_read(REG_NAND_DMACCSR) | DMACCSR_SWRST);
+					while(nuc980_fmi_read(REG_NAND_DMACCSR)&0x2);
+					nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) | (1<<14));
+					while(nuc980_fmi_read(REG_EMMCCSR)&(1<<14));
+				}
+			}
+		}
+	}
+
+	if ((!(host->flags & FL_SENT_STOP)) && host->request->stop) {
+		host->flags |= FL_SENT_STOP;
+		nuc980_fmi_send_stop(host, host->request->stop);
+	}
+	LEAVE();
+}
+
+/*
+ * Handle an MMC request
+ */
+static int nuc980_fmi_card_detect(struct mmc_host *mmc)
+{
+	struct nuc980_fmi_host *host = mmc_priv(mmc);
+	int ret;
+	ENTRY();
+	if (nuc980_fmi_read(REG_NAND_FMICSR) != FMICSR_EMMCEN)
+		nuc980_fmi_write(REG_NAND_FMICSR, FMICSR_EMMCEN);
+
+	host->present = nuc980_fmi_read(REG_EMMCISR) & EMMCISR_CDPS0;
+
+	ret = host->present ? 0 : 1;
+	LEAVE();
+	return ret;
+}
+
+static void nuc980_fmi_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct nuc980_fmi_host *host = mmc_priv(mmc);
+	int card_present;
+	host->request = mrq;
+	host->flags = 0;
+	ENTRY();
+	/* more than 1s timeout needed with slow SD cards */
+	card_present = nuc980_fmi_card_detect(mmc);
+	if (card_present == 0) {
+		nuc980_fmi_debug("no medium present\n");
+		host->request->cmd->error = -ENOMEDIUM;
+		mmc_request_done(host->mmc, host->request);
+	} else
+		nuc980_fmi_send_request(host);
+	LEAVE();
+}
+
+/*
+ * Set the IOS
+ */
+extern unsigned long get_cpu_clk(void);
+static void nuc980_fmi_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct nuc980_fmi_host *host = mmc_priv(mmc);
+	host->bus_mode = ios->bus_width;
+	ENTRY();
+	/* maybe switch power to the card */
+	switch (ios->power_mode) {
+	case MMC_POWER_OFF:
+		nuc980_fmi_write(REG_NAND_FMICSR, 0);
+		break;
+	case MMC_POWER_UP:
+	case MMC_POWER_ON: // enable 74 clocks
+		nuc980_fmi_write(REG_NAND_FMICSR, FMICSR_EMMCEN);
+
+		if (ios->clock == 0) {
+			return;
+		}
+		//printk("ios->clock=%d\n",ios->clock);
+		if (ios->clock <= 400000) {
+			clk_set_rate(host->upll_clk, 100000000);
+			clk_set_rate(host->fmi_clk, ios->clock);
+			nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) | EMMCCSR_CLK74_OE);
+			while (nuc980_fmi_read(REG_EMMCCSR) & EMMCCSR_CLK74_OE);
+		} else {
+			clk_set_rate(host->fmi_clk, ios->clock);
+		}
+		break;
+	default:
+		WARN_ON(1);
+	}
+
+	if (ios->bus_width == MMC_BUS_WIDTH_4) {
+		nuc980_fmi_debug("MMC: Setting controller bus width to 4\n");
+		nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) | EMMCCSR_DBW);
+	} else {
+		//nuc980_fmi_debug("MMC: Setting controller bus width to 1\n");
+		nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) & ~EMMCCSR_DBW);
+	}
+	LEAVE();
+}
+
+
+/*
+ * Handle CO, RI, and R2 event
+ */
+static int nuc980_fmi_event_thread(struct nuc980_fmi_host *sd_host)
+{
+	int event = 0;
+	int completed = 0;
+	ENTRY();
+
+	completed = 0;
+	event = fmi_event;
+	fmi_event = FMI_EVENT_NONE;
+	if (event & FMI_EVENT_CMD_OUT) {
+		while (1) {
+			if (!(nuc980_fmi_read(REG_EMMCCSR) & EMMCCSR_CO_EN)) {
+				completed = 1;
+				break;
+			}
+		}
+	}
+
+	if (event & FMI_EVENT_RSP_IN) {
+		while (1) {
+			if (!(nuc980_fmi_read(REG_EMMCCSR) & EMMCCSR_RI_EN)) {
+				completed = 1;
+				break;
+			}
+
+			if (nuc980_fmi_read(REG_EMMCISR) & EMMCISR_RITO_IF) {
+				nuc980_fmi_write(REG_EMMCTMOUT, 0x0);
+				nuc980_fmi_write(REG_EMMCISR, EMMCISR_RITO_IF);
+
+				completed = 1;
+				sd_host->cmd->error = -ETIMEDOUT;
+				break;
+			}
+		}
+	}
+
+	if (event & FMI_EVENT_RSP2_IN) {
+		while (1) {
+			if (!(nuc980_fmi_read(REG_EMMCCSR) & EMMCCSR_R2_EN)) {
+				completed = 1;
+				break;
+			}
+		}
+	}
+	if (completed) {
+		nuc980_fmi_completed_command(sd_host, event);
+	}
+
+	nuc980_fmi_debug("SD0 event quit\n");
+	LEAVE();
+	return 0;
+}
+
+/*
+ * Handle an interrupt
+ */
+static irqreturn_t nuc980_fmi_irq(int irq, void *devid)
+{
+	struct nuc980_fmi_host *host = devid;
+	unsigned int int_status, present;
+	ENTRY();
+	int_status = nuc980_fmi_read(REG_EMMCISR);
+
+	//nuc980_fmi_debug("FMI irq: status = %08X <0x%x, csr 0x%x>\n", int_status, nuc980_fmi_read(REG_MFP_GPD_L), nuc980_fmi_read(REG_EMMCCSR));
+	if (int_status & 0x400) { /* sdio 0 interrupt */
+		nuc980_fmi_write(REG_EMMCIER, nuc980_fmi_read(REG_EMMCIER) & ~0x400);
+		nuc980_fmi_write(REG_EMMCISR, 0x400);
+		mmc_signal_sdio_irq(host->mmc);
+	}
+
+	if (int_status & EMMCISR_BLKD_IF) {
+		nuc980_fmi_debug("FMI xfer done.\n");
+		if ((host->cmd == 0) || (host->cmd->data == 0)) {
+			return IRQ_NONE;
+		}
+
+		if (host->cmd->data->flags & MMC_DATA_WRITE) {
+			nuc980_fmi_handle_transmitted(host);
+		} else if (host->cmd->data->flags & MMC_DATA_READ) {
+			nuc980_fmi_post_dma_read(host);
+		}
+		nuc980_fmi_write(REG_EMMCISR, EMMCISR_BLKD_IF);
+		fmi_state_xfer = 1;
+		wake_up_interruptible(&fmi_wq_xfer);
+	}
+
+	/*
+	 * we expect this irq on both insert and remove,
+	 * and use a short delay to debounce.
+	 */
+
+	if (int_status & EMMCISR_CD0_IF) {
+		present = int_status & EMMCISR_CDPS0;
+		host->present = present;
+		nuc980_fmi_debug("%s: card %s\n", mmc_hostname(host->mmc), present ? "remove" : "insert");
+		if (!present) {
+			nuc980_fmi_debug("****** Resetting SD-card bus width ******\n");
+			nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) & ~EMMCCSR_DBW);
+		}
+		/* 0.5s needed because of early card detect switch firing */
+		mmc_detect_change(host->mmc, msecs_to_jiffies(500));
+		nuc980_fmi_write(REG_EMMCISR, EMMCISR_CD0_IF);
+	}
+	LEAVE();
+	return IRQ_HANDLED;
+}
+
+static int nuc980_fmi_get_ro(struct mmc_host *mmc)
+{
+	/* TODO: check write protect pin */
+	/* if write protect, it should return >0 value */
+
+	/* no write protect */
+	return 0;
+
+	/*
+	 * Board doesn't support read only detection; let the mmc core
+	 * decide what to do.
+	 */
+	//return -ENOSYS;
+}
+
+static void nuc900_sd_enable_sdio_irq(struct mmc_host *mmc, int enable)
+{
+	//struct nuc980_fmi_host *host = mmc_priv(mmc);
+	ENTRY();
+	nuc980_fmi_write(REG_NAND_DMACIER, DMACIER_TABORTIE);    //Enable target abort interrupt generation during DMA transfer
+	nuc980_fmi_write(REG_NAND_FMIIER, FMIIER_DTAIE); //Enable DMAC READ/WRITE target abort interrupt generation
+
+	nuc980_fmi_write(REG_EMMCIER, nuc980_fmi_read(REG_EMMCIER) & ~0x400);
+	nuc980_fmi_write(REG_EMMCISR, 0x400);
+	if (enable) {
+		nuc980_fmi_write(REG_EMMCIER, nuc980_fmi_read(REG_EMMCIER) | 0x4400); /* sdio interrupt */
+		nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) | 0x80);   /* clock keep */
+	} else {
+		nuc980_fmi_write(REG_EMMCIER, nuc980_fmi_read(REG_EMMCIER) & ~0x4400);/* sdio interrupt */
+		nuc980_fmi_write(REG_EMMCCSR, nuc980_fmi_read(REG_EMMCCSR) & ~0x80);  /* clock keep */
+	}
+	LEAVE();
+}
+
+static const struct mmc_host_ops nuc980_fmi_ops = {
+	.request    = nuc980_fmi_request,
+	.set_ios    = nuc980_fmi_set_ios,
+	.get_ro     = nuc980_fmi_get_ro,
+	.get_cd     = nuc980_fmi_card_detect,
+	.enable_sdio_irq = nuc900_sd_enable_sdio_irq,
+};
+
+/*
+ * Probe for the device
+ */
+static int nuc980_fmi_probe(struct platform_device *pdev)
+{
+	struct mmc_host *mmc=NULL;
+	struct nuc980_fmi_host *host=NULL;
+	struct resource *res;
+	int ret;
+	struct clk *clkmux;
+	struct pinctrl *p;
+	struct clk *fmi_clk,*upll_clk;
+	ENTRY();
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res)
+		return -ENXIO;
+
+	if (!request_mem_region(res->start, res->end - res->start + 1, DRIVER_NAME))
+		return -EBUSY;
+
+	/* initial SD0 pin -> PC5~10, PC12 */
+	p = devm_pinctrl_get_select(&pdev->dev, "sd0");
+	if (IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		ret = PTR_ERR(p);
+	}
+
+	clk_prepare(clk_get(NULL, "fmi_hclk"));
+	clk_enable(clk_get(NULL, "fmi_hclk"));
+	clk_prepare(clk_get(NULL, "sdh0_hclk"));
+	clk_enable(clk_get(NULL, "sdh0_hclk"));
+	fmi_clk = clk_get(NULL, "sdh0_eclk");
+	if (IS_ERR(fmi_clk)) {
+		ret = -ENODEV;
+		dev_dbg(&pdev->dev, "no fmi_clk?\n");
+		goto fail2;
+	}
+	clk_prepare(fmi_clk);
+	clk_enable(fmi_clk);       /* Enable the peripheral clock */
+
+	clkmux = clk_get(NULL, "sdh0_eclk_mux");
+	if (IS_ERR(clkmux)) {
+		printk(KERN_ERR "nuc980-fmi:failed to get sd0 clock source\n");
+		ret = PTR_ERR(clkmux);
+		return ret;
+	}
+
+	upll_clk = clk_get(NULL, "sdh0_eclk_div");
+	if (IS_ERR(upll_clk)) {
+		printk(KERN_ERR "nuc980-fmi:failed to get sd0 clock source\n");
+		ret = PTR_ERR(upll_clk);
+		return ret;
+	}
+	clk_set_parent(clkmux, upll_clk);
+	//clk_set_rate(upll_clk, 33000000);
+	clk_set_rate(upll_clk, 10000000);
+
+	mmc = mmc_alloc_host(sizeof(struct nuc980_fmi_host), &pdev->dev);
+	if (!mmc) {
+		ret = -ENOMEM;
+		dev_dbg(&pdev->dev, "couldn't allocate mmc host\n");
+		goto fail6;
+	}
+
+	mmc->ops = &nuc980_fmi_ops;
+	mmc->f_min = 300000;
+	mmc->f_max = 50000000;
+	mmc->ocr_avail = MMC_VDD_27_28|MMC_VDD_28_29|MMC_VDD_29_30|MMC_VDD_30_31|MMC_VDD_31_32|MMC_VDD_32_33 | MMC_VDD_33_34;
+	mmc->caps = 0;
+	mmc->max_blk_size  = MCI_MAXBLKSIZE;
+	mmc->max_blk_count = MCI_BLKATONCE;
+	mmc->max_req_size  = MCI_BUFSIZE;
+	mmc->max_segs      = MCI_BLKATONCE;
+	mmc->max_seg_size  = MCI_BUFSIZE;
+
+	host = mmc_priv(mmc);
+	host->mmc = mmc;
+	host->bus_mode = 0;
+	mmc->caps |= (MMC_CAP_4_BIT_DATA|MMC_CAP_SDIO_IRQ|MMC_CAP_SD_HIGHSPEED|MMC_CAP_MMC_HIGHSPEED);
+
+	host->buffer = dma_alloc_coherent(&pdev->dev, MCI_BUFSIZE, &host->physical_address, GFP_KERNEL);
+	if (!host->buffer) {
+		ret = -ENOMEM;
+		dev_err(&pdev->dev, "Can't allocate transmit buffer\n");
+		goto fail5;
+	}
+
+	host->fmi_clk = fmi_clk;
+	host->upll_clk = upll_clk;
+
+	nuc980_fmi_disable(host);
+	nuc980_fmi_enable(host);
+
+	/*
+	 * Allocate the MCI interrupt
+	 */
+	host->irq = platform_get_irq(pdev, 0);
+	ret = request_irq(host->irq, nuc980_fmi_irq, IRQF_SHARED, mmc_hostname(mmc), host);
+	if (ret) {
+		dev_dbg(&pdev->dev, "request MCI interrupt failed\n");
+		goto fail0;
+	}
+
+	/* add a thread to check CO, RI, and R2 */
+	setup_timer(&host->timer, nuc980_fmi_timeout_timer, (unsigned long)host);
+	platform_set_drvdata(pdev, mmc);
+
+	/*
+	 * Add host to MMC layer
+	 */
+	host->present = nuc980_fmi_read(REG_EMMCISR) & EMMCISR_CDPS0;
+	nuc980_fmi_write(REG_EMMCIER, nuc980_fmi_read(REG_EMMCIER) | EMMCIER_CD0_IE | EMMCIER_CD0SRC);    //Enable SD interrupt & select GPIO detect
+
+	mmc_add_host(mmc);
+	nuc980_fmi_debug("Added NUC980 FMI-SD driver\n");
+
+	return 0;
+
+fail0:
+	clk_disable(host->fmi_clk);
+	clk_put(host->fmi_clk);
+fail2:
+	if (host->buffer)
+		dma_free_coherent(&pdev->dev, MCI_BUFSIZE, host->buffer, host->physical_address);
+fail5:
+	mmc_free_host(mmc);
+fail6:
+	release_mem_region(res->start, res->end - res->start + 1);
+	dev_err(&pdev->dev, "probe failed, err %d\n", ret);
+	LEAVE();
+	return ret;
+}
+
+/*
+ * Remove a device
+ */
+static int nuc980_fmi_remove(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct nuc980_fmi_host *host;
+	ENTRY();
+	if (!mmc)
+		return -1;
+
+	host = mmc_priv(mmc);
+
+	if (host->buffer)
+		dma_free_coherent(&pdev->dev, MCI_BUFSIZE, host->buffer, host->physical_address);
+
+	nuc980_fmi_disable(host);
+	del_timer_sync(&host->timer);
+	mmc_remove_host(mmc);
+	free_irq(host->irq, host);
+
+	clk_disable(host->fmi_clk);            /* Disable the peripheral clock */
+	clk_put(host->fmi_clk);
+
+	mmc_free_host(mmc);
+	platform_set_drvdata(pdev, NULL);
+	nuc980_fmi_debug("NUC980 FMI-SD Removed\n");
+	LEAVE();
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_fmi_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct nuc980_fmi_host *host = mmc_priv(mmc);
+	int ret = 0;
+	ENTRY();
+	// For save, wait DMAC to ready
+	while ( readl(REG_NAND_DMACCSR)      & 0x200 );
+	nuc900_sd_enable_sdio_irq(mmc, 0);
+	nuc980_fmi_disable(host);
+	clk_disable(host->fmi_clk);
+	LEAVE();
+	return ret;
+}
+
+static int nuc980_fmi_resume(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct nuc980_fmi_host *host = mmc_priv(mmc);
+	int ret = 0;
+	ENTRY();
+	clk_enable(host->fmi_clk);
+	nuc980_fmi_enable(host);
+	nuc900_sd_enable_sdio_irq(mmc, 1);
+	LEAVE();
+	return ret;
+}
+#else
+#define nuc980_fmi_suspend   NULL
+#define nuc980_fmi_resume    NULL
+#endif
+
+static const struct of_device_id nuc980_fmi_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-fmi" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_fmi_of_match);
+
+static struct platform_driver nuc980_fmi_driver = {
+	.probe      = nuc980_fmi_probe,
+	.remove     = nuc980_fmi_remove,
+	.suspend    = nuc980_fmi_suspend,
+	.resume     = nuc980_fmi_resume,
+	.driver     = {
+		.name   = DRIVER_NAME,
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_fmi_of_match),
+	},
+};
+
+
+module_platform_driver(nuc980_fmi_driver);
+
+MODULE_DESCRIPTION("NUC980 FMI-SD Card Interface driver");
+MODULE_AUTHOR("HPChen");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980_fmi-SD");
diff -uprN linux-4.4.194/drivers/mmc/host/nuc980_sd.c NUC980-linux-4.4.194/drivers/mmc/host/nuc980_sd.c
--- linux-4.4.194/drivers/mmc/host/nuc980_sd.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/mmc/host/nuc980_sd.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1120 @@
+/*
+ *  linux/drivers/mmc/host/nuc980_sd.c - Nuvoton NUC980 SD Driver
+ *
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ */
+
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/mutex.h>
+#include <linux/ioport.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/blkdev.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/dma-mapping.h>
+#include <linux/clk.h>
+#include <linux/atmel_pdc.h>
+#include <linux/gfp.h>
+#include <linux/freezer.h>
+#include <linux/of.h>
+
+#include <linux/mmc/host.h>
+
+#include <asm/io.h>
+#include <asm/irq.h>
+
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-sdh.h>
+
+#if 0
+#define ENTRY()                                 printk("[%-20s] : Enter...\n", __FUNCTION__)
+#define LEAVE()                                 printk("[%-20s] : Leave...\n", __FUNCTION__)
+#else
+#define ENTRY()
+#define LEAVE()
+#endif
+
+//#define nuc980_sd_debug       printk
+#define nuc980_sd_debug(...)
+
+#define DRIVER_NAME    "nuc980-sdh"
+
+#define FL_SENT_COMMAND (1 << 0)
+#define FL_SENT_STOP    (1 << 1)
+
+#define nuc980_sd_read(reg)          __raw_readl(reg)
+#define nuc980_sd_write(reg, val)    __raw_writel((val), (reg))
+
+#define MCI_BLKSIZE         512
+#define MCI_MAXBLKSIZE      4095
+#define MCI_BLKATONCE       255
+#define MCI_BUFSIZE         (MCI_BLKSIZE * MCI_BLKATONCE)
+
+/* Driver thread command */
+#define SD_EVENT_NONE       0x00000000
+#define SD_EVENT_CMD_OUT    0x00000001
+#define SD_EVENT_RSP_IN     0x00000010
+#define SD_EVENT_RSP2_IN    0x00000100
+#define SD_EVENT_CLK_KEEP0  0x00001000
+#define SD_EVENT_CLK_KEEP1  0x00010000
+
+/*
+ * Low level type for this driver
+ */
+struct nuc980_sd_host {
+	struct mmc_host *mmc;
+	struct mmc_command *cmd;
+	struct mmc_request *request;
+
+	void __iomem *sd_base;
+	int irq;
+
+	int present;
+	struct clk *sd_clk, *upll_clk,*xin_clk,*div_clk,*mux_clk;
+	/*
+	 * Flag indicating when the command has been sent. This is used to
+	 * work out whether or not to send the stop
+	 */
+	unsigned int flags;
+	/* flag for current port */
+	u32 bus_mode;
+	u32 port;       // SD port 0 / 1
+
+	/* DMA buffer used for transmitting */
+	unsigned int* buffer;
+	dma_addr_t physical_address;
+	unsigned int total_length;
+
+	/* Latest in the scatterlist that has been enabled for transfer, but not freed */
+	int in_use_index;
+
+	/* Latest in the scatterlist that has been enabled for transfer */
+	int transfer_index;
+
+	/* chekc nuc980 chip version */
+	u32 IsVersionC;
+
+
+	/* Timer for timeouts */
+	struct timer_list timer;
+};
+
+/* SD Port 0 */
+static volatile int sd_event=0, sd_state_xfer=0, sd_ri_timeout=0;
+static DECLARE_WAIT_QUEUE_HEAD(sd_wq_xfer);
+static int nuc980_sd_event_thread(struct nuc980_sd_host *sd_host);
+
+//--- Define semaphore for SDH controller
+struct semaphore sdh_fmi_sem;
+
+#if 0
+static void dump_sdh_regs()
+{
+	printk("    REG_CLK_HCLKEN = 0x%x\n", nuc980_sd_read(REG_CLK_HCLKEN));
+	printk("    REG_CLKDIV9 = 0x%x\n", nuc980_sd_read(REG_CLK_DIV9));
+	printk("    REG_FMICSR  = 0x%x\n", nuc980_sd_read(REG_FMICSR));
+	printk("    REG_DMACCSR = 0x%x\n", nuc980_sd_read(REG_DMACCSR));
+	printk("    REG_SDCSR   = 0x%x\n", nuc980_sd_read(REG_SDCSR));
+	printk("    REG_SDARG   = 0x%x\n", nuc980_sd_read(REG_SDARG));
+	printk("    REG_SDIER   = 0x%x\n", nuc980_sd_read(REG_SDIER));
+	printk("    REG_SDISR   = 0x%x\n", nuc980_sd_read(REG_SDISR));
+	printk("    REG_SDRSP0  = 0x%x\n", nuc980_sd_read(REG_SDRSP0));
+	printk("    REG_SDRSP1  = 0x%x\n", nuc980_sd_read(REG_SDRSP1));
+	printk("    REG_SDBLEN  = 0x%x\n", nuc980_sd_read(REG_SDBLEN));
+	printk("    REG_SDTMOUT = 0x%x\n", nuc980_sd_read(REG_SDTMOUT));
+	printk("    REG_SDECR   = 0x%x\n", nuc980_sd_read(REG_SDECR));
+}
+#endif
+
+/*
+ * Reset the controller and restore most of the state
+ */
+static void nuc980_sd_reset_host(struct nuc980_sd_host *host)
+{
+	unsigned long flags;
+	ENTRY();
+	local_irq_save(flags);
+
+	nuc980_sd_write(REG_DMACCSR, DMACCSR_DMACEN | DMACCSR_SW_RST); //enable DMAC for FMI
+	nuc980_sd_write(REG_FMICSR, FMICSR_SW_RST); /* Enable SD functionality of FMI */
+	nuc980_sd_write(REG_FMICSR, FMICSR_SD_EN);
+	local_irq_restore(flags);
+	LEAVE();
+}
+
+static void nuc980_sd_timeout_timer(unsigned long data)
+{
+	struct nuc980_sd_host *host;
+
+	host = (struct nuc980_sd_host *)data;
+	ENTRY();
+	if (host->request) {
+		dev_err(host->mmc->parent, "Timeout waiting end of packet\n");
+
+		if (host->cmd && host->cmd->data) {
+			host->cmd->data->error = -ETIMEDOUT;
+		} else {
+			if (host->cmd)
+				host->cmd->error = -ETIMEDOUT;
+			else
+				host->request->cmd->error = -ETIMEDOUT;
+		}
+		nuc980_sd_reset_host(host);
+		mmc_request_done(host->mmc, host->request);
+	}
+	LEAVE();
+}
+
+/*
+ * Copy from sg to a dma block - used for transfers
+ */
+static inline void nuc980_sd_sg_to_dma(struct nuc980_sd_host *host, struct mmc_data *data)
+{
+	unsigned int len, i, size;
+	unsigned *dmabuf = host->buffer;
+	ENTRY();
+	size = data->blksz * data->blocks;
+	len = data->sg_len;
+
+	/*
+	 * Just loop through all entries. Size might not
+	 * be the entire list though so make sure that
+	 * we do not transfer too much.
+	 */
+	for (i = 0; i < len; i++) {
+		struct scatterlist *sg;
+		int amount;
+		unsigned int *sgbuffer;
+
+		sg = &data->sg[i];
+
+		sgbuffer = kmap_atomic(sg_page(sg)) + sg->offset;
+		amount = min(size, sg->length);
+		size -= amount;
+		{
+			char *tmpv = (char *)dmabuf;
+			memcpy(tmpv, sgbuffer, amount);
+			tmpv += amount;
+			dmabuf = (unsigned *)tmpv;
+		}
+
+		kunmap_atomic(sgbuffer);
+		data->bytes_xfered += amount;
+
+		if (size == 0)
+			break;
+	}
+
+	/*
+	 * Check that we didn't get a request to transfer
+	 * more data than can fit into the SG list.
+	 */
+	BUG_ON(size != 0);
+	LEAVE();
+}
+
+/*
+ * Handle after a dma read
+ */
+static void nuc980_sd_post_dma_read(struct nuc980_sd_host *host)
+{
+	struct mmc_command *cmd;
+	struct mmc_data *data;
+	unsigned int len, i, size;
+	unsigned *dmabuf = host->buffer;
+	ENTRY();
+	cmd = host->cmd;
+	if (!cmd) {
+		nuc980_sd_debug("no command\n");
+		return;
+	}
+
+	data = cmd->data;
+	if (!data) {
+		nuc980_sd_debug("no data\n");
+		return;
+	}
+
+	size = data->blksz * data->blocks;
+	len = data->sg_len;
+
+	for (i = 0; i < len; i++) {
+		struct scatterlist *sg;
+		int amount;
+		unsigned int *sgbuffer;
+
+		sg = &data->sg[i];
+
+		sgbuffer = kmap_atomic(sg_page(sg)) + sg->offset;
+		amount = min(size, sg->length);
+		size -= amount;
+		{
+			char *tmpv = (char *)dmabuf;
+			memcpy(sgbuffer, tmpv, amount);
+			tmpv += amount;
+			dmabuf = (unsigned *)tmpv;
+		}
+		flush_kernel_dcache_page(sg_page(sg));
+		kunmap_atomic(sgbuffer);
+		data->bytes_xfered += amount;
+		if (size == 0)
+			break;
+	}
+	LEAVE();
+}
+
+/*
+ * Handle transmitted data
+ */
+static void nuc980_sd_handle_transmitted(struct nuc980_sd_host *host)
+{
+	ENTRY();
+	if (nuc980_sd_read(REG_SDISR) & SDISR_CRC_IF)
+		nuc980_sd_write(REG_SDISR, SDISR_CRC_IF);
+
+	/* check read/busy */
+	nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) | SDCSR_CLK_KEEP0);
+
+	LEAVE();
+}
+
+
+/*
+ * Update bytes tranfered count during a write operation
+ */
+static void nuc980_sd_update_bytes_xfered(struct nuc980_sd_host *host)
+{
+	struct mmc_data *data;
+	ENTRY();
+	/* always deal with the effective request (and not the current cmd) */
+	if (host->request->cmd && host->request->cmd->error != 0)
+		return;
+
+	if (host->request->data) {
+		data = host->request->data;
+		if (data->flags & MMC_DATA_WRITE) {
+			/* card is in IDLE mode now */
+			data->bytes_xfered = data->blksz * data->blocks;
+		}
+	}
+	LEAVE();
+}
+
+/*-----------------------------------------------------------------------------
+ * Config SIC register to select SD port.
+ *---------------------------------------------------------------------------*/
+#include <linux/delay.h>
+
+/*
+ * Enable the controller
+ */
+static void nuc980_sd_enable(struct nuc980_sd_host *host)
+{
+	ENTRY();
+	nuc980_sd_write(REG_DMACCSR, DMACCSR_DMACEN);   // enable DMAC for FMI
+	nuc980_sd_write(REG_FMICSR, FMICSR_SD_EN);  /* Enable SD functionality of FMI */
+	nuc980_sd_write(REG_SDISR, 0xffffffff);
+	nuc980_sd_write(REG_SDIER, nuc980_sd_read(REG_SDIER) | SDIER_CD0SRC);   // select GPIO detect
+	nuc980_sd_write(REG_SDCSR, (nuc980_sd_read(REG_SDCSR) & 0x9fffffff)); //SD Port 0 is selected
+	nuc980_sd_write(REG_SDCSR, (nuc980_sd_read(REG_SDCSR) & ~0xfff0000)|0x09010000);
+	LEAVE();
+}
+
+/*
+ * Disable the controller
+ */
+static void nuc980_sd_disable(struct nuc980_sd_host *host)
+{
+	ENTRY();
+	nuc980_sd_write(REG_DMACCSR, DMACCSR_DMACEN | DMACCSR_SW_RST); //enable DMAC for FMI
+	nuc980_sd_write(REG_FMICSR, FMICSR_SW_RST); /* Enable SD functionality of FMI */
+	nuc980_sd_write(REG_SDISR, 0xffffffff);
+	nuc980_sd_write(REG_FMICSR, nuc980_sd_read(REG_FMICSR) & ~FMICSR_SD_EN);
+	LEAVE();
+}
+
+/*
+ * Send a command
+ */
+static void nuc980_sd_send_command(struct nuc980_sd_host *host, struct mmc_command *cmd)
+{
+	unsigned int volatile csr;
+	unsigned int block_length;
+	struct mmc_data *data = cmd->data;
+	int clock_free_run_status = 0;
+	unsigned int blocks;
+	ENTRY();
+	host->cmd = cmd;
+
+	sd_state_xfer = 0;
+
+	if (nuc980_sd_read(REG_FMICSR) != FMICSR_SD_EN)
+		nuc980_sd_write(REG_FMICSR, FMICSR_SD_EN);
+
+	csr = (nuc980_sd_read(REG_SDCSR) & 0xff00c080) | 0x09010000; //schung20170811
+
+	clock_free_run_status = csr | 0x80; /* clock keep */
+	csr = csr & ~0x80;
+	csr = csr | (cmd->opcode << 8) | SDCSR_CO_EN;   // set command code and enable command out
+	sd_event |= SD_EVENT_CMD_OUT;
+
+	if (host->bus_mode == MMC_BUS_WIDTH_4)
+		csr |= SDCSR_DBW;
+
+	if (mmc_resp_type(cmd) != MMC_RSP_NONE) {
+		/* if a response is expected then allow maximum response latancy */
+		/* set 136 bit response for R2, 48 bit response otherwise */
+		if (mmc_resp_type(cmd) == MMC_RSP_R2) {
+			csr |= SDCSR_R2_EN;
+			sd_event |= SD_EVENT_RSP2_IN;
+		} else {
+			csr |= SDCSR_RI_EN;
+			sd_event |= SD_EVENT_RSP_IN;
+		}
+		nuc980_sd_write(REG_SDISR, SDISR_RITO_IF);
+		sd_ri_timeout = 0;
+		nuc980_sd_write(REG_SDTMOUT, 0xffff);
+	}
+
+	if (data) {
+		nuc980_sd_write(REG_SDIER, nuc980_sd_read(REG_SDIER) | SDIER_BLKD_IE);  //Enable SD interrupt & select GPIO detect
+		block_length = data->blksz;
+		blocks = data->blocks;
+		//printk("block_length=%d\n",block_length); //schung
+		nuc980_sd_write(REG_SDBLEN, block_length-1);
+		if ((block_length > 512) || (blocks >= 256))
+			printk("ERROR: don't support read/write 256 blocks in on CMD\n");
+		else
+			csr = (csr & ~0x00ff0000) | (blocks << 16);
+	} else {
+		nuc980_sd_write(REG_SDIER, nuc980_sd_read(REG_SDIER) & ~SDIER_BLKD_IE); //disable SD interrupt & select GPIO detect
+		block_length = 0;
+		blocks = 0;
+	}
+
+	/*
+	 * Set the arguments and send the command
+	 */
+	nuc980_sd_debug("Sending command %d as 0x%0X, arg = 0x%08X, blocks = %d, length = %d\n",
+	                cmd->opcode, csr, cmd->arg, blocks, block_length);
+
+	if (data) {
+		data->bytes_xfered = 0;
+		host->transfer_index = 0;
+		host->in_use_index = 0;
+		if (data->flags & MMC_DATA_READ) {
+			/*
+			 * Handle a read
+			 */
+			//down_interruptible(&sdh_dmac_sem); //schung20170814
+			nuc980_sd_write(REG_SDTMOUT, 0x3fffff);  //schung20170810
+			host->total_length = 0;
+			nuc980_sd_write(REG_DMACSAR2, host->physical_address);
+			csr = csr | SDCSR_DI_EN;
+			nuc980_sd_debug("SDH - Reading %d bytes [phy_addr = 0x%x]\n", block_length * blocks, host->physical_address);
+		} else if (data->flags & MMC_DATA_WRITE) {
+			//if (down_interruptible(&sdh_dmac_sem))  // get sdio_dmac_sem for data writing.
+			//    return;
+			//down_interruptible(&sdh_dmac_sem); //schung20170808
+			host->total_length = block_length * blocks;
+			nuc980_sd_sg_to_dma(host, data);
+			nuc980_sd_debug("SDH - Transmitting %d bytes\n", host->total_length);
+			nuc980_sd_write(REG_DMACSAR2, host->physical_address);
+			csr = csr | SDCSR_DO_EN;
+		}
+	}
+	/*
+	 * Send the command and then enable the PDC - not the other way round as
+	 * the data sheet says
+	 */
+	nuc980_sd_write(REG_SDARG, cmd->arg);
+	nuc980_sd_write(REG_SDCSR, csr);
+
+	nuc980_sd_event_thread(host);
+	if (data) {
+		if (data->flags & MMC_DATA_WRITE) {
+			while (!(nuc980_sd_read(REG_SDISR) & SDISR_SDDAT0)) {
+				nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) | 0x40);   /* clk8_oe */
+				while (nuc980_sd_read(REG_SDCSR) & 0x40);
+			}
+			nuc980_sd_update_bytes_xfered(host);
+		}
+	}
+	if (clock_free_run_status) {
+		nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) | 0x80);   /* clock keep */
+	}
+	mmc_request_done(host->mmc, host->request);
+	LEAVE();
+}
+
+static void nuc980_sd_send_stop(struct nuc980_sd_host *host, struct mmc_command *cmd)
+{
+	unsigned int csr;
+	unsigned int block_length;
+	unsigned int blocks;
+	ENTRY();
+	host->cmd = cmd;
+
+	sd_state_xfer = 0;
+
+	if (nuc980_sd_read(REG_FMICSR) != FMICSR_SD_EN)
+		nuc980_sd_write(REG_FMICSR, FMICSR_SD_EN);
+
+	csr = (nuc980_sd_read(REG_SDCSR) & 0xff00c080) | 0x09010000; //schung20170811
+
+	csr = csr | (cmd->opcode << 8) | SDCSR_CO_EN;   // set command code and enable command out
+
+	sd_event |= SD_EVENT_CMD_OUT;
+
+	if (host->bus_mode == MMC_BUS_WIDTH_4)
+		csr |= SDCSR_DBW;
+
+	if (mmc_resp_type(cmd) != MMC_RSP_NONE) {
+		/* if a response is expected then allow maximum response latancy */
+
+		/* set 136 bit response for R2, 48 bit response otherwise */
+		if (mmc_resp_type(cmd) == MMC_RSP_R2) {
+			csr |= SDCSR_R2_EN;
+			sd_event |= SD_EVENT_RSP2_IN;
+		} else {
+			csr |= SDCSR_RI_EN;
+			sd_event |= SD_EVENT_RSP_IN;
+		}
+		nuc980_sd_write(REG_SDISR, SDISR_RITO_IF);
+		sd_ri_timeout = 0;
+		nuc980_sd_write(REG_SDTMOUT, 0xffff);
+	}
+
+	nuc980_sd_write(REG_SDIER, nuc980_sd_read(REG_SDIER) & ~SDIER_BLKD_IE); //disable SD interrupt & select GPIO detect
+	block_length = 0;
+	blocks = 0;
+
+	nuc980_sd_write(REG_SDARG, cmd->arg);
+	nuc980_sd_write(REG_SDCSR, csr);
+	nuc980_sd_event_thread(host);
+	mmc_request_done(host->mmc, host->request);
+	LEAVE();
+}
+
+
+/*
+ * Process the request
+ */
+static void nuc980_sd_send_request(struct nuc980_sd_host *host)
+{
+
+	ENTRY();
+
+	if (!(host->flags & FL_SENT_COMMAND)) {
+		host->flags |= FL_SENT_COMMAND;
+		nuc980_sd_send_command(host, host->request->cmd);
+	} else if ((!(host->flags & FL_SENT_STOP)) && host->request->stop) {
+		host->flags |= FL_SENT_STOP;
+		nuc980_sd_send_stop(host, host->request->stop);
+	} else {
+		del_timer(&host->timer);
+	}
+	LEAVE();
+}
+
+/*
+ * Handle a command that has been completed
+ */
+static void nuc980_sd_completed_command(struct nuc980_sd_host *host, unsigned int status)
+{
+	struct mmc_command *cmd = host->cmd;
+	struct mmc_data *data = cmd->data;
+	unsigned int i, j, tmp[5], err;
+	unsigned char *ptr;
+	ENTRY();
+	err = nuc980_sd_read(REG_SDISR);
+	if ((err & SDISR_RITO_IF) || (cmd->error)) {
+		nuc980_sd_write(REG_SDTMOUT, 0x0);
+		nuc980_sd_write(REG_SDISR, SDISR_RITO_IF);
+		cmd->error = -ETIMEDOUT;
+		cmd->resp[0] = cmd->resp[1] = cmd->resp[2] = cmd->resp[3] = 0;
+	} else {
+		if (status & SD_EVENT_RSP_IN) {
+			// if not R2
+			cmd->resp[0] = (nuc980_sd_read(REG_SDRSP0) << 8)|(nuc980_sd_read(REG_SDRSP1) & 0xff);
+			cmd->resp[1] = cmd->resp[2] = cmd->resp[3] = 0;
+		} else if (status & SD_EVENT_RSP2_IN) {
+			// if R2
+			ptr = (unsigned char *)FB0_BASE_ADDR;
+			for (i=0, j=0; j<5; i+=4, j++)
+				tmp[j] = (*(ptr+i)<<24)|(*(ptr+i+1)<<16)|(*(ptr+i+2)<<8)|(*(ptr+i+3));
+			for (i=0; i<4; i++)
+				cmd->resp[i] = ((tmp[i] & 0x00ffffff)<<8)|((tmp[i+1] & 0xff000000)>>24);
+		}
+	}
+	//nuc980_sd_debug("Event = 0x%0X [0x%08X 0x%08X] <0x%x>\n", status, cmd->resp[0], cmd->resp[1], err);
+
+	if (!cmd->error) {
+		if ((err & SDISR_CRC_7) == 0) {
+			if (!(mmc_resp_type(cmd) & MMC_RSP_CRC)) {
+				cmd->error = 0;
+				nuc980_sd_write(REG_SDISR, SDISR_CRC_IF);
+			} else {
+				cmd->error = -EIO;
+				nuc980_sd_debug("Error detected and set to %d/%d (cmd = %d, retries = %d)\n",
+				                cmd->error, data ? data->error : 0, cmd->opcode, cmd->retries);
+			}
+		} else
+			cmd->error = 0;
+		if (data) {
+			data->bytes_xfered = 0;
+			host->transfer_index = 0;
+			host->in_use_index = 0;
+
+			if(host->request->cmd->data->flags ==MMC_DATA_WRITE &&
+			    host->request->cmd->opcode == 53 &&
+			    host->request->cmd->data->blksz  <=64) {
+				/* To Avoid CMD53 reading data than less 64 bytes will be worng */
+				while((nuc980_sd_read(REG_SDISR)&0x70)!=0x20);
+				udelay(2);
+				nuc980_sd_write(REG_DMACCSR, nuc980_sd_read(REG_DMACCSR) | DMACCSR_SW_RST);
+				while(nuc980_sd_read(REG_DMACCSR)&0x2);
+				nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) | (1<<14));
+				while(nuc980_sd_read(REG_SDCSR)&(1<<14));
+			} else {
+				if (wait_event_interruptible_timeout(sd_wq_xfer, (sd_state_xfer != 0), 20000) == 0) {
+					printk("SD time-out cmd=%d blksz=%d\n",host->request->cmd->opcode,host->request->cmd->data->blksz);
+					nuc980_sd_write(REG_DMACCSR, nuc980_sd_read(REG_DMACCSR) | DMACCSR_SW_RST);
+					while(nuc980_sd_read(REG_DMACCSR)&0x2);
+					nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) | (1<<14));
+					while(nuc980_sd_read(REG_SDCSR)&(1<<14));
+				}
+			}
+		}
+	}
+
+	if (0) { //(cmd->opcode==51)
+		//schung
+		printk("0x%08x 0x%08x\n",
+		       host->buffer[0],
+		       host->buffer[1]
+		      );
+
+		printk("cmd->resp[0]=0x%08x\n",cmd->resp[0]);
+		printk("cmd->resp[1]=0x%08x\n",cmd->resp[1]);
+		printk("cmd->resp[2]=0x%08x\n",cmd->resp[2]);
+		printk("cmd->resp[3]=0x%08x\n",cmd->resp[3]);
+	}
+
+	if ((!(host->flags & FL_SENT_STOP)) && host->request->stop) {
+		host->flags |= FL_SENT_STOP;
+		nuc980_sd_send_stop(host, host->request->stop);
+	}
+	LEAVE();
+}
+
+/*
+ * Handle an MMC request
+ */
+static int nuc980_sd_card_detect(struct mmc_host *mmc)
+{
+	struct nuc980_sd_host *host = mmc_priv(mmc);
+	int ret;
+	ENTRY();
+	if (down_interruptible(&sdh_fmi_sem)) return -ERESTARTSYS;
+	if (nuc980_sd_read(REG_FMICSR) != FMICSR_SD_EN)
+		nuc980_sd_write(REG_FMICSR, FMICSR_SD_EN);
+
+	host->present = nuc980_sd_read(REG_SDISR) & SDISR_CDPS0;
+	ret = host->present ? 0 : 1;
+	up(&sdh_fmi_sem);
+	LEAVE();
+	return ret;
+}
+
+static void nuc980_sd_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct nuc980_sd_host *host = mmc_priv(mmc);
+	int card_present;
+	host->request = mrq;
+	host->flags = 0;
+	ENTRY();
+	/* more than 1s timeout needed with slow SD cards */
+	//mod_timer(&host->timer, jiffies +  msecs_to_jiffies(2000));
+	//return -ENOSYS;
+	card_present = nuc980_sd_card_detect(mmc);
+	if (down_interruptible(&sdh_fmi_sem)) return;
+	if (card_present == 0) {
+		nuc980_sd_debug("no medium present\n");
+		host->request->cmd->error = -ENOMEDIUM;
+		mmc_request_done(host->mmc, host->request);
+	} else
+		nuc980_sd_send_request(host);
+	up(&sdh_fmi_sem);
+	LEAVE();
+}
+
+/*
+ * Set the IOS
+ */
+extern unsigned long get_cpu_clk(void);
+static void nuc980_sd_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct nuc980_sd_host *host = mmc_priv(mmc);
+	host->bus_mode = ios->bus_width;
+	ENTRY();
+	if (down_interruptible(&sdh_fmi_sem)) return;
+	/* maybe switch power to the card */
+	switch (ios->power_mode) {
+	case MMC_POWER_OFF:
+		//dump_sdh_regs();
+		nuc980_sd_write(REG_FMICSR, 0);
+		__raw_writel(0x1, REG_SDECR);
+		break;
+	case MMC_POWER_UP:
+	case MMC_POWER_ON: // enable 74 clocks
+		__raw_writel(0, REG_SDECR);
+		nuc980_sd_write(REG_FMICSR, FMICSR_SD_EN);
+
+		if (ios->clock == 0) {
+			up(&sdh_fmi_sem);
+			LEAVE();
+			return;
+		}
+		//printk("ios->clock=%d\n",ios->clock);
+		if (ios->clock <= 400000) {
+			clk_set_parent(host->mux_clk, host->xin_clk);
+			clk_set_rate(host->div_clk, ios->clock);
+			//__raw_writel((__raw_readl(REG_CLK_DIV9) & ~0xff00) | ((0xff) << 8),REG_CLK_DIV9);     // SD clock divided by CLKDIV3[SD_N] [15:8]
+			nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) | SDCSR_CLK74_OE);
+			while (nuc980_sd_read(REG_SDCSR) & SDCSR_CLK74_OE);
+		} else {
+			clk_set_parent(host->mux_clk, host->upll_clk);
+			clk_set_rate(host->div_clk, ios->clock);
+		}
+		break;
+
+	default:
+		WARN_ON(1);
+	}
+
+	if (ios->bus_width == MMC_BUS_WIDTH_4) {
+		nuc980_sd_debug("MMC: Setting controller bus width to 4\n");
+		nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) | SDCSR_DBW);
+	} else {
+		//nuc980_sd_debug("MMC: Setting controller bus width to 1\n");
+		nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) & ~SDCSR_DBW);
+	}
+	up(&sdh_fmi_sem);
+	LEAVE();
+}
+
+
+/*
+ * Handle CO, RI, and R2 event
+ */
+static int nuc980_sd_event_thread(struct nuc980_sd_host *sd_host)
+{
+	int event = 0;
+	int completed = 0;
+	ENTRY();
+
+	completed = 0;
+	event = sd_event;
+	sd_event = SD_EVENT_NONE;
+	if (event & SD_EVENT_CMD_OUT) {
+		while (1) {
+			if (!(nuc980_sd_read(REG_SDCSR) & SDCSR_CO_EN)) {
+				completed = 1;
+				break;
+			}
+		}
+	}
+
+	if (event & SD_EVENT_RSP_IN) {
+		while (1) {
+			if (!(nuc980_sd_read(REG_SDCSR) & SDCSR_RI_EN)) {
+				completed = 1;
+				break;
+			}
+
+			if (nuc980_sd_read(REG_SDISR) & SDISR_RITO_IF) {
+				nuc980_sd_write(REG_SDTMOUT, 0x0);
+				nuc980_sd_write(REG_SDISR, SDISR_RITO_IF);
+
+				completed = 1;
+				sd_host->cmd->error = -ETIMEDOUT;
+				break;
+			}
+		}
+	}
+
+	if (event & SD_EVENT_RSP2_IN) {
+		while (1) {
+			if (!(nuc980_sd_read(REG_SDCSR) & SDCSR_R2_EN)) {
+				completed = 1;
+				break;
+			}
+		}
+	}
+	if (completed) {
+		nuc980_sd_completed_command(sd_host, event);
+	}
+
+	nuc980_sd_debug("SD0 event quit\n");
+	LEAVE();
+	return 0;
+}
+
+/*
+ * Handle an interrupt
+ */
+static irqreturn_t nuc980_sd_irq(int irq, void *devid)
+{
+	struct nuc980_sd_host *host = devid;
+	unsigned int int_status, present;
+	ENTRY();
+	int_status = nuc980_sd_read(REG_SDISR);
+	//nuc980_sd_debug("FMI irq: status = %08X <0x%x, csr 0x%x>\n", int_status, nuc980_sd_read(REG_MFP_GPD_L), nuc980_sd_read(REG_SDCSR));
+	if (int_status & 0x400) { /* sdio 0 interrupt */
+		nuc980_sd_write(REG_SDIER, nuc980_sd_read(REG_SDIER) & ~0x400);
+		nuc980_sd_write(REG_SDISR, 0x400);
+		mmc_signal_sdio_irq(host->mmc);
+	}
+
+
+	if (int_status & SDISR_BLKD_IF) {
+		nuc980_sd_debug("SDH xfer done.\n");
+
+		if ((host->cmd == 0) || (host->cmd->data == 0)) {
+			//nuc980_sd_debug("SD %d irq: port select = %d, found NULL pointer!!\n", host->port, reg_port_select);
+			return IRQ_NONE;
+		}
+
+		if (host->cmd->data->flags & MMC_DATA_WRITE) {
+			nuc980_sd_handle_transmitted(host);
+		} else if (host->cmd->data->flags & MMC_DATA_READ) {
+			nuc980_sd_post_dma_read(host);
+		}
+		nuc980_sd_write(REG_SDISR, SDISR_BLKD_IF);
+		sd_state_xfer = 1;
+		wake_up_interruptible(&sd_wq_xfer);
+
+	}
+
+	/*
+	 * we expect this irq on both insert and remove,
+	 * and use a short delay to debounce.
+	 */
+	/* SD card port 0 detect */
+	if (int_status & SDISR_CD0_IF) {
+		present = int_status & SDISR_CDPS0;
+		host->present = present;
+		nuc980_sd_debug("%s: card %s\n", mmc_hostname(host->mmc), present ? "remove" : "insert");
+		if (!present) {
+			nuc980_sd_debug("****** Resetting SD-card bus width ******\n");
+			nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) & ~SDCSR_DBW);
+		}
+		/* 0.5s needed because of early card detect switch firing */
+		mmc_detect_change(host->mmc, msecs_to_jiffies(500));
+		nuc980_sd_write(REG_SDISR, SDISR_CD0_IF);
+	}
+	LEAVE();
+	return IRQ_HANDLED;
+}
+
+static int nuc980_sd_get_ro(struct mmc_host *mmc)
+{
+	/* TODO: check write protect pin */
+	/* if write protect, it should return >0 value */
+
+	/* no write protect */
+	return 0;
+
+	/*
+	 * Board doesn't support read only detection; let the mmc core
+	 * decide what to do.
+	 */
+	//return -ENOSYS;
+}
+
+static void nuc900_sd_enable_sdio_irq(struct mmc_host *mmc, int enable)
+{
+	//struct nuc980_sd_host *host = mmc_priv(mmc);
+	ENTRY();
+	nuc980_sd_write(REG_DMACIER, DMACIER_TABORT_IE);    //Enable target abort interrupt generation during DMA transfer
+	nuc980_sd_write(REG_FMIIER, FMIIER_DTA_IE); //Enable DMAC READ/WRITE target abort interrupt generation
+
+	nuc980_sd_write(REG_SDIER, nuc980_sd_read(REG_SDIER) & ~0x400);
+	nuc980_sd_write(REG_SDISR, 0x400);
+	if (enable) {
+		nuc980_sd_write(REG_SDIER, nuc980_sd_read(REG_SDIER) | 0x4400); /* sdio interrupt */
+		nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) | 0x80);   /* clock keep */
+	} else {
+		nuc980_sd_write(REG_SDIER, nuc980_sd_read(REG_SDIER) & ~0x4400);/* sdio interrupt */
+		nuc980_sd_write(REG_SDCSR, nuc980_sd_read(REG_SDCSR) & ~0x80);  /* clock keep */
+	}
+	LEAVE();
+}
+
+static const struct mmc_host_ops nuc980_sd_ops = {
+	.request    = nuc980_sd_request,
+	.set_ios    = nuc980_sd_set_ios,
+	.get_ro     = nuc980_sd_get_ro,
+	.get_cd     = nuc980_sd_card_detect,
+	.enable_sdio_irq = nuc900_sd_enable_sdio_irq,
+};
+
+/*
+ * Probe for the device
+ */
+static int nuc980_sd_probe(struct platform_device *pdev)
+{
+	struct mmc_host *mmc=NULL;
+	struct nuc980_sd_host *host=NULL;
+	struct resource *res;
+	int ret;
+	struct clk *clkmux;
+#ifndef CONFIG_USE_OF
+	struct pinctrl *p;
+#endif
+	struct clk *sd_clk=NULL,*upll_clk=NULL,*xin_clk=NULL,*div_clk=NULL;
+	ENTRY();
+	printk("%s - pdev = %s\n", __func__, pdev->name);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res)
+		return -ENXIO;
+	if (!request_mem_region(res->start, res->end - res->start + 1, DRIVER_NAME))
+		return -EBUSY;
+
+	sema_init(&sdh_fmi_sem, 1);
+
+
+	/* initial SD1 pin -> PD0~7 */
+#ifndef CONFIG_USE_OF
+	//__raw_writel((__raw_readl(REG_MFP_GPF_L)&~0x0FFFFFFF) | 0x02222222,REG_MFP_GPF_L);
+	p = devm_pinctrl_get_select(&pdev->dev, "sd1");
+	if (IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		ret = PTR_ERR(p);
+		return ret;
+	}
+#endif
+
+	clk_prepare(clk_get(NULL, "sdh1_hclk"));
+	clk_enable(clk_get(NULL, "sdh1_hclk"));
+	sd_clk = clk_get(NULL, "sdh1_eclk");
+	if (IS_ERR(sd_clk)) {
+		ret = -ENODEV;
+		dev_dbg(&pdev->dev, "no sd_clk?\n");
+		goto fail2;
+	}
+	clk_prepare(sd_clk);
+	clk_enable(sd_clk);       /* Enable the peripheral clock */
+
+	clkmux = clk_get(NULL, "sdh1_eclk_mux");
+	if (IS_ERR(clkmux)) {
+		printk(KERN_ERR "nuc980-sdh:failed to get sdh clock source\n");
+		ret = PTR_ERR(clkmux);
+		return ret;
+	}
+
+	xin_clk = clk_get(NULL, "xin");
+	if (IS_ERR(upll_clk)) {
+		printk(KERN_ERR "nuc980-sdh:failed to get sdh clock source\n");
+		ret = PTR_ERR(upll_clk);
+		return ret;
+	}
+
+	upll_clk = clk_get(NULL, "upll");
+	if (IS_ERR(upll_clk)) {
+		printk(KERN_ERR "nuc980-sdh:failed to get sdh clock source\n");
+		ret = PTR_ERR(upll_clk);
+		return ret;
+	}
+	clk_set_parent(clkmux, upll_clk);
+
+	div_clk = clk_get(NULL, "sdh1_eclk_div");
+
+	clk_set_rate(div_clk, 10000000);
+	//__raw_writel((__raw_readl(REG_CLK_DIV9) & ~0xff00) | ((0xff) << 8),REG_CLK_DIV9);   // SD clock divided by CLKDIV3[SD_N] [15:8]
+
+#if defined (CONFIG_MMC_NUC980_SD)
+	/* SD Port 0 initial */
+	mmc = mmc_alloc_host(sizeof(struct nuc980_sd_host), &pdev->dev);
+	if (!mmc) {
+		ret = -ENOMEM;
+		dev_dbg(&pdev->dev, "couldn't allocate mmc host\n");
+		goto fail6;
+	}
+
+	mmc->ops = &nuc980_sd_ops;
+	mmc->f_min = 300000;
+	//mmc->f_max = 50000000;
+	mmc->f_max = 25000000; //for SDIO WIFI RTL8821AS
+	mmc->ocr_avail = MMC_VDD_27_28|MMC_VDD_28_29|MMC_VDD_29_30|MMC_VDD_30_31|MMC_VDD_31_32|MMC_VDD_32_33 | MMC_VDD_33_34;
+	mmc->caps = 0;
+	mmc->max_blk_size  = MCI_MAXBLKSIZE;
+	mmc->max_blk_count = MCI_BLKATONCE;
+	mmc->max_req_size  = MCI_BUFSIZE;
+	mmc->max_segs      = MCI_BLKATONCE;
+	mmc->max_seg_size  = MCI_BUFSIZE;
+
+	host = mmc_priv(mmc);
+	host->mmc = mmc;
+	host->bus_mode = 0;
+	mmc->caps |= (MMC_CAP_4_BIT_DATA|MMC_CAP_SDIO_IRQ|MMC_CAP_SD_HIGHSPEED|MMC_CAP_MMC_HIGHSPEED);
+	host->port = 0;     // default SD port to check
+
+	host->buffer = dma_alloc_coherent(&pdev->dev, MCI_BUFSIZE, &host->physical_address, GFP_KERNEL);
+	if (!host->buffer) {
+		ret = -ENOMEM;
+		dev_err(&pdev->dev, "Can't allocate transmit buffer\n");
+		goto fail5;
+	}
+
+	host->sd_clk = sd_clk;
+	host->upll_clk = upll_clk;
+	host->xin_clk= xin_clk;
+	host->div_clk = div_clk;
+	host->mux_clk = clkmux;
+
+	nuc980_sd_disable(host);
+	nuc980_sd_enable(host);
+
+	/*
+	 * Allocate the MCI interrupt
+	 */
+	host->irq = platform_get_irq(pdev, 0);
+	ret = request_irq(host->irq, nuc980_sd_irq, IRQF_SHARED, mmc_hostname(mmc), host);
+	if (ret) {
+		dev_dbg(&pdev->dev, "request MCI interrupt failed\n");
+		goto fail0;
+	}
+
+	/* add a thread to check CO, RI, and R2 */
+	//kernel_thread(sd_event_thread, NULL, 0);
+	setup_timer(&host->timer, nuc980_sd_timeout_timer, (unsigned long)host);
+	platform_set_drvdata(pdev, mmc);
+	/*
+	 * Add host to MMC layer
+	 */
+	host->present = nuc980_sd_read(REG_SDISR) & SDISR_CDPS0;
+	nuc980_sd_write(REG_SDIER, nuc980_sd_read(REG_SDIER) | SDIER_CD0_IE | SDIER_CD0SRC);    //Enable SD interrupt & select GPIO detect
+
+	mmc_add_host(mmc);
+	nuc980_sd_debug("Added NUC980 SD0 driver\n");
+#endif
+
+	LEAVE();
+	return 0;
+
+fail0:
+	clk_disable(host->sd_clk);
+	clk_put(host->sd_clk);
+fail2:
+	if (host->buffer)
+		dma_free_coherent(&pdev->dev, MCI_BUFSIZE, host->buffer, host->physical_address);
+fail5:
+	mmc_free_host(mmc);
+fail6:
+	release_mem_region(res->start, res->end - res->start + 1);
+	dev_err(&pdev->dev, "probe failed, err %d\n", ret);
+	LEAVE();
+	return ret;
+}
+
+/*
+ * Remove a device
+ */
+static int nuc980_sd_remove(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct nuc980_sd_host *host;
+	ENTRY();
+	if (!mmc)
+		return -1;
+
+	host = mmc_priv(mmc);
+
+	if (host->buffer)
+		dma_free_coherent(&pdev->dev, MCI_BUFSIZE, host->buffer, host->physical_address);
+
+	nuc980_sd_disable(host);
+	del_timer_sync(&host->timer);
+	mmc_remove_host(mmc);
+	free_irq(host->irq, host);
+
+	clk_disable(host->sd_clk);            /* Disable the peripheral clock */
+	clk_put(host->sd_clk);
+
+	mmc_free_host(mmc);
+	platform_set_drvdata(pdev, NULL);
+	nuc980_sd_debug("NUC980 SD Removed\n");
+	LEAVE();
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_sd_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct nuc980_sd_host *host = mmc_priv(mmc);
+	int ret = 0;
+	ENTRY();
+	// For save, wait DMAC to ready
+	while ( readl(REG_DMACCSR)      & 0x200 );
+	nuc900_sd_enable_sdio_irq(mmc, 0);
+	nuc980_sd_disable(host);
+	clk_disable(host->sd_clk);
+	LEAVE();
+	return ret;
+}
+
+static int nuc980_sd_resume(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct nuc980_sd_host *host = mmc_priv(mmc);
+	int ret = 0;
+	ENTRY();
+	clk_enable(host->sd_clk);
+	nuc980_sd_enable(host);
+	nuc900_sd_enable_sdio_irq(mmc, 1);
+	LEAVE();
+	return ret;
+}
+#else
+#define nuc980_sd_suspend   NULL
+#define nuc980_sd_resume    NULL
+#endif
+
+static const struct of_device_id nuc980_sdh_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-sdh" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_sdh_of_match);
+
+static struct platform_driver nuc980_sd_driver = {
+	.probe      = nuc980_sd_probe,
+	.remove     = nuc980_sd_remove,
+	.suspend    = nuc980_sd_suspend,
+	.resume     = nuc980_sd_resume,
+	.driver     = {
+		.name   = DRIVER_NAME,
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_sdh_of_match),
+	},
+};
+
+
+module_platform_driver(nuc980_sd_driver);
+
+MODULE_DESCRIPTION("NUC980 dual SD Card Interface driver");
+MODULE_AUTHOR("HPChen");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980_sd");
diff -uprN linux-4.4.194/drivers/mtd/nand/Kconfig NUC980-linux-4.4.194/drivers/mtd/nand/Kconfig
--- linux-4.4.194/drivers/mtd/nand/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/mtd/nand/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -513,6 +513,12 @@ config MTD_NAND_NUC900
 	  This enables the driver for the NAND Flash on evaluation board based
 	  on w90p910 / NUC9xx.
 
+config MTD_NAND_NUC980
+	tristate "Nuvoton NUC980 MTD NAND"
+	depends on ARCH_NUC980 && NUC980_FMI_MTD_NAND
+	help
+	  This enables the driver for the NAND Flash on NUC980.
+
 config MTD_NAND_JZ4740
 	tristate "Support for JZ4740 SoC NAND controller"
 	depends on MACH_JZ4740
diff -uprN linux-4.4.194/drivers/mtd/nand/Makefile NUC980-linux-4.4.194/drivers/mtd/nand/Makefile
--- linux-4.4.194/drivers/mtd/nand/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/mtd/nand/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -45,6 +45,7 @@ obj-$(CONFIG_MTD_NAND_MXC)		+= mxc_nand.
 obj-$(CONFIG_MTD_NAND_SOCRATES)		+= socrates_nand.o
 obj-$(CONFIG_MTD_NAND_TXX9NDFMC)	+= txx9ndfmc.o
 obj-$(CONFIG_MTD_NAND_NUC900)		+= nuc900_nand.o
+obj-$(CONFIG_MTD_NAND_NUC980)		+= nuc980_nand.o
 obj-$(CONFIG_MTD_NAND_MPC5121_NFC)	+= mpc5121_nfc.o
 obj-$(CONFIG_MTD_NAND_VF610_NFC)	+= vf610_nfc.o
 obj-$(CONFIG_MTD_NAND_RICOH)		+= r852.o
diff -uprN linux-4.4.194/drivers/mtd/nand/nand_ids.c NUC980-linux-4.4.194/drivers/mtd/nand/nand_ids.c
--- linux-4.4.194/drivers/mtd/nand/nand_ids.c	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/mtd/nand/nand_ids.c	2019-12-29 19:12:21.000000000 -0800
@@ -29,29 +29,83 @@ struct nand_flash_dev nand_flash_ids[] =
 	 * listed by full ID. We list them first so that we can easily identify
 	 * the most specific match.
 	 */
-	{"TC58NVG0S3E 1G 3.3V 8-bit",
+	{
+		"W25N01GV 1G 3.3V",
+		{ .id = {0xef, 0xaa} }, SZ_2K, 128, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"W25N02GV 2G 3.3V",
+		{ .id = {0xef, 0xab} }, SZ_2K, 256, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"MX35LF1GE4AB 1G 3.3V",
+		{ .id = {0xc2, 0x12} }, SZ_2K, 128, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"XT26G01A 1G 3.3V",
+		{ .id = {0x0b, 0xe1} }, SZ_2K, 128, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"XT26G02A 2G 3.3V",
+		{ .id = {0x0b, 0xe2} }, SZ_2K, 256, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"XT26G01BWSEGA 1G 3.3V",
+		{ .id = {0x0b, 0xf1} }, SZ_2K, 128, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"XT26G02BWSIGA 2G 3.3V",
+		{ .id = {0x0b, 0xf2} }, SZ_2K, 256, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"MKSV1GCW-BE 1G 3.3V",
+		{ .id = {0xd5, 0x11} }, SZ_2K, 128, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"MKSV1GCL-DE 1G 3.3V",
+		{ .id = {0xd5, 0x1c} }, SZ_2K, 128, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"ATO25D1GA 1G 3.3V",
+		{ .id = {0x9b, 0x12} }, SZ_2K, 128, SZ_128K, 0, 2, 64, NAND_ECC_INFO(1, SZ_512)
+	},
+	{
+		"TC58NVG0S3E 1G 3.3V 8-bit",
 		{ .id = {0x98, 0xd1, 0x90, 0x15, 0x76, 0x14, 0x01, 0x00} },
-		  SZ_2K, SZ_128, SZ_128K, 0, 8, 64, NAND_ECC_INFO(1, SZ_512),
-		  2 },
-	{"TC58NVG2S0F 4G 3.3V 8-bit",
+		SZ_2K, SZ_128, SZ_128K, 0, 8, 64, NAND_ECC_INFO(1, SZ_512),
+		2
+	},
+	{
+		"TC58NVG2S0F 4G 3.3V 8-bit",
 		{ .id = {0x98, 0xdc, 0x90, 0x26, 0x76, 0x15, 0x01, 0x08} },
-		  SZ_4K, SZ_512, SZ_256K, 0, 8, 224, NAND_ECC_INFO(4, SZ_512) },
-	{"TC58NVG3S0F 8G 3.3V 8-bit",
+		SZ_4K, SZ_512, SZ_256K, 0, 8, 224, NAND_ECC_INFO(4, SZ_512)
+	},
+	{
+		"TC58NVG3S0F 8G 3.3V 8-bit",
 		{ .id = {0x98, 0xd3, 0x90, 0x26, 0x76, 0x15, 0x02, 0x08} },
-		  SZ_4K, SZ_1K, SZ_256K, 0, 8, 232, NAND_ECC_INFO(4, SZ_512) },
-	{"TC58NVG5D2 32G 3.3V 8-bit",
+		SZ_4K, SZ_1K, SZ_256K, 0, 8, 232, NAND_ECC_INFO(4, SZ_512)
+	},
+	{
+		"TC58NVG5D2 32G 3.3V 8-bit",
 		{ .id = {0x98, 0xd7, 0x94, 0x32, 0x76, 0x56, 0x09, 0x00} },
-		  SZ_8K, SZ_4K, SZ_1M, 0, 8, 640, NAND_ECC_INFO(40, SZ_1K) },
-	{"TC58NVG6D2 64G 3.3V 8-bit",
+		SZ_8K, SZ_4K, SZ_1M, 0, 8, 640, NAND_ECC_INFO(40, SZ_1K)
+	},
+	{
+		"TC58NVG6D2 64G 3.3V 8-bit",
 		{ .id = {0x98, 0xde, 0x94, 0x82, 0x76, 0x56, 0x04, 0x20} },
-		  SZ_8K, SZ_8K, SZ_2M, 0, 8, 640, NAND_ECC_INFO(40, SZ_1K) },
-	{"SDTNRGAMA 64G 3.3V 8-bit",
+		SZ_8K, SZ_8K, SZ_2M, 0, 8, 640, NAND_ECC_INFO(40, SZ_1K)
+	},
+	{
+		"SDTNRGAMA 64G 3.3V 8-bit",
 		{ .id = {0x45, 0xde, 0x94, 0x93, 0x76, 0x50} },
-		  SZ_16K, SZ_8K, SZ_4M, 0, 6, 1280, NAND_ECC_INFO(40, SZ_1K) },
-	{"H27UCG8T2ATR-BC 64G 3.3V 8-bit",
+		SZ_16K, SZ_8K, SZ_4M, 0, 6, 1280, NAND_ECC_INFO(40, SZ_1K)
+	},
+	{
+		"H27UCG8T2ATR-BC 64G 3.3V 8-bit",
 		{ .id = {0xad, 0xde, 0x94, 0xda, 0x74, 0xc4} },
-		  SZ_8K, SZ_8K, SZ_2M, 0, 6, 640, NAND_ECC_INFO(40, SZ_1K),
-		  4 },
+		SZ_8K, SZ_8K, SZ_2M, 0, 6, 640, NAND_ECC_INFO(40, SZ_1K),
+		4
+	},
 
 	LEGACY_ID_NAND("NAND 4MiB 5V 8-bit",   0x6B, 4, SZ_8K, SP_OPTIONS),
 	LEGACY_ID_NAND("NAND 4MiB 3,3V 8-bit", 0xE3, 4, SZ_8K, SP_OPTIONS),
@@ -181,6 +235,9 @@ struct nand_manufacturers nand_manuf_ids
 	{NAND_MFR_SANDISK, "SanDisk"},
 	{NAND_MFR_INTEL, "Intel"},
 	{NAND_MFR_ATO, "ATO"},
+	{NAND_MFR_WINBOND, "Winbond"},
+	{NAND_MFR_XTX, "XTX"},
+	{NAND_MFR_MK, "MK"},
 	{0x0, "Unknown"}
 };
 
diff -uprN linux-4.4.194/drivers/mtd/nand/nuc980_nand.c NUC980-linux-4.4.194/drivers/mtd/nand/nuc980_nand.c
--- linux-4.4.194/drivers/mtd/nand/nuc980_nand.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/mtd/nand/nuc980_nand.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1482 @@
+/*
+ * Copyright  2018 Nuvoton technology corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/delay.h>
+#include <linux/clk.h>
+#include <linux/err.h>
+#include <linux/blkdev.h>
+
+#include <linux/freezer.h>
+#include <linux/of.h>
+
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-timer.h>
+#include <mach/regs-fmi.h>
+#include <linux/dma-mapping.h>
+#include "../mtdcore.h"
+
+
+#define RESET_FMI   0x01
+#define NAND_EN     0x08
+#define READYBUSY   (0x01 << 18)
+
+#define SWRST       0x01
+#define PSIZE       (0x01 << 3)
+#define DMARWEN     (0x03 << 1)
+#define BUSWID      (0x01 << 4)
+#define ECC4EN      (0x01 << 5)
+#define WP          (0x01 << 24)
+#define NANDCS      (0x01 << 25)
+#define ENDADDR     (0x01 << 31)
+
+#define BCH_T15     0x00400000
+#define BCH_T12     0x00200000
+#define BCH_T8      0x00100000
+#define BCH_T4      0x00080000
+#define BCH_T24     0x00040000
+
+#define NUC980_DRV_VERSION "20180301"
+#define DEF_RESERVER_OOB_SIZE_FOR_MARKER 4
+
+//#define NUC980_NAND_DEBUG
+#ifndef NUC980_NAND_DEBUG
+#define DBG(fmt, arg...)
+#define ENTER()
+#define LEAVE()
+#else
+#define DBG(fmt, arg...)    printk(fmt, ##arg)
+#define ENTER()
+#define LEAVE()
+#endif
+
+#define read_data_reg(dev)        readl(REG_SMDATA)
+
+#define write_data_reg(dev, val)  writel((val), REG_SMDATA)
+
+#define write_cmd_reg(dev, val)   writel((val), REG_SMCMD)
+
+#define write_addr_reg(dev, val)  writel((val), REG_SMADDR)
+
+struct nuc980_nand_info {
+	struct nand_hw_control  controller;
+	struct mtd_info         mtd;
+	struct nand_chip        chip;
+	struct mtd_partition    *parts;     // mtd partition
+	int                     nr_parts;   // mtd partition number
+	struct platform_device  *pdev;
+	struct clk              *clk;
+	struct clk              *fmi_clk;
+
+	void __iomem            *reg;
+	int                     eBCHAlgo;
+	int                     m_i32SMRASize;
+	int                     m_ePageSize;
+
+	unsigned char *         pnand_vaddr;
+	unsigned char *         pnand_phyaddr;
+
+	spinlock_t              lock;
+};
+
+typedef enum  {
+	eBCH_T8,
+	eBCH_T12,
+	eBCH_T24,
+	eBCH_CNT
+} E_BCHALGORITHM;
+
+typedef enum {
+	ePageSize_2048,
+	ePageSize_4096,
+	ePageSize_8192,
+	ePageSize_CNT
+} E_PAGESIZE;
+
+static const int g_i32BCHAlgoIdx[eBCH_CNT] = { BCH_T8, BCH_T12, BCH_T24 };
+static struct nand_ecclayout nuc980_nand_oob;
+static const int g_i32ParityNum[ePageSize_CNT][eBCH_CNT] = {
+	{ 60,     92,     90  },  // For 2K
+	{ 120,    184,    180 },  // For 4K
+	{ 240,    368,    360 },  // For 8K
+};
+
+
+#ifndef CONFIG_MTD_CMDLINE_PARTS
+#ifndef CONFIG_OF
+static struct mtd_partition partitions[] = {
+	{
+		.name = "u-boot",
+		.offset = 0,
+		.size = 2 * 1024 * 1024,
+		.ecclayout = (struct nand_ecclayout*)&nuc980_nand_oob
+	},
+	{
+		.name = "Kernel",
+		.size = 20 * 1024 * 1024,
+		.offset = MTDPART_OFS_APPEND,
+		.ecclayout = (struct nand_ecclayout*)&nuc980_nand_oob
+	},
+	{
+		.name = "user",
+		.offset = MTDPART_OFS_APPEND,
+		.size = MTDPART_SIZ_FULL
+	}
+};
+#endif
+#endif
+
+static void dump_chip_info( struct nand_chip * chip )
+{
+#ifndef NUC980_NAND_DEBUG
+	return;
+#endif
+
+	printk( "==========================\n" );
+
+	printk("chip_delay: %d\n", chip->chip_delay );
+	printk("chip->options: 0x%08X\n", chip->options );
+	printk("page size: %d Byte\n", 1<<chip->page_shift );
+
+	printk("chip->phys_erase_shift: %d\n", 1<<chip->phys_erase_shift );
+	printk("chip->bbt_erase_shift: %d\n", 1<<chip->bbt_erase_shift );
+
+	printk("chip->chip_shift: 0x%08X\n", chip->chip_shift );
+	printk("chip->numchips: %d\n", chip->numchips );
+
+	printk("chip->subpagesize: %d\n", 1<<chip->subpagesize );
+
+	printk( "==========================\n" );
+}
+
+
+static void dump_regs(int i32Line)
+{
+#ifndef NUC980_NAND_DEBUG
+	return;
+#endif
+
+	printk("============[%d]==============\n", i32Line);
+
+	printk("REG_NAND_FMICR[00] : 0x%08X\n",  readl(REG_NAND_FMICSR));
+
+	printk("REG_SMCSR[A0] : 0x%08X\n",  readl(REG_SMCSR));
+	printk("REG_SMISR[AC] : 0x%08X\n",  readl(REG_SMISR));
+	printk("REG_SMIER[A8] : 0x%08X\n",  readl(REG_SMIER));
+
+	printk("REG_SMCMD[B0] : 0x%08X\n",  readl(REG_SMCMD));
+	printk("REG_SMADDR[B4] : 0x%08X\n", readl(REG_SMADDR));
+	printk("REG_SMDATA[B8] : 0x%08X\n", readl(REG_SMDATA));
+
+	printk("REG_SMTCR[A4] : 0x%08X\n",  readl(REG_SMTCR));
+
+	printk("REG_NAND_DMACSAR[08] : 0x%08X\n", readl(REG_NAND_DMACSAR));
+
+	printk("============[%d]==============\n", i32Line);
+}
+
+
+/*
+ * nuc980_nand_hwecc_init - Initialize hardware ECC IP
+ */
+static void nuc980_nand_hwecc_init (struct mtd_info *mtd)
+{
+	struct nuc980_nand_info *nand = container_of(mtd, struct nuc980_nand_info, mtd);
+
+	writel ( readl(REG_SMCSR)|0x1, REG_SMCSR);    // reset SM controller
+
+	// Redundant area size
+	writel( nand->m_i32SMRASize , REG_SMREACTL );
+
+	// Protect redundant 3 bytes
+	// because we need to implement write_oob function to partial data to oob available area.
+	// Please note we skip 4 bytes
+	writel( readl(REG_SMCSR) | 0x100, REG_SMCSR);
+
+	// To read/write the ECC parity codes automatically from/to NAND Flash after data area field written.
+	writel( readl(REG_SMCSR) | 0x10, REG_SMCSR);
+
+	if ( nand->eBCHAlgo >= 0 ) {
+		// Set BCH algorithm
+		writel( (readl(REG_SMCSR) & (~0x007C0000)) | g_i32BCHAlgoIdx[nand->eBCHAlgo], REG_SMCSR);
+
+		// Enable H/W ECC, ECC parity check enable bit during read page
+		writel( readl(REG_SMCSR) | 0x00800080, REG_SMCSR);
+
+	} else  {
+		// Disable H/W ECC / ECC parity check enable bit during read page
+		writel( readl(REG_SMCSR) & (~0x00800000) &(~0x80), REG_SMCSR);
+	}
+}
+
+/*
+ * nuc980_nand_hwecc_fini - Finalize hardware ECC IP
+ */
+static void nuc980_nand_hwecc_fini (struct mtd_info *mtd)
+{
+	struct nand_chip *chip = mtd->priv;
+	if ( chip->ecc.mode == NAND_ECC_HW_OOB_FIRST )
+		writel(readl(REG_SMCSR)&(~0x00800000), REG_SMCSR); // ECC disable
+}
+
+static void nuc980_nand_initialize ( void )
+{
+	ENTER() ;
+
+	// Enable SM_EN
+	writel( NAND_EN, REG_NAND_FMICSR );
+
+	// Timing control
+	// writel(0x3050b, REG_SMTCR);
+	// tCLS= (2+1)TAHB,
+	// tCLH= (2*2+2)TAHB,
+	// tALS= (2*1+1)TAHB,
+	// tALH= (2*2+2)TAHB,
+	writel(0x20305, REG_SMTCR);
+
+	// Enable SM_CS0
+	writel((readl(REG_SMCSR)&(~0x06000000))|0x04000000, REG_SMCSR);
+	writel(0x1, REG_NFECR); /* un-lock write protect */
+
+	// NAND Reset
+	writel(readl(REG_SMCSR) | 0x1, REG_SMCSR);    // software reset
+
+	LEAVE();
+}
+
+/*-----------------------------------------------------------------------------
+ * Define some constants for BCH
+ *---------------------------------------------------------------------------*/
+// define the total padding bytes for 512/1024 data segment
+#define BCH_PADDING_LEN_512     32
+#define BCH_PADDING_LEN_1024    64
+// define the BCH parity code lenght for 512 bytes data pattern
+#define BCH_PARITY_LEN_T4  8
+#define BCH_PARITY_LEN_T8  15
+#define BCH_PARITY_LEN_T12 23
+#define BCH_PARITY_LEN_T15 29
+// define the BCH parity code lenght for 1024 bytes data pattern
+#define BCH_PARITY_LEN_T24 45
+
+
+/*-----------------------------------------------------------------------------
+ * Correct data by BCH alrogithm.
+ *      Support 8K page size NAND and BCH T4/8/12/15/24.
+ *---------------------------------------------------------------------------*/
+void fmiSM_CorrectData_BCH(u8 ucFieidIndex, u8 ucErrorCnt, u8* pDAddr)
+{
+	u32 uaData[24], uaAddr[24];
+	u32 uaErrorData[6];
+	u8  ii, jj;
+	u32 uPageSize;
+	u32 field_len, padding_len, parity_len;
+	u32 total_field_num;
+	u8  *smra_index;
+
+	ENTER();
+
+	//--- assign some parameters for different BCH and page size
+	switch (readl(REG_SMCSR) & 0x007C0000)
+	{
+		case BCH_T24:
+			field_len   = 1024;
+			padding_len = BCH_PADDING_LEN_1024;
+			parity_len  = BCH_PARITY_LEN_T24;
+			break;
+		case BCH_T15:
+			field_len   = 512;
+			padding_len = BCH_PADDING_LEN_512;
+			parity_len  = BCH_PARITY_LEN_T15;
+			break;
+		case BCH_T12:
+			field_len   = 512;
+			padding_len = BCH_PADDING_LEN_512;
+			parity_len  = BCH_PARITY_LEN_T12;
+			break;
+		case BCH_T8:
+			field_len   = 512;
+			padding_len = BCH_PADDING_LEN_512;
+			parity_len  = BCH_PARITY_LEN_T8;
+			break;
+		case BCH_T4:
+			field_len   = 512;
+			padding_len = BCH_PADDING_LEN_512;
+			parity_len  = BCH_PARITY_LEN_T4;
+			break;
+		default:
+			printk("NAND ERROR: %s(): invalid SMCR_BCH_TSEL = 0x%08X\n", __FUNCTION__, (u32)(readl(REG_SMCSR) & 0x7C0000));
+			LEAVE();
+			return;
+	}
+
+	uPageSize = readl(REG_SMCSR) & 0x00030000;
+	switch (uPageSize)
+	{
+		case 0x30000:  total_field_num = 8192 / field_len; break;
+		case 0x20000:  total_field_num = 4096 / field_len; break;
+		case 0x10000:  total_field_num = 2048 / field_len; break;
+		case 0x00000:  total_field_num =  512 / field_len; break;
+		default:
+			printk("NAND ERROR: %s(): invalid SMCR_PSIZE = 0x%08X\n", __FUNCTION__, uPageSize);
+			LEAVE();
+			return;
+	}
+
+	//--- got valid BCH_ECC_DATAx and parse them to uaData[]
+	// got the valid register number of BCH_ECC_DATAx since one register include 4 error bytes
+	jj = ucErrorCnt/4;
+	jj ++;
+	if (jj > 6)
+		jj = 6;     // there are 6 BCH_ECC_DATAx registers to support BCH T24
+
+	for(ii=0; ii<jj; ii++)
+	{
+		uaErrorData[ii] = readl(REG_BCH_ECC_DATA0 + ii*4);
+	}
+
+	for(ii=0; ii<jj; ii++)
+	{
+		uaData[ii*4+0] = uaErrorData[ii] & 0xff;
+		uaData[ii*4+1] = (uaErrorData[ii]>>8) & 0xff;
+		uaData[ii*4+2] = (uaErrorData[ii]>>16) & 0xff;
+		uaData[ii*4+3] = (uaErrorData[ii]>>24) & 0xff;
+	}
+
+	//--- got valid REG_BCH_ECC_ADDRx and parse them to uaAddr[]
+	// got the valid register number of REG_BCH_ECC_ADDRx since one register include 2 error addresses
+	jj = ucErrorCnt/2;
+	jj ++;
+	if (jj > 12)
+		jj = 12;    // there are 12 REG_BCH_ECC_ADDRx registers to support BCH T24
+
+	for(ii=0; ii<jj; ii++)
+	{
+		uaAddr[ii*2+0] = readl(REG_BCH_ECC_ADDR0 + ii*4) & 0x07ff;   // 11 bits for error address
+		uaAddr[ii*2+1] = (readl(REG_BCH_ECC_ADDR0 + ii*4)>>16) & 0x07ff;
+	}
+
+	//--- pointer to begin address of field that with data error
+	pDAddr += (ucFieidIndex-1) * field_len;
+
+	//--- correct each error bytes
+	for(ii=0; ii<ucErrorCnt; ii++)
+	{
+		// for wrong data in field
+		if (uaAddr[ii] < field_len)
+		{
+#ifdef NUC980_NAND_DEBUG
+			printk("BCH error corrected for data: address 0x%08X, data [0x%02X] --> ",
+				(unsigned int)(pDAddr+uaAddr[ii]), (unsigned int)(*(pDAddr+uaAddr[ii])));
+#endif
+			*(pDAddr+uaAddr[ii]) ^= uaData[ii];
+
+#ifdef NUC980_NAND_DEBUG
+			printk("[0x%02X]\n", *(pDAddr+uaAddr[ii]));
+#endif
+		}
+		// for wrong first-3-bytes in redundancy area
+		else if (uaAddr[ii] < (field_len+3))
+		{
+			uaAddr[ii] -= field_len;
+			uaAddr[ii] += (parity_len*(ucFieidIndex-1));    // field offset
+
+#ifdef NUC980_NAND_DEBUG
+			printk("BCH error corrected for 3 bytes: address 0x%08X, data [0x%02X] --> ",
+				(unsigned int)((u8 *)REG_SMRA0 + uaAddr[ii]), (unsigned int)(*((u8 *)REG_SMRA0 + uaAddr[ii])));
+#endif
+			*((u8 *)REG_SMRA0 + uaAddr[ii]) ^= uaData[ii];
+
+#ifdef NUC980_NAND_DEBUG
+			printk("[0x%02X]\n", *((u8 *)REG_SMRA0+uaAddr[ii]));
+#endif
+		}
+		// for wrong parity code in redundancy area
+		else
+		{
+			// BCH_ERR_ADDRx = [data in field] + [3 bytes] + [xx] + [parity code]
+			//                                   |<--     padding bytes      -->|
+			// The BCH_ERR_ADDRx for last parity code always = field size + padding size.
+			// So, the first parity code = field size + padding size - parity code length.
+			// For example, for BCH T12, the first parity code = 512 + 32 - 23 = 521.
+			// That is, error byte address offset within field is
+			uaAddr[ii] = uaAddr[ii] - (field_len + padding_len - parity_len);
+
+			// smra_index point to the first parity code of first field in register SMRA0~n
+			smra_index = (u8 *)
+						 (REG_SMRA0 + (readl(REG_SMREACTL) & 0x1ff) - // bottom of all parity code -
+						  (parity_len * total_field_num)                             // byte count of all parity code
+						 );
+
+			// final address = first parity code of first field +
+			//                 offset of fields +
+			//                 offset within field
+
+#ifdef NUC980_NAND_DEBUG
+			printk("BCH error corrected for parity: address 0x%08X, data [0x%02X] --> ",
+				(unsigned int)(smra_index + (parity_len * (ucFieidIndex-1)) + uaAddr[ii]),
+				(unsigned int)(*(smra_index + (parity_len * (ucFieidIndex-1)) + uaAddr[ii])));
+#endif
+			*((u8 *)smra_index + (parity_len * (ucFieidIndex-1)) + uaAddr[ii]) ^= uaData[ii];
+
+#ifdef NUC980_NAND_DEBUG
+			printk("[0x%02X]\n",
+				*((u8 *)smra_index + (parity_len * (ucFieidIndex-1)) + uaAddr[ii]));
+#endif
+		}
+	}   // end of for (ii<ucErrorCnt)
+	LEAVE();
+}
+
+int fmiSMCorrectData (struct mtd_info *mtd, unsigned long uDAddr )
+{
+	int uStatus, ii, jj, i32FieldNum=0;
+	volatile int uErrorCnt = 0;
+	volatile int uReportErrCnt = 0;
+
+	ENTER();
+
+	if ( readl ( REG_SMISR ) & 0x4 )
+	{
+		if ( ( readl(REG_SMCSR) & 0x7C0000) == BCH_T24 )
+			i32FieldNum = mtd->writesize / 1024;    // Block=1024 for BCH
+		else
+			i32FieldNum = mtd->writesize / 512;
+
+		if ( i32FieldNum < 4 )
+			i32FieldNum  = 1;
+		else
+			i32FieldNum /= 4;
+
+		for ( jj=0; jj<i32FieldNum; jj++ )
+		{
+			uStatus = readl ( REG_SMECC_ST0+jj*4 );
+			if ( !uStatus )
+				continue;
+
+			for ( ii=1; ii<5; ii++ )
+			{
+				if ( !(uStatus & 0x03) ) { // No error
+					uStatus >>= 8;
+					continue;
+				} else if ( (uStatus & 0x03)==0x01 ) { // Correctable error
+					uErrorCnt = (uStatus >> 2) & 0x1F;
+#ifdef NUC980_NAND_DEBUG
+					printk("Field (%d, %d) have %d error!!\n", jj, ii, uErrorCnt);
+#endif
+					fmiSM_CorrectData_BCH(jj*4+ii, uErrorCnt, (char*)uDAddr);
+					uReportErrCnt += uErrorCnt;
+					break;
+				} else // uncorrectable error or ECC error
+				{
+#ifdef NUC980_NAND_DEBUG
+					printk("SM uncorrectable error is encountered, 0x%4x !!\n", uStatus);
+#endif
+					LEAVE();
+					return -1;
+				}
+				uStatus >>= 8;
+			}
+		} //jj
+	}
+	LEAVE();
+	return uReportErrCnt;
+}
+
+/*
+ * HW ECC Correction
+ * function called after a read
+ * mtd:        MTD block structure
+ * dat:        raw data read from the chip
+ * read_ecc:   ECC from the chip (unused)
+ * isnull:     unused
+ */
+static int nuc980_nand_correct_data(struct mtd_info *mtd, u_char *dat, u_char *read_ecc, u_char *calc_ecc)
+{
+	return 0;
+}
+
+
+/*
+ * Enable HW ECC : unused on most chips
+ */
+void nuc980_nand_enable_hwecc(struct mtd_info *mtd, int mode)
+{
+	ENTER();
+#ifdef NUC980_NAND_DEBUG
+	{
+		char * ptr=REG_SMRA0;
+		int i=0;
+		if( mode == NAND_ECC_READ )
+			printk("[R]=\n");
+		else
+			printk("[W]=\n");
+
+		for(i=0; i<mtd->oobsize; i++)
+		{
+			printk("%X ",  *(ptr+i) );
+			if ( i % 32 == 31)
+				printk("\n");
+		}
+		printk("\n");
+	}
+#endif
+	LEAVE();
+}
+
+/*
+ * nuc980_nand_dmac_init - Initialize dma controller
+ */
+static void nuc980_nand_dmac_init( void )
+{
+	// DMAC enable
+	writel( readl(REG_NAND_DMACCSR) | 0x3, REG_NAND_DMACCSR);
+	writel( readl(REG_NAND_DMACCSR) & (~0x2), REG_NAND_DMACCSR);
+
+	// Clear DMA finished flag
+	writel( readl(REG_SMISR) | 0x1, REG_SMISR);
+
+	// Disable Interrupt
+	writel(readl(REG_SMIER) & ~(0x1), REG_SMIER);
+}
+
+/*
+ * nuc980_nand_dmac_fini - Finalize dma controller
+ */
+static void nuc980_nand_dmac_fini(void)
+{
+	// Clear DMA finished flag
+	writel(readl(REG_SMISR) | 0x1, REG_SMISR);
+}
+
+/*
+ * nuc980_nand_read_byte - read a byte from NAND controller into buffer
+ * @mtd: MTD device structure
+ */
+static unsigned char nuc980_nand_read_byte(struct mtd_info *mtd)
+{
+	unsigned char ret;
+	struct nuc980_nand_info *nand;
+
+	ENTER() ;
+
+	nand = container_of(mtd, struct nuc980_nand_info, mtd);
+	ret = (unsigned char)read_data_reg(nand);
+
+	LEAVE();
+	return ret;
+}
+
+
+/*
+ * nuc980_nand_read_buf - read data from NAND controller into buffer
+ * @mtd: MTD device structure
+ * @buf: virtual address in RAM of source
+ * @len: number of data bytes to be transferred
+ */
+static void nuc980_nand_read_buf(struct mtd_info *mtd, unsigned char *buf, int len)
+{
+	int i;
+	struct nuc980_nand_info *nand;
+	nand = container_of(mtd, struct nuc980_nand_info, mtd);
+
+	ENTER() ;
+
+	for (i = 0; i < len; i++)
+		buf[i] = (unsigned char)read_data_reg(nand);
+
+	LEAVE();
+}
+/*
+ * nuc980_nand_write_buf - write data from buffer into NAND controller
+ * @mtd: MTD device structure
+ * @buf: virtual address in RAM of source
+ * @len: number of data bytes to be transferred
+ */
+
+static void nuc980_nand_write_buf(struct mtd_info *mtd, const unsigned char *buf, int len)
+{
+	int i;
+	struct nuc980_nand_info *nand;
+	nand = container_of(mtd, struct nuc980_nand_info, mtd);
+
+	ENTER() ;
+
+	for (i = 0; i < len; i++)
+		write_data_reg(nand, buf[i]);
+
+	LEAVE();
+}
+
+/*
+ * _nuc980_nand_dma_transfer: configer and start dma transfer
+ * @mtd: MTD device structure
+ * @addr: virtual address in RAM of source/destination
+ * @len: number of data bytes to be transferred
+ * @is_write: flag for read/write operation
+ */
+static inline int _nuc980_nand_dma_transfer(struct mtd_info *mtd, const u_char *addr, unsigned int len, int is_write)
+{
+	struct nuc980_nand_info *nand = container_of(mtd, struct nuc980_nand_info, mtd);
+	dma_addr_t dma_addr = (dma_addr_t)nand->pnand_phyaddr;
+
+	ENTER() ;
+
+	// For save, wait DMAC to ready
+	while ( readl(REG_NAND_DMACCSR) & 0x200 );
+
+	// Reinitial dmac
+	nuc980_nand_dmac_init();
+
+	// Fill dma_addr
+	writel((unsigned long)dma_addr, REG_NAND_DMACSAR);
+
+	// Enable target abort interrupt generation during DMA transfer.
+	writel( 0x1, REG_NAND_DMACIER);
+
+	// Clear Ready/Busy 0 Rising edge detect flag
+	writel(0x400, REG_SMISR);
+
+	// Set which BCH algorithm
+	if ( nand->eBCHAlgo >= 0 ) {
+		// Set BCH algorithm
+		writel( (readl(REG_SMCSR) & (~0x7C0000)) | g_i32BCHAlgoIdx[nand->eBCHAlgo], REG_SMCSR);
+		// Enable H/W ECC, ECC parity check enable bit during read page
+		writel( readl(REG_SMCSR) | 0x00800000 | 0x80, REG_SMCSR);
+
+	} else  {
+		// Disable H/W ECC / ECC parity check enable bit during read page
+		writel( readl(REG_SMCSR) & (~0x00800080), REG_SMCSR);
+	}
+
+	writel( nand->m_i32SMRASize , REG_SMREACTL );
+
+	writel( readl(REG_SMIER) & (~0x4), REG_SMIER );
+	writel ( 0x4, REG_SMISR );
+
+	// Enable SM_CS0
+	writel((readl(REG_SMCSR)&(~0x06000000))|0x04000000, REG_SMCSR);
+	/* setup and start DMA using dma_addr */
+
+	if ( is_write ) {
+		register char * ptr=REG_SMRA0;
+		// To mark this page as dirty.
+		if ( ptr[3] == 0xFF )
+			ptr[3] = 0;
+		if ( ptr[2] == 0xFF )
+			ptr[2] = 0;
+
+		if ( addr )
+			memcpy( (void*)nand->pnand_vaddr, (void*)addr, len);
+
+		writel ( readl(REG_SMCSR) | 0x4, REG_SMCSR );
+		while ( !(readl(REG_SMISR) & 0x1) );
+
+	} else {
+		// Blocking for reading
+		// Enable DMA Read
+
+		writel ( readl(REG_SMCSR) | 0x2, REG_SMCSR);
+		if ( readl(REG_SMCSR) & 0x80 ) {
+			do {
+				int stat=0;
+				if ( (stat=fmiSMCorrectData ( mtd,  (unsigned long)nand->pnand_vaddr)) < 0 )
+				{
+					mtd->ecc_stats.failed++;
+					writel ( 0x4, REG_SMISR );
+					writel ( 0x3, REG_NAND_DMACCSR);          // reset DMAC
+					writel ( readl(REG_SMCSR)|0x1, REG_SMCSR);    // reset SM controller
+					break;
+				}
+				else if ( stat > 0 ) {
+					mtd->ecc_stats.corrected += stat;   // Add corrected bit count
+					writel ( 0x4, REG_SMISR );
+				}
+
+			} while ( !(readl(REG_SMISR) & 0x1) || (readl(REG_SMISR) & 0x4) );
+		} else
+			while ( !(readl(REG_SMISR) & 0x1) );
+
+		if ( addr )
+			memcpy( (void*)addr, (void*)nand->pnand_vaddr,  len );
+	}
+
+	nuc980_nand_dmac_fini();
+	LEAVE();
+	return 0;
+}
+
+/**
+ * nuc980_read_buf_dma_pref - read data from NAND controller into buffer
+ * @mtd: MTD device structure
+ * @buf: buffer to store date
+ * @len: number of bytes to read
+ */
+static void nuc980_read_buf_dma(struct mtd_info *mtd, u_char *buf, int len)
+{
+	ENTER();
+
+	if ( len == mtd->writesize ) /* start transfer in DMA mode */
+		_nuc980_nand_dma_transfer ( mtd, buf, len, 0x0);
+	else {
+		nuc980_nand_read_buf(mtd, buf, len);
+
+#ifdef NUC980_NAND_DEBUG
+		{
+		int i;
+		printk("R OOB %d\n", len );
+		for ( i=0; i<len; i++ )
+		{
+			printk("%02X ", buf[i] );
+			if ( i%32 == 31 )   printk("\n");
+		}
+		printk("\n");
+		}
+#endif
+	}
+	LEAVE();
+}
+
+/**
+ * nuc980_write_buf_dma_pref - write buffer to NAND controller
+ * @mtd: MTD device structure
+ * @buf: data buffer
+ * @len: number of bytes to write
+ */
+static void nuc980_write_buf_dma(struct mtd_info *mtd, const u_char *buf, int len)
+{
+	ENTER();
+
+	if ( len == mtd->writesize ) /* start transfer in DMA mode */
+		_nuc980_nand_dma_transfer(mtd, (u_char *)buf, len, 0x1);
+	else
+	{
+#ifdef NUC980_NAND_DEBUG
+		int i;
+		printk("W OOB %d\n", len);
+		for ( i=0; i<len; i++ )
+		{
+			printk("%02X ", buf[i] );
+			if ( i%32 == 31 )   printk("\n");
+		}
+#endif
+		nuc980_nand_write_buf(mtd, buf, len);
+	}
+
+	LEAVE();
+}
+
+
+/**
+ * nuc980_check_rb - check ready/busy pin
+ * @mtd: MTD device structure
+ */
+static int nuc980_check_rb(struct nuc980_nand_info *nand)
+{
+	unsigned int val;
+
+	ENTER();
+	spin_lock(&nand->lock);
+	val = readl(REG_SMISR) & READYBUSY;
+	spin_unlock(&nand->lock);
+	LEAVE();
+
+	return val;
+}
+
+static int nuc980_nand_devready(struct mtd_info *mtd)
+{
+	struct nuc980_nand_info *nand;
+	int ready;
+
+	ENTER() ;
+
+	nand = container_of(mtd, struct nuc980_nand_info, mtd);
+	ready = (nuc980_check_rb(nand)) ? 1 : 0;
+
+	LEAVE();
+	return ready;
+}
+
+static void nuc980_nand_command_lp(struct mtd_info *mtd, unsigned int command, int column, int page_addr)
+{
+	register struct nand_chip *chip = mtd->priv;
+	struct nuc980_nand_info *nand;
+
+	ENTER() ;
+
+	nand = container_of(mtd, struct nuc980_nand_info, mtd);
+
+	if (command == NAND_CMD_READOOB) {
+		column += mtd->writesize;
+		command = NAND_CMD_READ0;
+	}
+
+	write_cmd_reg(nand, command & 0xff);
+
+	if (command == NAND_CMD_READID)
+	{
+		write_addr_reg(nand, ENDADDR);
+	}
+	else
+	{
+		if (column != -1 || page_addr != -1) {
+			if (column != -1) {
+				write_addr_reg(nand, (column&0xFF) );
+				if ( page_addr != -1 )
+					write_addr_reg(nand, (column >> 8) );
+				else
+					write_addr_reg(nand, (column >> 8) | ENDADDR);
+
+			}
+
+			if (page_addr != -1) {
+				write_addr_reg(nand, (page_addr&0xFF) );
+
+				if ( chip->chipsize > (128 << 20) ) {
+					write_addr_reg(nand, (page_addr >> 8)&0xFF );
+					write_addr_reg(nand, ((page_addr >> 16)&0xFF)|ENDADDR );
+				} else {
+					write_addr_reg(nand, ((page_addr >> 8)&0xFF)|ENDADDR );
+				}
+			}
+		}
+	}
+
+	switch (command) {
+	case NAND_CMD_ERASE1:
+	case NAND_CMD_ERASE2:
+	case NAND_CMD_CACHEDPROG:
+	case NAND_CMD_PAGEPROG:
+	case NAND_CMD_SEQIN:
+	case NAND_CMD_RNDIN:
+	case NAND_CMD_STATUS:
+		LEAVE();
+		return;
+
+	case NAND_CMD_RESET:
+		if (chip->dev_ready)
+			break;
+
+		if ( chip->chip_delay )
+			udelay(chip->chip_delay);
+
+		write_cmd_reg(nand, NAND_CMD_STATUS);
+		write_cmd_reg(nand, command);
+
+		while (!nuc980_check_rb(nand)) ;
+
+		LEAVE();
+		return;
+
+	case NAND_CMD_RNDOUT:
+		write_cmd_reg(nand, NAND_CMD_RNDOUTSTART);
+		LEAVE();
+		return;
+
+	case NAND_CMD_READ0:
+		write_cmd_reg(nand, NAND_CMD_READSTART);
+		break;
+	default:
+		if (!chip->dev_ready) {
+			if ( chip->chip_delay )
+				udelay(chip->chip_delay);
+			LEAVE();
+			return;
+		}
+	}
+
+	while (!nuc980_check_rb(nand)) ;
+
+	LEAVE();
+}
+
+/* select chip */
+static void nuc980_nand_select_chip(struct mtd_info *mtd, int chip)
+{
+	writel((readl(REG_SMCSR)&(~0x06000000))|0x04000000, REG_SMCSR);
+	return;
+}
+
+/*
+ * Calculate HW ECC
+ * function called after a write
+ * mtd:        MTD block structure
+ * dat:        raw data (unused)
+ * ecc_code:   buffer for ECC
+ */
+static int nuc980_nand_calculate_ecc(struct mtd_info *mtd, const u_char *dat, u_char *ecc_code)
+{
+	return 0;
+}
+
+/**
+ * nand_write_page_hwecc - [REPLACABLE] hardware ecc based page write function
+ * @mtd:        mtd info structure
+ * @chip:       nand chip info structure
+ * @buf:        data buffer
+ */
+static int nuc980_nand_write_page_hwecc(struct mtd_info *mtd, struct nand_chip *chip,
+					const uint8_t *buf, int oob_required, int page)
+{
+	uint8_t *ecc_calc = chip->buffers->ecccalc;
+	uint32_t hweccbytes=chip->ecc.layout->eccbytes;
+	register char * ptr=REG_SMRA0;
+
+	ENTER();
+
+	memset ( (void*)ptr, 0xFF, mtd->oobsize );
+	memcpy ( (void*)ptr, (void*)chip->oob_poi,  mtd->oobsize - chip->ecc.total );
+
+	_nuc980_nand_dma_transfer( mtd, buf, mtd->writesize , 0x1);
+
+	// Copy parity code in SMRA to calc
+	memcpy ( (void*)ecc_calc,  (void*)( REG_SMRA0 + ( mtd->oobsize - chip->ecc.total ) ), chip->ecc.total );
+
+	// Copy parity code in calc to oob_poi
+	memcpy ( (void*)(chip->oob_poi+hweccbytes), (void*)ecc_calc, chip->ecc.total);
+
+	LEAVE();
+	return 0;
+}
+
+/**
+ * nuc980_nand_read_page_hwecc_oob_first - hardware ecc based page write function
+ * @mtd:        mtd info structure
+ * @chip:       nand chip info structure
+ * @buf:        buffer to store read data
+ * @page:       page number to read
+ */
+static int nuc980_nand_read_page_hwecc_oob_first(struct mtd_info *mtd, struct nand_chip *chip,
+						uint8_t *buf, int oob_required, int page)
+{
+	int eccsize = chip->ecc.size;
+	uint8_t *p = buf;
+	char * ptr=REG_SMRA0;
+
+	ENTER();
+
+	/* At first, read the OOB area  */
+	nuc980_nand_command_lp(mtd, NAND_CMD_READOOB, 0, page);
+	nuc980_nand_read_buf(mtd, chip->oob_poi, mtd->oobsize);
+
+	// Second, copy OOB data to SMRA for page read
+	memcpy ( (void*)ptr, (void*)chip->oob_poi, mtd->oobsize );
+
+	if ((*(ptr+2) != 0) && (*(ptr+3) != 0))
+	{
+		memset((void*)p, 0xff, eccsize);
+	}
+	else
+	{
+		// Third, read data from nand
+		nuc980_nand_command_lp(mtd, NAND_CMD_READ0, 0, page);
+		_nuc980_nand_dma_transfer(mtd, p, eccsize, 0x0);
+
+		// Fouth, restore OOB data from SMRA
+		memcpy ( (void*)chip->oob_poi, (void*)ptr, mtd->oobsize );
+	}
+
+	LEAVE();
+
+	return 0;
+}
+
+static void nuc980_layout_oob_table ( struct nand_ecclayout* pNandOOBTbl, int oobsize , int eccbytes )
+{
+	pNandOOBTbl->eccbytes = eccbytes;
+
+	pNandOOBTbl->oobavail = oobsize - DEF_RESERVER_OOB_SIZE_FOR_MARKER - eccbytes ;
+
+	pNandOOBTbl->oobfree[0].offset = DEF_RESERVER_OOB_SIZE_FOR_MARKER;  // Bad block marker size
+
+	pNandOOBTbl->oobfree[0].length = oobsize - eccbytes - pNandOOBTbl->oobfree[0].offset ;
+}
+
+/**
+ * nand_read_oob_std - [REPLACABLE] the most common OOB data read function
+ * @mtd:        mtd info structure
+ * @chip:       nand chip info structure
+ * @page:       page number to read
+ * @sndcmd:     flag whether to issue read command or not
+ */
+static int nuc980_nand_read_oob_hwecc(struct mtd_info *mtd, struct nand_chip *chip, int page)
+{
+	char * ptr=REG_SMRA0;
+
+	ENTER();
+
+	nuc980_nand_command_lp(mtd, NAND_CMD_READOOB, 0, page);
+
+	nuc980_nand_read_buf(mtd, &chip->oob_poi[0], mtd->oobsize);
+
+	// Second, copy OOB data to SMRA for page read
+	memcpy ( (void*)ptr, (void*)chip->oob_poi, mtd->oobsize );
+
+	if ((*(ptr+2) == 0) && (*(ptr+3) == 0))
+	{
+		// Third, read data from nand
+		nuc980_nand_command_lp(mtd, NAND_CMD_READ0, 0, page);
+		_nuc980_nand_dma_transfer(mtd, NULL, mtd->writesize, 0x0);
+
+		// Fouth, recovery OOB data for SMRA
+		memcpy ( (void*)chip->oob_poi, (void*)ptr, mtd->oobsize );
+	}
+
+	return 0;
+}
+
+/**
+ * nand_write_page - [REPLACEABLE] write one page
+ * @mtd:        MTD device structure
+ * @chip:       NAND chip descriptor
+ * @buf:        the data to write
+ * @page:       page number to write
+ * @cached:     cached programming
+ * @raw:        use _raw version of write_page
+ */
+
+
+static int nuc980_nand_write_page(struct mtd_info *mtd, struct nand_chip *chip, uint32_t offset, int data_len,
+				  const uint8_t *buf, int oob_required, int page, int cached, int raw)
+{
+	int status;
+
+	nuc980_nand_command_lp(mtd, NAND_CMD_SEQIN, 0x00, page);
+
+	if (unlikely(raw))
+		chip->ecc.write_page_raw(mtd, chip, buf, 0, page);
+	else
+	{
+		if ( page >= 0 && page < (1<<(chip->phys_erase_shift+2)) / mtd->writesize ) // four blocks
+		{
+			// Special pattern
+			char * ptr=REG_SMRA0;
+			memset ( (void*)ptr, 0xFF, mtd->oobsize );
+			ptr[3] = 0x00;
+			ptr[2] = 0x00;
+			ptr[1] = 0xFF;
+			_nuc980_nand_dma_transfer( mtd, buf, mtd->writesize , 0x1 );
+		}
+		else
+		{
+			nuc980_nand_write_page_hwecc ( mtd, chip, buf, oob_required, page );
+		}
+	}
+
+	/*
+	 * Cached progamming disabled for now, Not sure if its worth the
+	 * trouble. The speed gain is not very impressive. (2.3->2.6Mib/s)
+	 */
+	cached = 0;
+
+	if (!cached || !(chip->options & NAND_CACHEPRG)) {
+		nuc980_nand_command_lp(mtd, NAND_CMD_PAGEPROG, -1, -1);
+		status = chip->waitfunc(mtd, chip);
+		/*
+		 * See if operation failed and additional status checks are
+		 * available
+		 */
+		if ((status & NAND_STATUS_FAIL) && (chip->errstat))
+			status = chip->errstat(mtd, chip, FL_WRITING, status, page);
+
+		if (status & NAND_STATUS_FAIL)
+		{
+			return -EIO;
+		}
+	}
+	else {
+		nuc980_nand_command_lp(mtd, NAND_CMD_CACHEDPROG, -1, -1);
+		status = chip->waitfunc(mtd, chip);
+	}
+
+	return 0;
+}
+
+static int nuc980_nand_probe(struct platform_device *pdev)
+{
+	struct nand_chip *chip;
+	struct nuc980_nand_info *nuc980_nand;
+	struct mtd_part_parser_data ppdata = {};
+	struct mtd_info *mtd;
+	struct pinctrl *p;
+
+	int retval=0;
+	E_PAGESIZE ePageSize;
+
+	ENTER() ;
+
+	nuc980_nand = devm_kzalloc(&pdev->dev, sizeof(struct nuc980_nand_info), GFP_KERNEL);
+	if (!nuc980_nand)
+		return -ENOMEM;
+
+	if (pdev->dev.of_node)
+	{
+		pdev->dev.platform_data = nuc980_nand;
+		nuc980_nand = dev_get_platdata(&pdev->dev);
+	}
+
+	nuc980_nand->pnand_vaddr = (unsigned char *) dma_alloc_writecombine(NULL, 512*16, (dma_addr_t *)&nuc980_nand->pnand_phyaddr, GFP_KERNEL);
+	if(nuc980_nand->pnand_vaddr == NULL){
+		printk(KERN_ERR "nuc980_nand: failed to allocate ram for nand data.\n");
+		return -ENOMEM;
+	}
+
+	platform_set_drvdata(pdev, nuc980_nand);
+
+	spin_lock_init(&nuc980_nand->controller.lock);
+	init_waitqueue_head(&nuc980_nand->controller.wq);
+
+	nuc980_nand->pdev = pdev;
+	mtd = &nuc980_nand->mtd;
+	chip = &(nuc980_nand->chip);
+
+	nuc980_nand->mtd.priv   = chip;
+	nuc980_nand->mtd.owner  = THIS_MODULE;
+	spin_lock_init(&nuc980_nand->lock);
+
+	/*
+	 * Get Clock
+	 */
+	nuc980_nand->fmi_clk = clk_get(NULL, "fmi_hclk");
+	if (IS_ERR(nuc980_nand->fmi_clk)) {
+		printk("no fmi_clk?\n");
+		retval = -ENXIO;
+		goto fail1;
+	}
+
+	nuc980_nand->clk = clk_get(NULL, "nand_hclk");
+	if (IS_ERR(nuc980_nand->clk)) {
+		printk("no nand_clk?\n");
+		goto fail2;
+	}
+
+	clk_prepare(nuc980_nand->fmi_clk);
+	clk_enable(nuc980_nand->fmi_clk);
+	clk_prepare(nuc980_nand->clk);
+	clk_enable(nuc980_nand->clk);
+
+	nuc980_nand->chip.controller = &nuc980_nand->controller;
+
+	chip->cmdfunc     = nuc980_nand_command_lp;
+	chip->read_byte   = nuc980_nand_read_byte;
+	chip->select_chip = nuc980_nand_select_chip;
+	chip->read_buf  = nuc980_read_buf_dma;
+	chip->write_buf = nuc980_write_buf_dma;
+
+	// Check NAND device NBUSY0 pin
+	chip->dev_ready     = nuc980_nand_devready;
+	/* set up nand options */
+	chip->bbt_options = NAND_BBT_USE_FLASH | NAND_BBT_NO_OOB;
+	//chip->options     |= NAND_SKIP_BBTSCAN;
+
+	nuc980_nand->reg    = 0x00;
+
+	// Read OOB data first, then HW read page
+	chip->write_page     = nuc980_nand_write_page;
+	chip->ecc.mode       = NAND_ECC_HW_OOB_FIRST;
+	chip->ecc.hwctl      = nuc980_nand_enable_hwecc;
+	chip->ecc.calculate  = nuc980_nand_calculate_ecc;
+	chip->ecc.correct    = nuc980_nand_correct_data;
+	chip->ecc.write_page = nuc980_nand_write_page_hwecc;
+	chip->ecc.read_page  = nuc980_nand_read_page_hwecc_oob_first;
+	chip->ecc.read_oob   = nuc980_nand_read_oob_hwecc;
+	chip->ecc.layout     = &nuc980_nand_oob;
+
+#ifdef CONFIG_OF
+
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+	if (IS_ERR(p)) {
+		return PTR_ERR(p);
+	}
+
+	/*
+	 * Right now device-tree probed devices don't get dma_mask set.
+	 * Since shared usb code relies on it, set it here for now.
+	 * Once we have dma capability bindings this can go away.
+	 */
+	if (!pdev->dev.dma_mask)
+		pdev->dev.dma_mask = &pdev->dev.coherent_dma_mask;
+	if (!pdev->dev.coherent_dma_mask)
+		pdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+
+#else
+
+	p = devm_pinctrl_get_select(&pdev->dev, "nand");
+	if (IS_ERR(p))
+	{
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		retval = PTR_ERR(p);
+	}
+#endif
+
+	nuc980_nand_initialize( );
+
+	/* first scan to find the device and get the page size */
+	if (nand_scan_ident(&(nuc980_nand->mtd), 1, NULL)) {
+		retval = -ENXIO;
+		goto fail3;
+	}
+
+	//Set PSize bits of SMCSR register to select NAND card page size
+	switch (mtd->writesize) {
+		case 2048:
+			writel( (readl(REG_SMCSR)&(~0x30000)) + 0x10000, REG_SMCSR);
+			nuc980_nand->eBCHAlgo = 0; /* T8 */
+			nuc980_layout_oob_table ( &nuc980_nand_oob, mtd->oobsize, g_i32ParityNum[0][nuc980_nand->eBCHAlgo] );
+			ePageSize = ePageSize_2048;
+			break;
+
+		case 4096:
+			writel( (readl(REG_SMCSR)&(~0x30000)) + 0x20000, REG_SMCSR);
+			nuc980_nand->eBCHAlgo = 0; /* T8 */
+			nuc980_layout_oob_table ( &nuc980_nand_oob, mtd->oobsize, g_i32ParityNum[1][nuc980_nand->eBCHAlgo] );
+			ePageSize = ePageSize_4096;
+			break;
+
+		case 8192:
+			writel( (readl(REG_SMCSR)&(~0x30000)) + 0x30000, REG_SMCSR);
+			nuc980_nand->eBCHAlgo = 1; /* T12 */
+			nuc980_layout_oob_table ( &nuc980_nand_oob, mtd->oobsize, g_i32ParityNum[2][nuc980_nand->eBCHAlgo] );
+			ePageSize = ePageSize_8192;
+			break;
+
+		default:
+			printk("NUC980 NAND CONTROLLER IS NOT SUPPORT THE PAGE SIZE. (%d, %d)\n", mtd->writesize, mtd->oobsize );
+			goto fail3;
+	}
+	nuc980_nand->m_ePageSize = ePageSize;
+	{
+		/* check power on setting */
+		if ((readl(REG_PWRON) & 0x300) != 0x300) { /* ECC */
+			switch ((readl(REG_PWRON) & 0x300)) {
+				case 0x000: // T8
+					nuc980_nand->eBCHAlgo = 0;
+					break;
+
+				case 0x100: // T12
+					nuc980_nand->eBCHAlgo = 1;
+					break;
+
+				case 0x200: // T24
+					nuc980_nand->eBCHAlgo = 2;
+					break;
+
+				default:
+					printk("WRONG ECC Power-On-Setting (0x%x)\n", readl(REG_PWRON));
+			}
+		}
+		if ((readl(REG_PWRON) & 0xc0) != 0xc0) { /* page size */
+			switch ((readl(REG_PWRON) & 0xc0)) {
+				case 0x00: // 2KB
+					mtd->writesize = 2048;
+					writel( (readl(REG_SMCSR)&(~0x30000)) + 0x10000, REG_SMCSR);
+					mtd->oobsize = g_i32ParityNum[0][nuc980_nand->eBCHAlgo] + 8;
+					nuc980_layout_oob_table ( &nuc980_nand_oob, mtd->oobsize, g_i32ParityNum[0][nuc980_nand->eBCHAlgo] );
+					break;
+
+				case 0x40: // 4KB
+					mtd->writesize = 4096;
+					writel( (readl(REG_SMCSR)&(~0x30000)) + 0x20000, REG_SMCSR);
+					mtd->oobsize = g_i32ParityNum[1][nuc980_nand->eBCHAlgo] + 8;
+					nuc980_layout_oob_table ( &nuc980_nand_oob, mtd->oobsize, g_i32ParityNum[1][nuc980_nand->eBCHAlgo] );
+					break;
+
+				case 0x80: // 8KB
+					mtd->writesize = 8192;
+					writel( (readl(REG_SMCSR)&(~0x30000)) + 0x30000, REG_SMCSR);
+					mtd->oobsize = g_i32ParityNum[2][nuc980_nand->eBCHAlgo] + 8;
+					nuc980_layout_oob_table ( &nuc980_nand_oob, mtd->oobsize, g_i32ParityNum[2][nuc980_nand->eBCHAlgo] );
+					break;
+
+				default:
+					printk("WRONG NAND page Power-On-Setting (0x%x)\n", readl(REG_PWRON));
+			}
+		}
+		printk("nand: SMRA size %d, %d\n", mtd->oobsize, nuc980_nand_oob.eccbytes);
+	}
+
+#ifndef CONFIG_MTD_CMDLINE_PARTS
+#ifndef CONFIG_OF
+	nuc980_nand->parts = (struct mtd_partition*)partitions;
+	nuc980_nand->nr_parts = ARRAY_SIZE(partitions);
+#endif
+#endif
+
+	nuc980_nand->m_i32SMRASize = mtd->oobsize;
+	chip->ecc.bytes = nuc980_nand_oob.eccbytes;
+	chip->ecc.size  = mtd->writesize;
+
+	/* set BCH Tn */
+	switch (nuc980_nand->eBCHAlgo)
+	{
+		case eBCH_T8:
+			chip->ecc.strength  = 8;
+			mtd->bitflip_threshold = 6;
+			break;
+		case eBCH_T12:
+			chip->ecc.strength  = 12;
+			mtd->bitflip_threshold = 9;
+			break;
+		case eBCH_T24:
+			chip->ecc.strength  = 24;
+			mtd->bitflip_threshold = 18;
+			break;
+		default:
+			;
+	}
+
+	/* add mtd-id. The string should same as uboot definition */
+	mtd->name = "nand0";
+	ppdata.of_node = pdev->dev.of_node;
+
+	/* second phase scan */
+	if ( nand_scan_tail( &(nuc980_nand->mtd) ) ) {
+		retval = -ENXIO;
+		goto fail3;
+	}
+
+	if ( nuc980_nand->eBCHAlgo >= 0 )
+		nuc980_nand_hwecc_init (&(nuc980_nand->mtd));
+	else
+		nuc980_nand_hwecc_fini (&(nuc980_nand->mtd));
+
+	/* Doesn't handle subpage write */
+	mtd->subpage_sft = 0;
+	chip->subpagesize = mtd->writesize;
+
+	dump_chip_info( chip );
+
+	/* First look for RedBoot table or partitions on the command
+	 * line, these take precedence over device tree information */
+	mtd_device_parse_register(&(nuc980_nand->mtd), NULL, &ppdata, nuc980_nand->parts, nuc980_nand->nr_parts);
+
+	LEAVE();
+
+	dump_regs(__LINE__);
+
+	printk("fmi-sm: registered successfully! mtdid=%s\n", mtd->name);
+	return retval;
+
+fail3:
+fail2:
+fail1:
+	devm_kfree(&pdev->dev, nuc980_nand);//clyu
+	LEAVE();
+	return retval;
+}
+
+static int nuc980_nand_remove(struct platform_device *pdev)
+{
+	struct nuc980_nand_info *nuc980_nand = platform_get_drvdata(pdev);
+
+	struct mtd_info *mtd=&nuc980_nand->mtd;
+
+	nuc980_nand_hwecc_fini(mtd);
+
+	clk_disable(nuc980_nand->clk);
+	clk_put(nuc980_nand->clk);
+
+	dma_free_coherent(NULL, 512*16, nuc980_nand->pnand_vaddr, (dma_addr_t )nuc980_nand->pnand_phyaddr);
+
+	kfree(nuc980_nand);
+
+	platform_set_drvdata(pdev, NULL);
+
+	return 0;
+}
+
+/* PM Support */
+#ifdef CONFIG_PM
+static int nuc980_nand_suspend(struct platform_device *pdev, pm_message_t pm)
+{
+	struct nuc980_nand_info *nuc980_nand = platform_get_drvdata(pdev);
+
+	// For save, wait DMAC to ready
+	while ( readl(REG_NAND_DMACCSR) & 0x200 );
+	writel(0x0, REG_NFECR); /* write protect */
+	nuc980_nand_hwecc_fini(&nuc980_nand->mtd);
+	clk_disable(nuc980_nand->clk);
+
+	return 0;
+}
+
+static int nuc980_nand_resume(struct platform_device *pdev)
+{
+	struct nuc980_nand_info *nuc980_nand = platform_get_drvdata(pdev);
+
+	clk_enable(nuc980_nand->clk);
+	nuc980_nand_hwecc_init(&nuc980_nand->mtd);
+	writel(0x1, REG_NFECR); /* un-lock write protect */
+	nuc980_nand_dmac_init();
+
+
+	return 0;
+}
+
+#else
+#define nuc980_nand_suspend NULL
+#define nuc980_nand_resume NULL
+#endif
+
+static const struct of_device_id nuc980_fmi_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-fmi" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_fmi_of_match);
+
+static struct platform_driver nuc980_nand_driver = {
+		.driver = {
+		.name   = "nuc980-fmi",
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_fmi_of_match),
+		},
+		.probe      = nuc980_nand_probe,
+		.remove     = nuc980_nand_remove,
+		.suspend    = nuc980_nand_suspend,
+		.resume     = nuc980_nand_resume,
+};
+
+static int __init nuc980_nand_init(void)
+{
+	int ret;
+	printk("nuc980 mtd nand driver version: %s\n", NUC980_DRV_VERSION );
+
+	ret = platform_driver_register(&nuc980_nand_driver);
+	if (ret) {
+		printk("nand: failed to add device driver %s \n", nuc980_nand_driver.driver.name);
+		return ret;
+	}
+
+	return ret;
+}
+
+static void __exit nuc980_nand_exit(void)
+{
+	platform_driver_unregister(&nuc980_nand_driver);
+	printk("nand: unregistered successfully! \n");
+}
+
+module_init(nuc980_nand_init);
+module_exit(nuc980_nand_exit);
+
+MODULE_AUTHOR("nuvoton");
+MODULE_DESCRIPTION("nuc980 nand driver!");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-fmi");
diff -uprN linux-4.4.194/drivers/mtd/spi-nor/spi-nor.c NUC980-linux-4.4.194/drivers/mtd/spi-nor/spi-nor.c
--- linux-4.4.194/drivers/mtd/spi-nor/spi-nor.c	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/mtd/spi-nor/spi-nor.c	2019-12-29 19:12:21.000000000 -0800
@@ -845,6 +845,14 @@ static const struct flash_info spi_nor_i
 	{ "w25q128", INFO(0xef4018, 0, 64 * 1024, 256, SECT_4K) },
 	{ "w25q256", INFO(0xef4019, 0, 64 * 1024, 512, SECT_4K) },
 
+	/* XTX -- XT25x "blocks" are 64K, "sectors" are 4KiB */
+	{ "XT25F08BSSIGU", INFO(0x0b4013, 0, 64 * 1024,  16, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "XT25F16BSSIGU", INFO(0x0b4014, 0, 64 * 1024,  32, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "XT25F32BSSIGU", INFO(0x0b4015, 0, 64 * 1024,  64, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "XT25F64BSSIGU", INFO(0x0b4016, 0, 64 * 1024,  128, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "XT25F128BSSIGU", INFO(0x0b4017, 0, 64 * 1024,  256, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "XT25F256BSSIGU", INFO(0x0b4018, 0, 64 * 1024,  512, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+
 	/* Catalyst / On Semiconductor -- non-JEDEC */
 	{ "cat25c11", CAT25_INFO(  16, 8, 16, 1, SPI_NOR_NO_ERASE | SPI_NOR_NO_FR) },
 	{ "cat25c03", CAT25_INFO(  32, 8, 16, 2, SPI_NOR_NO_ERASE | SPI_NOR_NO_FR) },
diff -uprN linux-4.4.194/drivers/net/can/Kconfig NUC980-linux-4.4.194/drivers/net/can/Kconfig
--- linux-4.4.194/drivers/net/can/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/net/can/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -153,6 +153,8 @@ source "drivers/net/can/sja1000/Kconfig"
 
 source "drivers/net/can/c_can/Kconfig"
 
+source "drivers/net/can/nuc980_can/Kconfig"
+
 source "drivers/net/can/m_can/Kconfig"
 
 source "drivers/net/can/cc770/Kconfig"
diff -uprN linux-4.4.194/drivers/net/can/Makefile NUC980-linux-4.4.194/drivers/net/can/Makefile
--- linux-4.4.194/drivers/net/can/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/net/can/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -17,6 +17,7 @@ obj-y				+= softing/
 obj-$(CONFIG_CAN_SJA1000)	+= sja1000/
 obj-$(CONFIG_CAN_MSCAN)		+= mscan/
 obj-$(CONFIG_CAN_C_CAN)		+= c_can/
+obj-$(CONFIG_NUC980_CAN)        += nuc980_can/
 obj-$(CONFIG_CAN_M_CAN)		+= m_can/
 obj-$(CONFIG_CAN_CC770)		+= cc770/
 obj-$(CONFIG_CAN_AT91)		+= at91_can.o
diff -uprN linux-4.4.194/drivers/net/can/nuc980_can/Kconfig NUC980-linux-4.4.194/drivers/net/can/nuc980_can/Kconfig
--- linux-4.4.194/drivers/net/can/nuc980_can/Kconfig	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/can/nuc980_can/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,119 @@
+menuconfig NUC980_CAN
+	tristate "NUC980 CAN0~CAN3 devices"
+	depends on HAS_IOMEM
+
+if NUC980_CAN
+
+config NUC980_CAN0
+	bool "NUC980 CAN0 support"
+	help
+	  This selects NUC980 CAN0 driver
+
+config ENABLE_CAN0_RX_WAKEUP
+	bool "Enable CAN0 wake-up function"
+	depends on NUC980_CAN0
+	help
+	  This selects NUC980 CAN0 wake-up function
+
+choice
+	prompt "NUC980 CAN0 pin selection"
+	default NUC980_CAN0_PC
+	depends on NUC980_CAN0
+	help
+	  Select CAN0 multi-function pin.
+
+	config NUC980_CAN0_PC
+		bool "Rx:PC3, Tx:PC4"
+	config NUC980_CAN0_PD
+		bool "Rx:PD6, Tx:PD7"
+	config NUC980_CAN0_PG
+		bool "Rx:PG11, Tx:PG12"
+	config NUC980_CAN0_PE
+		bool "Rx:PE0, Tx:PE1"
+endchoice
+
+config NUC980_CAN1
+	bool "NUC980 CAN1 support"
+	help
+	  This selects NUC980 CAN1 driver
+
+config ENABLE_CAN1_RX_WAKEUP
+	bool "Enable CAN1 wake-up function"
+	depends on NUC980_CAN1
+	help
+	  This selects NUC980 CAN1 wake-up function
+
+choice
+	prompt "NUC980 CAN1 pin selection"
+	default NUC980_CAN1_PA
+	depends on NUC980_CAN1
+	help
+	  Select CAN1 multi-function pin.
+
+	config NUC980_CAN1_PA
+		bool "Rx:PA13, Tx:PA14"
+	config NUC980_CAN1_PD
+		bool "Rx:PD14, Tx:PD15"
+	config NUC980_CAN1_PG
+		bool "Rx:PG13, Tx:PG14"
+	config NUC980_CAN1_PE
+		bool "Rx:PE2, Tx:PE3"
+endchoice
+
+config NUC980_CAN2
+	bool "NUC980 CAN2 support"
+	help
+	  This selects NUC980 CAN2 driver
+
+config ENABLE_CAN2_RX_WAKEUP
+	bool "Enable CAN2 wake-up function"
+	depends on NUC980_CAN2
+	help
+	  This selects NUC980 CAN2 wake-up function
+
+choice
+	prompt "NUC980 CAN2 pin selection"
+	default NUC980_CAN2_PA
+	depends on NUC980_CAN2
+	help
+	  Select CAN2 multi-function pin.
+
+	config NUC980_CAN2_PA
+		bool "Rx:PA15, Tx:PG10"
+	config NUC980_CAN2_PB
+		bool "Rx:PB1, Tx:PB3"
+	config NUC980_CAN2_PB_PC
+		bool "Rx:PB8, Tx:PC0"
+	config NUC980_CAN2_PD
+		bool "Rx:PD12, Tx:PD13"
+	config NUC980_CAN2_PE
+		bool "Rx:PE4, Tx:PE5"
+endchoice
+
+config NUC980_CAN3
+	bool "NUC980 CAN3 support"
+	help
+	  This selects NUC980 CAN3 driver
+
+config ENABLE_CAN3_RX_WAKEUP
+	bool "Enable CAN3 wake-up function"
+	depends on NUC980_CAN3
+	help
+	  This selects NUC980 CAN3 wake-up function
+
+choice
+	prompt "NUC980 CAN3 pin selection"
+	default NUC980_CAN3_PA
+	depends on NUC980_CAN3
+	help
+	  Select CAN3 multi-function pin.
+
+	config NUC980_CAN3_PA
+		bool "Rx:PA0, Tx:PA1"
+	config NUC980_CAN3_PE_0
+		bool "Rx:PE6, Tx:PE7"
+	config NUC980_CAN3_PE_1
+		bool "Rx:PE10, Tx:PE12"
+endchoice
+
+endif
diff -uprN linux-4.4.194/drivers/net/can/nuc980_can/Makefile NUC980-linux-4.4.194/drivers/net/can/nuc980_can/Makefile
--- linux-4.4.194/drivers/net/can/nuc980_can/Makefile	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/can/nuc980_can/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,12 @@
+#
+#  Makefile for the NUC980 CAN controller drivers.
+#
+
+
+obj-$(CONFIG_NUC980_CAN) += nuc980_can.o
+obj-$(CONFIG_NUC980_CAN0) += nuc980_can0_platform.o
+obj-$(CONFIG_NUC980_CAN1) += nuc980_can1_platform.o
+obj-$(CONFIG_NUC980_CAN2) += nuc980_can2_platform.o
+obj-$(CONFIG_NUC980_CAN3) += nuc980_can3_platform.o
+
+ccflags-$(CONFIG_CAN_DEBUG_DEVICES) := -DDEBUG
diff -uprN linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can0_platform.c NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can0_platform.c
--- linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can0_platform.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can0_platform.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,284 @@
+/*
+ *  linux/drivers/net/can/nuc980_can/nuc980_can0_platform.c
+ *
+ *  NUC980 CAN driver
+ *
+ *
+ *  Copyright (C) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/if_arp.h>
+#include <linux/if_ether.h>
+#include <linux/list.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_irq.h>
+#include <linux/pinctrl/consumer.h>
+
+#include <linux/can/dev.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+
+#include "nuc980_can.h"
+
+#define CAN_RAMINIT_START_MASK(i)	(1 << (i))
+
+
+static u16 c_can_plat_read_reg_aligned_to_32bit(struct c_can_priv *priv,
+						enum reg index)
+{
+	return readw(priv->base + 2 * priv->regs[index]);
+}
+
+static void c_can_plat_write_reg_aligned_to_32bit(struct c_can_priv *priv,
+						enum reg index, u16 val)
+{
+	writew(val, priv->base + 2 * priv->regs[index]);
+}
+
+static struct platform_device_id nuc980_can0_driver_ids[] = {
+	[NUC980_CAN0] = {
+		.name = "nuc980-can0",
+		.driver_data = NUC980_CAN0,
+	},
+	{ },
+};
+MODULE_DEVICE_TABLE(platform, nuc980_can0_driver_ids);
+
+static const struct of_device_id nuc980_can0_of_table[] = {
+	{ .compatible = "nuvoton,nuc980-can0", .data = &nuc980_can0_driver_ids[NUC980_CAN0] },
+	{ /* sentinel */ },
+};
+MODULE_DEVICE_TABLE(of, nuc980_can0_of_table);
+
+static int c_can_plat_probe(struct platform_device *pdev)
+{
+	int ret;
+	void __iomem *addr;
+	struct net_device *dev;
+	struct c_can_priv *priv;
+	const struct of_device_id *match;
+	const struct platform_device_id *id;
+	struct pinctrl *pinctrl;
+	struct resource *mem;
+	int irq;
+	struct clk *clk;
+	int retval = 0;
+
+	if (pdev->dev.of_node) {
+		match = of_match_device(nuc980_can0_of_table, &pdev->dev);
+		if (!match) {
+			dev_err(&pdev->dev, "Failed to find matching dt id\n");
+			ret = -EINVAL;
+			goto exit;
+		}
+		id = match->data;
+	} else {
+		id = platform_get_device_id(pdev);
+	}
+
+#ifdef CONFIG_USE_OF
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+	#ifdef CONFIG_NUC980_CAN0_PC
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can0-PC");
+	#elif defined(CONFIG_NUC980_CAN0_PD)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can0-PD");
+	#elif defined(CONFIG_NUC980_CAN0_PG)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can0-PG");
+	#elif defined(CONFIG_NUC980_CAN0_PE)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can0-PE");
+	#endif
+#endif
+
+	if (IS_ERR(pinctrl))
+	{
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		retval = PTR_ERR(pinctrl);
+	}
+
+	clk = clk_get(NULL, "can0");
+	clk_prepare(clk);
+	clk_enable(clk);
+
+	/* get the platform data */
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	irq = platform_get_irq(pdev, 0);
+	if (!mem || irq <= 0) {
+		ret = -ENODEV;
+		goto exit_free_clk;
+	}
+
+	if (!request_mem_region(mem->start, resource_size(mem),
+				KBUILD_MODNAME)) {
+		dev_err(&pdev->dev, "resource unavailable\n");
+		ret = -ENODEV;
+		goto exit_free_clk;
+	}
+
+	addr = ioremap(mem->start, resource_size(mem));
+	if (!addr) {
+		dev_err(&pdev->dev, "failed to map can port\n");
+		ret = -ENOMEM;
+		goto exit_release_mem;
+	}
+
+	/* allocate the c_can device */
+	dev = alloc_c_can_dev();
+	if (!dev) {
+		ret = -ENOMEM;
+		goto exit_iounmap;
+	}
+
+	priv = netdev_priv(dev);
+
+	priv->regs = reg_map_c_can;
+	priv->read_reg = c_can_plat_read_reg_aligned_to_32bit;
+	priv->write_reg = c_can_plat_write_reg_aligned_to_32bit;
+
+	dev->irq = irq;
+	priv->base = addr;
+	priv->device = &pdev->dev;
+	priv->can.clock.freq = clk_get_rate(clk);
+	priv->priv = clk;
+	priv->type = id->driver_data;
+
+	platform_set_drvdata(pdev, dev);
+	SET_NETDEV_DEV(dev, &pdev->dev);
+
+	ret = register_c_can_dev(dev);
+	if (ret) {
+		dev_err(&pdev->dev, "registering %s failed (err=%d)\n",
+			KBUILD_MODNAME, ret);
+		goto exit_free_device;
+	}
+
+	dev_info(&pdev->dev, "%s device registered (regs=%p, irq=%d)\n",
+		 KBUILD_MODNAME, priv->base, dev->irq);
+	return 0;
+
+exit_free_device:
+	platform_set_drvdata(pdev, NULL);
+	free_c_can_dev(dev);
+exit_iounmap:
+	iounmap(addr);
+exit_release_mem:
+	release_mem_region(mem->start, resource_size(mem));
+exit_free_clk:
+	clk_put(clk);
+exit:
+	dev_err(&pdev->dev, "probe failed\n");
+
+	return ret;
+}
+
+static int c_can_plat_remove(struct platform_device *pdev)
+{
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct resource *mem;
+
+	unregister_c_can_dev(dev);
+	platform_set_drvdata(pdev, NULL);
+
+	free_c_can_dev(dev);
+	iounmap(priv->base);
+
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	release_mem_region(mem->start, resource_size(mem));
+
+	clk_put(priv->priv);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int c_can_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	int ret;
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(ndev);
+
+	#ifdef CONFIG_ENABLE_CAN0_RX_WAKEUP
+	__raw_writel(0x1,(priv->base+0x168));
+	__raw_writel((0x1<<8) | __raw_readl(REG_WKUPSER1),REG_WKUPSER1);
+	enable_irq_wake(ndev->irq);
+	#endif
+
+	if (netif_running(ndev)) {
+		netif_stop_queue(ndev);
+		netif_device_detach(ndev);
+	}
+
+	ret = c_can_power_down(ndev);
+	if (ret) {
+		netdev_err(ndev, "failed to enter power down mode\n");
+		return ret;
+	}
+
+	priv->can.state = CAN_STATE_SLEEPING;
+
+	return 0;
+}
+
+static int c_can_resume(struct platform_device *pdev)
+{
+	int ret;
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(ndev);
+
+	ret = c_can_power_up(ndev);
+	if (ret) {
+		netdev_err(ndev, "Still in power down mode\n");
+		return ret;
+	}
+
+	priv->can.state = CAN_STATE_ERROR_ACTIVE;
+
+	if (netif_running(ndev)) {
+		netif_device_attach(ndev);
+		netif_start_queue(ndev);
+	}
+
+	return 0;
+}
+#else
+#define c_can_suspend NULL
+#define c_can_resume NULL
+#endif
+
+static struct platform_driver nuc980_can0_driver = {
+		.driver 	= {
+			.name	= "nuc980-can0",
+			.owner	= THIS_MODULE,
+			.of_match_table = of_match_ptr(nuc980_can0_of_table),
+		},
+	.probe = c_can_plat_probe,
+	.remove = c_can_plat_remove,
+	.suspend = c_can_suspend,
+	.resume = c_can_resume,
+	.id_table = &nuc980_can0_driver_ids[NUC980_CAN0],
+};
+
+
+module_platform_driver(nuc980_can0_driver);
+
+MODULE_AUTHOR("nuvoton");
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Platform CAN bus driver for NUC980 controller");
diff -uprN linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can1_platform.c NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can1_platform.c
--- linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can1_platform.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can1_platform.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,300 @@
+/*
+ *  linux/drivers/net/can/nuc980_can/nuc980_can1_platform.c
+ *
+ *  NUC980 CAN driver
+ *
+ *
+ *  Copyright (C) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/if_arp.h>
+#include <linux/if_ether.h>
+#include <linux/list.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_irq.h>
+#include <linux/pinctrl/consumer.h>
+
+#include <linux/can/dev.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+
+#include "nuc980_can.h"
+
+#define CAN_RAMINIT_START_MASK(i)	(1 << (i))
+
+static u16 c_can_plat_read_reg_aligned_to_32bit(struct c_can_priv *priv,
+						enum reg index)
+{
+	return readw(priv->base + 2 * priv->regs[index]);
+}
+
+static void c_can_plat_write_reg_aligned_to_32bit(struct c_can_priv *priv,
+						enum reg index, u16 val)
+{
+	writew(val, priv->base + 2 * priv->regs[index]);
+}
+
+#if 0
+static void c_can_hw_raminit(const struct c_can_priv *priv, bool enable)
+{
+	u32 val;
+
+	val = readl(priv->raminit_ctrlreg);
+	if (enable)
+		val |= CAN_RAMINIT_START_MASK(priv->instance);
+	else
+		val &= ~CAN_RAMINIT_START_MASK(priv->instance);
+	writel(val, priv->raminit_ctrlreg);
+}
+#endif
+
+static struct platform_device_id nuc980_can1_driver_ids[] = {
+	[NUC980_CAN1] = {
+		.name = "nuc980-can1",
+		.driver_data = NUC980_CAN1,
+	},
+	{ },
+};
+MODULE_DEVICE_TABLE(platform, nuc980_can1_driver_ids);
+
+static const struct of_device_id nuc980_can1_of_table[] = {
+	{ .compatible = "nuvoton,nuc980-can1", .data = &nuc980_can1_driver_ids[NUC980_CAN1] },
+	{ /* sentinel */ },
+};
+MODULE_DEVICE_TABLE(of, nuc980_can1_of_table);
+
+static int c_can_plat_probe(struct platform_device *pdev)
+{
+	int ret;
+	void __iomem *addr;
+	struct net_device *dev;
+	struct c_can_priv *priv;
+	const struct of_device_id *match;
+	const struct platform_device_id *id;
+	struct resource *mem;
+	int irq;
+	struct clk *clk;
+	int retval = 0;
+	struct pinctrl *pinctrl;
+
+	if (pdev->dev.of_node) {
+		match = of_match_device(nuc980_can1_of_table, &pdev->dev);
+		if (!match) {
+			dev_err(&pdev->dev, "Failed to find matching dt id\n");
+			ret = -EINVAL;
+			goto exit;
+		}
+		id = match->data;
+	} else {
+	id = platform_get_device_id(pdev);
+	}
+
+#ifdef CONFIG_USE_OF
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+	#ifdef CONFIG_NUC980_CAN1_PA
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can1-PA");
+	#elif defined(CONFIG_NUC980_CAN1_PD)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can1-PD");
+	#elif defined(CONFIG_NUC980_CAN1_PG)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can1-PG");
+	#elif defined(CONFIG_NUC980_CAN1_PE)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can1-PE");
+	#endif
+#endif
+
+	if (IS_ERR(pinctrl))
+	{
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		retval = PTR_ERR(pinctrl);
+	}
+
+	/* get the appropriate clk */
+	clk = clk_get(NULL, "can1");
+	clk_prepare(clk);
+	clk_enable(clk);
+
+	/* get the platform data */
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	irq = platform_get_irq(pdev, 0);
+	if (!mem || irq <= 0) {
+		ret = -ENODEV;
+		goto exit_free_clk;
+	}
+
+	if (!request_mem_region(mem->start, resource_size(mem),
+				KBUILD_MODNAME)) {
+		dev_err(&pdev->dev, "resource unavailable\n");
+		ret = -ENODEV;
+		goto exit_free_clk;
+	}
+
+	addr = ioremap(mem->start, resource_size(mem));
+	if (!addr) {
+		dev_err(&pdev->dev, "failed to map can port\n");
+		ret = -ENOMEM;
+		goto exit_release_mem;
+	}
+
+	/* allocate the c_can device */
+	dev = alloc_c_can_dev();
+	if (!dev) {
+		ret = -ENOMEM;
+		goto exit_iounmap;
+	}
+
+	priv = netdev_priv(dev);
+
+	priv->regs = reg_map_c_can;
+	priv->read_reg = c_can_plat_read_reg_aligned_to_32bit;
+	priv->write_reg = c_can_plat_write_reg_aligned_to_32bit;
+
+	dev->irq = irq;
+	priv->base = addr;
+	priv->device = &pdev->dev;
+	priv->can.clock.freq = clk_get_rate(clk);
+	priv->priv = clk;
+	priv->type = id->driver_data;
+
+	platform_set_drvdata(pdev, dev);
+	SET_NETDEV_DEV(dev, &pdev->dev);
+
+	ret = register_c_can_dev(dev);
+	if (ret) {
+		dev_err(&pdev->dev, "registering %s failed (err=%d)\n",
+			KBUILD_MODNAME, ret);
+		goto exit_free_device;
+	}
+
+	dev_info(&pdev->dev, "%s device registered (regs=%p, irq=%d)\n",
+		 KBUILD_MODNAME, priv->base, dev->irq);
+	return 0;
+
+exit_free_device:
+	platform_set_drvdata(pdev, NULL);
+	free_c_can_dev(dev);
+exit_iounmap:
+	iounmap(addr);
+exit_release_mem:
+	release_mem_region(mem->start, resource_size(mem));
+exit_free_clk:
+	clk_put(clk);
+exit:
+	dev_err(&pdev->dev, "probe failed\n");
+
+	return ret;
+}
+
+static int c_can_plat_remove(struct platform_device *pdev)
+{
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct resource *mem;
+
+	unregister_c_can_dev(dev);
+	platform_set_drvdata(pdev, NULL);
+
+	free_c_can_dev(dev);
+	iounmap(priv->base);
+
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	release_mem_region(mem->start, resource_size(mem));
+
+	clk_put(priv->priv);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int c_can_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	int ret;
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(ndev);
+
+	#ifdef CONFIG_ENABLE_CAN1_RX_WAKEUP
+	__raw_writel(0x1,(priv->base+0x168));
+	__raw_writel((0x1<<9) | __raw_readl(REG_WKUPSER1),REG_WKUPSER1);
+	enable_irq_wake(ndev->irq);
+	#endif
+
+	if (netif_running(ndev)) {
+		netif_stop_queue(ndev);
+		netif_device_detach(ndev);
+	}
+
+	ret = c_can_power_down(ndev);
+	if (ret) {
+		netdev_err(ndev, "failed to enter power down mode\n");
+		return ret;
+	}
+
+	priv->can.state = CAN_STATE_SLEEPING;
+
+	return 0;
+}
+
+static int c_can_resume(struct platform_device *pdev)
+{
+	int ret;
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(ndev);
+
+	ret = c_can_power_up(ndev);
+	if (ret) {
+		netdev_err(ndev, "Still in power down mode\n");
+		return ret;
+	}
+
+	priv->can.state = CAN_STATE_ERROR_ACTIVE;
+
+	if (netif_running(ndev)) {
+		netif_device_attach(ndev);
+		netif_start_queue(ndev);
+	}
+
+	return 0;
+}
+#else
+#define c_can_suspend NULL
+#define c_can_resume NULL
+#endif
+
+
+static struct platform_driver nuc980_can1_driver = {
+		.driver 	= {
+			.name	= "nuc980-can1",
+			.owner	= THIS_MODULE,
+			.of_match_table = of_match_ptr(nuc980_can1_of_table),
+		},
+	.probe = c_can_plat_probe,
+	.remove = c_can_plat_remove,
+	.suspend = c_can_suspend,
+	.resume = c_can_resume,
+	.id_table = &nuc980_can1_driver_ids[NUC980_CAN1],
+};
+
+
+module_platform_driver(nuc980_can1_driver);
+
+
+MODULE_AUTHOR("nuvoton");
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Platform CAN bus driver for NUC980 controller");
diff -uprN linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can2_platform.c NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can2_platform.c
--- linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can2_platform.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can2_platform.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,286 @@
+/*
+ *  linux/drivers/net/can/nuc980_can/nuc980_can2_platform.c
+ *
+ *  NUC980 CAN driver
+ *
+ *
+ *  Copyright (C) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/if_arp.h>
+#include <linux/if_ether.h>
+#include <linux/list.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_irq.h>
+#include <linux/pinctrl/consumer.h>
+
+#include <linux/can/dev.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+
+#include "nuc980_can.h"
+
+#define CAN_RAMINIT_START_MASK(i)	(1 << (i))
+
+
+static u16 c_can_plat_read_reg_aligned_to_32bit(struct c_can_priv *priv,
+						enum reg index)
+{
+	return readw(priv->base + 2 * priv->regs[index]);
+}
+
+static void c_can_plat_write_reg_aligned_to_32bit(struct c_can_priv *priv,
+						enum reg index, u16 val)
+{
+	writew(val, priv->base + 2 * priv->regs[index]);
+}
+
+static struct platform_device_id nuc980_can2_driver_ids[] = {
+	[NUC980_CAN2] = {
+		.name = "nuc980-can2",
+		.driver_data = NUC980_CAN2,
+	},
+	{ },
+};
+MODULE_DEVICE_TABLE(platform, nuc980_can2_driver_ids);
+
+static const struct of_device_id nuc980_can2_of_table[] = {
+	{ .compatible = "nuvoton,nuc980-can2", .data = &nuc980_can2_driver_ids[NUC980_CAN2] },
+	{ /* sentinel */ },
+};
+MODULE_DEVICE_TABLE(of, nuc980_can2_of_table);
+
+static int c_can_plat_probe(struct platform_device *pdev)
+{
+	int ret;
+	void __iomem *addr;
+	struct net_device *dev;
+	struct c_can_priv *priv;
+	const struct of_device_id *match;
+	const struct platform_device_id *id;
+	struct pinctrl *pinctrl;
+	struct resource *mem;
+	int irq;
+	struct clk *clk;
+	int retval = 0;
+
+	if (pdev->dev.of_node) {
+		match = of_match_device(nuc980_can2_of_table, &pdev->dev);
+		if (!match) {
+			dev_err(&pdev->dev, "Failed to find matching dt id\n");
+			ret = -EINVAL;
+			goto exit;
+		}
+		id = match->data;
+	} else {
+		id = platform_get_device_id(pdev);
+	}
+
+#ifdef CONFIG_USE_OF
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+	#ifdef CONFIG_NUC980_CAN2_PA
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can2-PA");
+	#elif defined(CONFIG_NUC980_CAN2_PB)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can2-PB");
+	#elif defined(CONFIG_NUC980_CAN2_PB_PC)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can2-PB_PC");
+	#elif defined(CONFIG_NUC980_CAN2_PD)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can2-PD");
+	#elif defined(CONFIG_NUC980_CAN2_PE)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can2-PE");
+	#endif
+#endif
+
+	if (IS_ERR(pinctrl))
+	{
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		retval = PTR_ERR(pinctrl);
+	}
+
+	clk = clk_get(NULL, "can2");
+	clk_prepare(clk);
+	clk_enable(clk);
+
+	/* get the platform data */
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	irq = platform_get_irq(pdev, 0);
+	if (!mem || irq <= 0) {
+		ret = -ENODEV;
+		goto exit_free_clk;
+	}
+
+	if (!request_mem_region(mem->start, resource_size(mem),
+				KBUILD_MODNAME)) {
+		dev_err(&pdev->dev, "resource unavailable\n");
+		ret = -ENODEV;
+		goto exit_free_clk;
+	}
+
+	addr = ioremap(mem->start, resource_size(mem));
+	if (!addr) {
+		dev_err(&pdev->dev, "failed to map can port\n");
+		ret = -ENOMEM;
+		goto exit_release_mem;
+	}
+
+	/* allocate the c_can device */
+	dev = alloc_c_can_dev();
+	if (!dev) {
+		ret = -ENOMEM;
+		goto exit_iounmap;
+	}
+
+	priv = netdev_priv(dev);
+
+	priv->regs = reg_map_c_can;
+	priv->read_reg = c_can_plat_read_reg_aligned_to_32bit;
+	priv->write_reg = c_can_plat_write_reg_aligned_to_32bit;
+
+	dev->irq = irq;
+	priv->base = addr;
+	priv->device = &pdev->dev;
+	priv->can.clock.freq = clk_get_rate(clk);
+	priv->priv = clk;
+	priv->type = id->driver_data;
+
+	platform_set_drvdata(pdev, dev);
+	SET_NETDEV_DEV(dev, &pdev->dev);
+
+	ret = register_c_can_dev(dev);
+	if (ret) {
+		dev_err(&pdev->dev, "registering %s failed (err=%d)\n",
+			KBUILD_MODNAME, ret);
+		goto exit_free_device;
+	}
+
+	dev_info(&pdev->dev, "%s device registered (regs=%p, irq=%d)\n",
+		 KBUILD_MODNAME, priv->base, dev->irq);
+	return 0;
+
+exit_free_device:
+	platform_set_drvdata(pdev, NULL);
+	free_c_can_dev(dev);
+exit_iounmap:
+	iounmap(addr);
+exit_release_mem:
+	release_mem_region(mem->start, resource_size(mem));
+exit_free_clk:
+	clk_put(clk);
+exit:
+	dev_err(&pdev->dev, "probe failed\n");
+
+	return ret;
+}
+
+static int c_can_plat_remove(struct platform_device *pdev)
+{
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct resource *mem;
+
+	unregister_c_can_dev(dev);
+	platform_set_drvdata(pdev, NULL);
+
+	free_c_can_dev(dev);
+	iounmap(priv->base);
+
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	release_mem_region(mem->start, resource_size(mem));
+
+	clk_put(priv->priv);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int c_can_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	int ret;
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(ndev);
+
+	#ifdef CONFIG_ENABLE_CAN2_RX_WAKEUP
+	__raw_writel(0x1,(priv->base+0x168));
+	__raw_writel((0x1<<10) | __raw_readl(REG_WKUPSER1),REG_WKUPSER1);
+	enable_irq_wake(ndev->irq);
+	#endif
+
+	if (netif_running(ndev)) {
+		netif_stop_queue(ndev);
+		netif_device_detach(ndev);
+	}
+
+	ret = c_can_power_down(ndev);
+	if (ret) {
+		netdev_err(ndev, "failed to enter power down mode\n");
+		return ret;
+	}
+
+	priv->can.state = CAN_STATE_SLEEPING;
+
+	return 0;
+}
+
+static int c_can_resume(struct platform_device *pdev)
+{
+	int ret;
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(ndev);
+
+	ret = c_can_power_up(ndev);
+	if (ret) {
+		netdev_err(ndev, "Still in power down mode\n");
+		return ret;
+	}
+
+	priv->can.state = CAN_STATE_ERROR_ACTIVE;
+
+	if (netif_running(ndev)) {
+		netif_device_attach(ndev);
+		netif_start_queue(ndev);
+	}
+
+	return 0;
+}
+#else
+#define c_can_suspend NULL
+#define c_can_resume NULL
+#endif
+
+static struct platform_driver nuc980_can2_driver = {
+		.driver 	= {
+			.name	= "nuc980-can2",
+			.owner	= THIS_MODULE,
+			.of_match_table = of_match_ptr(nuc980_can2_of_table),
+		},
+	.probe = c_can_plat_probe,
+	.remove = c_can_plat_remove,
+	.suspend = c_can_suspend,
+	.resume = c_can_resume,
+	.id_table = &nuc980_can2_driver_ids[NUC980_CAN2],
+};
+
+
+module_platform_driver(nuc980_can2_driver);
+
+MODULE_AUTHOR("nuvoton");
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Platform CAN bus driver for NUC980 controller");
diff -uprN linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can3_platform.c NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can3_platform.c
--- linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can3_platform.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can3_platform.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,282 @@
+/*
+ *  linux/drivers/net/can/nuc980_can/nuc980_can3_platform.c
+ *
+ *  NUC980 CAN driver
+ *
+ *
+ *  Copyright (C) 2014 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/if_arp.h>
+#include <linux/if_ether.h>
+#include <linux/list.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_irq.h>
+#include <linux/pinctrl/consumer.h>
+
+#include <linux/can/dev.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+
+#include "nuc980_can.h"
+
+#define CAN_RAMINIT_START_MASK(i)	(1 << (i))
+
+
+static u16 c_can_plat_read_reg_aligned_to_32bit(struct c_can_priv *priv,
+						enum reg index)
+{
+	return readw(priv->base + 2 * priv->regs[index]);
+}
+
+static void c_can_plat_write_reg_aligned_to_32bit(struct c_can_priv *priv,
+						enum reg index, u16 val)
+{
+	writew(val, priv->base + 2 * priv->regs[index]);
+}
+
+static struct platform_device_id nuc980_can3_driver_ids[] = {
+	[NUC980_CAN3] = {
+		.name = "nuc980-can3",
+		.driver_data = NUC980_CAN3,
+	},
+	{ },
+};
+MODULE_DEVICE_TABLE(platform, nuc980_can3_driver_ids);
+
+static const struct of_device_id nuc980_can3_of_table[] = {
+	{ .compatible = "nuvoton,nuc980-can3", .data = &nuc980_can3_driver_ids[NUC980_CAN3] },
+	{ /* sentinel */ },
+};
+MODULE_DEVICE_TABLE(of, nuc980_can3_of_table);
+
+static int c_can_plat_probe(struct platform_device *pdev)
+{
+	int ret;
+	void __iomem *addr;
+	struct net_device *dev;
+	struct c_can_priv *priv;
+	const struct of_device_id *match;
+	const struct platform_device_id *id;
+	struct pinctrl *pinctrl;
+	struct resource *mem;
+	int irq;
+	struct clk *clk;
+	int retval = 0;
+
+	if (pdev->dev.of_node) {
+		match = of_match_device(nuc980_can3_of_table, &pdev->dev);
+		if (!match) {
+			dev_err(&pdev->dev, "Failed to find matching dt id\n");
+			ret = -EINVAL;
+			goto exit;
+		}
+		id = match->data;
+	} else {
+		id = platform_get_device_id(pdev);
+	}
+
+#ifdef CONFIG_USE_OF
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+	#ifdef CONFIG_NUC980_CAN3_PA
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can3-PA");
+	#elif defined(CONFIG_NUC980_CAN3_PE_0)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can3-PE_0");
+	#elif defined(CONFIG_NUC980_CAN3_PE_1)
+		pinctrl = devm_pinctrl_get_select(&pdev->dev, "can3-PE_1");
+	#endif
+#endif
+
+	if (IS_ERR(pinctrl))
+	{
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		retval = PTR_ERR(pinctrl);
+	}
+
+	clk = clk_get(NULL, "can3");
+	clk_prepare(clk);
+	clk_enable(clk);
+
+	/* get the platform data */
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	irq = platform_get_irq(pdev, 0);
+	if (!mem || irq <= 0) {
+		ret = -ENODEV;
+		goto exit_free_clk;
+	}
+
+	if (!request_mem_region(mem->start, resource_size(mem),
+				KBUILD_MODNAME)) {
+		dev_err(&pdev->dev, "resource unavailable\n");
+		ret = -ENODEV;
+		goto exit_free_clk;
+	}
+
+	addr = ioremap(mem->start, resource_size(mem));
+	if (!addr) {
+		dev_err(&pdev->dev, "failed to map can port\n");
+		ret = -ENOMEM;
+		goto exit_release_mem;
+	}
+
+	/* allocate the c_can device */
+	dev = alloc_c_can_dev();
+	if (!dev) {
+		ret = -ENOMEM;
+		goto exit_iounmap;
+	}
+
+	priv = netdev_priv(dev);
+
+	priv->regs = reg_map_c_can;
+	priv->read_reg = c_can_plat_read_reg_aligned_to_32bit;
+	priv->write_reg = c_can_plat_write_reg_aligned_to_32bit;
+
+	dev->irq = irq;
+	priv->base = addr;
+	priv->device = &pdev->dev;
+	priv->can.clock.freq = clk_get_rate(clk);
+	priv->priv = clk;
+	priv->type = id->driver_data;
+
+	platform_set_drvdata(pdev, dev);
+	SET_NETDEV_DEV(dev, &pdev->dev);
+
+	ret = register_c_can_dev(dev);
+	if (ret) {
+		dev_err(&pdev->dev, "registering %s failed (err=%d)\n",
+			KBUILD_MODNAME, ret);
+		goto exit_free_device;
+	}
+
+	dev_info(&pdev->dev, "%s device registered (regs=%p, irq=%d)\n",
+		 KBUILD_MODNAME, priv->base, dev->irq);
+	return 0;
+
+exit_free_device:
+	platform_set_drvdata(pdev, NULL);
+	free_c_can_dev(dev);
+exit_iounmap:
+	iounmap(addr);
+exit_release_mem:
+	release_mem_region(mem->start, resource_size(mem));
+exit_free_clk:
+	clk_put(clk);
+exit:
+	dev_err(&pdev->dev, "probe failed\n");
+
+	return ret;
+}
+
+static int c_can_plat_remove(struct platform_device *pdev)
+{
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct resource *mem;
+
+	unregister_c_can_dev(dev);
+	platform_set_drvdata(pdev, NULL);
+
+	free_c_can_dev(dev);
+	iounmap(priv->base);
+
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	release_mem_region(mem->start, resource_size(mem));
+
+	clk_put(priv->priv);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int c_can_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	int ret;
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(ndev);
+
+	#ifdef CONFIG_ENABLE_CAN3_RX_WAKEUP
+	__raw_writel(0x1,(priv->base+0x168));
+	__raw_writel((0x1<<11) | __raw_readl(REG_WKUPSER1),REG_WKUPSER1);
+	enable_irq_wake(ndev->irq);
+	#endif
+
+	if (netif_running(ndev)) {
+		netif_stop_queue(ndev);
+		netif_device_detach(ndev);
+	}
+
+	ret = c_can_power_down(ndev);
+	if (ret) {
+		netdev_err(ndev, "failed to enter power down mode\n");
+		return ret;
+	}
+
+	priv->can.state = CAN_STATE_SLEEPING;
+
+	return 0;
+}
+
+static int c_can_resume(struct platform_device *pdev)
+{
+	int ret;
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct c_can_priv *priv = netdev_priv(ndev);
+
+	ret = c_can_power_up(ndev);
+	if (ret) {
+		netdev_err(ndev, "Still in power down mode\n");
+		return ret;
+	}
+
+	priv->can.state = CAN_STATE_ERROR_ACTIVE;
+
+	if (netif_running(ndev)) {
+		netif_device_attach(ndev);
+		netif_start_queue(ndev);
+	}
+
+	return 0;
+}
+#else
+#define c_can_suspend NULL
+#define c_can_resume NULL
+#endif
+
+static struct platform_driver nuc980_can3_driver = {
+		.driver 	= {
+			.name	= "nuc980-can3",
+			.owner	= THIS_MODULE,
+			.of_match_table = of_match_ptr(nuc980_can3_of_table),
+		},
+	.probe = c_can_plat_probe,
+	.remove = c_can_plat_remove,
+	.suspend = c_can_suspend,
+	.resume = c_can_resume,
+	.id_table = &nuc980_can3_driver_ids[NUC980_CAN3],
+};
+
+
+module_platform_driver(nuc980_can3_driver);
+
+MODULE_AUTHOR("nuvoton");
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Platform CAN bus driver for NUC980 controller");
diff -uprN linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can.c NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can.c
--- linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1302 @@
+/*
+ *  linux/drivers/net/can/nuc980_can/nuc980_can.c
+ *
+ *  NUC980 CAN driver
+ *
+ *
+ *  Copyright (C) 2018 Nuvoton Technology Corp.
+ *
+ * Thi980s program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/if_arp.h>
+#include <linux/if_ether.h>
+#include <linux/list.h>
+#include <linux/io.h>
+#include <linux/pm_runtime.h>
+
+#include <linux/can.h>
+#include <linux/can/dev.h>
+#include <linux/can/error.h>
+#include <linux/can/led.h>
+
+#include "nuc980_can.h"
+
+/* Number of interface registers */
+#define IF_ENUM_REG_LEN		11
+#define C_CAN_IFACE(reg, iface)	(C_CAN_IF1_##reg + (iface) * IF_ENUM_REG_LEN)
+
+/* control extension register D_CAN specific */
+#define CONTROL_EX_PDR		BIT(8)
+
+/* control register */
+#define CONTROL_TEST		BIT(7)
+#define CONTROL_CCE		BIT(6)
+#define CONTROL_DISABLE_AR	BIT(5)
+#define CONTROL_ENABLE_AR	(0 << 5)
+#define CONTROL_EIE		BIT(3)
+#define CONTROL_SIE		BIT(2)
+#define CONTROL_IE		BIT(1)
+#define CONTROL_INIT		BIT(0)
+
+/* test register */
+#define TEST_RX			BIT(7)
+#define TEST_TX1		BIT(6)
+#define TEST_TX2		BIT(5)
+#define TEST_LBACK		BIT(4)
+#define TEST_SILENT		BIT(3)
+#define TEST_BASIC		BIT(2)
+
+/* status register */
+#define STATUS_PDA		BIT(10)
+#define STATUS_BOFF		BIT(7)
+#define STATUS_EWARN		BIT(6)
+#define STATUS_EPASS		BIT(5)
+#define STATUS_RXOK		BIT(4)
+#define STATUS_TXOK		BIT(3)
+
+/* error counter register */
+#define ERR_CNT_TEC_MASK	0xff
+#define ERR_CNT_TEC_SHIFT	0
+#define ERR_CNT_REC_SHIFT	8
+#define ERR_CNT_REC_MASK	(0x7f << ERR_CNT_REC_SHIFT)
+#define ERR_CNT_RP_SHIFT	15
+#define ERR_CNT_RP_MASK		(0x1 << ERR_CNT_RP_SHIFT)
+
+/* bit-timing register */
+#define BTR_BRP_MASK		0x3f
+#define BTR_BRP_SHIFT		0
+#define BTR_SJW_SHIFT		6
+#define BTR_SJW_MASK		(0x3 << BTR_SJW_SHIFT)
+#define BTR_TSEG1_SHIFT		8
+#define BTR_TSEG1_MASK		(0xf << BTR_TSEG1_SHIFT)
+#define BTR_TSEG2_SHIFT		12
+#define BTR_TSEG2_MASK		(0x7 << BTR_TSEG2_SHIFT)
+
+/* brp extension register */
+#define BRP_EXT_BRPE_MASK	0x0f
+#define BRP_EXT_BRPE_SHIFT	0
+
+/* IFx command request */
+#define IF_COMR_BUSY		BIT(15)
+
+/* IFx command mask */
+#define IF_COMM_WR		BIT(7)
+#define IF_COMM_MASK		BIT(6)
+#define IF_COMM_ARB		BIT(5)
+#define IF_COMM_CONTROL		BIT(4)
+#define IF_COMM_CLR_INT_PND	BIT(3)
+#define IF_COMM_TXRQST		BIT(2)
+#define IF_COMM_DATAA		BIT(1)
+#define IF_COMM_DATAB		BIT(0)
+#define IF_COMM_ALL		(IF_COMM_MASK | IF_COMM_ARB | \
+				IF_COMM_CONTROL | IF_COMM_TXRQST | \
+				IF_COMM_DATAA | IF_COMM_DATAB)
+
+/* IFx arbitration */
+#define IF_ARB_MSGVAL		BIT(15)
+#define IF_ARB_MSGXTD		BIT(14)
+#define IF_ARB_TRANSMIT		BIT(13)
+
+/* IFx message control */
+#define IF_MCONT_NEWDAT		BIT(15)
+#define IF_MCONT_MSGLST		BIT(14)
+#define IF_MCONT_CLR_MSGLST	(0 << 14)
+#define IF_MCONT_INTPND		BIT(13)
+#define IF_MCONT_UMASK		BIT(12)
+#define IF_MCONT_TXIE		BIT(11)
+#define IF_MCONT_RXIE		BIT(10)
+#define IF_MCONT_RMTEN		BIT(9)
+#define IF_MCONT_TXRQST		BIT(8)
+#define IF_MCONT_EOB		BIT(7)
+#define IF_MCONT_DLC_MASK	0xf
+
+/*
+ * IFx register masks:
+ * allow easy operation on 16-bit registers when the
+ * argument is 32-bit instead
+ */
+#define IFX_WRITE_LOW_16BIT(x)	((x) & 0xFFFF)
+#define IFX_WRITE_HIGH_16BIT(x)	(((x) & 0xFFFF0000) >> 16)
+
+/* message object split */
+#define C_CAN_NO_OF_OBJECTS	32
+#define C_CAN_MSG_OBJ_RX_NUM	16
+#define C_CAN_MSG_OBJ_TX_NUM	16
+
+#define C_CAN_MSG_OBJ_RX_FIRST	1
+#define C_CAN_MSG_OBJ_RX_LAST	(C_CAN_MSG_OBJ_RX_FIRST + \
+				C_CAN_MSG_OBJ_RX_NUM - 1)
+
+#define C_CAN_MSG_OBJ_TX_FIRST	(C_CAN_MSG_OBJ_RX_LAST + 1)
+#define C_CAN_MSG_OBJ_TX_LAST	(C_CAN_MSG_OBJ_TX_FIRST + \
+				C_CAN_MSG_OBJ_TX_NUM - 1)
+
+#define C_CAN_MSG_OBJ_RX_SPLIT	9
+#define C_CAN_MSG_RX_LOW_LAST	(C_CAN_MSG_OBJ_RX_SPLIT - 1)
+
+#define C_CAN_NEXT_MSG_OBJ_MASK	(C_CAN_MSG_OBJ_TX_NUM - 1)
+#define RECEIVE_OBJECT_BITS	0x0000ffff
+
+/* status interrupt */
+#define STATUS_INTERRUPT	0x8000
+
+/* global interrupt masks */
+#define ENABLE_ALL_INTERRUPTS	1
+#define DISABLE_ALL_INTERRUPTS	0
+
+/* minimum timeout for checking BUSY status */
+#define MIN_TIMEOUT_VALUE	6
+
+/* Wait for ~1 sec for INIT bit */
+#define INIT_WAIT_MS		1000
+
+/* napi related */
+#define C_CAN_NAPI_WEIGHT	C_CAN_MSG_OBJ_RX_NUM
+
+/* c_can lec values */
+enum c_can_lec_type {
+	LEC_NO_ERROR = 0,
+	LEC_STUFF_ERROR,
+	LEC_FORM_ERROR,
+	LEC_ACK_ERROR,
+	LEC_BIT1_ERROR,
+	LEC_BIT0_ERROR,
+	LEC_CRC_ERROR,
+	LEC_UNUSED,
+};
+
+/*
+ * c_can error types:
+ * Bus errors (BUS_OFF, ERROR_WARNING, ERROR_PASSIVE) are supported
+ */
+enum c_can_bus_error_types {
+	C_CAN_NO_ERROR = 0,
+	C_CAN_BUS_OFF,
+	C_CAN_ERROR_WARNING,
+	C_CAN_ERROR_PASSIVE,
+};
+
+static const struct can_bittiming_const c_can_bittiming_const = {
+	.name = KBUILD_MODNAME,
+	.tseg1_min = 2,		/* Time segment 1 = prop_seg + phase_seg1 */
+	.tseg1_max = 16,
+	.tseg2_min = 1,		/* Time segment 2 = phase_seg2 */
+	.tseg2_max = 8,
+	.sjw_max = 4,
+	.brp_min = 1,
+	.brp_max = 1024,	/* 6-bit BRP field + 4-bit BRPE field*/
+	.brp_inc = 1,
+};
+
+static inline void c_can_pm_runtime_enable(const struct c_can_priv *priv)
+{
+	if (priv->device)
+		pm_runtime_enable(priv->device);
+}
+
+static inline void c_can_pm_runtime_disable(const struct c_can_priv *priv)
+{
+	if (priv->device)
+		pm_runtime_disable(priv->device);
+}
+
+static inline void c_can_pm_runtime_get_sync(const struct c_can_priv *priv)
+{
+	if (priv->device)
+		pm_runtime_get_sync(priv->device);
+}
+
+static inline void c_can_pm_runtime_put_sync(const struct c_can_priv *priv)
+{
+	if (priv->device)
+		pm_runtime_put_sync(priv->device);
+}
+
+static inline void c_can_reset_ram(const struct c_can_priv *priv, bool enable)
+{
+	if (priv->raminit)
+		priv->raminit(priv, enable);
+}
+
+static inline int get_tx_next_msg_obj(const struct c_can_priv *priv)
+{
+	return (priv->tx_next & C_CAN_NEXT_MSG_OBJ_MASK) +
+			C_CAN_MSG_OBJ_TX_FIRST;
+}
+
+static inline int get_tx_echo_msg_obj(const struct c_can_priv *priv)
+{
+	return (priv->tx_echo & C_CAN_NEXT_MSG_OBJ_MASK) +
+			C_CAN_MSG_OBJ_TX_FIRST;
+}
+
+static u32 c_can_read_reg32(struct c_can_priv *priv, enum reg index)
+{
+	u32 val = priv->read_reg(priv, index);
+	val |= ((u32) priv->read_reg(priv, index + 1)) << 16;
+	return val;
+}
+
+static void c_can_enable_all_interrupts(struct c_can_priv *priv,
+						int enable)
+{
+	unsigned int cntrl_save = priv->read_reg(priv,
+						C_CAN_CTRL_REG);
+
+	if (enable)
+		cntrl_save |= (CONTROL_SIE | CONTROL_EIE | CONTROL_IE);
+	else
+		cntrl_save &= ~(CONTROL_EIE | CONTROL_IE | CONTROL_SIE);
+
+	priv->write_reg(priv, C_CAN_CTRL_REG, cntrl_save);
+}
+
+static inline int c_can_msg_obj_is_busy(struct c_can_priv *priv, int iface)
+{
+	int count = MIN_TIMEOUT_VALUE;
+
+	while (count && priv->read_reg(priv,
+				C_CAN_IFACE(COMREQ_REG, iface)) &
+				IF_COMR_BUSY) {
+		count--;
+		udelay(1);
+	}
+
+	if (!count)
+		return 1;
+
+	return 0;
+}
+
+static inline void c_can_object_get(struct net_device *dev,
+					int iface, int objno, int mask)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	/*
+	 * As per specs, after writting the message object number in the
+	 * IF command request register the transfer b/w interface
+	 * register and message RAM must be complete in 6 CAN-CLK
+	 * period.
+	 */
+	priv->write_reg(priv, C_CAN_IFACE(COMMSK_REG, iface),
+			IFX_WRITE_LOW_16BIT(mask));
+	priv->write_reg(priv, C_CAN_IFACE(COMREQ_REG, iface),
+			IFX_WRITE_LOW_16BIT(objno));
+
+	if (c_can_msg_obj_is_busy(priv, iface))
+		netdev_err(dev, "timed out in object get\n");
+}
+
+static inline void c_can_object_put(struct net_device *dev,
+					int iface, int objno, int mask)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	/*
+	 * As per specs, after writting the message object number in the
+	 * IF command request register the transfer b/w interface
+	 * register and message RAM must be complete in 6 CAN-CLK
+	 * period.
+	 */
+	priv->write_reg(priv, C_CAN_IFACE(COMMSK_REG, iface),
+			(IF_COMM_WR | IFX_WRITE_LOW_16BIT(mask)));
+	priv->write_reg(priv, C_CAN_IFACE(COMREQ_REG, iface),
+			IFX_WRITE_LOW_16BIT(objno));
+
+	if (c_can_msg_obj_is_busy(priv, iface))
+		netdev_err(dev, "timed out in object put\n");
+}
+
+static void c_can_write_msg_object(struct net_device *dev,
+			int iface, struct can_frame *frame, int objno)
+{
+	int i;
+	u16 flags = 0;
+	unsigned int id;
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	if (!(frame->can_id & CAN_RTR_FLAG))
+		flags |= IF_ARB_TRANSMIT;
+
+	if (frame->can_id & CAN_EFF_FLAG) {
+		id = frame->can_id & CAN_EFF_MASK;
+		flags |= IF_ARB_MSGXTD;
+	} else
+		id = ((frame->can_id & CAN_SFF_MASK) << 18);
+
+	flags |= IF_ARB_MSGVAL;
+
+	priv->write_reg(priv, C_CAN_IFACE(ARB1_REG, iface),
+				IFX_WRITE_LOW_16BIT(id));
+	priv->write_reg(priv, C_CAN_IFACE(ARB2_REG, iface), flags |
+				IFX_WRITE_HIGH_16BIT(id));
+
+	for (i = 0; i < frame->can_dlc; i += 2) {
+		priv->write_reg(priv, C_CAN_IFACE(DATA1_REG, iface) + i / 2,
+				frame->data[i] | (frame->data[i + 1] << 8));
+	}
+
+	/* enable interrupt for this message object */
+	priv->write_reg(priv, C_CAN_IFACE(MSGCTRL_REG, iface),
+			IF_MCONT_TXIE | IF_MCONT_TXRQST | IF_MCONT_EOB |
+			frame->can_dlc);
+	c_can_object_put(dev, iface, objno, IF_COMM_ALL);
+}
+
+static inline void c_can_mark_rx_msg_obj(struct net_device *dev,
+						int iface, int ctrl_mask,
+						int obj)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	priv->write_reg(priv, C_CAN_IFACE(MSGCTRL_REG, iface),
+			ctrl_mask & ~(IF_MCONT_MSGLST | IF_MCONT_INTPND));
+	c_can_object_put(dev, iface, obj, IF_COMM_CONTROL);
+
+}
+
+static inline void c_can_activate_all_lower_rx_msg_obj(struct net_device *dev,
+						int iface,
+						int ctrl_mask)
+{
+	int i;
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	for (i = C_CAN_MSG_OBJ_RX_FIRST; i <= C_CAN_MSG_RX_LOW_LAST; i++) {
+		priv->write_reg(priv, C_CAN_IFACE(MSGCTRL_REG, iface),
+				ctrl_mask & ~(IF_MCONT_MSGLST |
+					IF_MCONT_INTPND | IF_MCONT_NEWDAT));
+		c_can_object_put(dev, iface, i, IF_COMM_CONTROL);
+	}
+}
+
+static inline void c_can_activate_rx_msg_obj(struct net_device *dev,
+						int iface, int ctrl_mask,
+						int obj)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	priv->write_reg(priv, C_CAN_IFACE(MSGCTRL_REG, iface),
+			ctrl_mask & ~(IF_MCONT_MSGLST |
+				IF_MCONT_INTPND | IF_MCONT_NEWDAT));
+	c_can_object_put(dev, iface, obj, IF_COMM_CONTROL);
+}
+
+static void c_can_handle_lost_msg_obj(struct net_device *dev,
+					int iface, int objno)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct net_device_stats *stats = &dev->stats;
+	struct sk_buff *skb;
+	struct can_frame *frame;
+
+	netdev_err(dev, "msg lost in buffer %d\n", objno);
+
+	c_can_object_get(dev, iface, objno, IF_COMM_ALL & ~IF_COMM_TXRQST);
+
+	priv->write_reg(priv, C_CAN_IFACE(MSGCTRL_REG, iface),
+			IF_MCONT_CLR_MSGLST);
+
+	c_can_object_put(dev, 0, objno, IF_COMM_CONTROL);
+
+	/* create an error msg */
+	skb = alloc_can_err_skb(dev, &frame);
+	if (unlikely(!skb))
+		return;
+
+	frame->can_id |= CAN_ERR_CRTL;
+	frame->data[1] = CAN_ERR_CRTL_RX_OVERFLOW;
+	stats->rx_errors++;
+	stats->rx_over_errors++;
+
+	netif_receive_skb(skb);
+}
+
+static int c_can_read_msg_object(struct net_device *dev, int iface, int ctrl)
+{
+	u16 flags, data;
+	int i;
+	unsigned int val;
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct net_device_stats *stats = &dev->stats;
+	struct sk_buff *skb;
+	struct can_frame *frame;
+
+	skb = alloc_can_skb(dev, &frame);
+	if (!skb) {
+		stats->rx_dropped++;
+		return -ENOMEM;
+	}
+
+	frame->can_dlc = get_can_dlc(ctrl & 0x0F);
+
+	flags =	priv->read_reg(priv, C_CAN_IFACE(ARB2_REG, iface));
+	val = priv->read_reg(priv, C_CAN_IFACE(ARB1_REG, iface)) |
+		(flags << 16);
+
+	if (flags & IF_ARB_MSGXTD)
+		frame->can_id = (val & CAN_EFF_MASK) | CAN_EFF_FLAG;
+	else
+		frame->can_id = (val >> 18) & CAN_SFF_MASK;
+
+	if (flags & IF_ARB_TRANSMIT)
+		frame->can_id |= CAN_RTR_FLAG;
+	else {
+		for (i = 0; i < frame->can_dlc; i += 2) {
+			data = priv->read_reg(priv,
+				C_CAN_IFACE(DATA1_REG, iface) + i / 2);
+			frame->data[i] = data;
+			frame->data[i + 1] = data >> 8;
+		}
+	}
+
+	netif_receive_skb(skb);
+
+	stats->rx_packets++;
+	stats->rx_bytes += frame->can_dlc;
+
+	can_led_event(dev, CAN_LED_EVENT_RX);
+
+	return 0;
+}
+
+static void c_can_setup_receive_object(struct net_device *dev, int iface,
+					int objno, unsigned int mask,
+					unsigned int id, unsigned int mcont)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	priv->write_reg(priv, C_CAN_IFACE(MASK1_REG, iface),
+			IFX_WRITE_LOW_16BIT(mask));
+
+	/* According to C_CAN documentation, the reserved bit
+	 * in IFx_MASK2 register is fixed 1
+	 */
+	priv->write_reg(priv, C_CAN_IFACE(MASK2_REG, iface),
+			IFX_WRITE_HIGH_16BIT(mask) | BIT(13));
+
+	priv->write_reg(priv, C_CAN_IFACE(ARB1_REG, iface),
+			IFX_WRITE_LOW_16BIT(id));
+	priv->write_reg(priv, C_CAN_IFACE(ARB2_REG, iface),
+			(IF_ARB_MSGVAL | IFX_WRITE_HIGH_16BIT(id)));
+
+	priv->write_reg(priv, C_CAN_IFACE(MSGCTRL_REG, iface), mcont);
+	c_can_object_put(dev, iface, objno, IF_COMM_ALL & ~IF_COMM_TXRQST);
+
+	netdev_dbg(dev, "obj no:%d, msgval:0x%08x\n", objno,
+			c_can_read_reg32(priv, C_CAN_MSGVAL1_REG));
+}
+
+static void c_can_inval_msg_object(struct net_device *dev, int iface, int objno)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	priv->write_reg(priv, C_CAN_IFACE(ARB1_REG, iface), 0);
+	priv->write_reg(priv, C_CAN_IFACE(ARB2_REG, iface), 0);
+	priv->write_reg(priv, C_CAN_IFACE(MSGCTRL_REG, iface), 0);
+
+	c_can_object_put(dev, iface, objno, IF_COMM_ARB | IF_COMM_CONTROL);
+
+	netdev_dbg(dev, "obj no:%d, msgval:0x%08x\n", objno,
+			c_can_read_reg32(priv, C_CAN_MSGVAL1_REG));
+}
+
+static inline int c_can_is_next_tx_obj_busy(struct c_can_priv *priv, int objno)
+{
+	int val = c_can_read_reg32(priv, C_CAN_TXRQST1_REG);
+
+	/*
+	 * as transmission request register's bit n-1 corresponds to
+	 * message object n, we need to handle the same properly.
+	 */
+	if (val & (1 << (objno - 1)))
+		return 1;
+
+	return 0;
+}
+
+static netdev_tx_t c_can_start_xmit(struct sk_buff *skb,
+					struct net_device *dev)
+{
+	u32 msg_obj_no;
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct can_frame *frame = (struct can_frame *)skb->data;
+
+	if (can_dropped_invalid_skb(dev, skb))
+		return NETDEV_TX_OK;
+
+	msg_obj_no = get_tx_next_msg_obj(priv);
+
+	/* prepare message object for transmission */
+	c_can_write_msg_object(dev, 0, frame, msg_obj_no);
+	can_put_echo_skb(skb, dev, msg_obj_no - C_CAN_MSG_OBJ_TX_FIRST);
+
+	/*
+	 * we have to stop the queue in case of a wrap around or
+	 * if the next TX message object is still in use
+	 */
+	priv->tx_next++;
+	if (c_can_is_next_tx_obj_busy(priv, get_tx_next_msg_obj(priv)) ||
+			(priv->tx_next & C_CAN_NEXT_MSG_OBJ_MASK) == 0)
+		netif_stop_queue(dev);
+
+	return NETDEV_TX_OK;
+}
+
+static int c_can_set_bittiming(struct net_device *dev)
+{
+	unsigned int reg_btr, reg_brpe, ctrl_save;
+	u8 brp, brpe, sjw, tseg1, tseg2;
+	u32 ten_bit_brp;
+	struct c_can_priv *priv = netdev_priv(dev);
+	const struct can_bittiming *bt = &priv->can.bittiming;
+
+	/* c_can provides a 6-bit brp and 4-bit brpe fields */
+	ten_bit_brp = bt->brp - 1;
+	brp = ten_bit_brp & BTR_BRP_MASK;
+	brpe = ten_bit_brp >> 6;
+
+	sjw = bt->sjw - 1;
+	tseg1 = bt->prop_seg + bt->phase_seg1 - 1;
+	tseg2 = bt->phase_seg2 - 1;
+	reg_btr = brp | (sjw << BTR_SJW_SHIFT) | (tseg1 << BTR_TSEG1_SHIFT) |
+			(tseg2 << BTR_TSEG2_SHIFT);
+	reg_brpe = brpe & BRP_EXT_BRPE_MASK;
+
+	netdev_info(dev,
+		"setting BTR=%04x BRPE=%04x\n", reg_btr, reg_brpe);
+
+	ctrl_save = priv->read_reg(priv, C_CAN_CTRL_REG);
+	priv->write_reg(priv, C_CAN_CTRL_REG,
+			ctrl_save | CONTROL_CCE | CONTROL_INIT);
+	priv->write_reg(priv, C_CAN_BTR_REG, reg_btr);
+	priv->write_reg(priv, C_CAN_BRPEXT_REG, reg_brpe);
+	priv->write_reg(priv, C_CAN_CTRL_REG, ctrl_save);
+
+	return 0;
+}
+
+/*
+ * Configure C_CAN message objects for Tx and Rx purposes:
+ * C_CAN provides a total of 32 message objects that can be configured
+ * either for Tx or Rx purposes. Here the first 16 message objects are used as
+ * a reception FIFO. The end of reception FIFO is signified by the EoB bit
+ * being SET. The remaining 16 message objects are kept aside for Tx purposes.
+ * See user guide document for further details on configuring message
+ * objects.
+ */
+static void c_can_configure_msg_objects(struct net_device *dev)
+{
+	int i;
+
+	/* first invalidate all message objects */
+	for (i = C_CAN_MSG_OBJ_RX_FIRST; i <= C_CAN_NO_OF_OBJECTS; i++)
+		c_can_inval_msg_object(dev, 0, i);
+
+	/* setup receive message objects */
+	for (i = C_CAN_MSG_OBJ_RX_FIRST; i < C_CAN_MSG_OBJ_RX_LAST; i++)
+		c_can_setup_receive_object(dev, 0, i, 0, 0,
+			(IF_MCONT_RXIE | IF_MCONT_UMASK) & ~IF_MCONT_EOB);
+
+	c_can_setup_receive_object(dev, 0, C_CAN_MSG_OBJ_RX_LAST, 0, 0,
+			IF_MCONT_EOB | IF_MCONT_RXIE | IF_MCONT_UMASK);
+}
+
+/*
+ * Configure C_CAN chip:
+ * - enable/disable auto-retransmission
+ * - set operating mode
+ * - configure message objects
+ */
+static void c_can_chip_config(struct net_device *dev)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	/* enable automatic retransmission */
+	priv->write_reg(priv, C_CAN_CTRL_REG,
+			CONTROL_ENABLE_AR);
+
+	if ((priv->can.ctrlmode & CAN_CTRLMODE_LISTENONLY) &&
+	    (priv->can.ctrlmode & CAN_CTRLMODE_LOOPBACK)) {
+		/* loopback + silent mode : useful for hot self-test */
+		priv->write_reg(priv, C_CAN_CTRL_REG, CONTROL_EIE |
+				CONTROL_SIE | CONTROL_IE | CONTROL_TEST);
+		priv->write_reg(priv, C_CAN_TEST_REG,
+				TEST_LBACK | TEST_SILENT);
+	} else if (priv->can.ctrlmode & CAN_CTRLMODE_LOOPBACK) {
+		/* loopback mode : useful for self-test function */
+		priv->write_reg(priv, C_CAN_CTRL_REG, CONTROL_EIE |
+				CONTROL_SIE | CONTROL_IE | CONTROL_TEST);
+		priv->write_reg(priv, C_CAN_TEST_REG, TEST_LBACK);
+	} else if (priv->can.ctrlmode & CAN_CTRLMODE_LISTENONLY) {
+		/* silent mode : bus-monitoring mode */
+		priv->write_reg(priv, C_CAN_CTRL_REG, CONTROL_EIE |
+				CONTROL_SIE | CONTROL_IE | CONTROL_TEST);
+		priv->write_reg(priv, C_CAN_TEST_REG, TEST_SILENT);
+	} else
+		/* normal mode*/
+		priv->write_reg(priv, C_CAN_CTRL_REG,
+				CONTROL_EIE | CONTROL_SIE | CONTROL_IE);
+
+	/* configure message objects */
+	c_can_configure_msg_objects(dev);
+
+	/* set a `lec` value so that we can check for updates later */
+	priv->write_reg(priv, C_CAN_STS_REG, LEC_UNUSED);
+
+	/* set bittiming params */
+	c_can_set_bittiming(dev);
+}
+
+static void c_can_start(struct net_device *dev)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	/* basic c_can configuration */
+	c_can_chip_config(dev);
+
+	priv->can.state = CAN_STATE_ERROR_ACTIVE;
+
+	/* reset tx helper pointers */
+	priv->tx_next = priv->tx_echo = 0;
+
+	/* enable status change, error and module interrupts */
+	c_can_enable_all_interrupts(priv, ENABLE_ALL_INTERRUPTS);
+}
+
+static void c_can_stop(struct net_device *dev)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	/* disable all interrupts */
+	c_can_enable_all_interrupts(priv, DISABLE_ALL_INTERRUPTS);
+
+	/* set the state as STOPPED */
+	priv->can.state = CAN_STATE_STOPPED;
+}
+
+static int c_can_set_mode(struct net_device *dev, enum can_mode mode)
+{
+	switch (mode) {
+	case CAN_MODE_START:
+		c_can_start(dev);
+		netif_wake_queue(dev);
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+static int __c_can_get_berr_counter(const struct net_device *dev,
+				    struct can_berr_counter *bec)
+{
+	unsigned int reg_err_counter;
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	reg_err_counter = priv->read_reg(priv, C_CAN_ERR_CNT_REG);
+	bec->rxerr = (reg_err_counter & ERR_CNT_REC_MASK) >>
+				ERR_CNT_REC_SHIFT;
+	bec->txerr = reg_err_counter & ERR_CNT_TEC_MASK;
+
+	return 0;
+}
+
+static int c_can_get_berr_counter(const struct net_device *dev,
+				  struct can_berr_counter *bec)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+	int err;
+
+	c_can_pm_runtime_get_sync(priv);
+	err = __c_can_get_berr_counter(dev, bec);
+	c_can_pm_runtime_put_sync(priv);
+
+	return err;
+}
+
+/*
+ * theory of operation:
+ *
+ * priv->tx_echo holds the number of the oldest can_frame put for
+ * transmission into the hardware, but not yet ACKed by the CAN tx
+ * complete IRQ.
+ *
+ * We iterate from priv->tx_echo to priv->tx_next and check if the
+ * packet has been transmitted, echo it back to the CAN framework.
+ * If we discover a not yet transmitted packet, stop looking for more.
+ */
+static void c_can_do_tx(struct net_device *dev)
+{
+	u32 val;
+	u32 msg_obj_no;
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct net_device_stats *stats = &dev->stats;
+
+	for (/* nix */; (priv->tx_next - priv->tx_echo) > 0; priv->tx_echo++) {
+		msg_obj_no = get_tx_echo_msg_obj(priv);
+		val = c_can_read_reg32(priv, C_CAN_TXRQST1_REG);
+		if (!(val & (1 << (msg_obj_no - 1)))) {
+			can_get_echo_skb(dev,
+					msg_obj_no - C_CAN_MSG_OBJ_TX_FIRST);
+			stats->tx_bytes += priv->read_reg(priv,
+					C_CAN_IFACE(MSGCTRL_REG, 0))
+					& IF_MCONT_DLC_MASK;
+			stats->tx_packets++;
+			can_led_event(dev, CAN_LED_EVENT_TX);
+			c_can_inval_msg_object(dev, 0, msg_obj_no);
+		} else {
+			break;
+		}
+	}
+
+	/* restart queue if wrap-up or if queue stalled on last pkt */
+	if (((priv->tx_next & C_CAN_NEXT_MSG_OBJ_MASK) != 0) ||
+			((priv->tx_echo & C_CAN_NEXT_MSG_OBJ_MASK) == 0))
+		netif_wake_queue(dev);
+}
+
+/*
+ * theory of operation:
+ *
+ * c_can core saves a received CAN message into the first free message
+ * object it finds free (starting with the lowest). Bits NEWDAT and
+ * INTPND are set for this message object indicating that a new message
+ * has arrived. To work-around this issue, we keep two groups of message
+ * objects whose partitioning is defined by C_CAN_MSG_OBJ_RX_SPLIT.
+ *
+ * To ensure in-order frame reception we use the following
+ * approach while re-activating a message object to receive further
+ * frames:
+ * - if the current message object number is lower than
+ *   C_CAN_MSG_RX_LOW_LAST, do not clear the NEWDAT bit while clearing
+ *   the INTPND bit.
+ * - if the current message object number is equal to
+ *   C_CAN_MSG_RX_LOW_LAST then clear the NEWDAT bit of all lower
+ *   receive message objects.
+ * - if the current message object number is greater than
+ *   C_CAN_MSG_RX_LOW_LAST then clear the NEWDAT bit of
+ *   only this message object.
+ */
+static int c_can_do_rx_poll(struct net_device *dev, int quota)
+{
+	u32 num_rx_pkts = 0;
+	unsigned int msg_obj, msg_ctrl_save;
+	struct c_can_priv *priv = netdev_priv(dev);
+	u32 val = c_can_read_reg32(priv, C_CAN_INTPND1_REG);
+
+	for (msg_obj = C_CAN_MSG_OBJ_RX_FIRST;
+			msg_obj <= C_CAN_MSG_OBJ_RX_LAST && quota > 0;
+			val = c_can_read_reg32(priv, C_CAN_INTPND1_REG),
+			msg_obj++) {
+		/*
+		 * as interrupt pending register's bit n-1 corresponds to
+		 * message object n, we need to handle the same properly.
+		 */
+		if (val & (1 << (msg_obj - 1))) {
+			c_can_object_get(dev, 0, msg_obj, IF_COMM_ALL &
+					~IF_COMM_TXRQST);
+			msg_ctrl_save = priv->read_reg(priv,
+					C_CAN_IFACE(MSGCTRL_REG, 0));
+
+			if (msg_ctrl_save & IF_MCONT_MSGLST) {
+				c_can_handle_lost_msg_obj(dev, 0, msg_obj);
+				num_rx_pkts++;
+				quota--;
+				continue;
+			}
+
+			if (msg_ctrl_save & IF_MCONT_EOB)
+				return num_rx_pkts;
+
+			if (!(msg_ctrl_save & IF_MCONT_NEWDAT))
+				continue;
+
+			/* read the data from the message object */
+			c_can_read_msg_object(dev, 0, msg_ctrl_save);
+
+			if (msg_obj < C_CAN_MSG_RX_LOW_LAST)
+				c_can_mark_rx_msg_obj(dev, 0,
+						msg_ctrl_save, msg_obj);
+			else if (msg_obj > C_CAN_MSG_RX_LOW_LAST)
+				/* activate this msg obj */
+				c_can_activate_rx_msg_obj(dev, 0,
+						msg_ctrl_save, msg_obj);
+			else if (msg_obj == C_CAN_MSG_RX_LOW_LAST)
+				/* activate all lower message objects */
+				c_can_activate_all_lower_rx_msg_obj(dev,
+						0, msg_ctrl_save);
+
+			num_rx_pkts++;
+			quota--;
+		}
+	}
+
+	return num_rx_pkts;
+}
+
+static inline int c_can_has_and_handle_berr(struct c_can_priv *priv)
+{
+	return (priv->can.ctrlmode & CAN_CTRLMODE_BERR_REPORTING) &&
+		(priv->current_status & LEC_UNUSED);
+}
+
+static int c_can_handle_state_change(struct net_device *dev,
+				enum c_can_bus_error_types error_type)
+{
+	unsigned int reg_err_counter;
+	unsigned int rx_err_passive;
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct net_device_stats *stats = &dev->stats;
+	struct can_frame *cf;
+	struct sk_buff *skb;
+	struct can_berr_counter bec;
+
+	/* propagate the error condition to the CAN stack */
+	skb = alloc_can_err_skb(dev, &cf);
+	if (unlikely(!skb))
+		return 0;
+
+	__c_can_get_berr_counter(dev, &bec);
+	reg_err_counter = priv->read_reg(priv, C_CAN_ERR_CNT_REG);
+	rx_err_passive = (reg_err_counter & ERR_CNT_RP_MASK) >>
+				ERR_CNT_RP_SHIFT;
+
+	switch (error_type) {
+	case C_CAN_ERROR_WARNING:
+		/* error warning state */
+		priv->can.can_stats.error_warning++;
+		priv->can.state = CAN_STATE_ERROR_WARNING;
+		cf->can_id |= CAN_ERR_CRTL;
+		cf->data[1] = (bec.txerr > bec.rxerr) ?
+			CAN_ERR_CRTL_TX_WARNING :
+			CAN_ERR_CRTL_RX_WARNING;
+		cf->data[6] = bec.txerr;
+		cf->data[7] = bec.rxerr;
+
+		break;
+	case C_CAN_ERROR_PASSIVE:
+		/* error passive state */
+		priv->can.can_stats.error_passive++;
+		priv->can.state = CAN_STATE_ERROR_PASSIVE;
+		cf->can_id |= CAN_ERR_CRTL;
+		if (rx_err_passive)
+			cf->data[1] |= CAN_ERR_CRTL_RX_PASSIVE;
+		if (bec.txerr > 127)
+			cf->data[1] |= CAN_ERR_CRTL_TX_PASSIVE;
+
+		cf->data[6] = bec.txerr;
+		cf->data[7] = bec.rxerr;
+		break;
+	case C_CAN_BUS_OFF:
+		/* bus-off state */
+		priv->can.state = CAN_STATE_BUS_OFF;
+		cf->can_id |= CAN_ERR_BUSOFF;
+		/*
+		 * disable all interrupts in bus-off mode to ensure that
+		 * the CPU is not hogged down
+		 */
+		c_can_enable_all_interrupts(priv, DISABLE_ALL_INTERRUPTS);
+		can_bus_off(dev);
+		break;
+	default:
+		break;
+	}
+
+	netif_receive_skb(skb);
+	stats->rx_packets++;
+	stats->rx_bytes += cf->can_dlc;
+
+	return 1;
+}
+
+static int c_can_handle_bus_err(struct net_device *dev,
+				enum c_can_lec_type lec_type)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+	struct net_device_stats *stats = &dev->stats;
+	struct can_frame *cf;
+	struct sk_buff *skb;
+
+	/*
+	 * early exit if no lec update or no error.
+	 * no lec update means that no CAN bus event has been detected
+	 * since CPU wrote 0x7 value to status reg.
+	 */
+	if (lec_type == LEC_UNUSED || lec_type == LEC_NO_ERROR)
+		return 0;
+
+	/* propagate the error condition to the CAN stack */
+	skb = alloc_can_err_skb(dev, &cf);
+	if (unlikely(!skb))
+		return 0;
+
+	/*
+	 * check for 'last error code' which tells us the
+	 * type of the last error to occur on the CAN bus
+	 */
+
+	/* common for all type of bus errors */
+	priv->can.can_stats.bus_error++;
+	stats->rx_errors++;
+	cf->can_id |= CAN_ERR_PROT | CAN_ERR_BUSERROR;
+	cf->data[2] |= CAN_ERR_PROT_UNSPEC;
+
+	switch (lec_type) {
+	case LEC_STUFF_ERROR:
+		netdev_dbg(dev, "stuff error\n");
+		cf->data[2] |= CAN_ERR_PROT_STUFF;
+		break;
+	case LEC_FORM_ERROR:
+		netdev_dbg(dev, "form error\n");
+		cf->data[2] |= CAN_ERR_PROT_FORM;
+		break;
+	case LEC_ACK_ERROR:
+		netdev_dbg(dev, "ack error\n");
+		cf->data[3] |= (CAN_ERR_PROT_LOC_ACK |
+				CAN_ERR_PROT_LOC_ACK_DEL);
+		break;
+	case LEC_BIT1_ERROR:
+		netdev_dbg(dev, "bit1 error\n");
+		cf->data[2] |= CAN_ERR_PROT_BIT1;
+		break;
+	case LEC_BIT0_ERROR:
+		netdev_dbg(dev, "bit0 error\n");
+		cf->data[2] |= CAN_ERR_PROT_BIT0;
+		break;
+	case LEC_CRC_ERROR:
+		netdev_dbg(dev, "CRC error\n");
+		cf->data[3] |= (CAN_ERR_PROT_LOC_CRC_SEQ |
+				CAN_ERR_PROT_LOC_CRC_DEL);
+		break;
+	default:
+		break;
+	}
+
+	/* set a `lec` value so that we can check for updates later */
+	priv->write_reg(priv, C_CAN_STS_REG, LEC_UNUSED);
+
+	netif_receive_skb(skb);
+	stats->rx_packets++;
+	stats->rx_bytes += cf->can_dlc;
+
+	return 1;
+}
+
+static int c_can_poll(struct napi_struct *napi, int quota)
+{
+	u16 irqstatus;
+	int lec_type = 0;
+	int work_done = 0;
+	struct net_device *dev = napi->dev;
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	irqstatus = priv->irqstatus;
+	if (!irqstatus)
+		goto end;
+
+	/* status events have the highest priority */
+	if (irqstatus == STATUS_INTERRUPT) {
+		priv->current_status = priv->read_reg(priv,
+					C_CAN_STS_REG);
+
+		/* handle Tx/Rx events */
+		if (priv->current_status & STATUS_TXOK)
+			priv->write_reg(priv, C_CAN_STS_REG,
+					priv->current_status & ~STATUS_TXOK);
+
+		if (priv->current_status & STATUS_RXOK)
+			priv->write_reg(priv, C_CAN_STS_REG,
+					priv->current_status & ~STATUS_RXOK);
+
+		/* handle state changes */
+		if ((priv->current_status & STATUS_EWARN) &&
+				(!(priv->last_status & STATUS_EWARN))) {
+			netdev_dbg(dev, "entered error warning state\n");
+			work_done += c_can_handle_state_change(dev,
+						C_CAN_ERROR_WARNING);
+		}
+		if ((priv->current_status & STATUS_EPASS) &&
+				(!(priv->last_status & STATUS_EPASS))) {
+			netdev_dbg(dev, "entered error passive state\n");
+			work_done += c_can_handle_state_change(dev,
+						C_CAN_ERROR_PASSIVE);
+		}
+		if ((priv->current_status & STATUS_BOFF) &&
+				(!(priv->last_status & STATUS_BOFF))) {
+			netdev_dbg(dev, "entered bus off state\n");
+			work_done += c_can_handle_state_change(dev,
+						C_CAN_BUS_OFF);
+		}
+
+		/* handle bus recovery events */
+		if ((!(priv->current_status & STATUS_BOFF)) &&
+				(priv->last_status & STATUS_BOFF)) {
+			netdev_dbg(dev, "left bus off state\n");
+			priv->can.state = CAN_STATE_ERROR_ACTIVE;
+		}
+		if ((!(priv->current_status & STATUS_EPASS)) &&
+				(priv->last_status & STATUS_EPASS)) {
+			netdev_dbg(dev, "left error passive state\n");
+			priv->can.state = CAN_STATE_ERROR_ACTIVE;
+		}
+
+		priv->last_status = priv->current_status;
+
+		/* handle lec errors on the bus */
+		lec_type = c_can_has_and_handle_berr(priv);
+		if (lec_type)
+			work_done += c_can_handle_bus_err(dev, lec_type);
+	} else if ((irqstatus >= C_CAN_MSG_OBJ_RX_FIRST) &&
+			(irqstatus <= C_CAN_MSG_OBJ_RX_LAST)) {
+		/* handle events corresponding to receive message objects */
+		work_done += c_can_do_rx_poll(dev, (quota - work_done));
+	} else if ((irqstatus >= C_CAN_MSG_OBJ_TX_FIRST) &&
+			(irqstatus <= C_CAN_MSG_OBJ_TX_LAST)) {
+		/* handle events corresponding to transmit message objects */
+		c_can_do_tx(dev);
+	}
+
+end:
+	if (work_done < quota) {
+		napi_complete(napi);
+		/* enable all IRQs */
+		c_can_enable_all_interrupts(priv, ENABLE_ALL_INTERRUPTS);
+	}
+
+	return work_done;
+}
+
+static irqreturn_t c_can_isr(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *)dev_id;
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	if(__raw_readl(priv->base+0x16C))
+	{
+		__raw_writel(0x0,(priv->base+0x16C));
+		return IRQ_NONE;
+	}
+
+	priv->irqstatus = priv->read_reg(priv, C_CAN_INT_REG);
+	if (!priv->irqstatus)
+		return IRQ_NONE;
+
+	/* disable all interrupts and schedule the NAPI */
+	c_can_enable_all_interrupts(priv, DISABLE_ALL_INTERRUPTS);
+	napi_schedule(&priv->napi);
+
+	return IRQ_HANDLED;
+}
+
+static int c_can_open(struct net_device *dev)
+{
+	int err;
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	c_can_pm_runtime_get_sync(priv);
+	c_can_reset_ram(priv, true);
+
+	/* open the can device */
+	err = open_candev(dev);
+	if (err) {
+		netdev_err(dev, "failed to open can device\n");
+		goto exit_open_fail;
+	}
+
+	/* register interrupt handler */
+	err = request_irq(dev->irq, &c_can_isr, IRQF_NO_SUSPEND, dev->name,
+				dev);
+	if (err < 0) {
+		netdev_err(dev, "failed to request interrupt\n");
+		goto exit_irq_fail;
+	}
+
+	napi_enable(&priv->napi);
+
+	can_led_event(dev, CAN_LED_EVENT_OPEN);
+
+	/* start the c_can controller */
+	c_can_start(dev);
+
+	netif_start_queue(dev);
+
+	return 0;
+
+exit_irq_fail:
+	close_candev(dev);
+exit_open_fail:
+	c_can_reset_ram(priv, false);
+	c_can_pm_runtime_put_sync(priv);
+	return err;
+}
+
+static int c_can_close(struct net_device *dev)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	netif_stop_queue(dev);
+	napi_disable(&priv->napi);
+	c_can_stop(dev);
+	free_irq(dev->irq, dev);
+	close_candev(dev);
+
+	c_can_reset_ram(priv, false);
+	c_can_pm_runtime_put_sync(priv);
+
+	can_led_event(dev, CAN_LED_EVENT_STOP);
+
+	return 0;
+}
+
+struct net_device *alloc_c_can_dev(void)
+{
+	struct net_device *dev;
+	struct c_can_priv *priv;
+
+	dev = alloc_candev(sizeof(struct c_can_priv), C_CAN_MSG_OBJ_TX_NUM);
+	if (!dev)
+		return NULL;
+
+	priv = netdev_priv(dev);
+	netif_napi_add(dev, &priv->napi, c_can_poll, C_CAN_NAPI_WEIGHT);
+
+	priv->dev = dev;
+	priv->can.bittiming_const = &c_can_bittiming_const;
+	priv->can.do_set_mode = c_can_set_mode;
+	priv->can.do_get_berr_counter = c_can_get_berr_counter;
+	priv->can.ctrlmode_supported = CAN_CTRLMODE_LOOPBACK |
+					CAN_CTRLMODE_LISTENONLY |
+					CAN_CTRLMODE_BERR_REPORTING;
+
+	return dev;
+}
+EXPORT_SYMBOL_GPL(alloc_c_can_dev);
+
+#ifdef CONFIG_PM
+int c_can_power_down(struct net_device *dev)
+{
+	u32 val;
+	unsigned long time_out;
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	if (!(dev->flags & IFF_UP))
+		return 0;
+
+	/* set PDR value so the device goes to power down mode */
+	val = priv->read_reg(priv, C_CAN_CTRL_EX_REG);
+	val |= CONTROL_EX_PDR;
+	priv->write_reg(priv, C_CAN_CTRL_EX_REG, val);
+
+	/* Wait for the PDA bit to get set */
+	time_out = jiffies + msecs_to_jiffies(INIT_WAIT_MS);
+	while (!(priv->read_reg(priv, C_CAN_STS_REG) & STATUS_PDA) &&
+				time_after(time_out, jiffies))
+		cpu_relax();
+
+	if (time_after(jiffies, time_out))
+		return -ETIMEDOUT;
+
+	c_can_stop(dev);
+
+	c_can_reset_ram(priv, false);
+	c_can_pm_runtime_put_sync(priv);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(c_can_power_down);
+
+int c_can_power_up(struct net_device *dev)
+{
+	u32 val;
+	unsigned long time_out;
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	if (!(dev->flags & IFF_UP))
+		return 0;
+
+	c_can_pm_runtime_get_sync(priv);
+	c_can_reset_ram(priv, true);
+
+	/* Clear PDR and INIT bits */
+	val = priv->read_reg(priv, C_CAN_CTRL_EX_REG);
+	val &= ~CONTROL_EX_PDR;
+	priv->write_reg(priv, C_CAN_CTRL_EX_REG, val);
+	val = priv->read_reg(priv, C_CAN_CTRL_REG);
+	val &= ~CONTROL_INIT;
+	priv->write_reg(priv, C_CAN_CTRL_REG, val);
+
+	/* Wait for the PDA bit to get clear */
+	time_out = jiffies + msecs_to_jiffies(INIT_WAIT_MS);
+	while ((priv->read_reg(priv, C_CAN_STS_REG) & STATUS_PDA) &&
+				time_after(time_out, jiffies))
+		cpu_relax();
+
+	if (time_after(jiffies, time_out))
+		return -ETIMEDOUT;
+
+	c_can_start(dev);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(c_can_power_up);
+#endif
+
+void free_c_can_dev(struct net_device *dev)
+{
+	free_candev(dev);
+}
+EXPORT_SYMBOL_GPL(free_c_can_dev);
+
+static const struct net_device_ops c_can_netdev_ops = {
+	.ndo_open = c_can_open,
+	.ndo_stop = c_can_close,
+	.ndo_start_xmit = c_can_start_xmit,
+};
+
+int register_c_can_dev(struct net_device *dev)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+	int err;
+
+	c_can_pm_runtime_enable(priv);
+
+	dev->flags |= IFF_ECHO;	/* we support local echo */
+	dev->netdev_ops = &c_can_netdev_ops;
+
+	err = register_candev(dev);
+	if (err)
+		c_can_pm_runtime_disable(priv);
+	else
+		devm_can_led_init(dev);
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(register_c_can_dev);
+
+void unregister_c_can_dev(struct net_device *dev)
+{
+	struct c_can_priv *priv = netdev_priv(dev);
+
+	unregister_candev(dev);
+
+	c_can_pm_runtime_disable(priv);
+}
+EXPORT_SYMBOL_GPL(unregister_c_can_dev);
+
+MODULE_AUTHOR("nuvoton");
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Platform CAN bus driver for NUC980 controller");
diff -uprN linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can.h NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can.h
--- linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can.h	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/can/nuc980_can/nuc980_can.h	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,186 @@
+/*
+ *  linux/drivers/net/can/nuc980_can/nuc980_can.h
+ *
+ *  NUC980 CAN driver header file
+ *
+ *
+ *  Copyright (C) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+
+#ifndef NUC980_CAN_H
+#define NUC980_CAN_H
+
+enum reg {
+	C_CAN_CTRL_REG = 0,
+	C_CAN_CTRL_EX_REG,
+	C_CAN_STS_REG,
+	C_CAN_ERR_CNT_REG,
+	C_CAN_BTR_REG,
+	C_CAN_INT_REG,
+	C_CAN_TEST_REG,
+	C_CAN_BRPEXT_REG,
+	C_CAN_IF1_COMREQ_REG,
+	C_CAN_IF1_COMMSK_REG,
+	C_CAN_IF1_MASK1_REG,
+	C_CAN_IF1_MASK2_REG,
+	C_CAN_IF1_ARB1_REG,
+	C_CAN_IF1_ARB2_REG,
+	C_CAN_IF1_MSGCTRL_REG,
+	C_CAN_IF1_DATA1_REG,
+	C_CAN_IF1_DATA2_REG,
+	C_CAN_IF1_DATA3_REG,
+	C_CAN_IF1_DATA4_REG,
+	C_CAN_IF2_COMREQ_REG,
+	C_CAN_IF2_COMMSK_REG,
+	C_CAN_IF2_MASK1_REG,
+	C_CAN_IF2_MASK2_REG,
+	C_CAN_IF2_ARB1_REG,
+	C_CAN_IF2_ARB2_REG,
+	C_CAN_IF2_MSGCTRL_REG,
+	C_CAN_IF2_DATA1_REG,
+	C_CAN_IF2_DATA2_REG,
+	C_CAN_IF2_DATA3_REG,
+	C_CAN_IF2_DATA4_REG,
+	C_CAN_TXRQST1_REG,
+	C_CAN_TXRQST2_REG,
+	C_CAN_NEWDAT1_REG,
+	C_CAN_NEWDAT2_REG,
+	C_CAN_INTPND1_REG,
+	C_CAN_INTPND2_REG,
+	C_CAN_MSGVAL1_REG,
+	C_CAN_MSGVAL2_REG,
+};
+
+static const u16 reg_map_c_can[] = {
+	[C_CAN_CTRL_REG]	= 0x00,
+	[C_CAN_STS_REG]		= 0x02,
+	[C_CAN_ERR_CNT_REG]	= 0x04,
+	[C_CAN_BTR_REG]		= 0x06,
+	[C_CAN_INT_REG]		= 0x08,
+	[C_CAN_TEST_REG]	= 0x0A,
+	[C_CAN_BRPEXT_REG]	= 0x0C,
+	[C_CAN_IF1_COMREQ_REG]	= 0x10,
+	[C_CAN_IF1_COMMSK_REG]	= 0x12,
+	[C_CAN_IF1_MASK1_REG]	= 0x14,
+	[C_CAN_IF1_MASK2_REG]	= 0x16,
+	[C_CAN_IF1_ARB1_REG]	= 0x18,
+	[C_CAN_IF1_ARB2_REG]	= 0x1A,
+	[C_CAN_IF1_MSGCTRL_REG]	= 0x1C,
+	[C_CAN_IF1_DATA1_REG]	= 0x1E,
+	[C_CAN_IF1_DATA2_REG]	= 0x20,
+	[C_CAN_IF1_DATA3_REG]	= 0x22,
+	[C_CAN_IF1_DATA4_REG]	= 0x24,
+	[C_CAN_IF2_COMREQ_REG]	= 0x40,
+	[C_CAN_IF2_COMMSK_REG]	= 0x42,
+	[C_CAN_IF2_MASK1_REG]	= 0x44,
+	[C_CAN_IF2_MASK2_REG]	= 0x46,
+	[C_CAN_IF2_ARB1_REG]	= 0x48,
+	[C_CAN_IF2_ARB2_REG]	= 0x4A,
+	[C_CAN_IF2_MSGCTRL_REG]	= 0x4C,
+	[C_CAN_IF2_DATA1_REG]	= 0x4E,
+	[C_CAN_IF2_DATA2_REG]	= 0x50,
+	[C_CAN_IF2_DATA3_REG]	= 0x52,
+	[C_CAN_IF2_DATA4_REG]	= 0x54,
+	[C_CAN_TXRQST1_REG]	= 0x80,
+	[C_CAN_TXRQST2_REG]	= 0x82,
+	[C_CAN_NEWDAT1_REG]	= 0x90,
+	[C_CAN_NEWDAT2_REG]	= 0x92,
+	[C_CAN_INTPND1_REG]	= 0xA0,
+	[C_CAN_INTPND2_REG]	= 0xA2,
+	[C_CAN_MSGVAL1_REG]	= 0xB0,
+	[C_CAN_MSGVAL2_REG]	= 0xB2,
+};
+
+static const u16 reg_map_d_can[] = {
+	[C_CAN_CTRL_REG]	= 0x00,
+	[C_CAN_CTRL_EX_REG]	= 0x02,
+	[C_CAN_STS_REG]		= 0x04,
+	[C_CAN_ERR_CNT_REG]	= 0x08,
+	[C_CAN_BTR_REG]		= 0x0C,
+	[C_CAN_BRPEXT_REG]	= 0x0E,
+	[C_CAN_INT_REG]		= 0x10,
+	[C_CAN_TEST_REG]	= 0x14,
+	[C_CAN_TXRQST1_REG]	= 0x88,
+	[C_CAN_TXRQST2_REG]	= 0x8A,
+	[C_CAN_NEWDAT1_REG]	= 0x9C,
+	[C_CAN_NEWDAT2_REG]	= 0x9E,
+	[C_CAN_INTPND1_REG]	= 0xB0,
+	[C_CAN_INTPND2_REG]	= 0xB2,
+	[C_CAN_MSGVAL1_REG]	= 0xC4,
+	[C_CAN_MSGVAL2_REG]	= 0xC6,
+	[C_CAN_IF1_COMREQ_REG]	= 0x100,
+	[C_CAN_IF1_COMMSK_REG]	= 0x102,
+	[C_CAN_IF1_MASK1_REG]	= 0x104,
+	[C_CAN_IF1_MASK2_REG]	= 0x106,
+	[C_CAN_IF1_ARB1_REG]	= 0x108,
+	[C_CAN_IF1_ARB2_REG]	= 0x10A,
+	[C_CAN_IF1_MSGCTRL_REG]	= 0x10C,
+	[C_CAN_IF1_DATA1_REG]	= 0x110,
+	[C_CAN_IF1_DATA2_REG]	= 0x112,
+	[C_CAN_IF1_DATA3_REG]	= 0x114,
+	[C_CAN_IF1_DATA4_REG]	= 0x116,
+	[C_CAN_IF2_COMREQ_REG]	= 0x120,
+	[C_CAN_IF2_COMMSK_REG]	= 0x122,
+	[C_CAN_IF2_MASK1_REG]	= 0x124,
+	[C_CAN_IF2_MASK2_REG]	= 0x126,
+	[C_CAN_IF2_ARB1_REG]	= 0x128,
+	[C_CAN_IF2_ARB2_REG]	= 0x12A,
+	[C_CAN_IF2_MSGCTRL_REG]	= 0x12C,
+	[C_CAN_IF2_DATA1_REG]	= 0x130,
+	[C_CAN_IF2_DATA2_REG]	= 0x132,
+	[C_CAN_IF2_DATA3_REG]	= 0x134,
+	[C_CAN_IF2_DATA4_REG]	= 0x136,
+};
+
+
+enum c_can_dev_id {
+	NUC980_CAN0,
+	NUC980_CAN1,
+	NUC980_CAN2,
+	NUC980_CAN3,
+};
+
+
+
+/* c_can private data structure */
+struct c_can_priv {
+	struct can_priv can;	/* must be the first member */
+	struct napi_struct napi;
+	struct net_device *dev;
+	struct device *device;
+	int tx_object;
+	int current_status;
+	int last_status;
+	u16 (*read_reg) (struct c_can_priv *priv, enum reg index);
+	void (*write_reg) (struct c_can_priv *priv, enum reg index, u16 val);
+	void __iomem *base;
+	const u16 *regs;
+	unsigned long irq_flags; /* for request_irq() */
+	unsigned int tx_next;
+	unsigned int tx_echo;
+	void *priv;		/* for board-specific data */
+	u16 irqstatus;
+	enum c_can_dev_id type;
+	u32 __iomem *raminit_ctrlreg;
+	unsigned int instance;
+	void (*raminit) (const struct c_can_priv *priv, bool enable);
+};
+
+struct net_device *alloc_c_can_dev(void);
+void free_c_can_dev(struct net_device *dev);
+int register_c_can_dev(struct net_device *dev);
+void unregister_c_can_dev(struct net_device *dev);
+
+#ifdef CONFIG_PM
+int c_can_power_up(struct net_device *dev);
+int c_can_power_down(struct net_device *dev);
+#endif
+
+#endif /* NUC980_CAN_H */
diff -uprN linux-4.4.194/drivers/net/ethernet/nuvoton/Kconfig NUC980-linux-4.4.194/drivers/net/ethernet/nuvoton/Kconfig
--- linux-4.4.194/drivers/net/ethernet/nuvoton/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/net/ethernet/nuvoton/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -5,7 +5,7 @@
 config NET_VENDOR_NUVOTON
 	bool "Nuvoton devices"
 	default y
-	depends on ARM && ARCH_W90X900
+	depends on ARM && (ARCH_W90X900 || ARCH_NUC980)
 	---help---
 	  If you have a network (Ethernet) card belonging to this class, say Y.
 
@@ -25,4 +25,24 @@ config W90P910_ETH
 	  Say Y here if you want to use built-in Ethernet ports
 	  on w90p910 processor.
 
+config NUC980_ETH0
+        tristate "Nuvoton NUC980 Ethernet MAC 0"
+        depends on ARM && ARCH_NUC980
+        select PHYLIB
+        select NET_CORE
+        select MII
+        ---help---
+          Say Y here if you want to use built-in Ethernet MAC 0
+          on NUC980 MCU.
+
+config NUC980_ETH1
+        tristate "Nuvoton NUC980 Ethernet MAC 1"
+        depends on ARM && ARCH_NUC980
+        select PHYLIB
+        select NET_CORE
+        select MII
+        ---help---
+          Say Y here if you want to use built-in Ethernet MAC 1
+          on NUC980 MCU.
+
 endif # NET_VENDOR_NUVOTON
diff -uprN linux-4.4.194/drivers/net/ethernet/nuvoton/Makefile NUC980-linux-4.4.194/drivers/net/ethernet/nuvoton/Makefile
--- linux-4.4.194/drivers/net/ethernet/nuvoton/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/net/ethernet/nuvoton/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -3,3 +3,5 @@
 #
 
 obj-$(CONFIG_W90P910_ETH) += w90p910_ether.o
+obj-$(CONFIG_NUC980_ETH0) += nuc980_ether0.o
+obj-$(CONFIG_NUC980_ETH1) += nuc980_ether1.o
diff -uprN linux-4.4.194/drivers/net/ethernet/nuvoton/nuc980_ether0.c NUC980-linux-4.4.194/drivers/net/ethernet/nuvoton/nuc980_ether0.c
--- linux-4.4.194/drivers/net/ethernet/nuvoton/nuc980_ether0.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/ethernet/nuvoton/nuc980_ether0.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1348 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/mii.h>
+#include <linux/phy.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/ethtool.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/gfp.h>
+#include <linux/kthread.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/ctype.h>
+#include <linux/net_tstamp.h>
+
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-gcr.h>
+
+#define DRV_MODULE_NAME		"nuc980-emc0"
+#define DRV_MODULE_VERSION	"1.0"
+
+/* Ethernet MAC0 Registers */
+#define REG_CAMCMR		(void __iomem *)0xF0012000
+#define REG_CAMEN		(void __iomem *)0xF0012004
+#define REG_CAMM_BASE		(void __iomem *)0xF0012008
+#define REG_CAML_BASE		(void __iomem *)0xF001200c
+#define REG_TXDLSA		(void __iomem *)0xF0012088
+#define REG_RXDLSA		(void __iomem *)0xF001208C
+#define REG_MCMDR		(void __iomem *)0xF0012090
+#define REG_MIID		(void __iomem *)0xF0012094
+#define REG_MIIDA		(void __iomem *)0xF0012098
+#define REG_FFTCR		(void __iomem *)0xF001209C
+#define REG_TSDR		(void __iomem *)0xF00120a0
+#define REG_RSDR		(void __iomem *)0xF00120a4
+#define REG_DMARFC		(void __iomem *)0xF00120a8
+#define REG_MIEN		(void __iomem *)0xF00120ac
+#define REG_MISTA		(void __iomem *)0xF00120b0
+#define REG_CTXDSA		(void __iomem *)0xF00120cc
+#define REG_CTXBSA		(void __iomem *)0xF00120d0
+#define REG_CRXDSA		(void __iomem *)0xF00120d4
+#define REG_CRXBSA		(void __iomem *)0xF00120d8
+
+/* mac controller bit */
+#define MCMDR_RXON		0x01
+#define MCMDR_ACP		(0x01 << 3)
+#define MCMDR_SPCRC		(0x01 << 5)
+#define MCMDR_MGPWAKE		(0x01 << 6)
+#define MCMDR_TXON		(0x01 << 8)
+#define MCMDR_FDUP		(0x01 << 18)
+#define MCMDR_OPMOD		(0x01 << 20)
+#define SWR			(0x01 << 24)
+
+/* cam command register */
+#define CAMCMR_AUP		0x01
+#define CAMCMR_AMP		(0x01 << 1)
+#define CAMCMR_ABP		(0x01 << 2)
+#define CAMCMR_CCAM		(0x01 << 3)
+#define CAMCMR_ECMP		(0x01 << 4)
+#define CAM0EN			0x01
+
+/* mac mii controller bit */
+#define MDCON			(0x01 << 19)
+//#define PHYAD			(0x01 << 8)
+#define PHYWR			(0x01 << 16)
+#define PHYBUSY			(0x01 << 17)
+#define CAM_ENTRY_SIZE		0x08
+
+/* rx and tx status */
+#define TXDS_TXCP		(0x01 << 19)
+#define RXDS_CRCE		(0x01 << 17)
+#define RXDS_PTLE		(0x01 << 19)
+#define RXDS_RXGD		(0x01 << 20)
+#define RXDS_ALIE		(0x01 << 21)
+#define RXDS_RP			(0x01 << 22)
+
+/* mac interrupt status*/
+#define MISTA_EXDEF		(0x01 << 19)
+#define MISTA_TXBERR		(0x01 << 24)
+#define MISTA_TDU		(0x01 << 23)
+#define MISTA_RDU		(0x01 << 10)
+#define MISTA_RXBERR		(0x01 << 11)
+#define MISTA_WOL		(0x01 << 15)
+#define MISTA_RXGD		(0x01 << 4)
+#define MISTA_TXEMP		(0x01 << 17)
+#define MISTA_RXOV		(0x01 << 2)
+
+#define ENSTART			0x01
+#define ENRXINTR		0x01
+#define ENRXGD			(0x01 << 4)
+#define ENRDU			(0x01 << 10)
+#define ENRXBERR		(0x01 << 11)
+#define ENWOL			(0x01 << 15)
+#define ENTXINTR		(0x01 << 16)
+#define ENTXCP			(0x01 << 18)
+#define ENTXABT			(0x01 << 21)
+#define ENTXBERR		(0x01 << 24)
+#define PHYBUSY			(0x01 << 17)
+
+
+/* rx and tx owner bit */
+#define RX_OWEN_DMA		(0x01 << 31)
+#define RX_OWEN_CPU		(~(0x03 << 30))
+#define TX_OWEN_DMA		(0x01 << 31)
+#define TX_OWEN_CPU		(~(0x01 << 31))
+
+/* tx frame desc controller bit */
+#define MACTXINTEN		0x04
+#define CRCMODE			0x02
+#define PADDINGMODE		0x01
+
+/* fftcr controller bit */
+#define TXTHD 			(0x03 << 8)
+#define BLENGTH			(0x01 << 20)
+
+/* global setting for driver */
+#define RX_DESC_SIZE	32
+#define TX_DESC_SIZE	32
+#define MAX_RBUFF_SZ	0x600
+#define MAX_TBUFF_SZ	0x600
+#define TX_TIMEOUT	50
+#define DELAY		1000
+#define CAM0		0x0
+
+#define MII_TIMEOUT	100
+
+#define ETH_TRIGGER_RX	do{__raw_writel(ENSTART, REG_RSDR);}while(0)
+#define ETH_TRIGGER_TX	do{__raw_writel(ENSTART, REG_TSDR);}while(0)
+#define ETH_ENABLE_TX	do{__raw_writel(__raw_readl( REG_MCMDR) | MCMDR_TXON, REG_MCMDR);}while(0)
+#define ETH_ENABLE_RX	do{__raw_writel(__raw_readl( REG_MCMDR) | MCMDR_RXON, REG_MCMDR);}while(0)
+#define ETH_DISABLE_TX	do{__raw_writel(__raw_readl( REG_MCMDR) & ~MCMDR_TXON, REG_MCMDR);}while(0)
+#define ETH_DISABLE_RX	do{__raw_writel(__raw_readl( REG_MCMDR) & ~MCMDR_RXON, REG_MCMDR);}while(0)
+
+struct nuc980_rxbd {
+	unsigned int sl;
+	unsigned int buffer;
+	unsigned int reserved;
+	unsigned int next;
+};
+
+struct nuc980_txbd {
+	unsigned int mode;
+	unsigned int buffer;
+	unsigned int sl;
+	unsigned int next;
+};
+
+u8 nuc980_mac0[6] = { 0x08, 0x00, 0x27, 0x00, 0x01, 0x92 };
+
+static struct sk_buff *rx_skb[RX_DESC_SIZE];
+static struct sk_buff *tx_skb[TX_DESC_SIZE];
+
+struct  nuc980_ether {
+	spinlock_t lock;
+	struct nuc980_rxbd *rdesc;
+	struct nuc980_txbd *tdesc;
+	dma_addr_t rdesc_phys;
+	dma_addr_t tdesc_phys;
+	struct net_device_stats stats;
+	struct platform_device *pdev;
+	struct net_device *ndev;
+	struct resource *res;
+	struct clk *clk;
+	struct clk *eclk;
+	unsigned int msg_enable;
+	struct mii_bus *mii_bus;
+	struct phy_device *phy_dev;
+	struct napi_struct napi;
+	int rxirq;
+	int txirq;
+	unsigned int cur_tx;
+	unsigned int cur_rx;
+	unsigned int finish_tx;
+	unsigned int start_tx_ptr;
+	unsigned int start_rx_ptr;
+	int link;
+	int speed;
+	int duplex;
+	int wol;
+};
+
+
+static __init int setup_macaddr(char *str)
+{
+	u8 mac[6] = {0, 0, 0, 0, 0, 0};
+	char *c = str;
+	int i, j;
+
+	if (!str)
+		goto err;
+
+	for(i = 0; i < 6; i++) {
+		for(j = 0; j < 2; j++) {
+			mac[i] <<= 4;
+			if(isdigit(*c))
+				mac[i] += *c - '0';
+			else if(isxdigit(*c))
+				mac[i] += toupper(*c) - 'A' + 10;
+			else {
+				goto err;
+			}
+			c++;
+		}
+
+		if(i != 5)
+			if(*c != ':') {
+				goto err;
+			}
+
+		c++;
+	}
+
+	// all good
+	for(i = 0; i < 6; i++) {
+		nuc980_mac0[i] = mac[i];
+
+	}
+	return 0;
+
+err:
+	return -EINVAL;
+}
+early_param("ethaddr0", setup_macaddr);
+
+static void adjust_link(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct phy_device *phydev = ether->phy_dev;
+	unsigned int val;
+	bool status_change = false;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ether->lock, flags);
+
+	if (phydev->link) {
+		if ((ether->speed != phydev->speed) ||
+		    (ether->duplex != phydev->duplex)) {
+			ether->speed = phydev->speed;
+			ether->duplex = phydev->duplex;
+			status_change = true;
+		}
+	} else {
+		// disable tx/rx
+		__raw_writel(__raw_readl( REG_MCMDR) & ~(MCMDR_RXON | MCMDR_TXON), REG_MCMDR);
+		ether->speed = 0;
+		ether->duplex = -1;
+	}
+
+	if (phydev->link != ether->link) {
+
+		ether->link = phydev->link;
+		if(phydev->link)
+			status_change = true;
+	}
+
+	spin_unlock_irqrestore(&ether->lock, flags);
+
+	if (status_change) {
+
+		val = __raw_readl( REG_MCMDR) | MCMDR_RXON | MCMDR_TXON;
+
+		if (ether->speed == 100) {
+			val |= MCMDR_OPMOD;
+		} else {
+			val &= ~MCMDR_OPMOD;
+		}
+
+		if(ether->duplex == DUPLEX_FULL) {
+			val |= MCMDR_FDUP;
+		} else {
+			val &= ~MCMDR_FDUP;
+		}
+
+		__raw_writel(val,  REG_MCMDR);
+		ETH_TRIGGER_TX; // in case some packets queued in descriptor
+	}
+}
+
+
+
+static void nuc980_write_cam(struct net_device *dev,
+				unsigned int x, unsigned char *pval)
+{
+	unsigned int msw, lsw;
+
+	msw = (pval[0] << 24) | (pval[1] << 16) | (pval[2] << 8) | pval[3];
+
+	lsw = (pval[4] << 24) | (pval[5] << 16);
+
+	__raw_writel(lsw,  REG_CAML_BASE + x * CAM_ENTRY_SIZE);
+	__raw_writel(msw,  REG_CAMM_BASE + x * CAM_ENTRY_SIZE);
+}
+
+
+static struct sk_buff * get_new_skb(struct net_device *dev, u32 i) {
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct sk_buff *skb = dev_alloc_skb(1520);
+
+	if (skb == NULL)
+		return NULL;
+
+	skb_reserve(skb, 2);
+	skb->dev = dev;
+
+	(ether->rdesc + i)->buffer = dma_map_single(&dev->dev, skb->data,
+							1520, DMA_FROM_DEVICE);
+	rx_skb[i] = skb;
+
+	return skb;
+}
+
+static int nuc980_init_desc(struct net_device *dev)
+{
+	struct nuc980_ether *ether;
+	struct nuc980_txbd  *tdesc;
+	struct nuc980_rxbd  *rdesc;
+	struct platform_device *pdev;
+	unsigned int i;
+
+	ether = netdev_priv(dev);
+	pdev = ether->pdev;
+
+	ether->tdesc = (struct nuc980_txbd *)
+			dma_alloc_coherent(&pdev->dev, sizeof(struct nuc980_txbd) * TX_DESC_SIZE,
+						&ether->tdesc_phys, GFP_KERNEL);
+
+	if (!ether->tdesc) {
+		dev_err(&pdev->dev, "Failed to allocate memory for tx desc\n");
+		return -ENOMEM;
+	}
+
+	ether->rdesc = (struct nuc980_rxbd *)
+			dma_alloc_coherent(&pdev->dev, sizeof(struct nuc980_rxbd) * RX_DESC_SIZE,
+						&ether->rdesc_phys, GFP_KERNEL);
+
+	if (!ether->rdesc) {
+		dev_err(&pdev->dev, "Failed to allocate memory for rx desc\n");
+		dma_free_coherent(&pdev->dev, sizeof(struct nuc980_txbd) * TX_DESC_SIZE,
+						ether->tdesc, ether->tdesc_phys);
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < TX_DESC_SIZE; i++) {
+		unsigned int offset;
+
+		tx_skb[i] = NULL;
+		tdesc = (ether->tdesc + i);
+
+		if (i == TX_DESC_SIZE - 1)
+			offset = 0;
+		else
+			offset = sizeof(struct nuc980_txbd) * (i + 1);
+
+		tdesc->next = ether->tdesc_phys + offset;
+		tdesc->buffer = (unsigned int)NULL;
+		tdesc->sl = 0;
+		tdesc->mode = PADDINGMODE | CRCMODE | MACTXINTEN;
+	}
+
+	ether->start_tx_ptr = ether->tdesc_phys;
+
+	for (i = 0; i < RX_DESC_SIZE; i++) {
+		unsigned int offset;
+
+		rdesc = (ether->rdesc + i);
+
+		if (i == RX_DESC_SIZE - 1)
+			offset = 0;
+		else
+			offset = sizeof(struct nuc980_rxbd) * (i + 1);
+
+		rdesc->next = ether->rdesc_phys + offset;
+		rdesc->sl = RX_OWEN_DMA;
+		if(get_new_skb(dev, i) == NULL) {
+			dma_free_coherent(&pdev->dev, sizeof(struct nuc980_txbd) * TX_DESC_SIZE,
+						ether->tdesc, ether->tdesc_phys);
+			dma_free_coherent(&pdev->dev, sizeof(struct nuc980_rxbd) * RX_DESC_SIZE,
+						ether->rdesc, ether->rdesc_phys);
+
+			for(; i != 0; i--) {
+				dma_unmap_single(&dev->dev, (dma_addr_t)((ether->rdesc + i)->buffer),
+							1520, DMA_FROM_DEVICE);
+				dev_kfree_skb_any(rx_skb[i]);
+			}
+			return -ENOMEM;
+		}
+	}
+
+	ether->start_rx_ptr = ether->rdesc_phys;
+
+	return 0;
+}
+
+// This API must call with Tx/Rx stopped
+static void nuc980_free_desc(struct net_device *dev)
+{
+	struct sk_buff *skb;
+	u32 i;
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev = ether->pdev;
+
+	for (i = 0; i < TX_DESC_SIZE; i++) {
+		skb = tx_skb[i];
+		if(skb != NULL) {
+			dma_unmap_single(&dev->dev, (dma_addr_t)((ether->tdesc + i)->buffer), skb->len, DMA_TO_DEVICE);
+			dev_kfree_skb_any(skb);
+		}
+	}
+
+	for (i = 0; i < RX_DESC_SIZE; i++) {
+		skb = rx_skb[i];
+		if(skb != NULL) {
+			dma_unmap_single(&dev->dev, (dma_addr_t)((ether->rdesc + i)->buffer), 1520, DMA_FROM_DEVICE);
+			dev_kfree_skb_any(skb);
+		}
+	}
+
+	dma_free_coherent(&pdev->dev, sizeof(struct nuc980_txbd) * TX_DESC_SIZE,
+				ether->tdesc, ether->tdesc_phys);
+	dma_free_coherent(&pdev->dev, sizeof(struct nuc980_rxbd) * RX_DESC_SIZE,
+				ether->rdesc, ether->rdesc_phys);
+
+}
+
+static void nuc980_set_fifo_threshold(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = TXTHD | BLENGTH;
+	__raw_writel(val,  REG_FFTCR);
+}
+
+static void nuc980_return_default_idle(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = __raw_readl( REG_MCMDR);
+	val |= SWR;
+	__raw_writel(val,  REG_MCMDR);
+}
+
+
+static void nuc980_enable_mac_interrupt(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = ENTXINTR | ENRXINTR | ENRXGD | ENTXCP | ENRDU;
+	val |= ENTXBERR | ENRXBERR | ENTXABT | ENWOL;
+
+	__raw_writel(val,  REG_MIEN);
+}
+
+static void nuc980_get_and_clear_int(struct net_device *dev,
+							unsigned int *val, unsigned int mask)
+{
+	*val = __raw_readl( REG_MISTA) & mask;
+	__raw_writel(*val,  REG_MISTA);
+}
+
+static void nuc980_set_global_maccmd(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = __raw_readl( REG_MCMDR);
+	val |= MCMDR_SPCRC | MCMDR_ACP;
+	__raw_writel(val,  REG_MCMDR);
+	__raw_writel(1518,  REG_DMARFC);
+}
+
+static void nuc980_enable_cam(struct net_device *dev)
+{
+	unsigned int val;
+
+	nuc980_write_cam(dev, CAM0, dev->dev_addr);
+
+	val = __raw_readl( REG_CAMEN);
+	val |= CAM0EN;
+	__raw_writel(val,  REG_CAMEN);
+}
+
+static void nuc980_enable_cam_command(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = CAMCMR_ECMP | CAMCMR_ABP | CAMCMR_AMP;
+	__raw_writel(val,  REG_CAMCMR);
+}
+
+
+static void nuc980_set_curdest(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	__raw_writel(ether->start_rx_ptr,  REG_RXDLSA);
+	__raw_writel(ether->start_tx_ptr,  REG_TXDLSA);
+}
+
+static void nuc980_reset_mac(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	ETH_DISABLE_TX;
+	ETH_DISABLE_RX;;
+
+	nuc980_return_default_idle(dev);
+	nuc980_set_fifo_threshold(dev);
+
+	if (!netif_queue_stopped(dev))
+		netif_stop_queue(dev);
+
+	nuc980_init_desc(dev);
+
+	ether->cur_tx = 0x0;
+	ether->finish_tx = 0x0;
+	ether->cur_rx = 0x0;
+
+	nuc980_set_curdest(dev);
+	nuc980_enable_cam(dev);
+	nuc980_enable_cam_command(dev);
+	nuc980_enable_mac_interrupt(dev);
+
+	dev->trans_start = jiffies; /* prevent tx timeout */
+
+	if (netif_queue_stopped(dev))
+		netif_wake_queue(dev);
+}
+
+static int nuc980_mdio_write(struct mii_bus *bus, int phy_id, int regnum,
+		u16 value)
+{
+	unsigned long timeout = jiffies + msecs_to_jiffies(MII_TIMEOUT * 100);
+
+	__raw_writel(value,  REG_MIID);
+	__raw_writel((phy_id << 0x08) | regnum | PHYBUSY | MDCON | PHYWR,  REG_MIIDA);
+
+
+	/* Wait for completion */
+	while (__raw_readl( REG_MIIDA) & PHYBUSY) {
+		if (time_after(jiffies, timeout))
+			return -ETIMEDOUT;
+		cpu_relax();
+	}
+
+	return 0;
+
+}
+
+static int nuc980_mdio_read(struct mii_bus *bus, int phy_id, int regnum)
+{
+	unsigned long timeout = jiffies + msecs_to_jiffies(MII_TIMEOUT * 100);
+
+
+	__raw_writel((phy_id << 0x08) | regnum | PHYBUSY | MDCON,  REG_MIIDA);
+
+	/* Wait for completion */
+	while (__raw_readl( REG_MIIDA) & PHYBUSY) {
+		if (time_after(jiffies, timeout))
+			return -ETIMEDOUT;
+		cpu_relax();
+	}
+
+	return __raw_readl(REG_MIID);
+}
+
+static int nuc980_mdio_reset(struct mii_bus *bus)
+{
+
+	// reser EMAC engine??
+	return 0;
+}
+
+static int nuc980_set_mac_address(struct net_device *dev, void *addr)
+{
+	struct sockaddr *address = addr;
+
+	if (!is_valid_ether_addr(address->sa_data))
+		return -EADDRNOTAVAIL;
+
+	memcpy(dev->dev_addr, address->sa_data, dev->addr_len);
+	nuc980_write_cam(dev, CAM0, dev->dev_addr);
+
+	return 0;
+}
+
+static int nuc980_ether_close(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev;
+
+	pdev = ether->pdev;
+
+	ETH_DISABLE_TX;
+	ETH_DISABLE_RX;
+	netif_stop_queue(dev);
+	napi_disable(&ether->napi);
+	free_irq(ether->txirq, dev);
+	free_irq(ether->rxirq, dev);
+
+	nuc980_return_default_idle(dev);
+	nuc980_free_desc(dev);
+
+	if (ether->phy_dev)
+		phy_stop(ether->phy_dev);
+
+	return 0;
+}
+
+static struct net_device_stats *nuc980_ether_stats(struct net_device *dev)
+{
+	struct nuc980_ether *ether;
+
+	ether = netdev_priv(dev);
+
+	return &ether->stats;
+}
+
+
+static int nuc980_ether_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct nuc980_txbd *txbd;
+
+	txbd = ether->tdesc + ether->cur_tx;
+	if(txbd->mode & TX_OWEN_DMA) {
+		netif_stop_queue(dev);
+		return NETDEV_TX_BUSY;
+	}
+
+	txbd->buffer = dma_map_single(&dev->dev, skb->data,
+					skb->len, DMA_TO_DEVICE);
+
+//	tx_skb[ether->cur_tx]  = skb;
+	txbd->sl = skb->len > 1514 ? 1514 : skb->len;
+	wmb();	// This is dummy function for ARM9
+	txbd->mode |= TX_OWEN_DMA;
+	wmb();	// This is dummy function for ARM9
+	tx_skb[ether->cur_tx]  = skb;
+	ETH_TRIGGER_TX;
+
+	if (++ether->cur_tx >= TX_DESC_SIZE)
+		ether->cur_tx = 0;
+	txbd = ether->tdesc + ether->cur_tx;
+	if(txbd->mode & TX_OWEN_DMA) {
+		netif_stop_queue(dev);
+		//return NETDEV_TX_BUSY;
+	}
+	return NETDEV_TX_OK;
+}
+
+static irqreturn_t nuc980_tx_interrupt(int irq, void *dev_id)
+{
+	struct nuc980_ether *ether;
+	struct platform_device *pdev;
+	struct net_device *dev;
+	unsigned int status;
+	struct sk_buff *s;
+	struct nuc980_txbd *txbd;
+
+	dev = dev_id;
+	ether = netdev_priv(dev);
+	pdev = ether->pdev;
+
+	nuc980_get_and_clear_int(dev, &status, 0xFFFF0000);
+
+	txbd = ether->tdesc + ether->finish_tx;
+	while((txbd->mode & TX_OWEN_DMA) != TX_OWEN_DMA) {
+		if((s = tx_skb[ether->finish_tx]) != NULL) {
+			dma_unmap_single(&dev->dev, txbd->buffer, s->len, DMA_TO_DEVICE);
+			dev_kfree_skb_irq(s);
+			tx_skb[ether->finish_tx] = NULL;
+			if (txbd->sl & TXDS_TXCP) {
+				ether->stats.tx_packets++;
+				ether->stats.tx_bytes += (txbd->sl & 0xFFFF);
+			} else {
+				ether->stats.tx_errors++;
+			}
+		} else
+			break;
+		ether->finish_tx = (ether->finish_tx + 1) % TX_DESC_SIZE;
+		txbd = ether->tdesc + ether->finish_tx;
+	}
+
+	if (status & MISTA_EXDEF) {
+		dev_err(&pdev->dev, "emc defer exceed interrupt\n");
+	} else if (status & MISTA_TXBERR) {
+		dev_err(&pdev->dev, "emc bus error interrupt\n");
+		BUG();
+	}
+
+	if (netif_queue_stopped(dev)) {
+		netif_wake_queue(dev);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static int nuc980_poll(struct napi_struct *napi, int budget)
+{
+	struct nuc980_ether *ether = container_of(napi, struct nuc980_ether, napi);
+	struct nuc980_rxbd *rxbd;
+	struct net_device *dev = ether->ndev;
+	struct sk_buff *skb, *s;
+	unsigned int length, status;
+	int rx_cnt = 0;
+	int complete = 0;
+
+	rxbd = (ether->rdesc + ether->cur_rx);
+
+	while(rx_cnt < budget) {
+
+		if((rxbd->sl & RX_OWEN_DMA) == RX_OWEN_DMA) {
+			complete = 1;
+			break;
+		}
+
+		s = rx_skb[ether->cur_rx];
+		status = rxbd->sl;
+		length = status & 0xFFFF;
+
+		if (likely(status & RXDS_RXGD)) {
+
+			skb = dev_alloc_skb(1520);
+			if (!skb) {
+				struct platform_device *pdev = ether->pdev;
+				dev_err(&pdev->dev, "get skb buffer error\n");
+				ether->stats.rx_dropped++;
+				goto rx_out;
+			}
+			dma_unmap_single(&dev->dev, (dma_addr_t)rxbd->buffer, 1520, DMA_FROM_DEVICE);
+
+			skb_put(s, length);
+			s->protocol = eth_type_trans(s, dev);
+			netif_receive_skb(s);
+			ether->stats.rx_packets++;
+			ether->stats.rx_bytes += length;
+			skb_reserve(skb, 2);
+			skb->dev = dev;
+
+			rxbd->buffer = dma_map_single(&dev->dev, skb->data,
+							1520, DMA_FROM_DEVICE);
+
+			rx_skb[ether->cur_rx] = skb;
+			rx_cnt++;
+
+		} else {
+			ether->stats.rx_errors++;
+
+			if (status & RXDS_RP) {
+				ether->stats.rx_length_errors++;
+			} else if (status & RXDS_CRCE) {
+				ether->stats.rx_crc_errors++;
+			} else if (status & RXDS_ALIE) {
+				ether->stats.rx_frame_errors++;
+			} else if (status & RXDS_PTLE) {
+				ether->stats.rx_over_errors++;
+			}
+		}
+
+		wmb();	// This is dummy function for ARM9
+		rxbd->sl = RX_OWEN_DMA;
+
+		if (++ether->cur_rx >= RX_DESC_SIZE)
+			ether->cur_rx = 0;
+
+		rxbd = (ether->rdesc + ether->cur_rx);
+
+	}
+
+	if(complete) {
+		napi_complete(napi);
+		__raw_writel(__raw_readl(REG_MIEN) | ENRXINTR,  REG_MIEN);
+	}
+
+rx_out:
+
+	ETH_TRIGGER_RX;
+	return(rx_cnt);
+}
+
+static irqreturn_t nuc980_rx_interrupt(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *)dev_id;
+	struct nuc980_ether *ether = netdev_priv(dev);
+	unsigned int status;
+
+	nuc980_get_and_clear_int(dev, &status, 0xFFFF);
+
+	if (unlikely(status & MISTA_RXBERR)) {
+		struct platform_device *pdev = ether->pdev;
+
+		dev_err(&pdev->dev, "emc rx bus error\n");
+		BUG();
+
+	} else {
+		if(status & MISTA_WOL) {
+
+		}
+
+		if(status & MISTA_RXGD) {
+			__raw_writel(__raw_readl(REG_MIEN) & ~ENRXINTR,  REG_MIEN);
+			napi_schedule(&ether->napi);
+		}
+	}
+	return IRQ_HANDLED;
+}
+
+
+static int nuc980_ether_open(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev = ether->pdev;
+
+	nuc980_reset_mac(dev);
+	nuc980_set_global_maccmd(dev);
+
+	if (request_irq(ether->txirq, nuc980_tx_interrupt,
+						0x0, pdev->name, dev)) {
+		dev_err(&pdev->dev, "register irq tx failed\n");
+		return -EAGAIN;
+	}
+
+	if (request_irq(ether->rxirq, nuc980_rx_interrupt,
+						IRQF_NO_SUSPEND, pdev->name, dev)) {
+		dev_err(&pdev->dev, "register irq rx failed\n");
+		free_irq(ether->txirq, dev);
+		return -EAGAIN;
+	}
+
+	phy_start(ether->phy_dev);
+	netif_start_queue(dev);
+	napi_enable(&ether->napi);
+
+	ETH_ENABLE_RX;
+
+	dev_info(&pdev->dev, "%s is OPENED\n", dev->name);
+
+	return 0;
+}
+
+static void nuc980_ether_set_multicast_list(struct net_device *dev)
+{
+	struct nuc980_ether *ether;
+	unsigned int rx_mode;
+
+	ether = netdev_priv(dev);
+
+	if (dev->flags & IFF_PROMISC)
+		rx_mode = CAMCMR_AUP | CAMCMR_AMP | CAMCMR_ABP | CAMCMR_ECMP;
+	else if ((dev->flags & IFF_ALLMULTI) || !netdev_mc_empty(dev))
+		rx_mode = CAMCMR_AMP | CAMCMR_ABP | CAMCMR_ECMP;
+	else
+		rx_mode = CAMCMR_ECMP | CAMCMR_ABP;
+	__raw_writel(rx_mode,  REG_CAMCMR);
+}
+
+static int nuc980_ether_ioctl(struct net_device *dev,
+						struct ifreq *ifr, int cmd)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct phy_device *phydev = ether->phy_dev;
+
+	if (!netif_running(dev))
+		return -EINVAL;
+
+	if (!phydev)
+		return -ENODEV;;
+
+	return phy_mii_ioctl(phydev, ifr, cmd);
+}
+
+static void nuc980_get_drvinfo(struct net_device *dev,
+					struct ethtool_drvinfo *info)
+{
+	strlcpy(info->driver, DRV_MODULE_NAME, sizeof(info->driver));
+	strlcpy(info->version, DRV_MODULE_VERSION, sizeof(info->version));
+	strlcpy(info->fw_version, "N/A", sizeof(info->fw_version));
+	strlcpy(info->bus_info, "N/A", sizeof(info->bus_info));
+}
+
+static int nuc980_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct phy_device *phydev = ether->phy_dev;
+
+	if (NULL == phydev)
+		return -ENODEV;
+
+	return phy_ethtool_gset(phydev, cmd);
+}
+
+static int nuc980_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct phy_device *phydev = ether->phy_dev;
+
+	if (NULL == phydev)
+		return -ENODEV;
+
+	return phy_ethtool_sset(phydev, cmd);
+}
+
+static u32 nuc980_get_msglevel(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	return ether->msg_enable;
+}
+
+static void nuc980_set_msglevel(struct net_device *dev, u32 level)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	ether->msg_enable = level;
+}
+
+static int nuc980_get_eee(struct net_device *dev, struct ethtool_eee *edata)
+{
+	return -EOPNOTSUPP;
+}
+
+static int nuc980_set_eee(struct net_device *dev, struct ethtool_eee *edata)
+{
+	return -EOPNOTSUPP;
+}
+
+static int nuc980_get_regs_len(struct net_device *dev)
+{
+	return 76 * sizeof(u32);
+}
+
+static void nuc980_get_regs(struct net_device *dev, struct ethtool_regs *regs, void *p)
+{
+
+	regs->version = 0;
+	memcpy(p, REG_CAMCMR, 76 * sizeof(u32));
+}
+
+#ifdef CONFIG_PM
+static void nuc980_get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	wol->supported = WAKE_MAGIC;
+	wol->wolopts = ether->wol ? WAKE_MAGIC : 0;
+
+}
+
+static int nuc980_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	if (wol->wolopts & ~WAKE_MAGIC)
+		return -EINVAL;
+
+	ether->wol = wol->wolopts & WAKE_MAGIC ? 1 : 0;
+
+	device_set_wakeup_capable(&dev->dev, wol->wolopts & WAKE_MAGIC);
+	device_set_wakeup_enable(&dev->dev, wol->wolopts & WAKE_MAGIC);
+
+	return 0;
+}
+#endif
+
+static int nuc980_get_ts_info(struct net_device *dev, struct ethtool_ts_info *info)
+{
+	info->so_timestamping = SOF_TIMESTAMPING_TX_HARDWARE |
+				SOF_TIMESTAMPING_RX_HARDWARE |
+				SOF_TIMESTAMPING_RAW_HARDWARE;
+	info->phc_index = 0;
+	info->tx_types = (1 << HWTSTAMP_TX_OFF) |
+			 (1 << HWTSTAMP_TX_ON);
+	info->rx_filters = (1 << HWTSTAMP_FILTER_NONE) |
+			   (1 << HWTSTAMP_FILTER_ALL);
+	return 0;
+}
+
+static const struct ethtool_ops nuc980_ether_ethtool_ops = {
+	.get_settings	= nuc980_get_settings,
+	.set_settings	= nuc980_set_settings,
+	.get_drvinfo	= nuc980_get_drvinfo,
+	.get_msglevel	= nuc980_get_msglevel,
+	.set_msglevel	= nuc980_set_msglevel,
+	.get_link 	= ethtool_op_get_link,
+	.get_eee	= nuc980_get_eee,
+	.set_eee	= nuc980_set_eee,
+	.get_regs_len	= nuc980_get_regs_len,
+	.get_regs	= nuc980_get_regs,
+#ifdef CONFIG_PM
+	.get_wol 	= nuc980_get_wol,
+	.set_wol 	= nuc980_set_wol,
+#endif
+	.get_ts_info	= nuc980_get_ts_info,
+};
+
+static const struct net_device_ops nuc980_ether_netdev_ops = {
+	.ndo_open		= nuc980_ether_open,
+	.ndo_stop		= nuc980_ether_close,
+	.ndo_start_xmit		= nuc980_ether_start_xmit,
+	.ndo_get_stats		= nuc980_ether_stats,
+	.ndo_set_rx_mode	= nuc980_ether_set_multicast_list,
+	.ndo_set_mac_address	= nuc980_set_mac_address,
+	.ndo_do_ioctl		= nuc980_ether_ioctl,
+	.ndo_validate_addr	= eth_validate_addr,
+	.ndo_change_mtu		= eth_change_mtu,
+};
+
+static void __init get_mac_address(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev;
+
+	pdev = ether->pdev;
+
+	if (is_valid_ether_addr(nuc980_mac0))
+		memcpy(dev->dev_addr, &nuc980_mac0[0], 0x06);
+	else
+		dev_err(&pdev->dev, "invalid mac address\n");
+}
+
+
+static int nuc980_mii_setup(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev;
+	struct phy_device *phydev;
+	int i, err = 0;
+
+	pdev = ether->pdev;
+
+	ether->mii_bus = mdiobus_alloc();
+	if (!ether->mii_bus) {
+		err = -ENOMEM;
+		dev_err(&pdev->dev, "mdiobus_alloc() failed\n");
+		goto out0;
+	}
+
+	ether->mii_bus->name = "nuc980_rmii0";
+	ether->mii_bus->read = &nuc980_mdio_read;
+	ether->mii_bus->write = &nuc980_mdio_write;
+	ether->mii_bus->reset = &nuc980_mdio_reset;
+	snprintf(ether->mii_bus->id, MII_BUS_ID_SIZE, "%s-%x",
+		 ether->pdev->name, ether->pdev->id);
+	ether->mii_bus->priv = ether;
+	ether->mii_bus->parent = &ether->pdev->dev;
+
+	ether->mii_bus->irq = kmalloc(sizeof(int) * PHY_MAX_ADDR, GFP_KERNEL);
+	if (!ether->mii_bus->irq) {
+		err = -ENOMEM;
+		dev_err(&pdev->dev, "kmalloc() failed\n");
+		goto out1;
+
+	}
+
+	for (i = 0; i < PHY_MAX_ADDR; i++)
+		ether->mii_bus->irq[i] = PHY_POLL;
+	//ether->mii_bus->irq[1] = ??   write me after the irq number is known
+
+	if (mdiobus_register(ether->mii_bus)) {
+		dev_err(&pdev->dev, "mdiobus_register() failed\n");
+		goto out2;
+	}
+
+	phydev = phy_find_first(ether->mii_bus);
+	if(phydev == NULL) {
+		err = -ENODEV;
+		dev_err(&pdev->dev, "phy_find_first() failed\n");
+		goto out3;
+	}
+
+	phydev = phy_connect(dev, dev_name(&phydev->dev),
+			     &adjust_link,
+			     PHY_INTERFACE_MODE_RMII);
+
+	if(IS_ERR(phydev)) {
+		err = PTR_ERR(phydev);
+		dev_err(&pdev->dev, "phy_connect() failed\n");
+		goto out3;
+	}
+
+	phydev->supported &= PHY_BASIC_FEATURES;
+	phydev->advertising = phydev->supported;
+	ether->phy_dev = phydev;
+	ether->wol = 0;
+
+	return 0;
+
+out3:
+	mdiobus_unregister(ether->mii_bus);
+out2:
+	kfree(ether->mii_bus->irq);
+out1:
+	mdiobus_free(ether->mii_bus);
+out0:
+
+	return err;
+}
+
+static int nuc980_ether_probe(struct platform_device *pdev)
+{
+	struct nuc980_ether *ether;
+	struct net_device *dev;
+	int error;
+	struct pinctrl *pinctrl;
+
+	dev = alloc_etherdev(sizeof(struct nuc980_ether));
+	if (!dev)
+		return -ENOMEM;
+
+	ether = netdev_priv(dev);
+
+	ether->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (ether->res == NULL) {
+		dev_err(&pdev->dev, "failed to get I/O memory\n");
+		error = -ENXIO;
+		goto err0;
+	}
+
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+	if (IS_ERR(pinctrl)) {
+		return PTR_ERR(pinctrl);
+	}
+
+	ether->txirq = platform_get_irq(pdev, 0);
+	if (ether->txirq < 0) {
+		dev_err(&pdev->dev, "failed to get ether tx irq\n");
+		error = -ENXIO;
+		goto err0;
+	}
+
+	ether->rxirq = platform_get_irq(pdev, 1);
+	if (ether->rxirq < 0) {
+		dev_err(&pdev->dev, "failed to get ether rx irq\n");
+		error = -ENXIO;
+		goto err0;
+	}
+
+	SET_NETDEV_DEV(dev, &pdev->dev);
+	platform_set_drvdata(pdev, dev);
+	ether->ndev = dev;
+
+	ether->eclk = clk_get(NULL, "emac0_eclk");
+	if (IS_ERR(ether->eclk)) {
+		dev_err(&pdev->dev, "failed to get emac0_eclk clock\n");
+		error = PTR_ERR(ether->eclk);
+		goto err1;
+	}
+
+	// Set MDC to 1M
+	clk_set_rate(ether->eclk, 1000000);
+
+	clk_prepare(ether->eclk);
+	clk_enable(ether->eclk);
+
+	ether->clk = clk_get(NULL, "emac0_hclk");
+	if (IS_ERR(ether->clk)) {
+		dev_err(&pdev->dev, "failed to get emac0_hclk clock\n");
+		error = PTR_ERR(ether->clk);
+		goto err1;
+	}
+
+	clk_prepare(ether->clk);
+	clk_enable(ether->clk);
+
+	ether->pdev = pdev;
+	ether->msg_enable = NETIF_MSG_LINK;
+
+	dev->netdev_ops = &nuc980_ether_netdev_ops;
+	dev->ethtool_ops = &nuc980_ether_ethtool_ops;
+
+	dev->tx_queue_len = 32;
+	dev->dma = 0x0;
+	dev->watchdog_timeo = TX_TIMEOUT;
+
+	get_mac_address(dev);
+
+	ether->cur_tx = 0x0;
+	ether->cur_rx = 0x0;
+	ether->finish_tx = 0x0;
+	ether->link = 0;
+	ether->speed = 100;
+	ether->duplex = DUPLEX_FULL;
+	spin_lock_init(&ether->lock);
+
+	netif_napi_add(dev, &ether->napi, nuc980_poll, 32);
+
+	ether_setup(dev);
+
+	if((error = nuc980_mii_setup(dev)) < 0) {
+		dev_err(&pdev->dev, "nuc980_mii_setup err\n");
+		goto err2;
+	}
+	netif_carrier_off(dev);
+	error = register_netdev(dev);
+	if (error != 0) {
+		dev_err(&pdev->dev, "register_netdev() failed\n");
+		error = -ENODEV;
+		goto err2;
+	}
+
+	return 0;
+
+err2:
+	clk_disable(ether->clk);
+	clk_put(ether->clk);
+err1:
+	platform_set_drvdata(pdev, NULL);
+err0:
+	free_netdev(dev);
+
+	return error;
+}
+
+static int nuc980_ether_remove(struct platform_device *pdev)
+{
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	unregister_netdev(dev);
+
+	clk_disable(ether->clk);
+	clk_put(ether->clk);
+
+	clk_disable(ether->eclk);
+	clk_put(ether->eclk);
+
+	free_irq(ether->txirq, dev);
+	free_irq(ether->rxirq, dev);
+	phy_disconnect(ether->phy_dev);
+
+	mdiobus_unregister(ether->mii_bus);
+	kfree(ether->mii_bus->irq);
+	mdiobus_free(ether->mii_bus);
+
+	platform_set_drvdata(pdev, NULL);
+
+	free_netdev(dev);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_ether_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	netif_device_detach(dev);
+
+	if(netif_running(dev)) {
+		ETH_DISABLE_TX;
+		ETH_DISABLE_RX;
+
+		napi_disable(&ether->napi);
+
+		if(ether->wol) {  // enable wakeup from magic packet
+			__raw_writel(__raw_readl(REG_MCMDR) | MCMDR_MGPWAKE, REG_MCMDR);
+			__raw_writel(__raw_readl(REG_WKUPSER1) | (1 << 16), REG_WKUPSER1);
+		} else {
+			phy_stop(ether->phy_dev);
+		}
+
+	}
+
+	return 0;
+
+}
+
+static int nuc980_ether_resume(struct platform_device *pdev)
+{
+
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	if (netif_running(dev)) {
+
+		if(ether->wol) {  // enable wakeup from magic packet
+			__raw_writel(__raw_readl(REG_WKUPSER1) & ~(1 << 16), REG_WKUPSER1);
+			__raw_writel(__raw_readl(REG_MCMDR) & ~MCMDR_MGPWAKE, REG_MCMDR);
+		} else {
+
+			phy_start(ether->phy_dev);
+		}
+
+		napi_enable(&ether->napi);
+
+		ETH_ENABLE_TX;
+		ETH_ENABLE_RX;
+
+	}
+
+	netif_device_attach(dev);
+	return 0;
+
+}
+
+#else
+#define nuc980_ether_suspend NULL
+#define nuc980_ether_resume NULL
+#endif
+
+static const struct of_device_id nuc980_emac0_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-emac0" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_emac0_of_match);
+
+static struct platform_driver nuc980_ether_driver = {
+	.probe		= nuc980_ether_probe,
+	.remove		= nuc980_ether_remove,
+	.suspend 	= nuc980_ether_suspend,
+	.resume 	= nuc980_ether_resume,
+	.driver		= {
+		.name	= "nuc980-emac0",
+		.of_match_table = of_match_ptr(nuc980_emac0_of_match),
+		.owner	= THIS_MODULE,
+	},
+};
+
+static int __init nuc980_ether_init(void)
+{
+
+	return platform_driver_register(&nuc980_ether_driver);
+}
+
+static void __exit nuc980_ether_exit(void)
+{
+	platform_driver_unregister(&nuc980_ether_driver);
+}
+
+module_init(nuc980_ether_init);
+module_exit(nuc980_ether_exit);
+
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_DESCRIPTION("NUC980 MAC0 driver");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-emac0");
diff -uprN linux-4.4.194/drivers/net/ethernet/nuvoton/nuc980_ether1.c NUC980-linux-4.4.194/drivers/net/ethernet/nuvoton/nuc980_ether1.c
--- linux-4.4.194/drivers/net/ethernet/nuvoton/nuc980_ether1.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/ethernet/nuvoton/nuc980_ether1.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1348 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/mii.h>
+#include <linux/phy.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/ethtool.h>
+#include <linux/platform_device.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/gfp.h>
+#include <linux/kthread.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/ctype.h>
+#include <linux/net_tstamp.h>
+
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-gcr.h>
+
+#define DRV_MODULE_NAME		"nuc980-emc1"
+#define DRV_MODULE_VERSION	"1.0"
+
+/* Ethernet MAC1 Registers */
+#define REG_CAMCMR		(void __iomem *)0xF0022000
+#define REG_CAMEN		(void __iomem *)0xF0022004
+#define REG_CAMM_BASE		(void __iomem *)0xF0022008
+#define REG_CAML_BASE		(void __iomem *)0xF002200c
+#define REG_TXDLSA		(void __iomem *)0xF0022088
+#define REG_RXDLSA		(void __iomem *)0xF002208C
+#define REG_MCMDR		(void __iomem *)0xF0022090
+#define REG_MIID		(void __iomem *)0xF0022094
+#define REG_MIIDA		(void __iomem *)0xF0022098
+#define REG_FFTCR		(void __iomem *)0xF002209C
+#define REG_TSDR		(void __iomem *)0xF00220a0
+#define REG_RSDR		(void __iomem *)0xF00220a4
+#define REG_DMARFC		(void __iomem *)0xF00220a8
+#define REG_MIEN		(void __iomem *)0xF00220ac
+#define REG_MISTA		(void __iomem *)0xF00220b0
+#define REG_CTXDSA		(void __iomem *)0xF00220cc
+#define REG_CTXBSA		(void __iomem *)0xF00220d0
+#define REG_CRXDSA		(void __iomem *)0xF00220d4
+#define REG_CRXBSA		(void __iomem *)0xF00220d8
+
+/* mac controller bit */
+#define MCMDR_RXON		0x01
+#define MCMDR_ACP		(0x01 << 3)
+#define MCMDR_SPCRC		(0x01 << 5)
+#define MCMDR_MGPWAKE		(0x01 << 6)
+#define MCMDR_TXON		(0x01 << 8)
+#define MCMDR_FDUP		(0x01 << 18)
+#define MCMDR_OPMOD		(0x01 << 20)
+#define SWR			(0x01 << 24)
+
+/* cam command register */
+#define CAMCMR_AUP		0x01
+#define CAMCMR_AMP		(0x01 << 1)
+#define CAMCMR_ABP		(0x01 << 2)
+#define CAMCMR_CCAM		(0x01 << 3)
+#define CAMCMR_ECMP		(0x01 << 4)
+#define CAM0EN			0x01
+
+/* mac mii controller bit */
+#define MDCON			(0x01 << 19)
+//#define PHYAD			(0x01 << 8)
+#define PHYWR			(0x01 << 16)
+#define PHYBUSY			(0x01 << 17)
+#define CAM_ENTRY_SIZE		0x08
+
+/* rx and tx status */
+#define TXDS_TXCP		(0x01 << 19)
+#define RXDS_CRCE		(0x01 << 17)
+#define RXDS_PTLE		(0x01 << 19)
+#define RXDS_RXGD		(0x01 << 20)
+#define RXDS_ALIE		(0x01 << 21)
+#define RXDS_RP			(0x01 << 22)
+
+/* mac interrupt status*/
+#define MISTA_EXDEF		(0x01 << 19)
+#define MISTA_TXBERR		(0x01 << 24)
+#define MISTA_TDU		(0x01 << 23)
+#define MISTA_RDU		(0x01 << 10)
+#define MISTA_RXBERR		(0x01 << 11)
+#define MISTA_WOL		(0x01 << 15)
+#define MISTA_RXGD		(0x01 << 4)
+#define MISTA_TXEMP		(0x01 << 17)
+#define MISTA_RXOV		(0x01 << 2)
+
+#define ENSTART			0x01
+#define ENRXINTR		0x01
+#define ENRXGD			(0x01 << 4)
+#define ENRDU			(0x01 << 10)
+#define ENRXBERR		(0x01 << 11)
+#define ENWOL			(0x01 << 15)
+#define ENTXINTR		(0x01 << 16)
+#define ENTXCP			(0x01 << 18)
+#define ENTXABT			(0x01 << 21)
+#define ENTXBERR		(0x01 << 24)
+#define PHYBUSY			(0x01 << 17)
+
+
+/* rx and tx owner bit */
+#define RX_OWEN_DMA		(0x01 << 31)
+#define RX_OWEN_CPU		(~(0x03 << 30))
+#define TX_OWEN_DMA		(0x01 << 31)
+#define TX_OWEN_CPU		(~(0x01 << 31))
+
+/* tx frame desc controller bit */
+#define MACTXINTEN		0x04
+#define CRCMODE			0x02
+#define PADDINGMODE		0x01
+
+/* fftcr controller bit */
+#define TXTHD 			(0x03 << 8)
+#define BLENGTH			(0x01 << 20)
+
+/* global setting for driver */
+#define RX_DESC_SIZE	32
+#define TX_DESC_SIZE	32
+#define MAX_RBUFF_SZ	0x600
+#define MAX_TBUFF_SZ	0x600
+#define TX_TIMEOUT	50
+#define DELAY		1000
+#define CAM0		0x0
+
+#define MII_TIMEOUT	100
+
+#define ETH_TRIGGER_RX	do{__raw_writel(ENSTART, REG_RSDR);}while(0)
+#define ETH_TRIGGER_TX	do{__raw_writel(ENSTART, REG_TSDR);}while(0)
+#define ETH_ENABLE_TX	do{__raw_writel(__raw_readl( REG_MCMDR) | MCMDR_TXON, REG_MCMDR);}while(0)
+#define ETH_ENABLE_RX	do{__raw_writel(__raw_readl( REG_MCMDR) | MCMDR_RXON, REG_MCMDR);}while(0)
+#define ETH_DISABLE_TX	do{__raw_writel(__raw_readl( REG_MCMDR) & ~MCMDR_TXON, REG_MCMDR);}while(0)
+#define ETH_DISABLE_RX	do{__raw_writel(__raw_readl( REG_MCMDR) & ~MCMDR_RXON, REG_MCMDR);}while(0)
+
+struct nuc980_rxbd {
+	unsigned int sl;
+	unsigned int buffer;
+	unsigned int reserved;
+	unsigned int next;
+};
+
+struct nuc980_txbd {
+	unsigned int mode;
+	unsigned int buffer;
+	unsigned int sl;
+	unsigned int next;
+};
+
+u8 nuc980_mac1[6] = { 0x08, 0x00, 0x27, 0x00, 0x01, 0x93 };
+
+static struct sk_buff *rx_skb[RX_DESC_SIZE];
+static struct sk_buff *tx_skb[TX_DESC_SIZE];
+
+struct  nuc980_ether {
+	spinlock_t lock;
+	struct nuc980_rxbd *rdesc;
+	struct nuc980_txbd *tdesc;
+	dma_addr_t rdesc_phys;
+	dma_addr_t tdesc_phys;
+	struct net_device_stats stats;
+	struct platform_device *pdev;
+	struct net_device *ndev;
+	struct resource *res;
+	struct clk *clk;
+	struct clk *eclk;
+	unsigned int msg_enable;
+	struct mii_bus *mii_bus;
+	struct phy_device *phy_dev;
+	struct napi_struct napi;
+	int rxirq;
+	int txirq;
+	unsigned int cur_tx;
+	unsigned int cur_rx;
+	unsigned int finish_tx;
+	unsigned int start_tx_ptr;
+	unsigned int start_rx_ptr;
+	int link;
+	int speed;
+	int duplex;
+	int wol;
+};
+
+
+static __init int setup_macaddr(char *str)
+{
+	u8 mac[6] = {0, 0, 0, 0, 0, 0};
+	char *c = str;
+	int i, j;
+
+	if (!str)
+		goto err;
+
+	for(i = 0; i < 6; i++) {
+		for(j = 0; j < 2; j++) {
+			mac[i] <<= 4;
+			if(isdigit(*c))
+				mac[i] += *c - '0';
+			else if(isxdigit(*c))
+				mac[i] += toupper(*c) - 'A' + 10;
+			else {
+				goto err;
+			}
+			c++;
+		}
+
+		if(i != 5)
+			if(*c != ':') {
+				goto err;
+			}
+
+		c++;
+	}
+
+	// all good
+	for(i = 0; i < 6; i++) {
+		nuc980_mac1[i] = mac[i];
+
+	}
+	return 0;
+
+err:
+	return -EINVAL;
+}
+early_param("ethaddr1", setup_macaddr);
+
+static void adjust_link(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct phy_device *phydev = ether->phy_dev;
+	unsigned int val;
+	bool status_change = false;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ether->lock, flags);
+
+	if (phydev->link) {
+		if ((ether->speed != phydev->speed) ||
+		    (ether->duplex != phydev->duplex)) {
+			ether->speed = phydev->speed;
+			ether->duplex = phydev->duplex;
+			status_change = true;
+		}
+	} else {
+		// disable tx/rx
+		__raw_writel(__raw_readl( REG_MCMDR) & ~(MCMDR_RXON | MCMDR_TXON), REG_MCMDR);
+		ether->speed = 0;
+		ether->duplex = -1;
+	}
+
+	if (phydev->link != ether->link) {
+
+		ether->link = phydev->link;
+		if(phydev->link)
+			status_change = true;
+	}
+
+	spin_unlock_irqrestore(&ether->lock, flags);
+
+	if (status_change) {
+
+		val = __raw_readl( REG_MCMDR) | MCMDR_RXON | MCMDR_TXON;
+
+		if (ether->speed == 100) {
+			val |= MCMDR_OPMOD;
+		} else {
+			val &= ~MCMDR_OPMOD;
+		}
+
+		if(ether->duplex == DUPLEX_FULL) {
+			val |= MCMDR_FDUP;
+		} else {
+			val &= ~MCMDR_FDUP;
+		}
+
+		__raw_writel(val,  REG_MCMDR);
+		ETH_TRIGGER_TX; // in case some packets queued in descriptor
+	}
+}
+
+
+
+static void nuc980_write_cam(struct net_device *dev,
+				unsigned int x, unsigned char *pval)
+{
+	unsigned int msw, lsw;
+
+	msw = (pval[0] << 24) | (pval[1] << 16) | (pval[2] << 8) | pval[3];
+
+	lsw = (pval[4] << 24) | (pval[5] << 16);
+
+	__raw_writel(lsw,  REG_CAML_BASE + x * CAM_ENTRY_SIZE);
+	__raw_writel(msw,  REG_CAMM_BASE + x * CAM_ENTRY_SIZE);
+}
+
+
+static struct sk_buff * get_new_skb(struct net_device *dev, u32 i) {
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct sk_buff *skb = dev_alloc_skb(1520);
+
+	if (skb == NULL)
+		return NULL;
+
+	skb_reserve(skb, 2);
+	skb->dev = dev;
+
+	(ether->rdesc + i)->buffer = dma_map_single(&dev->dev, skb->data,
+							1520, DMA_FROM_DEVICE);
+	rx_skb[i] = skb;
+
+	return skb;
+}
+
+static int nuc980_init_desc(struct net_device *dev)
+{
+	struct nuc980_ether *ether;
+	struct nuc980_txbd  *tdesc;
+	struct nuc980_rxbd  *rdesc;
+	struct platform_device *pdev;
+	unsigned int i;
+
+	ether = netdev_priv(dev);
+	pdev = ether->pdev;
+
+	ether->tdesc = (struct nuc980_txbd *)
+			dma_alloc_coherent(&pdev->dev, sizeof(struct nuc980_txbd) * TX_DESC_SIZE,
+						&ether->tdesc_phys, GFP_KERNEL);
+
+	if (!ether->tdesc) {
+		dev_err(&pdev->dev, "Failed to allocate memory for tx desc\n");
+		return -ENOMEM;
+	}
+
+	ether->rdesc = (struct nuc980_rxbd *)
+			dma_alloc_coherent(&pdev->dev, sizeof(struct nuc980_rxbd) * RX_DESC_SIZE,
+						&ether->rdesc_phys, GFP_KERNEL);
+
+	if (!ether->rdesc) {
+		dev_err(&pdev->dev, "Failed to allocate memory for rx desc\n");
+		dma_free_coherent(&pdev->dev, sizeof(struct nuc980_txbd) * TX_DESC_SIZE,
+						ether->tdesc, ether->tdesc_phys);
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < TX_DESC_SIZE; i++) {
+		unsigned int offset;
+
+		tx_skb[i] = NULL;
+		tdesc = (ether->tdesc + i);
+
+		if (i == TX_DESC_SIZE - 1)
+			offset = 0;
+		else
+			offset = sizeof(struct nuc980_txbd) * (i + 1);
+
+		tdesc->next = ether->tdesc_phys + offset;
+		tdesc->buffer = (unsigned int)NULL;
+		tdesc->sl = 0;
+		tdesc->mode = PADDINGMODE | CRCMODE | MACTXINTEN;
+	}
+
+	ether->start_tx_ptr = ether->tdesc_phys;
+
+	for (i = 0; i < RX_DESC_SIZE; i++) {
+		unsigned int offset;
+
+		rdesc = (ether->rdesc + i);
+
+		if (i == RX_DESC_SIZE - 1)
+			offset = 0;
+		else
+			offset = sizeof(struct nuc980_rxbd) * (i + 1);
+
+		rdesc->next = ether->rdesc_phys + offset;
+		rdesc->sl = RX_OWEN_DMA;
+		if(get_new_skb(dev, i) == NULL) {
+			dma_free_coherent(&pdev->dev, sizeof(struct nuc980_txbd) * TX_DESC_SIZE,
+						ether->tdesc, ether->tdesc_phys);
+			dma_free_coherent(&pdev->dev, sizeof(struct nuc980_rxbd) * RX_DESC_SIZE,
+						ether->rdesc, ether->rdesc_phys);
+
+			for(; i != 0; i--) {
+				dma_unmap_single(&dev->dev, (dma_addr_t)((ether->rdesc + i)->buffer),
+							1520, DMA_FROM_DEVICE);
+				dev_kfree_skb_any(rx_skb[i]);
+			}
+			return -ENOMEM;
+		}
+	}
+
+	ether->start_rx_ptr = ether->rdesc_phys;
+
+	return 0;
+}
+
+// This API must call with Tx/Rx stopped
+static void nuc980_free_desc(struct net_device *dev)
+{
+	struct sk_buff *skb;
+	u32 i;
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev = ether->pdev;
+
+	for (i = 0; i < TX_DESC_SIZE; i++) {
+		skb = tx_skb[i];
+		if(skb != NULL) {
+			dma_unmap_single(&dev->dev, (dma_addr_t)((ether->tdesc + i)->buffer), skb->len, DMA_TO_DEVICE);
+			dev_kfree_skb_any(skb);
+		}
+	}
+
+	for (i = 0; i < RX_DESC_SIZE; i++) {
+		skb = rx_skb[i];
+		if(skb != NULL) {
+			dma_unmap_single(&dev->dev, (dma_addr_t)((ether->rdesc + i)->buffer), 1520, DMA_FROM_DEVICE);
+			dev_kfree_skb_any(skb);
+		}
+	}
+
+	dma_free_coherent(&pdev->dev, sizeof(struct nuc980_txbd) * TX_DESC_SIZE,
+				ether->tdesc, ether->tdesc_phys);
+	dma_free_coherent(&pdev->dev, sizeof(struct nuc980_rxbd) * RX_DESC_SIZE,
+				ether->rdesc, ether->rdesc_phys);
+
+}
+
+static void nuc980_set_fifo_threshold(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = TXTHD | BLENGTH;
+	__raw_writel(val,  REG_FFTCR);
+}
+
+static void nuc980_return_default_idle(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = __raw_readl( REG_MCMDR);
+	val |= SWR;
+	__raw_writel(val,  REG_MCMDR);
+}
+
+
+static void nuc980_enable_mac_interrupt(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = ENTXINTR | ENRXINTR | ENRXGD | ENTXCP | ENRDU;
+	val |= ENTXBERR | ENRXBERR | ENTXABT | ENWOL;
+
+	__raw_writel(val,  REG_MIEN);
+}
+
+static void nuc980_get_and_clear_int(struct net_device *dev,
+							unsigned int *val, unsigned int mask)
+{
+	*val = __raw_readl( REG_MISTA) & mask;
+	__raw_writel(*val,  REG_MISTA);
+}
+
+static void nuc980_set_global_maccmd(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = __raw_readl( REG_MCMDR);
+	val |= MCMDR_SPCRC | MCMDR_ACP;
+	__raw_writel(val,  REG_MCMDR);
+	__raw_writel(1518,  REG_DMARFC);
+}
+
+static void nuc980_enable_cam(struct net_device *dev)
+{
+	unsigned int val;
+
+	nuc980_write_cam(dev, CAM0, dev->dev_addr);
+
+	val = __raw_readl( REG_CAMEN);
+	val |= CAM0EN;
+	__raw_writel(val,  REG_CAMEN);
+}
+
+static void nuc980_enable_cam_command(struct net_device *dev)
+{
+	unsigned int val;
+
+	val = CAMCMR_ECMP | CAMCMR_ABP | CAMCMR_AMP;
+	__raw_writel(val,  REG_CAMCMR);
+}
+
+
+static void nuc980_set_curdest(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	__raw_writel(ether->start_rx_ptr,  REG_RXDLSA);
+	__raw_writel(ether->start_tx_ptr,  REG_TXDLSA);
+}
+
+static void nuc980_reset_mac(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	ETH_DISABLE_TX;
+	ETH_DISABLE_RX;;
+
+	nuc980_return_default_idle(dev);
+	nuc980_set_fifo_threshold(dev);
+
+	if (!netif_queue_stopped(dev))
+		netif_stop_queue(dev);
+
+	nuc980_init_desc(dev);
+
+	ether->cur_tx = 0x0;
+	ether->finish_tx = 0x0;
+	ether->cur_rx = 0x0;
+
+	nuc980_set_curdest(dev);
+	nuc980_enable_cam(dev);
+	nuc980_enable_cam_command(dev);
+	nuc980_enable_mac_interrupt(dev);
+
+	dev->trans_start = jiffies; /* prevent tx timeout */
+
+	if (netif_queue_stopped(dev))
+		netif_wake_queue(dev);
+}
+
+static int nuc980_mdio_write(struct mii_bus *bus, int phy_id, int regnum,
+		u16 value)
+{
+	unsigned long timeout = jiffies + msecs_to_jiffies(MII_TIMEOUT * 100);
+
+	__raw_writel(value,  REG_MIID);
+	__raw_writel((phy_id << 0x08) | regnum | PHYBUSY | MDCON | PHYWR,  REG_MIIDA);
+
+
+	/* Wait for completion */
+	while (__raw_readl( REG_MIIDA) & PHYBUSY) {
+		if (time_after(jiffies, timeout))
+			return -ETIMEDOUT;
+		cpu_relax();
+	}
+
+	return 0;
+
+}
+
+static int nuc980_mdio_read(struct mii_bus *bus, int phy_id, int regnum)
+{
+	unsigned long timeout = jiffies + msecs_to_jiffies(MII_TIMEOUT * 100);
+
+
+	__raw_writel((phy_id << 0x08) | regnum | PHYBUSY | MDCON,  REG_MIIDA);
+
+	/* Wait for completion */
+	while (__raw_readl( REG_MIIDA) & PHYBUSY) {
+		if (time_after(jiffies, timeout))
+			return -ETIMEDOUT;
+		cpu_relax();
+	}
+
+	return __raw_readl(REG_MIID);
+}
+
+static int nuc980_mdio_reset(struct mii_bus *bus)
+{
+
+	// reser EMAC engine??
+	return 0;
+}
+
+static int nuc980_set_mac_address(struct net_device *dev, void *addr)
+{
+	struct sockaddr *address = addr;
+
+	if (!is_valid_ether_addr(address->sa_data))
+		return -EADDRNOTAVAIL;
+
+	memcpy(dev->dev_addr, address->sa_data, dev->addr_len);
+	nuc980_write_cam(dev, CAM0, dev->dev_addr);
+
+	return 0;
+}
+
+static int nuc980_ether_close(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev;
+
+	pdev = ether->pdev;
+
+	ETH_DISABLE_TX;
+	ETH_DISABLE_RX;
+	netif_stop_queue(dev);
+	napi_disable(&ether->napi);
+	free_irq(ether->txirq, dev);
+	free_irq(ether->rxirq, dev);
+
+	nuc980_return_default_idle(dev);
+	nuc980_free_desc(dev);
+
+	if (ether->phy_dev)
+		phy_stop(ether->phy_dev);
+
+	return 0;
+}
+
+static struct net_device_stats *nuc980_ether_stats(struct net_device *dev)
+{
+	struct nuc980_ether *ether;
+
+	ether = netdev_priv(dev);
+
+	return &ether->stats;
+}
+
+
+static int nuc980_ether_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct nuc980_txbd *txbd;
+
+	txbd = ether->tdesc + ether->cur_tx;
+	if(txbd->mode & TX_OWEN_DMA) {
+		netif_stop_queue(dev);
+		return NETDEV_TX_BUSY;
+	}
+
+	txbd->buffer = dma_map_single(&dev->dev, skb->data,
+					skb->len, DMA_TO_DEVICE);
+
+//	tx_skb[ether->cur_tx]  = skb;
+	txbd->sl = skb->len > 1514 ? 1514 : skb->len;
+	wmb();	// This is dummy function for ARM9
+	txbd->mode |= TX_OWEN_DMA;
+	wmb();	// This is dummy function for ARM9
+	tx_skb[ether->cur_tx]  = skb;
+	ETH_TRIGGER_TX;
+
+	if (++ether->cur_tx >= TX_DESC_SIZE)
+		ether->cur_tx = 0;
+	txbd = ether->tdesc + ether->cur_tx;
+	if(txbd->mode & TX_OWEN_DMA) {
+		netif_stop_queue(dev);
+		//return NETDEV_TX_BUSY;
+	}
+	return NETDEV_TX_OK;
+}
+
+static irqreturn_t nuc980_tx_interrupt(int irq, void *dev_id)
+{
+	struct nuc980_ether *ether;
+	struct platform_device *pdev;
+	struct net_device *dev;
+	unsigned int status;
+	struct sk_buff *s;
+	struct nuc980_txbd *txbd;
+
+	dev = dev_id;
+	ether = netdev_priv(dev);
+	pdev = ether->pdev;
+
+	nuc980_get_and_clear_int(dev, &status, 0xFFFF0000);
+
+	txbd = ether->tdesc + ether->finish_tx;
+	while((txbd->mode & TX_OWEN_DMA) != TX_OWEN_DMA) {
+		if((s = tx_skb[ether->finish_tx]) != NULL) {
+			dma_unmap_single(&dev->dev, txbd->buffer, s->len, DMA_TO_DEVICE);
+			dev_kfree_skb_irq(s);
+			tx_skb[ether->finish_tx] = NULL;
+			if (txbd->sl & TXDS_TXCP) {
+				ether->stats.tx_packets++;
+				ether->stats.tx_bytes += (txbd->sl & 0xFFFF);
+			} else {
+				ether->stats.tx_errors++;
+			}
+		} else
+			break;
+		ether->finish_tx = (ether->finish_tx + 1) % TX_DESC_SIZE;
+		txbd = ether->tdesc + ether->finish_tx;
+	}
+
+	if (status & MISTA_EXDEF) {
+		dev_err(&pdev->dev, "emc defer exceed interrupt\n");
+	} else if (status & MISTA_TXBERR) {
+		dev_err(&pdev->dev, "emc bus error interrupt\n");
+		BUG();
+	}
+
+	if (netif_queue_stopped(dev)) {
+		netif_wake_queue(dev);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static int nuc980_poll(struct napi_struct *napi, int budget)
+{
+	struct nuc980_ether *ether = container_of(napi, struct nuc980_ether, napi);
+	struct nuc980_rxbd *rxbd;
+	struct net_device *dev = ether->ndev;
+	struct sk_buff *skb, *s;
+	unsigned int length, status;
+	int rx_cnt = 0;
+	int complete = 0;
+
+	rxbd = (ether->rdesc + ether->cur_rx);
+
+	while(rx_cnt < budget) {
+
+		if((rxbd->sl & RX_OWEN_DMA) == RX_OWEN_DMA) {
+			complete = 1;
+			break;
+		}
+
+		s = rx_skb[ether->cur_rx];
+		status = rxbd->sl;
+		length = status & 0xFFFF;
+
+		if (likely(status & RXDS_RXGD)) {
+
+			skb = dev_alloc_skb(1520);
+			if (!skb) {
+				struct platform_device *pdev = ether->pdev;
+				dev_err(&pdev->dev, "get skb buffer error\n");
+				ether->stats.rx_dropped++;
+				goto rx_out;
+			}
+			dma_unmap_single(&dev->dev, (dma_addr_t)rxbd->buffer, 1520, DMA_FROM_DEVICE);
+
+			skb_put(s, length);
+			s->protocol = eth_type_trans(s, dev);
+			netif_receive_skb(s);
+			ether->stats.rx_packets++;
+			ether->stats.rx_bytes += length;
+			skb_reserve(skb, 2);
+			skb->dev = dev;
+
+			rxbd->buffer = dma_map_single(&dev->dev, skb->data,
+							1520, DMA_FROM_DEVICE);
+
+			rx_skb[ether->cur_rx] = skb;
+			rx_cnt++;
+
+		} else {
+			ether->stats.rx_errors++;
+
+			if (status & RXDS_RP) {
+				ether->stats.rx_length_errors++;
+			} else if (status & RXDS_CRCE) {
+				ether->stats.rx_crc_errors++;
+			} else if (status & RXDS_ALIE) {
+				ether->stats.rx_frame_errors++;
+			} else if (status & RXDS_PTLE) {
+				ether->stats.rx_over_errors++;
+			}
+		}
+
+		wmb();	// This is dummy function for ARM9
+		rxbd->sl = RX_OWEN_DMA;
+
+		if (++ether->cur_rx >= RX_DESC_SIZE)
+			ether->cur_rx = 0;
+
+		rxbd = (ether->rdesc + ether->cur_rx);
+
+	}
+
+	if(complete) {
+		napi_complete(napi);
+		__raw_writel(__raw_readl(REG_MIEN) | ENRXINTR,  REG_MIEN);
+	}
+
+rx_out:
+
+	ETH_TRIGGER_RX;
+	return(rx_cnt);
+}
+
+static irqreturn_t nuc980_rx_interrupt(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *)dev_id;
+	struct nuc980_ether *ether = netdev_priv(dev);
+	unsigned int status;
+
+	nuc980_get_and_clear_int(dev, &status, 0xFFFF);
+
+	if (unlikely(status & MISTA_RXBERR)) {
+		struct platform_device *pdev = ether->pdev;
+
+		dev_err(&pdev->dev, "emc rx bus error\n");
+		BUG();
+
+	} else {
+		if(status & MISTA_WOL) {
+
+		}
+
+		if(status & MISTA_RXGD) {
+			__raw_writel(__raw_readl(REG_MIEN) & ~ENRXINTR,  REG_MIEN);
+			napi_schedule(&ether->napi);
+		}
+	}
+	return IRQ_HANDLED;
+}
+
+
+static int nuc980_ether_open(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev = ether->pdev;
+
+	nuc980_reset_mac(dev);
+	nuc980_set_global_maccmd(dev);
+
+	if (request_irq(ether->txirq, nuc980_tx_interrupt,
+						0x0, pdev->name, dev)) {
+		dev_err(&pdev->dev, "register irq tx failed\n");
+		return -EAGAIN;
+	}
+
+	if (request_irq(ether->rxirq, nuc980_rx_interrupt,
+						IRQF_NO_SUSPEND, pdev->name, dev)) {
+		dev_err(&pdev->dev, "register irq rx failed\n");
+		free_irq(ether->txirq, dev);
+		return -EAGAIN;
+	}
+
+	phy_start(ether->phy_dev);
+	netif_start_queue(dev);
+	napi_enable(&ether->napi);
+
+	ETH_ENABLE_RX;
+
+	dev_info(&pdev->dev, "%s is OPENED\n", dev->name);
+
+	return 0;
+}
+
+static void nuc980_ether_set_multicast_list(struct net_device *dev)
+{
+	struct nuc980_ether *ether;
+	unsigned int rx_mode;
+
+	ether = netdev_priv(dev);
+
+	if (dev->flags & IFF_PROMISC)
+		rx_mode = CAMCMR_AUP | CAMCMR_AMP | CAMCMR_ABP | CAMCMR_ECMP;
+	else if ((dev->flags & IFF_ALLMULTI) || !netdev_mc_empty(dev))
+		rx_mode = CAMCMR_AMP | CAMCMR_ABP | CAMCMR_ECMP;
+	else
+		rx_mode = CAMCMR_ECMP | CAMCMR_ABP;
+	__raw_writel(rx_mode,  REG_CAMCMR);
+}
+
+static int nuc980_ether_ioctl(struct net_device *dev,
+						struct ifreq *ifr, int cmd)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct phy_device *phydev = ether->phy_dev;
+
+	if (!netif_running(dev))
+		return -EINVAL;
+
+	if (!phydev)
+		return -ENODEV;;
+
+	return phy_mii_ioctl(phydev, ifr, cmd);
+}
+
+static void nuc980_get_drvinfo(struct net_device *dev,
+					struct ethtool_drvinfo *info)
+{
+	strlcpy(info->driver, DRV_MODULE_NAME, sizeof(info->driver));
+	strlcpy(info->version, DRV_MODULE_VERSION, sizeof(info->version));
+	strlcpy(info->fw_version, "N/A", sizeof(info->fw_version));
+	strlcpy(info->bus_info, "N/A", sizeof(info->bus_info));
+}
+
+static int nuc980_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct phy_device *phydev = ether->phy_dev;
+
+	if (NULL == phydev)
+		return -ENODEV;
+
+	return phy_ethtool_gset(phydev, cmd);
+}
+
+static int nuc980_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct phy_device *phydev = ether->phy_dev;
+
+	if (NULL == phydev)
+		return -ENODEV;
+
+	return phy_ethtool_sset(phydev, cmd);
+}
+
+static u32 nuc980_get_msglevel(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	return ether->msg_enable;
+}
+
+static void nuc980_set_msglevel(struct net_device *dev, u32 level)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	ether->msg_enable = level;
+}
+
+static int nuc980_get_eee(struct net_device *dev, struct ethtool_eee *edata)
+{
+	return -EOPNOTSUPP;
+}
+
+static int nuc980_set_eee(struct net_device *dev, struct ethtool_eee *edata)
+{
+	return -EOPNOTSUPP;
+}
+
+static int nuc980_get_regs_len(struct net_device *dev)
+{
+	return 76 * sizeof(u32);
+}
+
+static void nuc980_get_regs(struct net_device *dev, struct ethtool_regs *regs, void *p)
+{
+
+	regs->version = 0;
+	memcpy(p, REG_CAMCMR, 76 * sizeof(u32));
+}
+
+#ifdef CONFIG_PM
+static void nuc980_get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	wol->supported = WAKE_MAGIC;
+	wol->wolopts = ether->wol ? WAKE_MAGIC : 0;
+
+}
+
+static int nuc980_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	if (wol->wolopts & ~WAKE_MAGIC)
+		return -EINVAL;
+
+	ether->wol = wol->wolopts & WAKE_MAGIC ? 1 : 0;
+
+	device_set_wakeup_capable(&dev->dev, wol->wolopts & WAKE_MAGIC);
+	device_set_wakeup_enable(&dev->dev, wol->wolopts & WAKE_MAGIC);
+
+	return 0;
+}
+#endif
+
+static int nuc980_get_ts_info(struct net_device *dev, struct ethtool_ts_info *info)
+{
+	info->so_timestamping = SOF_TIMESTAMPING_TX_HARDWARE |
+				SOF_TIMESTAMPING_RX_HARDWARE |
+				SOF_TIMESTAMPING_RAW_HARDWARE;
+	info->phc_index = 0;
+	info->tx_types = (1 << HWTSTAMP_TX_OFF) |
+			 (1 << HWTSTAMP_TX_ON);
+	info->rx_filters = (1 << HWTSTAMP_FILTER_NONE) |
+			   (1 << HWTSTAMP_FILTER_ALL);
+	return 0;
+}
+
+static const struct ethtool_ops nuc980_ether_ethtool_ops = {
+	.get_settings	= nuc980_get_settings,
+	.set_settings	= nuc980_set_settings,
+	.get_drvinfo	= nuc980_get_drvinfo,
+	.get_msglevel	= nuc980_get_msglevel,
+	.set_msglevel	= nuc980_set_msglevel,
+	.get_link 	= ethtool_op_get_link,
+	.get_eee	= nuc980_get_eee,
+	.set_eee	= nuc980_set_eee,
+	.get_regs_len	= nuc980_get_regs_len,
+	.get_regs	= nuc980_get_regs,
+#ifdef CONFIG_PM
+	.get_wol 	= nuc980_get_wol,
+	.set_wol 	= nuc980_set_wol,
+#endif
+	.get_ts_info	= nuc980_get_ts_info,
+};
+
+static const struct net_device_ops nuc980_ether_netdev_ops = {
+	.ndo_open		= nuc980_ether_open,
+	.ndo_stop		= nuc980_ether_close,
+	.ndo_start_xmit		= nuc980_ether_start_xmit,
+	.ndo_get_stats		= nuc980_ether_stats,
+	.ndo_set_rx_mode	= nuc980_ether_set_multicast_list,
+	.ndo_set_mac_address	= nuc980_set_mac_address,
+	.ndo_do_ioctl		= nuc980_ether_ioctl,
+	.ndo_validate_addr	= eth_validate_addr,
+	.ndo_change_mtu		= eth_change_mtu,
+};
+
+static void __init get_mac_address(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev;
+
+	pdev = ether->pdev;
+
+	if (is_valid_ether_addr(nuc980_mac1))
+		memcpy(dev->dev_addr, &nuc980_mac1[0], 0x06);
+	else
+		dev_err(&pdev->dev, "invalid mac address\n");
+}
+
+
+static int nuc980_mii_setup(struct net_device *dev)
+{
+	struct nuc980_ether *ether = netdev_priv(dev);
+	struct platform_device *pdev;
+	struct phy_device *phydev;
+	int i, err = 0;
+
+	pdev = ether->pdev;
+
+	ether->mii_bus = mdiobus_alloc();
+	if (!ether->mii_bus) {
+		err = -ENOMEM;
+		dev_err(&pdev->dev, "mdiobus_alloc() failed\n");
+		goto out0;
+	}
+
+	ether->mii_bus->name = "nuc980_rmii1";
+	ether->mii_bus->read = &nuc980_mdio_read;
+	ether->mii_bus->write = &nuc980_mdio_write;
+	ether->mii_bus->reset = &nuc980_mdio_reset;
+	snprintf(ether->mii_bus->id, MII_BUS_ID_SIZE, "%s-%x",
+		 ether->pdev->name, ether->pdev->id);
+	ether->mii_bus->priv = ether;
+	ether->mii_bus->parent = &ether->pdev->dev;
+
+	ether->mii_bus->irq = kmalloc(sizeof(int) * PHY_MAX_ADDR, GFP_KERNEL);
+	if (!ether->mii_bus->irq) {
+		err = -ENOMEM;
+		dev_err(&pdev->dev, "kmalloc() failed\n");
+		goto out1;
+
+	}
+
+	for (i = 0; i < PHY_MAX_ADDR; i++)
+		ether->mii_bus->irq[i] = PHY_POLL;
+	//ether->mii_bus->irq[1] = ??   write me after the irq number is known
+
+	if (mdiobus_register(ether->mii_bus)) {
+		dev_err(&pdev->dev, "mdiobus_register() failed\n");
+		goto out2;
+	}
+
+	phydev = phy_find_first(ether->mii_bus);
+	if(phydev == NULL) {
+		err = -ENODEV;
+		dev_err(&pdev->dev, "phy_find_first() failed\n");
+		goto out3;
+	}
+
+	phydev = phy_connect(dev, dev_name(&phydev->dev),
+			     &adjust_link,
+			     PHY_INTERFACE_MODE_RMII);
+
+	if(IS_ERR(phydev)) {
+		err = PTR_ERR(phydev);
+		dev_err(&pdev->dev, "phy_connect() failed\n");
+		goto out3;
+	}
+
+	phydev->supported &= PHY_BASIC_FEATURES;
+	phydev->advertising = phydev->supported;
+	ether->phy_dev = phydev;
+	ether->wol = 0;
+
+	return 0;
+
+out3:
+	mdiobus_unregister(ether->mii_bus);
+out2:
+	kfree(ether->mii_bus->irq);
+out1:
+	mdiobus_free(ether->mii_bus);
+out0:
+
+	return err;
+}
+
+static int nuc980_ether_probe(struct platform_device *pdev)
+{
+	struct nuc980_ether *ether;
+	struct net_device *dev;
+	int error;
+	struct pinctrl *pinctrl;
+
+	dev = alloc_etherdev(sizeof(struct nuc980_ether));
+	if (!dev)
+		return -ENOMEM;
+
+	ether = netdev_priv(dev);
+
+	ether->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (ether->res == NULL) {
+		dev_err(&pdev->dev, "failed to get I/O memory\n");
+		error = -ENXIO;
+		goto err0;
+	}
+
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+	if (IS_ERR(pinctrl)) {
+		return PTR_ERR(pinctrl);
+	}
+
+	ether->txirq = platform_get_irq(pdev, 0);
+	if (ether->txirq < 0) {
+		dev_err(&pdev->dev, "failed to get ether tx irq\n");
+		error = -ENXIO;
+		goto err0;
+	}
+
+	ether->rxirq = platform_get_irq(pdev, 1);
+	if (ether->rxirq < 0) {
+		dev_err(&pdev->dev, "failed to get ether rx irq\n");
+		error = -ENXIO;
+		goto err0;
+	}
+
+	SET_NETDEV_DEV(dev, &pdev->dev);
+	platform_set_drvdata(pdev, dev);
+	ether->ndev = dev;
+
+	ether->eclk = clk_get(NULL, "emac1_eclk");
+	if (IS_ERR(ether->eclk)) {
+		dev_err(&pdev->dev, "failed to get emac1_eclk clock\n");
+		error = PTR_ERR(ether->eclk);
+		goto err1;
+	}
+
+	// Set MDC to 1M
+	clk_set_rate(ether->eclk, 1000000);
+
+	clk_prepare(ether->eclk);
+	clk_enable(ether->eclk);
+
+	ether->clk = clk_get(NULL, "emac1_hclk");
+	if (IS_ERR(ether->clk)) {
+		dev_err(&pdev->dev, "failed to get emac1_hclk clock\n");
+		error = PTR_ERR(ether->clk);
+		goto err1;
+	}
+
+	clk_prepare(ether->clk);
+	clk_enable(ether->clk);
+
+	ether->pdev = pdev;
+	ether->msg_enable = NETIF_MSG_LINK;
+
+	dev->netdev_ops = &nuc980_ether_netdev_ops;
+	dev->ethtool_ops = &nuc980_ether_ethtool_ops;
+
+	dev->tx_queue_len = 32;
+	dev->dma = 0x0;
+	dev->watchdog_timeo = TX_TIMEOUT;
+
+	get_mac_address(dev);
+
+	ether->cur_tx = 0x0;
+	ether->cur_rx = 0x0;
+	ether->finish_tx = 0x0;
+	ether->link = 0;
+	ether->speed = 100;
+	ether->duplex = DUPLEX_FULL;
+	spin_lock_init(&ether->lock);
+
+	netif_napi_add(dev, &ether->napi, nuc980_poll, 32);
+
+	ether_setup(dev);
+
+	if((error = nuc980_mii_setup(dev)) < 0) {
+		dev_err(&pdev->dev, "nuc980_mii_setup err\n");
+		goto err2;
+	}
+	netif_carrier_off(dev);
+	error = register_netdev(dev);
+	if (error != 0) {
+		dev_err(&pdev->dev, "register_netdev() failed\n");
+		error = -ENODEV;
+		goto err2;
+	}
+
+	return 0;
+
+err2:
+	clk_disable(ether->clk);
+	clk_put(ether->clk);
+err1:
+	platform_set_drvdata(pdev, NULL);
+err0:
+	free_netdev(dev);
+
+	return error;
+}
+
+static int nuc980_ether_remove(struct platform_device *pdev)
+{
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	unregister_netdev(dev);
+
+	clk_disable(ether->clk);
+	clk_put(ether->clk);
+
+	clk_disable(ether->eclk);
+	clk_put(ether->eclk);
+
+	free_irq(ether->txirq, dev);
+	free_irq(ether->rxirq, dev);
+	phy_disconnect(ether->phy_dev);
+
+	mdiobus_unregister(ether->mii_bus);
+	kfree(ether->mii_bus->irq);
+	mdiobus_free(ether->mii_bus);
+
+	platform_set_drvdata(pdev, NULL);
+
+	free_netdev(dev);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_ether_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	netif_device_detach(dev);
+
+	if(netif_running(dev)) {
+		ETH_DISABLE_TX;
+		ETH_DISABLE_RX;
+
+		napi_disable(&ether->napi);
+
+		if(ether->wol) {  // enable wakeup from magic packet
+			__raw_writel(__raw_readl(REG_MCMDR) | MCMDR_MGPWAKE, REG_MCMDR);
+			__raw_writel(__raw_readl(REG_WKUPSER1) | (1 << 17), REG_WKUPSER1);
+		} else {
+			phy_stop(ether->phy_dev);
+		}
+
+	}
+
+	return 0;
+
+}
+
+static int nuc980_ether_resume(struct platform_device *pdev)
+{
+
+	struct net_device *dev = platform_get_drvdata(pdev);
+	struct nuc980_ether *ether = netdev_priv(dev);
+
+	if (netif_running(dev)) {
+
+		if(ether->wol) {  // enable wakeup from magic packet
+			__raw_writel(__raw_readl(REG_WKUPSER1) & ~(1 << 17), REG_WKUPSER1);
+			__raw_writel(__raw_readl(REG_MCMDR) & ~MCMDR_MGPWAKE, REG_MCMDR);
+		} else {
+
+			phy_start(ether->phy_dev);
+		}
+
+		napi_enable(&ether->napi);
+
+		ETH_ENABLE_TX;
+		ETH_ENABLE_RX;
+
+	}
+
+	netif_device_attach(dev);
+	return 0;
+
+}
+
+#else
+#define nuc980_ether_suspend NULL
+#define nuc980_ether_resume NULL
+#endif
+
+static const struct of_device_id nuc980_emac1_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-emac1" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_emac1_of_match);
+
+static struct platform_driver nuc980_ether_driver = {
+	.probe		= nuc980_ether_probe,
+	.remove		= nuc980_ether_remove,
+	.suspend 	= nuc980_ether_suspend,
+	.resume 	= nuc980_ether_resume,
+	.driver		= {
+		.name	= "nuc980-emac1",
+		.of_match_table = of_match_ptr(nuc980_emac1_of_match),
+		.owner	= THIS_MODULE,
+	},
+};
+
+static int __init nuc980_ether_init(void)
+{
+
+	return platform_driver_register(&nuc980_ether_driver);
+}
+
+static void __exit nuc980_ether_exit(void)
+{
+	platform_driver_unregister(&nuc980_ether_driver);
+}
+
+module_init(nuc980_ether_init);
+module_exit(nuc980_ether_exit);
+
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_DESCRIPTION("NUC980 MAC1 driver");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-emac1");
diff -uprN linux-4.4.194/drivers/net/irda/Kconfig NUC980-linux-4.4.194/drivers/net/irda/Kconfig
--- linux-4.4.194/drivers/net/irda/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/net/irda/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -17,6 +17,12 @@ config IRTTY_SIR
 
 	  If unsure, say Y.
 
+config NUC980_SIR
+	tristate "NUC980 SIR on UART"
+	depends on IRDA && TTY
+	help
+      Enable SIR function device on NUC980 UART devcies.
+
 config BFIN_SIR
 	tristate "Blackfin SIR on UART"
 	depends on BLACKFIN && IRDA
diff -uprN linux-4.4.194/drivers/net/irda/Makefile NUC980-linux-4.4.194/drivers/net/irda/Makefile
--- linux-4.4.194/drivers/net/irda/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/net/irda/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -24,6 +24,7 @@ obj-$(CONFIG_SH_IRDA)		+= sh_irda.o
 obj-$(CONFIG_IRTTY_SIR)		+= irtty-sir.o	sir-dev.o
 obj-$(CONFIG_BFIN_SIR)		+= bfin_sir.o
 obj-$(CONFIG_SH_SIR)		+= sh_sir.o
+obj-$(CONFIG_NUC980_SIR)	+= nuc980-sir.o sir-dev.o
 # dongle drivers for SIR drivers
 obj-$(CONFIG_ESI_DONGLE)	+= esi-sir.o
 obj-$(CONFIG_TEKRAM_DONGLE)	+= tekram-sir.o
diff -uprN linux-4.4.194/drivers/net/irda/nuc980-sir.c NUC980-linux-4.4.194/drivers/net/irda/nuc980-sir.c
--- linux-4.4.194/drivers/net/irda/nuc980-sir.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/irda/nuc980-sir.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,580 @@
+/*
+ *  linux/drivers/net/irda/nuc980_sir.c
+ *
+ *  NUC980 IrDA driver
+ *
+ *
+ *  Copyright (C) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/tty.h>
+#include <linux/init.h>
+#include <asm/uaccess.h>
+#include <linux/delay.h>
+#include <linux/mutex.h>
+#include <linux/serial_core.h>
+#include <linux/serial.h>
+#include <net/irda/irda.h>
+#include <net/irda/irda_device.h>
+#include <asm/serial.h>
+#include <mach/map.h>
+#include <mach/regs-serial.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+#include "sir-dev.h"
+#include "nuc980_sir.h"
+
+/*
+ * This defines the low- and high-watermarks for throttling and
+ * unthrottling the TTY driver.  These watermarks are used for
+ * controlling the space in the read buffer.
+ */
+#define TTY_THRESHOLD_THROTTLE    128 /* now based on remaining room */
+#define TTY_THRESHOLD_UNTHROTTLE  128
+
+static int qos_mtt_bits = 0x03;      /* 5 ms or more */
+
+module_param(qos_mtt_bits, int, 0);
+MODULE_PARM_DESC(qos_mtt_bits, "Minimum Turn Time");
+
+/* serialize ldisc open/close with sir_dev */
+static DEFINE_MUTEX(nuc980irda_mutex);
+
+struct n_irda_data
+{
+	unsigned char lnext:1, erasing:1, raw:1, real_raw:1, icanon:1;
+
+	DECLARE_BITMAP(read_flags, N_TTY_BUF_SIZE);
+
+	char *read_buf;
+	int read_head;
+	int read_tail;
+	int read_cnt;
+
+	int canon_data;
+	unsigned long canon_head;
+	unsigned int canon_column;
+
+	struct mutex atomic_read_lock;
+	raw_spinlock_t read_lock;
+
+	void  *priv;
+};
+
+struct uart_nuc980sir_port
+{
+	struct uart_port	port;
+
+	unsigned short		capabilities;	/* port capabilities */
+	unsigned char		ier;
+	unsigned char		lcr;
+	unsigned char		mcr;
+	unsigned char		mcr_mask;	/* mask of user bits */
+	unsigned char		mcr_force;	/* mask of forced bits */
+
+	/*
+	 * We provide a per-port pm hook.
+	 */
+	void  (*pm)(struct uart_port *port, unsigned int state, unsigned int old);
+};
+
+static void n_irda_set_room(struct tty_struct *tty);
+
+/* called from sir_dev when there is more data to send
+ * context is either netdev->hard_xmit or some transmit-completion bh
+ * i.e. we are under spinlock here and must not sleep.
+ */
+static int nuc980irda_do_write(struct sir_dev *dev, const unsigned char *ptr, size_t len)
+{
+	struct sirtty_cb *priv = dev->priv;
+	struct tty_struct *tty;
+	int writelen;
+
+	IRDA_ASSERT(priv != NULL, return -1;);
+	IRDA_ASSERT(priv->magic == IRTTY_MAGIC, return -1;);
+
+	tty = priv->tty;
+	if (!tty->ops->write)
+		return 0;
+	set_bit(TTY_DO_WRITE_WAKEUP, &tty->flags);
+	writelen = tty_write_room(tty);
+	if (writelen > len)
+		writelen = len;
+	return tty->ops->write(tty, ptr, writelen);
+}
+
+/* notifier from sir_dev when irda% device gets opened (ifup) */
+static int nuc980irda_start_dev(struct sir_dev *dev)
+{
+	struct sirtty_cb *priv;
+	struct tty_struct *tty;
+
+	/* serialize with ldisc open/close */
+	mutex_lock(&nuc980irda_mutex);
+
+	priv = dev->priv;
+	if (unlikely(!priv || priv->magic!=IRTTY_MAGIC)) {
+		mutex_unlock(&nuc980irda_mutex);
+		return -ESTALE;
+	}
+
+	tty = priv->tty;
+
+	if (tty->ops->start)
+		tty->ops->start(tty);
+
+	mutex_unlock(&nuc980irda_mutex);
+	return 0;
+}
+
+
+static struct sir_driver sir_nuc980_drv = {
+	.owner              = THIS_MODULE,
+	.driver_name        = "sir_nuc980",
+	.start_dev          = nuc980irda_start_dev,
+	//.stop_dev         = NULL,
+	.do_write           = nuc980irda_do_write,
+	//.chars_in_buffer  = NULL,
+	//.wait_until_sent  = NULL,
+	//.set_speed        = NULL,
+	//.set_dtr_rts      = NULL,
+};
+
+
+/*
+ * Function nuc980irda_ioctl (tty, file, cmd, arg)
+ *
+ *     The Swiss army knife of system calls :-)
+ *
+ */
+static int nuc980irda_ioctl(struct tty_struct *tty, struct file *file, unsigned int cmd, unsigned long arg)
+{
+	struct irtty_info { char name[6]; } ;
+	int err = 0;
+
+	switch (cmd)
+	{
+		case IRTTY_IOCTDONGLE:
+
+		break;
+
+		case IRTTY_IOCGET:
+
+		break;
+
+		default:
+			err = tty_mode_ioctl(tty, file, cmd, arg);
+		break;
+	}
+
+	return err;
+}
+
+static inline void nuc980_stop_receiver(struct tty_struct *tty, int stop)
+{
+	struct ktermios old_termios;
+	int cflag;
+
+	down_write(&tty->termios_rwsem);
+	old_termios = tty->termios;
+	cflag = tty->termios.c_cflag;
+
+	if (stop)
+		cflag &= ~CREAD;
+	else
+		cflag |= CREAD;
+
+	tty->termios.c_cflag = cflag;
+	if (tty->ops->set_termios)
+		tty->ops->set_termios(tty, &old_termios);
+
+	up_write(&tty->termios_rwsem);
+}
+
+
+static void nuc980_reset_buffer_flags(struct n_irda_data *ldata)
+{
+	unsigned long flags;
+
+	raw_spin_lock_irqsave(&ldata->read_lock, flags);
+	ldata->read_head = ldata->read_tail = ldata->read_cnt = 0;
+	raw_spin_unlock_irqrestore(&ldata->read_lock, flags);
+
+	ldata->canon_head = ldata->canon_data = ldata->erasing = 0;
+	bitmap_zero(ldata->read_flags, N_TTY_BUF_SIZE);
+}
+
+/*
+ *  Function nuc980irda_open
+ *
+ *    This function is called by the TTY module when the IrDA line
+ *    discipline is called for.  Because we are sure the tty line exists,
+ *    we only have to link it to a free IrDA channel.
+ */
+static int nuc980irda_open(struct tty_struct *tty)
+{
+	struct sir_dev *dev;
+	struct sirtty_cb *priv = NULL;
+	int ret = 0;
+	struct n_irda_data *ldata = NULL;
+
+	ldata = kzalloc(sizeof(*ldata), GFP_KERNEL);
+	if (!ldata)
+	{
+		ret = -ENOMEM;
+		goto err_free_bufs;
+	}
+
+	ldata->read_buf = kzalloc(N_TTY_BUF_SIZE, GFP_KERNEL);
+	if (!ldata->read_buf)
+	{
+		ret = -ENOMEM;
+		goto err_free_bufs;
+	}
+
+	/* stop the underlying  driver */
+	nuc980_stop_receiver(tty, TRUE);
+	if (tty->ops->stop)
+		tty->ops->stop(tty);
+
+	tty_driver_flush_buffer(tty);
+
+	/* apply mtt override */
+	sir_nuc980_drv.qos_mtt_bits = qos_mtt_bits;
+
+	/* get a sir device instance for this driver */
+	dev = sirdev_get_instance(&sir_nuc980_drv, tty->name);
+
+	if (!dev)
+	{
+		ret = -ENODEV;
+		goto out;
+	}
+
+	/* allocate private device info block */
+	priv = kzalloc(sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+	{
+		ret = -ENOMEM;
+		goto err_free_bufs;
+	}
+
+	priv->magic = IRTTY_MAGIC;
+	priv->tty   = tty;
+	priv->dev   = dev;
+
+	/* serialize with start_dev - in case we were racing with ifup */
+	mutex_lock(&nuc980irda_mutex);
+
+	dev->priv = priv;
+
+	tty->disc_data = ldata;
+	ldata->priv = priv;
+	//tty->disc_data = priv;
+	nuc980_reset_buffer_flags(tty->disc_data);
+
+	tty->receive_room = 65536;
+
+	mutex_unlock(&nuc980irda_mutex);
+
+	pr_debug("%s - %s: irda line discipline opened\n", __func__, tty->name);
+
+	return 0;
+
+out:
+
+err_free_bufs:
+		kfree(ldata->read_buf);
+		kfree(ldata);
+		kfree(priv);
+
+	return ret;
+}
+
+/*
+ *  Function nuc980irda_close (tty)
+ *
+ *    Close down a IrDA channel. This means flushing out any pending queues,
+ *    and then restoring the TTY line discipline to what it was before it got
+ *    hooked to IrDA (which usually is TTY again).
+ */
+static void nuc980irda_close(struct tty_struct *tty)
+{
+	struct n_irda_data *ldata = tty->disc_data;
+	struct sirtty_cb *priv = ldata->priv;
+
+	/* we are dead now */
+	tty->disc_data = NULL;
+
+	sirdev_put_instance(priv->dev);
+
+	kfree(priv);
+
+	pr_debug("%s - %s: irda line discipline closed\n", __func__, tty->name);
+}
+
+
+/**
+ *	nuc980irda_copy_from_read_buf	-	copy read data directly
+ *	@tty: terminal device
+ *	@b: user data
+ *	@nr: size of data
+ *
+ *	Helper function to speed up n_tty_read.  It is only called when
+ *	ICANON is off; it copies characters straight from the tty queue to
+ *	user space directly.  It can be profitably called twice; once to
+ *	drain the space from the tail pointer to the (physical) end of the
+ *	buffer, and once to drain the space from the (physical) beginning of
+ *	the buffer to head pointer.
+ *
+ *	Called under the ldata->atomic_read_lock sem
+ *
+ */
+static int nuc980irda_copy_from_read_buf(struct tty_struct *tty, unsigned char __user **b, size_t *nr)
+{
+	struct n_irda_data *ldata = tty->disc_data;
+	int retval;
+	size_t n;
+	unsigned long flags;
+	bool is_eof;
+
+	retval = 0;
+	raw_spin_lock_irqsave(&ldata->read_lock, flags);
+	n = min(ldata->read_cnt, N_TTY_BUF_SIZE - ldata->read_tail);
+	n = min(*nr, n);
+	raw_spin_unlock_irqrestore(&ldata->read_lock, flags);
+	if (n)
+	{
+		retval = copy_to_user(*b, &ldata->read_buf[ldata->read_tail], n);
+		n -= retval;
+		is_eof = n == 1 &&
+			ldata->read_buf[ldata->read_tail] == EOF_CHAR(tty);
+		tty_audit_add_data(tty, &ldata->read_buf[ldata->read_tail], n,
+				ldata->icanon);
+		raw_spin_lock_irqsave(&ldata->read_lock, flags);
+		ldata->read_tail = (ldata->read_tail + n) & (N_TTY_BUF_SIZE-1);
+		ldata->read_cnt -= n;
+		/* Turn single EOF into zero-length read */
+		if (L_EXTPROC(tty) && ldata->icanon && is_eof && !ldata->read_cnt)
+			n = 0;
+		raw_spin_unlock_irqrestore(&ldata->read_lock, flags);
+		*b += n;
+		*nr -= n;
+	}
+	return retval;
+}
+
+ssize_t	nuc980irda_read(struct tty_struct *tty, struct file *file, unsigned char __user *buf, size_t nr)
+{
+	unsigned char __user *b = buf;
+	DECLARE_WAITQUEUE(wait, current);
+	int minimum, time;
+	ssize_t retval = 0;
+	ssize_t size;
+	//long timeout;
+	int uncopied;
+
+	minimum = time = 0;
+	//timeout = MAX_SCHEDULE_TIMEOUT;
+
+	add_wait_queue(&tty->read_wait, &wait);
+	while (nr)
+	{
+		uncopied = nuc980irda_copy_from_read_buf(tty, &b, &nr);
+
+		if (uncopied)
+		{
+			retval = -EFAULT;
+			//break;
+			continue;
+		}
+
+		if (b - buf >= minimum)
+			break;
+	}
+
+	remove_wait_queue(&tty->read_wait, &wait);
+
+	size = b - buf;
+	if (size)
+		retval = size;
+
+	n_irda_set_room(tty);
+	return retval;
+}
+
+
+ssize_t	nuc980irda_write(struct tty_struct *tty, struct file *file, const unsigned char *buf, size_t nr)
+{
+	int writelen;
+
+	writelen = tty_write_room(tty);
+	if (writelen > nr)
+		writelen = nr;
+	return tty->ops->write(tty, buf, writelen);
+}
+
+/**
+ *	n_irda_set_room	-	receive space
+ *	@tty: terminal
+ *
+ *	Called by the driver to find out how much data it is
+ *	permitted to feed to the line discipline without any being lost
+ *	and thus to manage flow control. Not serialized. Answers for the
+ *	"instant".
+ */
+
+static void n_irda_set_room(struct tty_struct *tty)
+{
+	struct n_irda_data *ldata = tty->disc_data;
+	int left;
+	int old_left;
+
+	/* ldata->read_cnt is not read locked ? */
+	if (I_PARMRK(tty))
+	{
+		/* Multiply read_cnt by 3, since each byte might take up to
+		 * three times as many spaces when PARMRK is set (depending on
+		 * its flags, e.g. parity error). */
+		left = N_TTY_BUF_SIZE - ldata->read_cnt * 3 - 1;
+	}
+	else
+		left = N_TTY_BUF_SIZE - ldata->read_cnt - 1;
+
+	/*
+	 * If we are doing input canonicalization, and there are no
+	 * pending newlines, let characters through without limit, so
+	 * that erase characters will be handled.  Other excess
+	 * characters will be beeped.
+	 */
+	if (left <= 0)
+		left = ldata->icanon && !ldata->canon_data;
+	old_left = tty->receive_room;
+	tty->receive_room = left;
+
+	/* Did this open up the receive buffer? We may need to flip */
+	if (left && !old_left)
+	{
+		WARN_RATELIMIT(tty->port->itty == NULL,
+				"scheduling with invalid itty\n");
+		/* see if ldisc has been killed - if so, this means that
+		 * even though the ldisc has been halted and ->buf.work
+		 * cancelled, ->buf.work is about to be rescheduled
+		 */
+		WARN_RATELIMIT(test_bit(TTY_LDISC_HALTED, &tty->flags), "scheduling buffer work for halted ldisc\n");
+		schedule_work(&tty->port->buf.work);
+	}
+}
+
+/*
+ *  Function nuc980irda_receive_buf( tty, cp, count)
+ *
+ *    Handle the 'receiver data ready' interrupt.  This function is called
+ *    by the 'tty_io' module in the kernel when a block of IrDA data has
+ *    been received, which can now be decapsulated and delivered for
+ *    further processing
+ *
+ * calling context depends on underlying driver and tty->port->low_latency!
+ * for example (low_latency: 1 / 0):
+ * serial.c:	uart-interrupt / softint
+ * usbserial:	urb-complete-interrupt / softint
+ */
+static void nuc980irda_receive_buf(struct tty_struct *tty, const unsigned char *cp, char *fp, int count)
+{
+	struct n_irda_data *ldata = tty->disc_data;
+	int i;
+	unsigned long cpuflags;
+
+	raw_spin_lock_irqsave(&ldata->read_lock, cpuflags);
+	i = min(N_TTY_BUF_SIZE - ldata->read_cnt,
+		N_TTY_BUF_SIZE - ldata->read_head);
+	i = min(count, i);
+	memcpy(ldata->read_buf + ldata->read_head, cp, i);
+	ldata->read_head = (ldata->read_head + i) & (N_TTY_BUF_SIZE-1);
+	ldata->read_cnt += i;
+	cp += i;
+	count -= i;
+
+	raw_spin_unlock_irqrestore(&ldata->read_lock, cpuflags);
+
+	n_irda_set_room(tty);
+
+	/*
+	 * Check the remaining room for the input canonicalization
+	 * mode.  We don't want to throttle the driver if we're in
+	 * canonical mode and don't have a newline yet!
+	 */
+	while (1)
+	{
+		tty_set_flow_change(tty, TTY_THROTTLE_SAFE);
+		if (tty->receive_room >= TTY_THRESHOLD_THROTTLE)
+			break;
+		if (!tty_throttle_safe(tty))
+			break;
+	}
+	__tty_set_flow_change(tty, 0);
+}
+
+/*
+ * Function nuc980irda_write_wakeup (tty)
+ *
+ *    Called by the driver when there's room for more data.  If we have
+ *    more packets to send, we send them here.
+ *
+ */
+static void nuc980irda_write_wakeup(struct tty_struct *tty)
+{
+
+}
+
+static struct tty_ldisc_ops nuc980irda_ldisc =
+{
+	.magic		= TTY_LDISC_MAGIC,
+	.name		= "nuc980-sir",
+	.flags		= 0,
+	.open		= nuc980irda_open,
+	.close		= nuc980irda_close,
+	.read		= nuc980irda_read,
+	.write		= nuc980irda_write,
+	.ioctl		= nuc980irda_ioctl,
+	.poll		= NULL,
+	.receive_buf	= nuc980irda_receive_buf,
+	.write_wakeup	= nuc980irda_write_wakeup,
+	.owner		= THIS_MODULE,
+};
+
+static int __init nuc980_sir_init(void)
+{
+	int err;
+
+	if ((err = tty_register_ldisc(N_IRDA, &nuc980irda_ldisc)) != 0)
+		pr_debug("IrDA: can't register line discipline (err = %d)\n", err);
+	return err;
+}
+
+static void __exit nuc980_sir_cleanup(void)
+{
+	int err;
+
+	if ((err = tty_unregister_ldisc(N_IRDA)))
+	{
+		pr_debug("%s(), can't unregister line discipline (err = %d)\n", __func__, err);
+	}
+}
+
+
+module_init(nuc980_sir_init);
+module_exit(nuc980_sir_cleanup);
+
+MODULE_DESCRIPTION("IrDA device driver");
+MODULE_ALIAS_LDISC(N_IRDA);
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/net/irda/nuc980_sir.h NUC980-linux-4.4.194/drivers/net/irda/nuc980_sir.h
--- linux-4.4.194/drivers/net/irda/nuc980_sir.h	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/net/irda/nuc980_sir.h	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,35 @@
+/*
+ *  linux/drivers/net/irda/nuc980_sir.h
+ *
+ *  NUC980 IrDA driver
+ *
+ *
+ *  Copyright (C) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+#ifndef IRTTYSIR_H
+#define IRTTYSIR_H
+
+#include <net/irda/irda.h>
+#include <net/irda/irda_device.h>
+
+#define IRTTY_IOC_MAGIC 'e'
+#define IRTTY_IOCTDONGLE  _IO(IRTTY_IOC_MAGIC, 1)
+#define IRTTY_IOCGET      _IOR(IRTTY_IOC_MAGIC, 2, struct irtty_info)
+#define IRTTY_IOC_MAXNR   2
+
+struct sirtty_cb {
+	magic_t magic;
+
+	struct sir_dev *dev;
+	struct tty_struct  *tty;
+
+	chipio_t io; /* IrDA controller information */
+};
+
+#endif
diff -uprN linux-4.4.194/drivers/pinctrl/Kconfig NUC980-linux-4.4.194/drivers/pinctrl/Kconfig
--- linux-4.4.194/drivers/pinctrl/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/pinctrl/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -247,6 +247,14 @@ config PINCTRL_ZYNQ
 	help
 	  This selectes the pinctrl driver for Xilinx Zynq.
 
+config PINCTRL_NUC980
+	bool "NUC980 pinctrl driver"
+	depends on ARCH_NUC980
+	select PINMUX
+	select PINCONF
+	help
+	  Say Y here to enable NUC980 pinctrl driver
+
 source "drivers/pinctrl/bcm/Kconfig"
 source "drivers/pinctrl/berlin/Kconfig"
 source "drivers/pinctrl/freescale/Kconfig"
diff -uprN linux-4.4.194/drivers/pinctrl/Makefile NUC980-linux-4.4.194/drivers/pinctrl/Makefile
--- linux-4.4.194/drivers/pinctrl/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/pinctrl/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -39,7 +39,11 @@ obj-$(CONFIG_PINCTRL_LPC18XX)	+= pinctrl
 obj-$(CONFIG_PINCTRL_TB10X)	+= pinctrl-tb10x.o
 obj-$(CONFIG_PINCTRL_ST) 	+= pinctrl-st.o
 obj-$(CONFIG_PINCTRL_ZYNQ)	+= pinctrl-zynq.o
-
+ifeq ($(CONFIG_USE_OF),y)
+obj-$(CONFIG_PINCTRL_NUC980)    += pinctrl-nuc980-dt.o
+else
+obj-$(CONFIG_PINCTRL_NUC980)    += pinctrl-nuc980.o
+endif
 obj-$(CONFIG_ARCH_BCM)		+= bcm/
 obj-$(CONFIG_ARCH_BERLIN)	+= berlin/
 obj-y				+= freescale/
diff -uprN linux-4.4.194/drivers/pinctrl/pinctrl-nuc980.c NUC980-linux-4.4.194/drivers/pinctrl/pinctrl-nuc980.c
--- linux-4.4.194/drivers/pinctrl/pinctrl-nuc980.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/pinctrl/pinctrl-nuc980.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,4887 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/pinctrl/machine.h>
+#include <linux/pinctrl/pinctrl.h>
+#include <linux/pinctrl/pinmux.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+// The numbering is not related to actual layout.
+const struct pinctrl_pin_desc nuc980_pins[] = {
+	PINCTRL_PIN(0x00, "PA0"),
+	PINCTRL_PIN(0x01, "PA1"),
+	PINCTRL_PIN(0x02, "PA2"),
+	PINCTRL_PIN(0x03, "PA3"),
+	PINCTRL_PIN(0x04, "PA4"),
+	PINCTRL_PIN(0x05, "PA5"),
+	PINCTRL_PIN(0x06, "PA6"),
+	PINCTRL_PIN(0x07, "PA7"),
+	PINCTRL_PIN(0x08, "PA8"),
+	PINCTRL_PIN(0x09, "PA9"),
+	PINCTRL_PIN(0x0A, "PA10"),
+	PINCTRL_PIN(0x0B, "PA11"),
+	PINCTRL_PIN(0x0C, "PA12"),
+	PINCTRL_PIN(0x0D, "PA13"),
+	PINCTRL_PIN(0x0E, "PA14"),
+	PINCTRL_PIN(0x0F, "PA15"),
+	PINCTRL_PIN(0x10, "PB0"),
+	PINCTRL_PIN(0x11, "PB1"),
+	PINCTRL_PIN(0x12, "PB2"),
+	PINCTRL_PIN(0x13, "PB3"),
+	PINCTRL_PIN(0x14, "PB4"),
+	PINCTRL_PIN(0x15, "PB5"),
+	PINCTRL_PIN(0x16, "PB6"),
+	PINCTRL_PIN(0x17, "PB7"),
+	PINCTRL_PIN(0x18, "PB8"),
+	PINCTRL_PIN(0x19, "PB9"),
+	PINCTRL_PIN(0x1A, "PB10"),
+	PINCTRL_PIN(0x1B, "PB11"),
+	PINCTRL_PIN(0x1C, "PB12"),
+	PINCTRL_PIN(0x1D, "PB13"),
+	PINCTRL_PIN(0x1E, "PB14"),
+	PINCTRL_PIN(0x1F, "PB15"),
+	PINCTRL_PIN(0x20, "PC0"),
+	PINCTRL_PIN(0x21, "PC1"),
+	PINCTRL_PIN(0x22, "PC2"),
+	PINCTRL_PIN(0x23, "PC3"),
+	PINCTRL_PIN(0x24, "PC4"),
+	PINCTRL_PIN(0x25, "PC5"),
+	PINCTRL_PIN(0x26, "PC6"),
+	PINCTRL_PIN(0x27, "PC7"),
+	PINCTRL_PIN(0x28, "PC8"),
+	PINCTRL_PIN(0x29, "PC9"),
+	PINCTRL_PIN(0x2A, "PC10"),
+	PINCTRL_PIN(0x2B, "PC11"),
+	PINCTRL_PIN(0x2C, "PC12"),
+	PINCTRL_PIN(0x2D, "PC13"),
+	PINCTRL_PIN(0x2E, "PC14"),
+	PINCTRL_PIN(0x2F, "PC15"),
+	PINCTRL_PIN(0x30, "PD0"),
+	PINCTRL_PIN(0x31, "PD1"),
+	PINCTRL_PIN(0x32, "PD2"),
+	PINCTRL_PIN(0x33, "PD3"),
+	PINCTRL_PIN(0x34, "PD4"),
+	PINCTRL_PIN(0x35, "PD5"),
+	PINCTRL_PIN(0x36, "PD6"),
+	PINCTRL_PIN(0x37, "PD7"),
+	PINCTRL_PIN(0x38, "PD8"),
+	PINCTRL_PIN(0x39, "PD9"),
+	PINCTRL_PIN(0x3A, "PD10"),
+	PINCTRL_PIN(0x3B, "PD11"),
+	PINCTRL_PIN(0x3C, "PD12"),
+	PINCTRL_PIN(0x3D, "PD13"),
+	PINCTRL_PIN(0x3E, "PD14"),
+	PINCTRL_PIN(0x3F, "PD15"),
+	PINCTRL_PIN(0x40, "PE0"),
+	PINCTRL_PIN(0x41, "PE1"),
+	PINCTRL_PIN(0x42, "PE2"),
+	PINCTRL_PIN(0x43, "PE3"),
+	PINCTRL_PIN(0x44, "PE4"),
+	PINCTRL_PIN(0x45, "PE5"),
+	PINCTRL_PIN(0x46, "PE6"),
+	PINCTRL_PIN(0x47, "PE7"),
+	PINCTRL_PIN(0x48, "PE8"),
+	PINCTRL_PIN(0x49, "PE9"),
+	PINCTRL_PIN(0x4A, "PE10"),
+	PINCTRL_PIN(0x4B, "PE11"),
+	PINCTRL_PIN(0x4C, "PE12"),
+	PINCTRL_PIN(0x4D, "PE13"),
+	PINCTRL_PIN(0x4E, "PE14"),
+	PINCTRL_PIN(0x4F, "PE15"),
+	PINCTRL_PIN(0x50, "PF0"),
+	PINCTRL_PIN(0x51, "PF1"),
+	PINCTRL_PIN(0x52, "PF2"),
+	PINCTRL_PIN(0x53, "PF3"),
+	PINCTRL_PIN(0x54, "PF4"),
+	PINCTRL_PIN(0x55, "PF5"),
+	PINCTRL_PIN(0x56, "PF6"),
+	PINCTRL_PIN(0x57, "PF7"),
+	PINCTRL_PIN(0x58, "PF8"),
+	PINCTRL_PIN(0x59, "PF9"),
+	PINCTRL_PIN(0x5A, "PF10"),
+	PINCTRL_PIN(0x5B, "PF11"),
+	PINCTRL_PIN(0x5C, "PF12"),
+	PINCTRL_PIN(0x5D, "PF13"),
+	PINCTRL_PIN(0x5E, "PF14"),
+	PINCTRL_PIN(0x5F, "PF15"),
+	PINCTRL_PIN(0x60, "PG0"),
+	PINCTRL_PIN(0x61, "PG1"),
+	PINCTRL_PIN(0x62, "PG2"),
+	PINCTRL_PIN(0x63, "PG3"),
+	PINCTRL_PIN(0x64, "PG4"),
+	PINCTRL_PIN(0x65, "PG5"),
+	PINCTRL_PIN(0x66, "PG6"),
+	PINCTRL_PIN(0x67, "PG7"),
+	PINCTRL_PIN(0x68, "PG8"),
+	PINCTRL_PIN(0x69, "PG9"),
+	PINCTRL_PIN(0x6A, "PG10"),
+	PINCTRL_PIN(0x6B, "PG11"),
+	PINCTRL_PIN(0x6C, "PG12"),
+	PINCTRL_PIN(0x6D, "PG13"),
+	PINCTRL_PIN(0x6E, "PG14"),
+	PINCTRL_PIN(0x6F, "PG15"),
+};
+
+
+
+struct nuc980_pinctrl_group {
+	const char *name;
+	const unsigned int *pins;
+	const unsigned num_pins;
+	const unsigned func;
+};
+
+static const unsigned nadc_pins[] = {
+#ifdef CONFIG_IIO_NUC980ADC_Ch0
+	0x10,
+#endif
+#ifdef CONFIG_IIO_NUC980ADC_Ch1
+	0x11,
+#endif
+#ifdef CONFIG_IIO_NUC980ADC_Ch2
+	0x12,
+#endif
+#ifdef CONFIG_IIO_NUC980ADC_Ch3
+	0x13,
+#endif
+#ifdef CONFIG_IIO_NUC980ADC_Ch4
+	0x14,
+#endif
+#ifdef CONFIG_IIO_NUC980ADC_Ch5
+	0x15,
+#endif
+#ifdef CONFIG_IIO_NUC980ADC_Ch6
+	0x16,
+#endif
+#ifdef CONFIG_IIO_NUC980ADC_Ch7
+	0x17
+#endif
+}; // Port B
+static const unsigned emac0_pins[] = {0x40, 0x41, 0x42, 0x43, 0x44, 0x45, 0x46, 0x47, 0x48, 0x49}; // Port E
+static const unsigned emac1_pins[] = {0x50, 0x51, 0x52, 0x53, 0x54, 0x55, 0x56, 0x57, 0x58, 0x59}; // Port F
+//static const unsigned pps0_pin[] = {0x5E};
+//static const unsigned pps1_pin[] = {0x4D};
+
+static const unsigned vcap0_pins[] = {0x23, 0x24, 0x25, 0x26, /*0x27,*/ 0x28, 0x29, 0x2A, 0x2B, 0x2C, 0x2D, 0x2E, 0x2F};
+static const unsigned vcap1_pins[] = {0x4C, 0x5A, 0x40, 0x41, /*0x4A,*/ 0x42, 0x43, 0x44, 0x45, 0x46, 0x47, 0x48, 0x49};
+
+static const unsigned sd0_pins[] = {0x2C, 0x25, 0x26, 0x27, 0x28, 0x29, 0x2A};
+static const unsigned sd1_pins[] = {0x56, 0x50, 0x51, 0x52, 0x53, 0x54, 0x55};
+
+static const unsigned nand_pins[] = {0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27, 0x28, 0x29, 0x2A, 0x2B, 0x2C, 0x2D, 0x2E, 0x2F};
+
+static const unsigned usbd_pin[] = {0x4B};  // vbvld
+
+static const unsigned i2c0_0_pins[] = {0x00, 0x01};
+static const unsigned i2c0_1_pins[] = {0x0F, 0x6A};
+static const unsigned i2c0_2_pins[] = {0x4A, 0x4C};
+
+static const unsigned i2c1_0_pins[] = {0x0D, 0x0E};
+static const unsigned i2c1_1_pins[] = {0x16, 0x14};
+static const unsigned i2c1_2_pins[] = {0x23, 0x24};
+
+static const unsigned i2c2_0_pins[] = {0x17, 0x15};
+static const unsigned i2c2_1_pins[] = {0x18, 0x20};
+
+static const unsigned i2c3_0_pins[] = {0x11, 0x13};
+static const unsigned i2c3_1_pins[] = {0x3E, 0x3F};
+
+static const unsigned i2s_0_pins[] = {0x02, 0x03, 0x04, 0x05, 0x06};
+static const unsigned i2s_1_pins[] = {0x16, 0x14, 0x17, 0x15, 0x11};
+
+static const unsigned uart0_pins[] = {0x5C, 0x5B}; // tx, rx
+
+static const unsigned uart1_0_pins[] = {0x01, 0x00}; // tx, rx
+static const unsigned uart1_1_pins[] = {0x25, 0x26}; // tx, rx
+static const unsigned uart1_2_pins[] = {0x27, 0x28}; // rts, cts
+static const unsigned uart1_3_pins[] = {0x58, 0x57}; // rts, cts
+static const unsigned uart1_4_pins[] = {0x5A, 0x59}; // tx, rx
+
+static const unsigned uart2_0_pins[] = {0x08, 0x07}; // rts, cts
+static const unsigned uart2_1_pins[] = {0x0A, 0x09}; // tx, rx
+static const unsigned uart2_2_pins[] = {0x63, 0x62}; // rts, cts
+static const unsigned uart2_3_pins[] = {0x08, 0x10}; // rts, cts
+static const unsigned uart2_4_pins[] = {0x61, 0x60}; // tx, rx
+static const unsigned uart2_5_pins[] = {0x36, 0x37}; // tx, rx
+
+static const unsigned uart3_0_pins[] = {0x23, 0x24}; // tx, rx
+static const unsigned uart3_1_pins[] = {0x19, 0x1A}; // tx, rx
+static const unsigned uart3_2_pins[] = {0x1B, 0x1C}; // rts, cts
+static const unsigned uart3_3_pins[] = {0x32, 0x33}; // tx, rx
+static const unsigned uart3_4_pins[] = {0x34, 0x35}; // rts, cts
+static const unsigned uart3_5_pins[] = {0x55, 0x54}; // rts, cts
+static const unsigned uart3_6_pins[] = {0x1D, 0x56}; // tx, rx
+static const unsigned uart3_7_pins[] = {0x57, 0x56}; // tx, rx
+
+static const unsigned uart4_0_pins[] = {0x29, 0x2A}; // tx, rx
+static const unsigned uart4_1_pins[] = {0x3C, 0x3D}; // tx, rx
+static const unsigned uart4_2_pins[] = {0x3E, 0x3F}; // rts, cts
+static const unsigned uart4_3_pins[] = {0x41, 0x40}; // rts, cts
+static const unsigned uart4_4_pins[] = {0x43, 0x42}; // tx, rx
+
+static const unsigned uart5_0_pins[] = {0x67, 0x66}; // tx, rx
+static const unsigned uart5_1_pins[] = {0x65, 0x64}; // rts, cts
+static const unsigned uart5_2_pins[] = {0x30, 0x31}; // tx, rx
+static const unsigned uart5_3_pins[] = {0x6C, 0x6B}; // rts, cts
+static const unsigned uart5_4_pins[] = {0x6E, 0x6D}; // tx, rx
+
+static const unsigned uart6_0_pins[] = {0x03, 0x02}; // rts, cts
+static const unsigned uart6_1_pins[] = {0x05, 0x04}; // tx, rx
+static const unsigned uart6_2_pins[] = {0x39, 0x38}; // rts, cts
+static const unsigned uart6_3_pins[] = {0x3A, 0x3B}; // tx, rx
+static const unsigned uart6_4_pins[] = {0x49, 0x48}; // tx, rx
+
+static const unsigned uart7_0_pins[] = {0x0D, 0x0E}; // tx, rx
+static const unsigned uart7_1_pins[] = {0x16, 0x14}; // tx, rx
+static const unsigned uart7_2_pins[] = {0x15, 0x17}; // rts, cts
+static const unsigned uart7_3_pins[] = {0x21, 0x22}; // tx, rx
+static const unsigned uart7_4_pins[] = {0x51, 0x50}; // rts, cts
+static const unsigned uart7_5_pins[] = {0x53, 0x52}; // tx, rx
+
+static const unsigned uart8_0_pins[] = {0x0C, 0x0B}; // tx, rx
+static const unsigned uart8_1_pins[] = {0x68, 0x69}; // rts, cts
+static const unsigned uart8_2_pins[] = {0x18, 0x20}; // tx, rx
+static const unsigned uart8_3_pins[] = {0x2C, 0x2D}; // tx, rx
+static const unsigned uart8_4_pins[] = {0x2E, 0x2F}; // cts, rts
+
+static const unsigned uart9_0_pins[] = {0x11, 0x13}; // tx, rx
+//static const unsigned uart9_1_pins[] = {0x12, 0x44}; // rts, cts
+static const unsigned uart9_2_pins[] = {0x45, 0x44}; // rts, cts
+static const unsigned uart9_3_pins[] = {0x47, 0x46}; // tx, rx
+static const unsigned uart9_4_pins[] = {0x4C, 0x4A}; // tx, rx
+
+static const unsigned sc0_0_pins[] = {0x02, 0x03, 0x04, 0x05, 0x06};
+static const unsigned sc0_1_pins[] = {0x2B, 0x2C, 0x2D, 0x2E, 0x2F};
+static const unsigned sc0_2_pins[] = {0x04, 0x05};  // scuart
+static const unsigned sc0_3_pins[] = {0x2C, 0x2D};  // scuart
+static const unsigned sc1_0_pins[] = {0x26, 0x27, 0x28, 0x29, 0x2A};
+static const unsigned sc1_1_pins[] = {0x50, 0x51, 0x52, 0x53, 0x54};
+static const unsigned sc1_2_pins[] = {0x27, 0x28};  // scuart
+static const unsigned sc1_3_pins[] = {0x51, 0x52};  // scuart
+
+static const unsigned qspi0_0_pins[] = {0x00, 0x32, 0x33, 0x34, 0x35}; // ss1: PA0
+static const unsigned qspi0_1_pins[] = {0x30, 0x32, 0x33, 0x34, 0x35}; // ss1: PD0
+static const unsigned qspi0_2_pins[] = {0x32, 0x33, 0x34, 0x35,0x36, 0x37}; // quad
+static const unsigned qspi0_3_pins[] = {0x32, 0x33, 0x34, 0x35}; // normal
+static const unsigned qspi0_4_pins[] = {0x00, 0x32, 0x33, 0x34, 0x35,0x36, 0x37}; // quad ss1:PA0
+static const unsigned qspi0_5_pins[] = {0x30, 0x32, 0x33, 0x34, 0x35,0x36, 0x37}; // quad ss1:PD0
+
+static const unsigned spi0_0_pins[] = {0x38, 0x39, 0x3A, 0x3B};
+static const unsigned spi0_1_pins[] = {0x31, 0x38, 0x39, 0x3A, 0x3B}; // ss1: PD1
+static const unsigned spi0_2_pins[] = {0x6F, 0x38, 0x39, 0x3A, 0x3B}; // ss1: PG15
+static const unsigned spi0_3_pins[] = {0x25, 0x26, 0x27, 0x28};
+static const unsigned spi0_4_pins[] = {0x20, 0x25, 0x26, 0x27, 0x28}; // ss1: PC0
+
+static const unsigned spi1_0_pins[] = {0x19, 0x1A, 0x1B, 0x1C};
+static const unsigned spi1_1_pins[] = {0x6B, 0x6C, 0x6D, 0x6E};
+static const unsigned spi1_2_pins[] = {0x6F, 0x6B, 0x6C, 0x6D, 0x6E}; // ss1: PG15
+static const unsigned spi1_3_pins[] = {0x16, 0x14, 0x17, 0x15};
+static const unsigned spi1_4_pins[] = {0x11, 0x16, 0x14, 0x17, 0x15}; // ss1: PB1
+
+static const unsigned can0_0_pins[] = {0x23, 0x24};
+static const unsigned can0_1_pins[] = {0x36, 0x37};
+static const unsigned can0_2_pins[] = {0x6B, 0x6C};
+static const unsigned can0_3_pins[] = {0x40, 0x41};
+static const unsigned can1_0_pins[] = {0x0D, 0x0E};
+static const unsigned can1_1_pins[] = {0x3E, 0x3F};
+static const unsigned can1_2_pins[] = {0x6D, 0x6E};
+static const unsigned can1_3_pins[] = {0x42, 0x43};
+static const unsigned can2_0_pins[] = {0x0F, 0x6A};
+static const unsigned can2_1_pins[] = {0x11, 0x13};
+static const unsigned can2_2_pins[] = {0x18, 0x20};
+static const unsigned can2_3_pins[] = {0x3C, 0x3D};
+static const unsigned can2_4_pins[] = {0x44, 0x45};
+static const unsigned can3_0_pins[] = {0x00, 0x01};
+static const unsigned can3_1_pins[] = {0x46, 0x47};
+static const unsigned can3_2_pins[] = {0x4A, 0x4C};
+
+static const unsigned pwm00_0_pin[] = {0x6A};
+static const unsigned pwm01_0_pin[] = {0x0F};
+static const unsigned pwm02_0_pin[] = {0x0E};
+static const unsigned pwm03_0_pin[] = {0x0D};
+static const unsigned pwm00_1_pin[] = {0x60};
+static const unsigned pwm01_1_pin[] = {0x61};
+static const unsigned pwm02_1_pin[] = {0x62};
+static const unsigned pwm03_1_pin[] = {0x63};
+static const unsigned pwm00_2_pin[] = {0x3C};
+static const unsigned pwm01_2_pin[] = {0x3D};
+static const unsigned pwm02_2_pin[] = {0x3E};
+static const unsigned pwm03_2_pin[] = {0x3F};
+static const unsigned pwm00_3_pin[] = {0x55};
+static const unsigned pwm01_3_pin[] = {0x56};
+static const unsigned pwm02_3_pin[] = {0x57};
+static const unsigned pwm03_3_pin[] = {0x58};
+static const unsigned pwm02_4_pin[] = {0x1D};
+
+static const unsigned pwm10_0_pin[] = {0x66};
+static const unsigned pwm11_0_pin[] = {0x67};
+static const unsigned pwm12_0_pin[] = {0x68};
+static const unsigned pwm13_0_pin[] = {0x69};
+static const unsigned pwm10_1_pin[] = {0x1C};
+static const unsigned pwm11_1_pin[] = {0x1B};
+static const unsigned pwm12_1_pin[] = {0x1A};
+static const unsigned pwm13_1_pin[] = {0x19};
+static const unsigned pwm10_2_pin[] = {0x6B};
+static const unsigned pwm11_2_pin[] = {0x6C};
+static const unsigned pwm12_2_pin[] = {0x6D};
+static const unsigned pwm13_2_pin[] = {0x6E};
+static const unsigned pwm10_3_pin[] = {0x59};
+static const unsigned pwm11_3_pin[] = {0x5A};
+static const unsigned pwm12_3_pin[] = {0x4A};
+static const unsigned pwm13_3_pin[] = {0x4C};
+
+static const unsigned etimer0_0_pin[] = {0x00}; // ecnt
+static const unsigned etimer0_1_pin[] = {0x13}; // tgl
+static const unsigned etimer0_2_pin[] = {0x11}; // cap
+static const unsigned etimer0_3_pin[] = {0x20}; // tgl
+static const unsigned etimer0_4_pin[] = {0x18}; // cap
+static const unsigned etimer0_5_pin[] = {0x19}; // tgl
+static const unsigned etimer0_6_pin[] = {0x1A}; // cap
+static const unsigned etimer0_7_pin[] = {0x36}; // ecnt
+static const unsigned etimer0_8_pin[] = {0x50}; // ecnt
+
+static const unsigned etimer1_0_pin[] = {0x01}; // ecnt
+static const unsigned etimer1_1_pin[] = {0x0E}; // tgl
+static const unsigned etimer1_2_pin[] = {0x0D}; // cap
+static const unsigned etimer1_3_pin[] = {0x30}; // tgl
+static const unsigned etimer1_4_pin[] = {0x31}; // cap
+static const unsigned etimer1_5_pin[] = {0x37}; // ecnt
+static const unsigned etimer1_6_pin[] = {0x6B}; // tgl
+static const unsigned etimer1_7_pin[] = {0x6C}; // cap
+static const unsigned etimer1_8_pin[] = {0x51}; // ecnt
+static const unsigned etimer1_9_pin[] = {0x58}; // tgl
+static const unsigned etimer1_A_pin[] = {0x59}; // cap
+
+static const unsigned etimer2_0_pin[] = {0x02}; // ecnt
+static const unsigned etimer2_1_pin[] = {0x0A}; // tgl
+static const unsigned etimer2_2_pin[] = {0x09}; // cap
+static const unsigned etimer2_3_pin[] = {0x1C}; // tgl
+static const unsigned etimer2_4_pin[] = {0x1B}; // cap
+static const unsigned etimer2_5_pin[] = {0x38}; // ecnt
+static const unsigned etimer2_6_pin[] = {0x3C}; // tgl
+static const unsigned etimer2_7_pin[] = {0x3D}; // cap
+static const unsigned etimer2_8_pin[] = {0x52}; // ecnt
+
+static const unsigned etimer3_0_pin[] = {0x03}; // ecnt
+static const unsigned etimer3_1_pin[] = {0x08}; // tgl
+static const unsigned etimer3_2_pin[] = {0x07}; // cap
+static const unsigned etimer3_3_pin[] = {0x39}; // ecnt
+static const unsigned etimer3_4_pin[] = {0x3E}; // tgl
+static const unsigned etimer3_5_pin[] = {0x3F}; // cap
+static const unsigned etimer3_6_pin[] = {0x53}; // ecnt
+
+static const unsigned etimer4_0_pin[] = {0x04}; // ecnt
+static const unsigned etimer4_1_pin[] = {0x0C}; // tgl
+static const unsigned etimer4_2_pin[] = {0x0B}; // cap
+static const unsigned etimer4_3_pin[] = {0x33}; // tgl
+static const unsigned etimer4_4_pin[] = {0x32}; // cap
+static const unsigned etimer4_5_pin[] = {0x3A}; // ecnt
+static const unsigned etimer4_6_pin[] = {0x54}; // ecnt
+static const unsigned etimer4_7_pin[] = {0x1D}; // tgl
+static const unsigned etimer4_8_pin[] = {0x56}; // cap
+
+static const unsigned etimer5_0_pin[] = {0x05}; // ecnt
+static const unsigned etimer5_1_pin[] = {0x6A}; // tgl
+static const unsigned etimer5_2_pin[] = {0x0F}; // cap
+static const unsigned etimer5_3_pin[] = {0x35}; // tgl
+static const unsigned etimer5_4_pin[] = {0x34}; // cap
+static const unsigned etimer5_5_pin[] = {0x3B}; // ecnt
+static const unsigned etimer5_6_pin[] = {0x55}; // ecnt
+static const unsigned etimer5_7_pin[] = {0x5A}; // tgl
+static const unsigned etimer5_8_pin[] = {0x57}; // cap
+
+static const unsigned jtag0_pins[] = {0x6B, 0x6C, 0x6D, 0x6E, 0x6F};
+static const unsigned jtag1_pins[] = {0x02, 0x03, 0x04, 0x05, 0x06};
+
+static const unsigned eint0_0_pin[] = {0x00};
+static const unsigned eint0_1_pin[] = {0x0D};
+static const unsigned eint1_0_pin[] = {0x01};
+static const unsigned eint1_1_pin[] = {0x0E};
+static const unsigned eint2_0_pin[] = {0x30};
+static const unsigned eint2_1_pin[] = {0x4A};
+static const unsigned eint2_2_pin[] = {0x13};
+static const unsigned eint2_3_pin[] = {0x1D};
+static const unsigned eint3_0_pin[] = {0x31};
+static const unsigned eint3_1_pin[] = {0x4C};
+static const unsigned eint3_2_pin[] = {0x6F};
+
+static const unsigned ebi8_0_pin[] =    {0x09, 0x08, 0x07, // nCS0, nRE, nWE,
+                                         0x60, 0x61, 0x12, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x10, 0x0D, 0x0E, 0x17, 0x15, 0x11, 0x13, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27 // data0~7
+                                        };
+static const unsigned ebi8_1_pin[] =    {0x09, 0x08, 0x07, // nCS0, nRE, nWE,
+                                         0x60, 0x61, 0x62, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x65, 0x16, 0x14, 0x17, 0x15, 0x11, 0x64, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27 // data0~7
+                                        };
+static const unsigned ebi8_2_pin[] =    {0x06, 0x08, 0x07, // nCS1, nRE, nWE,
+                                         0x60, 0x61, 0x12, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x10, 0x0D, 0x0E, 0x17, 0x15, 0x11, 0x13, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27 // data0~7
+                                        };
+static const unsigned ebi8_3_pin[] =    {0x06, 0x08, 0x07, // nCS1, nRE, nWE,
+                                         0x60, 0x61, 0x62, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x65, 0x16, 0x14, 0x17, 0x15, 0x11, 0x64, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27 // data0~7
+                                        };
+static const unsigned ebi8_4_pin[] =    {0x01, 0x08, 0x07, // nCS2, nRE, nWE,
+                                         0x60, 0x61, 0x12, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x10, 0x0D, 0x0E, 0x17, 0x15, 0x11, 0x13, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27 // data0~7
+                                        };
+static const unsigned ebi8_5_pin[] =    {0x01, 0x08, 0x07, // nCS2, nRE, nWE,
+                                         0x60, 0x61, 0x62, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x65, 0x16, 0x14, 0x17, 0x15, 0x11, 0x64, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27 // data0~7
+                                        };
+
+static const unsigned ebi16_0_pin[] =   {0x09, 0x08, 0x07, // nCS0, nRE, nWE,
+                                         0x60, 0x61, 0x12, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x10, 0x0D, 0x0E, 0x17, 0x15, 0x11, 0x13, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27, // data0~7
+                                         0x28, 0x29, 0x2A, 0x2B, 0x2C, 0x2D, 0x2E, 0x2F // data8~data15
+                                        };
+static const unsigned ebi16_1_pin[] =   {0x09, 0x08, 0x07, // nCS0, nRE, nWE,
+                                         0x60, 0x61, 0x62, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x65, 0x16, 0x14, 0x17, 0x15, 0x11, 0x64, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27, // data0~7
+                                         0x28, 0x29, 0x2A, 0x2B, 0x2C, 0x2D, 0x2E, 0x2F // data8~data15
+                                        };
+static const unsigned ebi16_2_pin[] =   {0x06, 0x08, 0x07, // nCS1, nRE, nWE,
+                                         0x60, 0x61, 0x12, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x10, 0x0D, 0x0E, 0x17, 0x15, 0x11, 0x13, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27, // data0~7
+                                         0x28, 0x29, 0x2A, 0x2B, 0x2C, 0x2D, 0x2E, 0x2F // data8~data15
+                                        };
+static const unsigned ebi16_3_pin[] =   {0x06, 0x08, 0x07, // nCS1, nRE, nWE,
+                                         0x60, 0x61, 0x62, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x65, 0x16, 0x14, 0x17, 0x15, 0x11, 0x64, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27, // data0~7
+                                         0x28, 0x29, 0x2A, 0x2B, 0x2C, 0x2D, 0x2E, 0x2F // data8~data15
+                                        };
+static const unsigned ebi16_4_pin[] =   {0x01, 0x08, 0x07, // nCS2, nRE, nWE,
+                                         0x60, 0x61, 0x12, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x10, 0x0D, 0x0E, 0x17, 0x15, 0x11, 0x13, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27, // data0~7
+                                         0x28, 0x29, 0x2A, 0x2B, 0x2C, 0x2D, 0x2E, 0x2F // data8~data15
+                                        };
+static const unsigned ebi16_5_pin[] =   {0x01, 0x08, 0x07, // nCS2, nRE, nWE,
+                                         0x60, 0x61, 0x62, 0x63, 0x66, 0x67, 0x68, 0x69, 0x0C, 0x0B, //address0~9
+                                         0x0A, 0x18, 0x65, 0x16, 0x14, 0x17, 0x15, 0x11, 0x64, 0x0F, //address10~19
+                                         0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27, // data0~7
+                                         0x28, 0x29, 0x2A, 0x2B, 0x2C, 0x2D, 0x2E, 0x2F // data8~data15
+                                        };
+
+static const unsigned usbh_pwren_ovc_pin[]   = {0x4c, 0x4a};  // USBH_PWREN PE.12 and USB_OVC PE.10
+static const unsigned usbh_pwren_pin[]       = {0x4c};        // USBH_PWREN PE.12
+static const unsigned usbh_ovc_pin[]         = {0x4a};        // USB_OVC PE.10
+
+
+static const unsigned usbh_lite0_pb4_pb6[]   = {0x14, 0x16};   // USBH Lite0 D+/D- is PB.4/PB.6
+static const unsigned usbh_lite0_pb5_pb7[]   = {0x15, 0x17};   // USBH Lite0 D+/D- is PB.5/PB.7
+static const unsigned usbh_lite0_pb10_pb9[]  = {0x1a, 0x19};   // USBH Lite0 D+/D- is PB.10/PB.9
+static const unsigned usbh_lite0_pd15_pd14[] = {0x3f, 0x3e};   // USBH Lite0 D+/D- is PD.15/PD.14
+
+static const unsigned usbh_lite1_pe1_pe0[]   = {0x41, 0x40};   // USBH Lite1 D+/D- is PE.1/PE.0
+static const unsigned usbh_lite1_pf1_pf0[]   = {0x51, 0x50};   // USBH Lite1 D+/D- is PF.1/PF.0
+
+static const unsigned usbh_lite2_pe3_pe2[]   = {0x43, 0x42};   // USBH Lite2 D+/D- is PE.3/PE.2
+static const unsigned usbh_lite2_pf3_pf2[]   = {0x53, 0x52};   // USBH Lite2 D+/D- is PF.3/PF.2
+
+static const unsigned usbh_lite3_pe5_pe4[]   = {0x45, 0x44};   // USBH Lite3 D+/D- is PE.5/PE.4
+static const unsigned usbh_lite3_pf5_pf4[]   = {0x55, 0x54};   // USBH Lite3 D+/D- is PF.5/PF.4
+
+static const unsigned usbh_lite4_pe7_pe6[]   = {0x47, 0x46};   // USBH Lite4 D+/D- is PE.7/PE.6
+static const unsigned usbh_lite4_pf7_pf6[]   = {0x57, 0x56};   // USBH Lite4 D+/D- is PF.7/PF.6
+static const unsigned usbh_lite4_pg10_pa15[] = {0x6a, 0x0f};   // USBH Lite4 D+/D- is PG.10/PA.15
+static const unsigned usbh_lite4_pb13_pf6[]  = {0x1d, 0x56};   // USBH Lite4 D+/D- is PB.13/PF.6
+
+static const unsigned usbh_lite5_pe9_pe8[]   = {0x49, 0x48};   // USBH Lite5 D+/D- is PE.9/PE.8
+static const unsigned usbh_lite5_pf9_pf8[]   = {0x59, 0x58};   // USBH Lite5 D+/D- is PF.9/PF.8
+static const unsigned usbh_lite5_pa14_pa13[] = {0x0e, 0x0d};   // USBH Lite5 D+/D- is PA.14/PA.13
+static const unsigned usbh_lite5_pb12_pb11[] = {0x1c, 0x1b};   // USBH Lite5 D+/D- is PB.12/PB.11
+
+// TODO: CKO
+
+static const struct nuc980_pinctrl_group nuc980_pinctrl_groups[] = {
+	{
+		.name = "nadc_grp",
+		.pins = nadc_pins,
+		.num_pins = ARRAY_SIZE(nadc_pins),
+		.func = 0x8,
+	},
+	{
+		.name = "emac0_grp",
+		.pins = emac0_pins,
+		.num_pins = ARRAY_SIZE(emac0_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "emac1_grp",
+		.pins = emac1_pins,
+		.num_pins = ARRAY_SIZE(emac1_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "vcap0_grp",
+		.pins = vcap0_pins,
+		.num_pins = ARRAY_SIZE(vcap0_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "vcap1_grp",
+		.pins = vcap1_pins,
+		.num_pins = ARRAY_SIZE(vcap1_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "sd0_grp",
+		.pins = sd0_pins,
+		.num_pins = ARRAY_SIZE(sd0_pins),
+		.func = 0x6,
+	},
+	{
+		.name = "sd1_grp",
+		.pins = sd1_pins,
+		.num_pins = ARRAY_SIZE(sd1_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "nand_grp",
+		.pins = nand_pins,
+		.num_pins = ARRAY_SIZE(nand_pins),
+		.func = 0x3,
+	},
+	{
+		.name = "usbd_grp",
+		.pins = usbd_pin,
+		.num_pins = ARRAY_SIZE(usbd_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "i2c0_0_grp",
+		.pins = i2c0_0_pins,
+		.num_pins = ARRAY_SIZE(i2c0_0_pins),
+		.func = 0x3,
+	},
+	{
+		.name = "i2c0_1_grp",
+		.pins = i2c0_1_pins,
+		.num_pins = ARRAY_SIZE(i2c0_1_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "i2c0_2_grp",
+		.pins = i2c0_2_pins,
+		.num_pins = ARRAY_SIZE(i2c0_2_pins),
+		.func = 0x6,
+	},
+	{
+		.name = "i2c1_0_grp",
+		.pins = i2c1_0_pins,
+		.num_pins = ARRAY_SIZE(i2c1_0_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "i2c1_1_grp",
+		.pins = i2c1_1_pins,
+		.num_pins = ARRAY_SIZE(i2c1_1_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "i2c1_2_grp",
+		.pins = i2c1_2_pins,
+		.num_pins = ARRAY_SIZE(i2c1_2_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "i2c2_0_grp",
+		.pins = i2c2_0_pins,
+		.num_pins = ARRAY_SIZE(i2c2_0_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "i2c2_1_grp",
+		.pins = i2c2_1_pins,
+		.num_pins = ARRAY_SIZE(i2c2_1_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "i2c3_0_grp",
+		.pins = i2c3_0_pins,
+		.num_pins = ARRAY_SIZE(i2c3_0_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "i2c3_1_grp",
+		.pins = i2c3_1_pins,
+		.num_pins = ARRAY_SIZE(i2c3_1_pins),
+		.func = 0x3,
+	},
+	{
+		.name = "i2s_0_grp",
+		.pins = i2s_0_pins,
+		.num_pins = ARRAY_SIZE(i2s_0_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "i2s_1_grp",
+		.pins = i2s_1_pins,
+		.num_pins = ARRAY_SIZE(i2s_1_pins),
+		.func = 0x3,
+	},
+	{
+		.name = "uart0_grp",
+		.pins = uart0_pins,
+		.num_pins = ARRAY_SIZE(uart0_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "uart1_0_grp",
+		.pins = uart1_0_pins,
+		.num_pins = ARRAY_SIZE(uart1_0_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "uart1_1_grp",
+		.pins = uart1_1_pins,
+		.num_pins = ARRAY_SIZE(uart1_1_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "uart1_2_grp",
+		.pins = uart1_2_pins,
+		.num_pins = ARRAY_SIZE(uart1_2_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "uart1_3_grp",
+		.pins = uart1_3_pins,
+		.num_pins = ARRAY_SIZE(uart1_3_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart1_4_grp",
+		.pins = uart1_4_pins,
+		.num_pins = ARRAY_SIZE(uart1_4_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart2_0_grp",
+		.pins = uart2_0_pins,
+		.num_pins = ARRAY_SIZE(uart2_0_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart2_1_grp",
+		.pins = uart2_1_pins,
+		.num_pins = ARRAY_SIZE(uart2_1_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart2_2_grp",
+		.pins = uart2_2_pins,
+		.num_pins = ARRAY_SIZE(uart2_2_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart2_3_grp",
+		.pins = uart2_3_pins,
+		.num_pins = ARRAY_SIZE(uart2_3_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart2_4_grp",
+		.pins = uart2_4_pins,
+		.num_pins = ARRAY_SIZE(uart2_4_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart2_5_grp",
+		.pins = uart2_5_pins,
+		.num_pins = ARRAY_SIZE(uart2_5_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart3_0_grp",
+		.pins = uart3_0_pins,
+		.num_pins = ARRAY_SIZE(uart3_0_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart3_1_grp",
+		.pins = uart3_1_pins,
+		.num_pins = ARRAY_SIZE(uart3_1_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "uart3_2_grp",
+		.pins = uart3_2_pins,
+		.num_pins = ARRAY_SIZE(uart3_2_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "uart3_3_grp",
+		.pins = uart3_3_pins,
+		.num_pins = ARRAY_SIZE(uart3_3_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart3_4_grp",
+		.pins = uart3_4_pins,
+		.num_pins = ARRAY_SIZE(uart3_4_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart3_5_grp",
+		.pins = uart3_5_pins,
+		.num_pins = ARRAY_SIZE(uart3_5_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart3_6_grp",
+		.pins = uart3_6_pins,
+		.num_pins = ARRAY_SIZE(uart3_6_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart3_7_grp",
+		.pins = uart3_7_pins,
+		.num_pins = ARRAY_SIZE(uart3_7_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart4_0_grp",
+		.pins = uart4_0_pins,
+		.num_pins = ARRAY_SIZE(uart4_0_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "uart4_1_grp",
+		.pins = uart4_1_pins,
+		.num_pins = ARRAY_SIZE(uart4_1_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "uart4_2_grp",
+		.pins = uart4_2_pins,
+		.num_pins = ARRAY_SIZE(uart4_2_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "uart4_3_grp",
+		.pins = uart4_3_pins,
+		.num_pins = ARRAY_SIZE(uart4_3_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart4_4_grp",
+		.pins = uart4_4_pins,
+		.num_pins = ARRAY_SIZE(uart4_4_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart5_0_grp",
+		.pins = uart5_0_pins,
+		.num_pins = ARRAY_SIZE(uart5_0_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart5_1_grp",
+		.pins = uart5_1_pins,
+		.num_pins = ARRAY_SIZE(uart5_1_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart5_2_grp",
+		.pins = uart5_2_pins,
+		.num_pins = ARRAY_SIZE(uart5_2_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart5_3_grp",
+		.pins = uart5_3_pins,
+		.num_pins = ARRAY_SIZE(uart5_3_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart5_4_grp",
+		.pins = uart5_4_pins,
+		.num_pins = ARRAY_SIZE(uart5_4_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart6_0_grp",
+		.pins = uart6_0_pins,
+		.num_pins = ARRAY_SIZE(uart6_0_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "uart6_1_grp",
+		.pins = uart6_1_pins,
+		.num_pins = ARRAY_SIZE(uart6_1_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "uart6_2_grp",
+		.pins = uart6_2_pins,
+		.num_pins = ARRAY_SIZE(uart6_2_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart6_3_grp",
+		.pins = uart6_3_pins,
+		.num_pins = ARRAY_SIZE(uart6_3_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart6_4_grp",
+		.pins = uart6_4_pins,
+		.num_pins = ARRAY_SIZE(uart6_4_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart7_0_grp",
+		.pins = uart7_0_pins,
+		.num_pins = ARRAY_SIZE(uart7_0_pins),
+		.func = 0x6,
+	},
+	{
+		.name = "uart7_1_grp",
+		.pins = uart7_1_pins,
+		.num_pins = ARRAY_SIZE(uart7_1_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart7_2_grp",
+		.pins = uart7_2_pins,
+		.num_pins = ARRAY_SIZE(uart7_2_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart7_3_grp",
+		.pins = uart7_3_pins,
+		.num_pins = ARRAY_SIZE(uart7_3_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "uart7_4_grp",
+		.pins = uart7_4_pins,
+		.num_pins = ARRAY_SIZE(uart7_4_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart7_5_grp",
+		.pins = uart7_5_pins,
+		.num_pins = ARRAY_SIZE(uart7_5_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart8_0_grp",
+		.pins = uart8_0_pins,
+		.num_pins = ARRAY_SIZE(uart8_0_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart8_1_grp",
+		.pins = uart8_1_pins,
+		.num_pins = ARRAY_SIZE(uart8_1_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "uart8_2_grp",
+		.pins = uart8_2_pins,
+		.num_pins = ARRAY_SIZE(uart8_2_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "uart8_3_grp",
+		.pins = uart8_3_pins,
+		.num_pins = ARRAY_SIZE(uart8_3_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "uart8_4_grp",
+		.pins = uart8_4_pins,
+		.num_pins = ARRAY_SIZE(uart8_4_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "uart9_0_grp",
+		.pins = uart9_0_pins,
+		.num_pins = ARRAY_SIZE(uart9_0_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "uart9_2_grp",
+		.pins = uart9_2_pins,
+		.num_pins = ARRAY_SIZE(uart9_2_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart9_3_grp",
+		.pins = uart9_3_pins,
+		.num_pins = ARRAY_SIZE(uart9_3_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "uart9_4_grp",
+		.pins = uart9_4_pins,
+		.num_pins = ARRAY_SIZE(uart9_4_pins),
+		.func = 0x3,
+	},
+	{
+		.name = "sc0_0_grp",
+		.pins = sc0_0_pins,
+		.num_pins = ARRAY_SIZE(sc0_0_pins),
+		.func = 0x3,
+	},
+	{
+		.name = "sc0_1_grp",
+		.pins = sc0_1_pins,
+		.num_pins = ARRAY_SIZE(sc0_1_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "sc0_2_grp",
+		.pins = sc0_2_pins,
+		.num_pins = ARRAY_SIZE(sc0_2_pins),
+		.func = 0x3,
+	},
+	{
+		.name = "sc0_3_grp",
+		.pins = sc0_3_pins,
+		.num_pins = ARRAY_SIZE(sc0_3_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "sc1_0_grp",
+		.pins = sc1_0_pins,
+		.num_pins = ARRAY_SIZE(sc1_0_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "sc1_1_grp",
+		.pins = sc1_1_pins,
+		.num_pins = ARRAY_SIZE(sc1_1_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "sc1_2_grp",
+		.pins = sc1_2_pins,
+		.num_pins = ARRAY_SIZE(sc1_2_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "sc1_3_grp",
+		.pins = sc1_3_pins,
+		.num_pins = ARRAY_SIZE(sc1_3_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "qspi0_0_grp",
+		.pins = qspi0_0_pins,
+		.num_pins = ARRAY_SIZE(qspi0_0_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "qspi0_1_grp",
+		.pins = qspi0_1_pins,
+		.num_pins = ARRAY_SIZE(qspi0_1_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "qspi0_2_grp",
+		.pins = qspi0_2_pins,
+		.num_pins = ARRAY_SIZE(qspi0_2_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "qspi0_3_grp",
+		.pins = qspi0_3_pins,
+		.num_pins = ARRAY_SIZE(qspi0_3_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "qspi0_4_grp",
+		.pins = qspi0_4_pins,
+		.num_pins = ARRAY_SIZE(qspi0_4_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "qspi0_5_grp",
+		.pins = qspi0_5_pins,
+		.num_pins = ARRAY_SIZE(qspi0_5_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "spi0_0_grp",
+		.pins = spi0_0_pins,
+		.num_pins = ARRAY_SIZE(spi0_0_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "spi0_1_grp",
+		.pins = spi0_1_pins,
+		.num_pins = ARRAY_SIZE(spi0_1_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "spi0_2_grp",
+		.pins = spi0_2_pins,
+		.num_pins = ARRAY_SIZE(spi0_2_pins),
+		.func = 0x1,
+	},
+	{
+		.name = "spi0_3_grp",
+		.pins = spi0_3_pins,
+		.num_pins = ARRAY_SIZE(spi0_3_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "spi0_4_grp",
+		.pins = spi0_4_pins,
+		.num_pins = ARRAY_SIZE(spi0_4_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "spi1_0_grp",
+		.pins = spi1_0_pins,
+		.num_pins = ARRAY_SIZE(spi1_0_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "spi1_1_grp",
+		.pins = spi1_1_pins,
+		.num_pins = ARRAY_SIZE(spi1_1_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "spi1_2_grp",
+		.pins = spi1_2_pins,
+		.num_pins = ARRAY_SIZE(spi1_2_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "spi1_3_grp",
+		.pins = spi1_3_pins,
+		.num_pins = ARRAY_SIZE(spi1_3_pins),
+		.func = 0x6,
+	},
+	{
+		.name = "spi1_4_grp",
+		.pins = spi1_4_pins,
+		.num_pins = ARRAY_SIZE(spi1_4_pins),
+		.func = 0x6,
+	},
+	{
+		.name = "can0_0_grp",
+		.pins = can0_0_pins,
+		.num_pins = ARRAY_SIZE(can0_0_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "can0_1_grp",
+		.pins = can0_1_pins,
+		.num_pins = ARRAY_SIZE(can0_1_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "can0_2_grp",
+		.pins = can0_2_pins,
+		.num_pins = ARRAY_SIZE(can0_2_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "can0_3_grp",
+		.pins = can0_3_pins,
+		.num_pins = ARRAY_SIZE(can0_3_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "can1_0_grp",
+		.pins = can1_0_pins,
+		.num_pins = ARRAY_SIZE(can1_0_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "can1_1_grp",
+		.pins = can1_1_pins,
+		.num_pins = ARRAY_SIZE(can1_1_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "can1_2_grp",
+		.pins = can1_2_pins,
+		.num_pins = ARRAY_SIZE(can1_2_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "can1_3_grp",
+		.pins = can1_3_pins,
+		.num_pins = ARRAY_SIZE(can1_3_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "can2_0_grp",
+		.pins = can2_0_pins,
+		.num_pins = ARRAY_SIZE(can2_0_pins),
+		.func = 0x5,
+	},
+	{
+		.name = "can2_1_grp",
+		.pins = can2_1_pins,
+		.num_pins = ARRAY_SIZE(can2_1_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "can2_2_grp",
+		.pins = can2_2_pins,
+		.num_pins = ARRAY_SIZE(can2_2_pins),
+		.func = 0x3,
+	},
+	{
+		.name = "can2_3_grp",
+		.pins = can2_3_pins,
+		.num_pins = ARRAY_SIZE(can2_3_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "can2_4_grp",
+		.pins = can2_4_pins,
+		.num_pins = ARRAY_SIZE(can2_4_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "can3_0_grp",
+		.pins = can3_0_pins,
+		.num_pins = ARRAY_SIZE(can3_0_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "can3_1_grp",
+		.pins = can3_1_pins,
+		.num_pins = ARRAY_SIZE(can3_1_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "can3_2_grp",
+		.pins = can3_2_pins,
+		.num_pins = ARRAY_SIZE(can3_2_pins),
+		.func = 0x2,
+	},
+	{
+		.name = "pwm00_0_grp",
+		.pins = pwm00_0_pin,
+		.num_pins = ARRAY_SIZE(pwm00_0_pin),
+		.func = 0x7,
+	},
+	{
+		.name = "pwm01_0_grp",
+		.pins = pwm01_0_pin,
+		.num_pins = ARRAY_SIZE(pwm01_0_pin),
+		.func = 0x7,
+	},
+	{
+		.name = "pwm02_0_grp",
+		.pins = pwm02_0_pin,
+		.num_pins = ARRAY_SIZE(pwm02_0_pin),
+		.func = 0x7,
+	},
+	{
+		.name = "pwm03_0_grp",
+		.pins = pwm03_0_pin,
+		.num_pins = ARRAY_SIZE(pwm03_0_pin),
+		.func = 0x7,
+	},
+
+	{
+		.name = "pwm00_1_grp",
+		.pins = pwm00_1_pin,
+		.num_pins = ARRAY_SIZE(pwm00_1_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm01_1_grp",
+		.pins = pwm01_1_pin,
+		.num_pins = ARRAY_SIZE(pwm01_1_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm02_1_grp",
+		.pins = pwm02_1_pin,
+		.num_pins = ARRAY_SIZE(pwm02_1_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm03_1_grp",
+		.pins = pwm03_1_pin,
+		.num_pins = ARRAY_SIZE(pwm03_1_pin),
+		.func = 0x6,
+	},
+
+	{
+		.name = "pwm00_2_grp",
+		.pins = pwm00_2_pin,
+		.num_pins = ARRAY_SIZE(pwm00_2_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm01_2_grp",
+		.pins = pwm01_2_pin,
+		.num_pins = ARRAY_SIZE(pwm01_2_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm02_2_grp",
+		.pins = pwm02_2_pin,
+		.num_pins = ARRAY_SIZE(pwm02_2_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm03_2_grp",
+		.pins = pwm03_2_pin,
+		.num_pins = ARRAY_SIZE(pwm03_2_pin),
+		.func = 0x6,
+	},
+
+	{
+		.name = "pwm00_3_grp",
+		.pins = pwm00_3_pin,
+		.num_pins = ARRAY_SIZE(pwm00_3_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "pwm01_3_grp",
+		.pins = pwm01_3_pin,
+		.num_pins = ARRAY_SIZE(pwm01_3_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "pwm02_3_grp",
+		.pins = pwm02_3_pin,
+		.num_pins = ARRAY_SIZE(pwm02_3_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "pwm03_3_grp",
+		.pins = pwm03_3_pin,
+		.num_pins = ARRAY_SIZE(pwm03_3_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "pwm02_4_grp",
+		.pins = pwm02_4_pin,
+		.num_pins = ARRAY_SIZE(pwm02_4_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "pwm10_0_grp",
+		.pins = pwm10_0_pin,
+		.num_pins = ARRAY_SIZE(pwm10_0_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm11_0_grp",
+		.pins = pwm11_0_pin,
+		.num_pins = ARRAY_SIZE(pwm11_0_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm12_0_grp",
+		.pins = pwm12_0_pin,
+		.num_pins = ARRAY_SIZE(pwm12_0_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm13_0_grp",
+		.pins = pwm13_0_pin,
+		.num_pins = ARRAY_SIZE(pwm13_0_pin),
+		.func = 0x6,
+	},
+
+	{
+		.name = "pwm10_1_grp",
+		.pins = pwm10_1_pin,
+		.num_pins = ARRAY_SIZE(pwm10_1_pin),
+		.func = 0x2,
+	},
+	{
+		.name = "pwm11_1_grp",
+		.pins = pwm11_1_pin,
+		.num_pins = ARRAY_SIZE(pwm11_1_pin),
+		.func = 0x2,
+	},
+	{
+		.name = "pwm12_1_grp",
+		.pins = pwm12_1_pin,
+		.num_pins = ARRAY_SIZE(pwm12_1_pin),
+		.func = 0x2,
+	},
+	{
+		.name = "pwm13_1_grp",
+		.pins = pwm13_1_pin,
+		.num_pins = ARRAY_SIZE(pwm13_1_pin),
+		.func = 0x2,
+	},
+
+	{
+		.name = "pwm10_2_grp",
+		.pins = pwm10_2_pin,
+		.num_pins = ARRAY_SIZE(pwm10_2_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm11_2_grp",
+		.pins = pwm11_2_pin,
+		.num_pins = ARRAY_SIZE(pwm11_2_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm12_2_grp",
+		.pins = pwm12_2_pin,
+		.num_pins = ARRAY_SIZE(pwm12_2_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "pwm13_2_grp",
+		.pins = pwm13_2_pin,
+		.num_pins = ARRAY_SIZE(pwm13_2_pin),
+		.func = 0x6,
+	},
+
+	{
+		.name = "pwm10_3_grp",
+		.pins = pwm10_3_pin,
+		.num_pins = ARRAY_SIZE(pwm10_3_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "pwm11_3_grp",
+		.pins = pwm11_3_pin,
+		.num_pins = ARRAY_SIZE(pwm11_3_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "pwm12_3_grp",
+		.pins = pwm12_3_pin,
+		.num_pins = ARRAY_SIZE(pwm12_3_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "pwm13_3_grp",
+		.pins = pwm13_3_pin,
+		.num_pins = ARRAY_SIZE(pwm13_3_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "etimer0_0_grp",
+		.pins = etimer0_0_pin,
+		.num_pins = ARRAY_SIZE(etimer0_0_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "etimer0_1_grp",
+		.pins = etimer0_1_pin,
+		.num_pins = ARRAY_SIZE(etimer0_1_pin),
+		.func = 0x5,
+	},
+	{
+		.name = "etimer0_2_grp",
+		.pins = etimer0_2_pin,
+		.num_pins = ARRAY_SIZE(etimer0_2_pin),
+		.func = 0x5,
+	},
+	{
+		.name = "etimer0_3_grp",
+		.pins = etimer0_3_pin,
+		.num_pins = ARRAY_SIZE(etimer0_3_pin),
+		.func = 0x7,
+	},
+	{
+		.name = "etimer0_4_grp",
+		.pins = etimer0_4_pin,
+		.num_pins = ARRAY_SIZE(etimer0_4_pin),
+		.func = 0x7,
+	},
+	{
+		.name = "etimer0_5_grp",
+		.pins = etimer0_5_pin,
+		.num_pins = ARRAY_SIZE(etimer0_5_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer0_6_grp",
+		.pins = etimer0_6_pin,
+		.num_pins = ARRAY_SIZE(etimer0_6_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer0_7_grp",
+		.pins = etimer0_7_pin,
+		.num_pins = ARRAY_SIZE(etimer0_7_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer0_8_grp",
+		.pins = etimer0_8_pin,
+		.num_pins = ARRAY_SIZE(etimer0_8_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_0_grp",
+		.pins = etimer1_0_pin,
+		.num_pins = ARRAY_SIZE(etimer1_0_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "etimer1_1_grp",
+		.pins = etimer1_1_pin,
+		.num_pins = ARRAY_SIZE(etimer1_1_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_2_grp",
+		.pins = etimer1_2_pin,
+		.num_pins = ARRAY_SIZE(etimer1_2_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_3_grp",
+		.pins = etimer1_3_pin,
+		.num_pins = ARRAY_SIZE(etimer1_3_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_4_grp",
+		.pins = etimer1_4_pin,
+		.num_pins = ARRAY_SIZE(etimer1_4_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_5_grp",
+		.pins = etimer1_5_pin,
+		.num_pins = ARRAY_SIZE(etimer1_5_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_6_grp",
+		.pins = etimer1_6_pin,
+		.num_pins = ARRAY_SIZE(etimer1_6_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_7_grp",
+		.pins = etimer1_7_pin,
+		.num_pins = ARRAY_SIZE(etimer1_7_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_8_grp",
+		.pins = etimer1_8_pin,
+		.num_pins = ARRAY_SIZE(etimer1_8_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_9_grp",
+		.pins = etimer1_9_pin,
+		.num_pins = ARRAY_SIZE(etimer1_9_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer1_A_grp",
+		.pins = etimer1_A_pin,
+		.num_pins = ARRAY_SIZE(etimer1_A_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer2_0_grp",
+		.pins = etimer2_0_pin,
+		.num_pins = ARRAY_SIZE(etimer2_0_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "etimer2_1_grp",
+		.pins = etimer2_1_pin,
+		.num_pins = ARRAY_SIZE(etimer2_1_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer2_2_grp",
+		.pins = etimer2_2_pin,
+		.num_pins = ARRAY_SIZE(etimer2_2_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer2_3_grp",
+		.pins = etimer2_3_pin,
+		.num_pins = ARRAY_SIZE(etimer2_3_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer2_4_grp",
+		.pins = etimer2_4_pin,
+		.num_pins = ARRAY_SIZE(etimer2_4_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer2_5_grp",
+		.pins = etimer2_5_pin,
+		.num_pins = ARRAY_SIZE(etimer2_5_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer2_6_grp",
+		.pins = etimer2_6_pin,
+		.num_pins = ARRAY_SIZE(etimer2_6_pin),
+		.func = 0x2,
+	},
+	{
+		.name = "etimer2_7_grp",
+		.pins = etimer2_7_pin,
+		.num_pins = ARRAY_SIZE(etimer2_7_pin),
+		.func = 0x2,
+	},
+	{
+		.name = "etimer2_8_grp",
+		.pins = etimer2_8_pin,
+		.num_pins = ARRAY_SIZE(etimer2_8_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer3_0_grp",
+		.pins = etimer3_0_pin,
+		.num_pins = ARRAY_SIZE(etimer3_0_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "etimer3_1_grp",
+		.pins = etimer3_1_pin,
+		.num_pins = ARRAY_SIZE(etimer3_1_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer3_2_grp",
+		.pins = etimer3_2_pin,
+		.num_pins = ARRAY_SIZE(etimer3_2_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer3_3_grp",
+		.pins = etimer3_3_pin,
+		.num_pins = ARRAY_SIZE(etimer3_3_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer3_4_grp",
+		.pins = etimer3_4_pin,
+		.num_pins = ARRAY_SIZE(etimer3_4_pin),
+		.func = 0x2,
+	},
+	{
+		.name = "etimer3_5_grp",
+		.pins = etimer3_5_pin,
+		.num_pins = ARRAY_SIZE(etimer3_5_pin),
+		.func = 0x2,
+	},
+	{
+		.name = "etimer3_6_grp",
+		.pins = etimer3_6_pin,
+		.num_pins = ARRAY_SIZE(etimer3_6_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer4_0_grp",
+		.pins = etimer4_0_pin,
+		.num_pins = ARRAY_SIZE(etimer4_0_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "etimer4_1_grp",
+		.pins = etimer4_1_pin,
+		.num_pins = ARRAY_SIZE(etimer4_1_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer4_2_grp",
+		.pins = etimer4_2_pin,
+		.num_pins = ARRAY_SIZE(etimer4_2_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer4_3_grp",
+		.pins = etimer4_3_pin,
+		.num_pins = ARRAY_SIZE(etimer4_3_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer4_4_grp",
+		.pins = etimer4_4_pin,
+		.num_pins = ARRAY_SIZE(etimer4_4_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer4_5_grp",
+		.pins = etimer4_5_pin,
+		.num_pins = ARRAY_SIZE(etimer4_5_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer4_6_grp",
+		.pins = etimer4_6_pin,
+		.num_pins = ARRAY_SIZE(etimer4_6_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer4_7_grp",
+		.pins = etimer4_7_pin,
+		.num_pins = ARRAY_SIZE(etimer4_7_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer4_8_grp",
+		.pins = etimer4_8_pin,
+		.num_pins = ARRAY_SIZE(etimer4_8_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer5_0_grp",
+		.pins = etimer5_0_pin,
+		.num_pins = ARRAY_SIZE(etimer5_0_pin),
+		.func = 0x6,
+	},
+	{
+		.name = "etimer5_1_grp",
+		.pins = etimer5_1_pin,
+		.num_pins = ARRAY_SIZE(etimer5_1_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer5_2_grp",
+		.pins = etimer5_2_pin,
+		.num_pins = ARRAY_SIZE(etimer5_2_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer5_3_grp",
+		.pins = etimer5_3_pin,
+		.num_pins = ARRAY_SIZE(etimer5_3_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer5_4_grp",
+		.pins = etimer5_4_pin,
+		.num_pins = ARRAY_SIZE(etimer5_4_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer5_5_grp",
+		.pins = etimer5_5_pin,
+		.num_pins = ARRAY_SIZE(etimer5_5_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer5_6_grp",
+		.pins = etimer5_6_pin,
+		.num_pins = ARRAY_SIZE(etimer5_6_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer5_7_grp",
+		.pins = etimer5_7_pin,
+		.num_pins = ARRAY_SIZE(etimer5_7_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "etimer5_8_grp",
+		.pins = etimer5_8_pin,
+		.num_pins = ARRAY_SIZE(etimer5_8_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "jtag0_grp",
+		.pins = jtag0_pins,
+		.num_pins = ARRAY_SIZE(jtag0_pins),
+		.func = 0x7,
+	},
+	{
+		.name = "jtag1_grp",
+		.pins = jtag1_pins,
+		.num_pins = ARRAY_SIZE(jtag1_pins),
+		.func = 0x4,
+	},
+	{
+		.name = "eint0_0_grp",
+		.pins = eint0_0_pin,
+		.num_pins = ARRAY_SIZE(eint0_0_pin),
+		.func = 0x5,
+	},
+	{
+		.name = "eint0_1_grp",
+		.pins = eint0_1_pin,
+		.num_pins = ARRAY_SIZE(eint0_1_pin),
+		.func = 0x8,
+	},
+	{
+		.name = "eint1_0_grp",
+		.pins = eint1_0_pin,
+		.num_pins = ARRAY_SIZE(eint1_0_pin),
+		.func = 0x5,
+	},
+	{
+		.name = "eint1_1_grp",
+		.pins = eint1_1_pin,
+		.num_pins = ARRAY_SIZE(eint1_1_pin),
+		.func = 0x8,
+	},
+	{
+		.name = "eint2_0_grp",
+		.pins = eint2_0_pin,
+		.num_pins = ARRAY_SIZE(eint2_0_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "eint2_1_grp",
+		.pins = eint2_1_pin,
+		.num_pins = ARRAY_SIZE(eint2_1_pin),
+		.func = 0x5,
+	},
+	{
+		.name = "eint2_2_grp",
+		.pins = eint2_2_pin,
+		.num_pins = ARRAY_SIZE(eint2_2_pin),
+		.func = 0x3,
+	},
+	{
+		.name = "eint2_3_grp",
+		.pins = eint2_3_pin,
+		.num_pins = ARRAY_SIZE(eint2_3_pin),
+		.func = 0x2,
+	},
+	{
+		.name = "eint3_0_grp",
+		.pins = eint3_0_pin,
+		.num_pins = ARRAY_SIZE(eint3_0_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "eint3_1_grp",
+		.pins = eint3_1_pin,
+		.num_pins = ARRAY_SIZE(eint3_1_pin),
+		.func = 0x5,
+	},
+	{
+		.name = "eint3_2_grp",
+		.pins = eint3_2_pin,
+		.num_pins = ARRAY_SIZE(eint3_2_pin),
+		.func = 0x4,
+	},
+	{
+		.name = "ebi8_0_grp",
+		.pins = ebi8_0_pin,
+		.num_pins = ARRAY_SIZE(ebi8_0_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi8_1_grp",
+		.pins = ebi8_1_pin,
+		.num_pins = ARRAY_SIZE(ebi8_1_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi8_2_grp",
+		.pins = ebi8_2_pin,
+		.num_pins = ARRAY_SIZE(ebi8_2_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi8_3_grp",
+		.pins = ebi8_3_pin,
+		.num_pins = ARRAY_SIZE(ebi8_3_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi8_4_grp",
+		.pins = ebi8_4_pin,
+		.num_pins = ARRAY_SIZE(ebi8_4_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi8_5_grp",
+		.pins = ebi8_5_pin,
+		.num_pins = ARRAY_SIZE(ebi8_5_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi16_0_grp",
+		.pins = ebi16_0_pin,
+		.num_pins = ARRAY_SIZE(ebi16_0_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi16_1_grp",
+		.pins = ebi16_1_pin,
+		.num_pins = ARRAY_SIZE(ebi16_1_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi16_2_grp",
+		.pins = ebi16_2_pin,
+		.num_pins = ARRAY_SIZE(ebi16_2_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi16_3_grp",
+		.pins = ebi16_3_pin,
+		.num_pins = ARRAY_SIZE(ebi16_3_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi16_4_grp",
+		.pins = ebi16_4_pin,
+		.num_pins = ARRAY_SIZE(ebi16_4_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "ebi16_5_grp",
+		.pins = ebi16_5_pin,
+		.num_pins = ARRAY_SIZE(ebi16_5_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "usbh_power_1_grp",
+		.pins = usbh_pwren_ovc_pin,
+		.num_pins = ARRAY_SIZE(usbh_pwren_ovc_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "usbh_power_2_grp",
+		.pins = usbh_pwren_pin,
+		.num_pins = ARRAY_SIZE(usbh_pwren_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "usbh_power_3_grp",
+		.pins = usbh_ovc_pin,
+		.num_pins = ARRAY_SIZE(usbh_ovc_pin),
+		.func = 0x1,
+	},
+	{
+		.name = "usbh_lite0_1_grp",
+		.pins = usbh_lite0_pb4_pb6,
+		.num_pins = ARRAY_SIZE(usbh_lite0_pb4_pb6),
+		.func = 0x4,
+	},
+	{
+		.name = "usbh_lite0_2_grp",
+		.pins = usbh_lite0_pb5_pb7,
+		.num_pins = ARRAY_SIZE(usbh_lite0_pb5_pb7),
+		.func = 0x4,
+	},
+	{
+		.name = "usbh_lite0_3_grp",
+		.pins = usbh_lite0_pb10_pb9,
+		.num_pins = ARRAY_SIZE(usbh_lite0_pb10_pb9),
+		.func = 0x4,
+	},
+	{
+		.name = "usbh_lite0_4_grp",
+		.pins = usbh_lite0_pd15_pd14,
+		.num_pins = ARRAY_SIZE(usbh_lite0_pd15_pd14),
+		.func = 0x5,
+	},
+	{
+		.name = "usbh_lite1_1_grp",
+		.pins = usbh_lite1_pe1_pe0,
+		.num_pins = ARRAY_SIZE(usbh_lite1_pe1_pe0),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite1_2_grp",
+		.pins = usbh_lite1_pf1_pf0,
+		.num_pins = ARRAY_SIZE(usbh_lite1_pf1_pf0),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite2_1_grp",
+		.pins = usbh_lite2_pe3_pe2,
+		.num_pins = ARRAY_SIZE(usbh_lite2_pe3_pe2),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite2_2_grp",
+		.pins = usbh_lite2_pf3_pf2,
+		.num_pins = ARRAY_SIZE(usbh_lite2_pf3_pf2),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite3_1_grp",
+		.pins = usbh_lite3_pe5_pe4,
+		.num_pins = ARRAY_SIZE(usbh_lite3_pe5_pe4),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite3_2_grp",
+		.pins = usbh_lite3_pf5_pf4,
+		.num_pins = ARRAY_SIZE(usbh_lite3_pf5_pf4),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite4_1_grp",
+		.pins = usbh_lite4_pe7_pe6,
+		.num_pins = ARRAY_SIZE(usbh_lite4_pe7_pe6),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite4_2_grp",
+		.pins = usbh_lite4_pf7_pf6,
+		.num_pins = ARRAY_SIZE(usbh_lite4_pf7_pf6),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite4_3_grp",
+		.pins = usbh_lite4_pg10_pa15,
+		.num_pins = ARRAY_SIZE(usbh_lite4_pg10_pa15),
+		.func = 0x4,
+	},
+	{
+		.name = "usbh_lite4_4_grp",
+		.pins = usbh_lite4_pb13_pf6,
+		.num_pins = ARRAY_SIZE(usbh_lite4_pb13_pf6),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite5_1_grp",
+		.pins = usbh_lite5_pe9_pe8,
+		.num_pins = ARRAY_SIZE(usbh_lite5_pe9_pe8),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite5_2_grp",
+		.pins = usbh_lite5_pf9_pf8,
+		.num_pins = ARRAY_SIZE(usbh_lite5_pf9_pf8),
+		.func = 0x6,
+	},
+	{
+		.name = "usbh_lite5_3_grp",
+		.pins = usbh_lite5_pa14_pa13,
+		.num_pins = ARRAY_SIZE(usbh_lite5_pa14_pa13),
+		.func = 0x4,
+	},
+	{
+		.name = "usbh_lite5_4_grp",
+		.pins = usbh_lite5_pb12_pb11,
+		.num_pins = ARRAY_SIZE(usbh_lite5_pb12_pb11),
+		.func = 0x4,
+	},
+};
+
+static int nuc980_get_groups_count(struct pinctrl_dev *pctldev)
+{
+	return ARRAY_SIZE(nuc980_pinctrl_groups);
+}
+
+static const char *nuc980_get_group_name(struct pinctrl_dev *pctldev,
+        unsigned selector)
+{
+	;
+	return nuc980_pinctrl_groups[selector].name;
+}
+
+static int nuc980_get_group_pins(struct pinctrl_dev *pctldev, unsigned selector,
+                                 const unsigned ** pins,
+                                 unsigned * num_pins)
+{
+	*pins = (unsigned *) nuc980_pinctrl_groups[selector].pins;
+	*num_pins = nuc980_pinctrl_groups[selector].num_pins;
+	return 0;
+}
+
+static struct pinctrl_ops nuc980_pctrl_ops = {
+	.get_groups_count = nuc980_get_groups_count,
+	.get_group_name = nuc980_get_group_name,
+	.get_group_pins = nuc980_get_group_pins,
+};
+
+struct nuc980_pmx_func {
+	const char *name;
+	const char * const *groups;
+	const unsigned num_groups;
+};
+
+static const char * const nadc_groups[] = {"nadc_grp"};
+static const char * const emac0_groups[] = {"emac0_grp"};
+static const char * const emac1_groups[] = {"emac1_grp"};
+static const char * const vcap0_groups[] = {"vcap0_grp"};
+static const char * const vcap1_groups[] = {"vcap1_grp"};
+static const char * const sd0_groups[] = {"sd0_grp"};
+static const char * const sd1_groups[] = {"sd1_grp"};
+static const char * const nand_groups[] = {"nand_grp"};
+static const char * const usbd_groups[] = {"usbd_grp"};
+static const char * const i2c0_groups[] = {"i2c0_0_grp", "i2c0_1_grp", "i2c0_2_grp"};
+static const char * const i2c1_groups[] = {"i2c1_0_grp", "i2c1_1_grp", "i2c1_2_grp"};
+static const char * const i2c2_groups[] = {"i2c2_0_grp", "i2c2_1_grp"};
+static const char * const i2c3_groups[] = {"i2c3_0_grp", "i2c3_1_grp"};
+static const char * const i2s_groups[] = {"i2s_0_grp", "i2s_1_grp"};
+static const char * const uart0_groups[] = {"uart0_grp"};
+static const char * const uart1_groups[] = {"uart1_0_grp", "uart1_1_grp", "uart1_4_grp"};
+static const char * const uart1_fc_groups[] = {"uart1_2_grp", "uart1_3_grp"};
+static const char * const uart2_groups[] = {"uart2_1_grp", "uart2_4_grp", "uart2_5_grp"};
+static const char * const uart2_fc_groups[] = {"uart2_0_grp", "uart2_2_grp", "uart2_3_grp"};
+static const char * const uart3_groups[] = {"uart3_0_grp", "uart3_1_grp", "uart3_3_grp", "uart3_6_grp", "uart3_7_grp"};
+static const char * const uart3_fc_groups[] = {"uart3_2_grp", "uart3_4_grp", "uart3_5_grp"};
+static const char * const uart4_groups[] = {"uart4_0_grp", "uart4_1_grp", "uart4_4_grp"};
+static const char * const uart4_fc_groups[] = {"uart4_2_grp", "uart4_3_grp"};
+static const char * const uart5_groups[] = {"uart5_0_grp", "uart5_2_grp", "uart5_4_grp"};
+static const char * const uart5_fc_groups[] = {"uart5_1_grp", "uart5_3_grp"};
+static const char * const uart6_groups[] = {"uart6_1_grp", "uart6_3_grp", "uart6_4_grp"};
+static const char * const uart6_fc_groups[] = {"uart6_0_grp", "uart6_2_grp"};
+static const char * const uart7_groups[] = {"uart7_0_grp", "uart7_1_grp", "uart7_3_grp", "uart7_5_grp"};
+static const char * const uart7_fc_groups[] = {"uart7_2_grp", "uart7_4_grp"};
+static const char * const uart8_groups[] = {"uart8_0_grp", "uart8_2_grp", "uart8_3_grp"};
+static const char * const uart8_fc_groups[] = {"uart8_1_grp", "uart8_4_grp"};
+static const char * const uart9_groups[] = {"uart9_0_grp", "uart9_3_grp", "uart9_4_grp"};
+static const char * const uart9_fc_groups[] = {"uart9_2_grp"};
+static const char * const sc0_groups[] = {"sc0_0_grp", "sc0_1_grp"};
+static const char * const sc1_groups[] = {"sc1_0_grp", "sc1_1_grp"};
+static const char * const scuart0_groups[] = {"sc0_2_grp", "sc0_3_grp"};
+static const char * const scuart1_groups[] = {"sc1_2_grp", "sc1_3_grp"};
+static const char * const qspi0_groups[] = {"qspi0_3_grp"};
+static const char * const qspi0_quad_groups[] = {"qspi0_2_grp"};
+static const char * const qspi0_ss1_groups[] = {"qspi0_0_grp", "qspi0_1_grp"};
+static const char * const qspi0_quad_ss1_groups[] = {"qspi0_4_grp","qspi0_5_grp"};
+static const char * const spi0_groups[] = {"spi0_0_grp","spi0_3_grp"};
+static const char * const spi0_ss1_groups[] = {"spi0_1_grp","spi0_2_grp","spi0_4_grp"};
+static const char * const spi1_groups[] = {"spi1_0_grp", "spi1_1_grp", "spi1_3_grp"};
+static const char * const spi1_ss1_groups[] = {"spi1_2_grp", "spi1_4_grp"};
+static const char * const can0_groups[] = {"can0_0_grp", "can0_1_grp", "can0_2_grp", "can0_3_grp"};
+static const char * const can1_groups[] = {"can1_0_grp", "can1_1_grp", "can1_2_grp", "can1_3_grp"};
+static const char * const can2_groups[] = {"can2_0_grp", "can2_1_grp", "can2_2_grp", "can2_3_grp", "can2_4_grp"};
+static const char * const can3_groups[] = {"can3_0_grp", "can3_1_grp", "can3_2_grp"};
+static const char * const pwm00_groups[] = {"pwm00_0_grp", "pwm00_1_grp", "pwm00_2_grp", "pwm00_3_grp"};
+static const char * const pwm01_groups[] = {"pwm01_0_grp", "pwm01_1_grp", "pwm01_2_grp", "pwm01_3_grp"};
+static const char * const pwm02_groups[] = {"pwm02_0_grp", "pwm02_1_grp", "pwm02_2_grp", "pwm02_3_grp", "pwm02_4_grp"};
+static const char * const pwm03_groups[] = {"pwm03_0_grp", "pwm03_1_grp", "pwm03_2_grp", "pwm03_3_grp"};
+static const char * const pwm10_groups[] = {"pwm10_0_grp", "pwm10_1_grp", "pwm10_2_grp", "pwm10_3_grp"};
+static const char * const pwm11_groups[] = {"pwm11_0_grp", "pwm11_1_grp", "pwm11_2_grp", "pwm11_3_grp"};
+static const char * const pwm12_groups[] = {"pwm12_0_grp", "pwm12_1_grp", "pwm12_2_grp", "pwm12_3_grp"};
+static const char * const pwm13_groups[] = {"pwm13_0_grp", "pwm13_1_grp", "pwm13_2_grp", "pwm13_3_grp"};
+static const char * const etimer0_ecnt_groups[] = {"etimer0_0_grp", "etimer0_7_grp", "etimer0_8_grp"};
+static const char * const etimer0_tgl_groups[] = {"etimer0_1_grp", "etimer0_3_grp", "etimer0_5_grp"};
+static const char * const etimer0_cap_groups[] = {"etimer0_2_grp", "etimer0_4_grp", "etimer0_6_grp"};
+static const char * const etimer1_ecnt_groups[] = {"etimer1_0_grp", "etimer1_5_grp","etimer1_8_grp"};
+static const char * const etimer1_tgl_groups[] = {"etimer1_1_grp", "etimer1_3_grp","etimer1_6_grp", "etimer1_9_grp"};
+static const char * const etimer1_cap_groups[] = {"etimer1_2_grp", "etimer1_4_grp", "etimer1_7_grp", "etimer1_A_grp"};
+static const char * const etimer2_ecnt_groups[] = {"etimer2_0_grp", "etimer2_5_grp", "etimer2_8_grp"};
+static const char * const etimer2_tgl_groups[] = {"etimer2_1_grp", "etimer2_3_grp", "etimer2_6_grp"};
+static const char * const etimer2_cap_groups[] = {"etimer2_2_grp", "etimer2_4_grp", "etimer2_7_grp"};
+static const char * const etimer3_ecnt_groups[] = {"etimer3_0_grp", "etimer3_3_grp", "etimer3_6_grp"};
+static const char * const etimer3_tgl_groups[] = {"etimer3_1_grp", "etimer3_4_grp"};
+static const char * const etimer3_cap_groups[] = {"etimer3_2_grp", "etimer3_5_grp"};
+static const char * const etimer4_ecnt_groups[] = {"etimer4_0_grp", "etimer4_5_grp", "etimer4_6_grp"};
+static const char * const etimer4_tgl_groups[] = {"etimer4_1_grp", "etimer4_3_grp", "etimer4_7_grp"};
+static const char * const etimer4_cap_groups[] = {"etimer4_2_grp", "etimer4_4_grp", "etimer4_8_grp"};
+static const char * const etimer5_ecnt_groups[] = {"etimer5_0_grp", "etimer5_5_grp", "etimer5_6_grp"};
+static const char * const etimer5_tgl_groups[] = {"etimer5_1_grp", "etimer5_3_grp", "etimer5_7_grp"};
+static const char * const etimer5_cap_groups[] = {"etimer5_2_grp", "etimer5_4_grp", "etimer5_8_grp"};
+static const char * const jtag0_groups[] = {"jtag0_grp"};
+static const char * const jtag1_groups[] = {"jtag1_grp"};
+static const char * const eint0_groups[] = {"eint0_0_grp", "eint0_1_grp"};
+static const char * const eint1_groups[] = {"eint1_0_grp", "eint1_1_grp"};
+static const char * const eint2_groups[] = {"eint2_0_grp", "eint2_1_grp", "eint2_2_grp", "eint2_3_grp"};
+static const char * const eint3_groups[] = {"eint3_0_grp", "eint3_1_grp", "eint3_2_grp"};
+static const char * const ebi8_0_groups[] = {"ebi8_0_grp"};
+static const char * const ebi8_1_groups[] = {"ebi8_1_grp"};
+static const char * const ebi8_2_groups[] = {"ebi8_2_grp"};
+static const char * const ebi8_3_groups[] = {"ebi8_3_grp"};
+static const char * const ebi8_4_groups[] = {"ebi8_4_grp"};
+static const char * const ebi8_5_groups[] = {"ebi8_5_grp"};;
+static const char * const ebi16_0_groups[] = {"ebi16_0_grp"};
+static const char * const ebi16_1_groups[] = {"ebi16_1_grp"};
+static const char * const ebi16_2_groups[] = {"ebi16_2_grp"};
+static const char * const ebi16_3_groups[] = {"ebi16_3_grp"};
+static const char * const ebi16_4_groups[] = {"ebi16_4_grp"};
+static const char * const ebi16_5_groups[] = {"ebi16_5_grp"};
+static const char * const usbh_power_groups[] = {"usbh_power_1_grp", "usbh_power_2_grp", "usbh_power_3_grp"};
+static const char * const usbh_lite0_groups[] = {"usbh_lite0_1_grp", "usbh_lite0_2_grp", "usbh_lite0_3_grp", "usbh_lite0_4_grp"};
+static const char * const usbh_lite1_groups[] = {"usbh_lite1_1_grp", "usbh_lite1_2_grp"};
+static const char * const usbh_lite2_groups[] = {"usbh_lite2_1_grp", "usbh_lite2_2_grp"};
+static const char * const usbh_lite3_groups[] = {"usbh_lite3_1_grp", "usbh_lite3_2_grp"};
+static const char * const usbh_lite4_groups[] = {"usbh_lite4_1_grp", "usbh_lite4_2_grp", "usbh_lite4_3_grp", "usbh_lite4_4_grp"};
+static const char * const usbh_lite5_groups[] = {"usbh_lite5_1_grp", "usbh_lite5_2_grp", "usbh_lite5_3_grp", "usbh_lite5_4_grp"};
+
+static const struct nuc980_pmx_func nuc980_functions[] = {
+	{
+		.name = "nadc",
+		.groups = nadc_groups,
+		.num_groups = ARRAY_SIZE(nadc_groups),
+	},
+	{
+		.name = "emac0",
+		.groups = emac0_groups,
+		.num_groups = ARRAY_SIZE(emac0_groups),
+	},
+	{
+		.name = "emac1",
+		.groups = emac1_groups,
+		.num_groups = ARRAY_SIZE(emac1_groups),
+	},
+	{
+		.name = "vcap0",
+		.groups = vcap0_groups,
+		.num_groups = ARRAY_SIZE(vcap0_groups),
+	},
+	{
+		.name = "vcap1",
+		.groups = vcap1_groups,
+		.num_groups = ARRAY_SIZE(vcap1_groups),
+	},
+	{
+		.name = "sd0",
+		.groups = sd0_groups,
+		.num_groups = ARRAY_SIZE(sd0_groups),
+	},
+	{
+		.name = "sd1",
+		.groups = sd1_groups,
+		.num_groups = ARRAY_SIZE(sd1_groups),
+	},
+	{
+		.name = "nand",
+		.groups = nand_groups,
+		.num_groups = ARRAY_SIZE(nand_groups),
+	},
+	{
+		.name = "usbd",
+		.groups = usbd_groups,
+		.num_groups = ARRAY_SIZE(usbd_groups),
+	},
+	{
+		.name = "i2c0",
+		.groups = i2c0_groups,
+		.num_groups = ARRAY_SIZE(i2c0_groups),
+	},
+	{
+		.name = "i2c1",
+		.groups = i2c1_groups,
+		.num_groups = ARRAY_SIZE(i2c1_groups),
+	},
+	{
+		.name = "i2c2",
+		.groups = i2c2_groups,
+		.num_groups = ARRAY_SIZE(i2c2_groups),
+	},
+	{
+		.name = "i2c3",
+		.groups = i2c3_groups,
+		.num_groups = ARRAY_SIZE(i2c3_groups),
+	},
+	{
+		.name = "i2s",
+		.groups = i2s_groups,
+		.num_groups = ARRAY_SIZE(i2s_groups),
+	},
+	{
+		.name = "uart0",
+		.groups = uart0_groups,
+		.num_groups = ARRAY_SIZE(uart0_groups),
+	},
+	{
+		.name = "uart1",
+		.groups = uart1_groups,
+		.num_groups = ARRAY_SIZE(uart1_groups),
+	},
+	{
+		.name = "uart1_fc",
+		.groups = uart1_fc_groups,
+		.num_groups = ARRAY_SIZE(uart1_fc_groups),
+	},
+	{
+		.name = "uart2",
+		.groups = uart2_groups,
+		.num_groups = ARRAY_SIZE(uart2_groups),
+	},
+	{
+		.name = "uart2_fc",
+		.groups = uart2_fc_groups,
+		.num_groups = ARRAY_SIZE(uart2_fc_groups),
+	},
+	{
+		.name = "uart3",
+		.groups = uart3_groups,
+		.num_groups = ARRAY_SIZE(uart3_groups),
+	},
+	{
+		.name = "uart3_fc",
+		.groups = uart3_fc_groups,
+		.num_groups = ARRAY_SIZE(uart3_fc_groups),
+	},
+	{
+		.name = "uart4",
+		.groups = uart4_groups,
+		.num_groups = ARRAY_SIZE(uart4_groups),
+	},
+	{
+		.name = "uart4_fc",
+		.groups = uart4_fc_groups,
+		.num_groups = ARRAY_SIZE(uart4_fc_groups),
+	},
+	{
+		.name = "uart5",
+		.groups = uart5_groups,
+		.num_groups = ARRAY_SIZE(uart5_groups),
+	},
+	{
+		.name = "uart5_fc",
+		.groups = uart5_fc_groups,
+		.num_groups = ARRAY_SIZE(uart5_fc_groups),
+	},
+	{
+		.name = "uart6",
+		.groups = uart6_groups,
+		.num_groups = ARRAY_SIZE(uart6_groups),
+	},
+	{
+		.name = "uart6_fc",
+		.groups = uart6_fc_groups,
+		.num_groups = ARRAY_SIZE(uart6_fc_groups),
+	},
+	{
+		.name = "uart7",
+		.groups = uart7_groups,
+		.num_groups = ARRAY_SIZE(uart7_groups),
+	},
+	{
+		.name = "uart7_fc",
+		.groups = uart7_fc_groups,
+		.num_groups = ARRAY_SIZE(uart7_fc_groups),
+	},
+	{
+		.name = "uart8",
+		.groups = uart8_groups,
+		.num_groups = ARRAY_SIZE(uart8_groups),
+	},
+	{
+		.name = "uart8_fc",
+		.groups = uart8_fc_groups,
+		.num_groups = ARRAY_SIZE(uart8_fc_groups),
+	},
+	{
+		.name = "uart9",
+		.groups = uart9_groups,
+		.num_groups = ARRAY_SIZE(uart9_groups),
+	},
+	{
+		.name = "uart9_fc",
+		.groups = uart9_fc_groups,
+		.num_groups = ARRAY_SIZE(uart9_fc_groups),
+	},
+	{
+		.name = "sc0",
+		.groups = sc0_groups,
+		.num_groups = ARRAY_SIZE(sc0_groups),
+	},
+	{
+		.name = "sc1",
+		.groups = sc1_groups,
+		.num_groups = ARRAY_SIZE(sc1_groups),
+	},
+	{
+		.name = "scuart0",
+		.groups = scuart0_groups,
+		.num_groups = ARRAY_SIZE(scuart0_groups),
+	},
+	{
+		.name = "scuart1",
+		.groups = scuart1_groups,
+		.num_groups = ARRAY_SIZE(scuart1_groups),
+	},
+	{
+		.name = "qspi0",
+		.groups = qspi0_groups,
+		.num_groups = ARRAY_SIZE(qspi0_groups),
+	},
+	{
+		.name = "qspi0_quad",
+		.groups = qspi0_quad_groups,
+		.num_groups = ARRAY_SIZE(qspi0_quad_groups),
+	},
+	{
+		.name = "qspi0_ss1",
+		.groups = qspi0_ss1_groups,
+		.num_groups = ARRAY_SIZE(qspi0_ss1_groups),
+	},
+	{
+		.name = "qspi0_quad_ss1",
+		.groups = qspi0_quad_ss1_groups,
+		.num_groups = ARRAY_SIZE(qspi0_quad_ss1_groups),
+	},
+	{
+		.name = "spi0",
+		.groups = spi0_groups,
+		.num_groups = ARRAY_SIZE(spi0_groups),
+	},
+	{
+		.name = "spi0_ss1",
+		.groups = spi0_ss1_groups,
+		.num_groups = ARRAY_SIZE(spi0_ss1_groups),
+	},
+	{
+		.name = "spi1",
+		.groups = spi1_groups,
+		.num_groups = ARRAY_SIZE(spi1_groups),
+	},
+	{
+		.name = "spi1_ss1",
+		.groups = spi1_ss1_groups,
+		.num_groups = ARRAY_SIZE(spi1_ss1_groups),
+	},
+	{
+		.name = "can0",
+		.groups = can0_groups,
+		.num_groups = ARRAY_SIZE(can0_groups),
+	},
+	{
+		.name = "can1",
+		.groups = can1_groups,
+		.num_groups = ARRAY_SIZE(can1_groups),
+	},
+	{
+		.name = "can2",
+		.groups = can2_groups,
+		.num_groups = ARRAY_SIZE(can2_groups),
+	},
+	{
+		.name = "can3",
+		.groups = can3_groups,
+		.num_groups = ARRAY_SIZE(can3_groups),
+	},
+	{
+		.name = "pwm00",
+		.groups = pwm00_groups,
+		.num_groups = ARRAY_SIZE(pwm00_groups),
+	},
+	{
+		.name = "pwm01",
+		.groups = pwm01_groups,
+		.num_groups = ARRAY_SIZE(pwm01_groups),
+	},
+	{
+		.name = "pwm02",
+		.groups = pwm02_groups,
+		.num_groups = ARRAY_SIZE(pwm02_groups),
+	},
+	{
+		.name = "pwm03",
+		.groups = pwm03_groups,
+		.num_groups = ARRAY_SIZE(pwm03_groups),
+	},
+	{
+		.name = "pwm10",
+		.groups = pwm10_groups,
+		.num_groups = ARRAY_SIZE(pwm10_groups),
+	},
+	{
+		.name = "pwm11",
+		.groups = pwm11_groups,
+		.num_groups = ARRAY_SIZE(pwm11_groups),
+	},
+	{
+		.name = "pwm12",
+		.groups = pwm12_groups,
+		.num_groups = ARRAY_SIZE(pwm12_groups),
+	},
+	{
+		.name = "pwm13",
+		.groups = pwm13_groups,
+		.num_groups = ARRAY_SIZE(pwm13_groups),
+	},
+	{
+		.name = "etimer0_ecnt",
+		.groups = etimer0_ecnt_groups,
+		.num_groups = ARRAY_SIZE(etimer0_ecnt_groups),
+	},
+	{
+		.name = "etimer0_tgl",
+		.groups = etimer0_tgl_groups,
+		.num_groups = ARRAY_SIZE(etimer0_tgl_groups),
+	},
+	{
+		.name = "etimer0_cap",
+		.groups = etimer0_cap_groups,
+		.num_groups = ARRAY_SIZE(etimer0_cap_groups),
+	},
+	{
+		.name = "etimer1_ecnt",
+		.groups = etimer1_ecnt_groups,
+		.num_groups = ARRAY_SIZE(etimer1_ecnt_groups),
+	},
+	{
+		.name = "etimer1_tgl",
+		.groups = etimer1_tgl_groups,
+		.num_groups = ARRAY_SIZE(etimer1_tgl_groups),
+	},
+	{
+		.name = "etimer1_cap",
+		.groups = etimer1_cap_groups,
+		.num_groups = ARRAY_SIZE(etimer1_cap_groups),
+	},
+	{
+		.name = "etimer2_ecnt",
+		.groups = etimer2_ecnt_groups,
+		.num_groups = ARRAY_SIZE(etimer2_ecnt_groups),
+	},
+	{
+		.name = "etimer2_tgl",
+		.groups = etimer2_tgl_groups,
+		.num_groups = ARRAY_SIZE(etimer2_tgl_groups),
+	},
+	{
+		.name = "etimer2_cap",
+		.groups = etimer2_cap_groups,
+		.num_groups = ARRAY_SIZE(etimer2_cap_groups),
+	},
+	{
+		.name = "etimer3_ecnt",
+		.groups = etimer3_ecnt_groups,
+		.num_groups = ARRAY_SIZE(etimer3_ecnt_groups),
+	},
+	{
+		.name = "etimer3_tgl",
+		.groups = etimer3_tgl_groups,
+		.num_groups = ARRAY_SIZE(etimer3_tgl_groups),
+	},
+	{
+		.name = "etimer3_cap",
+		.groups = etimer3_cap_groups,
+		.num_groups = ARRAY_SIZE(etimer3_cap_groups),
+	},
+	{
+		.name = "etimer4_ecnt",
+		.groups = etimer4_ecnt_groups,
+		.num_groups = ARRAY_SIZE(etimer4_ecnt_groups),
+	},
+	{
+		.name = "etimer4_tgl",
+		.groups = etimer4_tgl_groups,
+		.num_groups = ARRAY_SIZE(etimer4_tgl_groups),
+	},
+	{
+		.name = "etimer4_cap",
+		.groups = etimer4_cap_groups,
+		.num_groups = ARRAY_SIZE(etimer4_cap_groups),
+	},
+	{
+		.name = "etimer5_ecnt",
+		.groups = etimer5_ecnt_groups,
+		.num_groups = ARRAY_SIZE(etimer5_ecnt_groups),
+	},
+	{
+		.name = "etimer5_tgl",
+		.groups = etimer5_tgl_groups,
+		.num_groups = ARRAY_SIZE(etimer5_tgl_groups),
+	},
+	{
+		.name = "etimer5_cap",
+		.groups = etimer5_cap_groups,
+		.num_groups = ARRAY_SIZE(etimer5_cap_groups),
+	},
+	{
+		.name = "jtag0",
+		.groups = jtag0_groups,
+		.num_groups = ARRAY_SIZE(jtag0_groups),
+	},
+	{
+		.name = "jtag1",
+		.groups = jtag1_groups,
+		.num_groups = ARRAY_SIZE(jtag1_groups),
+	},
+	{
+		.name = "eint0",
+		.groups = eint0_groups,
+		.num_groups = ARRAY_SIZE(eint0_groups),
+	},
+	{
+		.name = "eint1",
+		.groups = eint1_groups,
+		.num_groups = ARRAY_SIZE(eint1_groups),
+	},
+	{
+		.name = "eint2",
+		.groups = eint2_groups,
+		.num_groups = ARRAY_SIZE(eint2_groups),
+	},
+	{
+		.name = "eint3",
+		.groups = eint3_groups,
+		.num_groups = ARRAY_SIZE(eint3_groups),
+	},
+	{
+		.name = "ebi_8_0",
+		.groups = ebi8_0_groups,
+		.num_groups = ARRAY_SIZE(ebi8_0_groups),
+	},
+	{
+		.name = "ebi_8_1",
+		.groups = ebi8_1_groups,
+		.num_groups = ARRAY_SIZE(ebi8_1_groups),
+	},
+	{
+		.name = "ebi_8_2",
+		.groups = ebi8_2_groups,
+		.num_groups = ARRAY_SIZE(ebi8_2_groups),
+	},
+	{
+		.name = "ebi_8_3",
+		.groups = ebi8_3_groups,
+		.num_groups = ARRAY_SIZE(ebi8_3_groups),
+	},
+	{
+		.name = "ebi_8_4",
+		.groups = ebi8_4_groups,
+		.num_groups = ARRAY_SIZE(ebi8_4_groups),
+	},
+	{
+		.name = "ebi_8_5",
+		.groups = ebi8_5_groups,
+		.num_groups = ARRAY_SIZE(ebi8_5_groups),
+	},
+	{
+		.name = "ebi_16_0",
+		.groups = ebi16_0_groups,
+		.num_groups = ARRAY_SIZE(ebi16_0_groups),
+	},
+	{
+		.name = "ebi_16_1",
+		.groups = ebi16_1_groups,
+		.num_groups = ARRAY_SIZE(ebi16_1_groups),
+	},
+	{
+		.name = "ebi_16_2",
+		.groups = ebi16_2_groups,
+		.num_groups = ARRAY_SIZE(ebi16_2_groups),
+	},
+	{
+		.name = "ebi_16_3",
+		.groups = ebi16_3_groups,
+		.num_groups = ARRAY_SIZE(ebi16_3_groups),
+	},
+	{
+		.name = "ebi_16_4",
+		.groups = ebi16_4_groups,
+		.num_groups = ARRAY_SIZE(ebi16_4_groups),
+	},
+	{
+		.name = "ebi_16_5",
+		.groups = ebi16_5_groups,
+		.num_groups = ARRAY_SIZE(ebi16_5_groups),
+	},
+	{
+		.name = "usbh_pwren_ovc",
+		.groups = usbh_power_groups,
+		.num_groups = ARRAY_SIZE(usbh_power_groups),
+	},
+	{
+		.name = "usbh_lite0_dp_dm",
+		.groups = usbh_lite0_groups,
+		.num_groups = ARRAY_SIZE(usbh_lite0_groups),
+	},
+	{
+		.name = "usbh_lite1_dp_dm",
+		.groups = usbh_lite1_groups,
+		.num_groups = ARRAY_SIZE(usbh_lite1_groups),
+	},
+	{
+		.name = "usbh_lite2_dp_dm",
+		.groups = usbh_lite2_groups,
+		.num_groups = ARRAY_SIZE(usbh_lite2_groups),
+	},
+	{
+		.name = "usbh_lite3_dp_dm",
+		.groups = usbh_lite3_groups,
+		.num_groups = ARRAY_SIZE(usbh_lite3_groups),
+	},
+	{
+		.name = "usbh_lite4_dp_dm",
+		.groups = usbh_lite4_groups,
+		.num_groups = ARRAY_SIZE(usbh_lite4_groups),
+	},
+	{
+		.name = "usbh_lite5_dp_dm",
+		.groups = usbh_lite5_groups,
+		.num_groups = ARRAY_SIZE(usbh_lite5_groups),
+	},
+};
+
+
+int nuc980_get_functions_count(struct pinctrl_dev *pctldev)
+{
+	return ARRAY_SIZE(nuc980_functions);
+}
+
+const char *nuc980_get_fname(struct pinctrl_dev *pctldev, unsigned selector)
+{
+	return nuc980_functions[selector].name;
+}
+
+static int nuc980_get_groups(struct pinctrl_dev *pctldev, unsigned selector,
+                             const char * const **groups,
+                             unsigned * const num_groups)
+{
+	*groups = nuc980_functions[selector].groups;
+	*num_groups = nuc980_functions[selector].num_groups;
+	return 0;
+}
+
+/*
+ * selector = data.nux.func, which is entry number in nuc980_functions,
+ * and group = data.mux.group, which is entry number in nuc980_pmx_func
+ * group is not used since some function use different setting between
+ * different ports. for example UART....
+ */
+int nuc980_set_mux(struct pinctrl_dev *pctldev, unsigned selector,
+                  unsigned group)
+{
+	unsigned int i, j;
+	unsigned int reg, offset;
+
+	//printk("set mux =>%x %x  %s\n", selector, group, nuc980_pinctrl_groups[group].name);
+	for(i = 0; i < nuc980_pinctrl_groups[group].num_pins; i++) {
+		j = nuc980_pinctrl_groups[group].pins[i];
+		offset = (j >> 4) * 8 + ((j & 0x8) ? 4 : 0);
+
+		reg = __raw_readl(REG_MFP_GPA_L + offset);
+		reg = (reg & ~(0xF << ((j & 0x7) * 4))) | (nuc980_pinctrl_groups[group].func << ((j & 0x7) * 4));
+
+		__raw_writel(reg, REG_MFP_GPA_L + offset);
+	}
+	return 0;
+}
+
+
+struct pinmux_ops nuc980_pmxops = {
+	.get_functions_count = nuc980_get_functions_count,
+	.get_function_name = nuc980_get_fname,
+	.get_function_groups = nuc980_get_groups,
+	.set_mux = nuc980_set_mux,
+};
+
+static struct pinctrl_desc nuc980_pinctrl_desc = {
+	.name = "nuc980-pinctrl_desc",
+	.pins = nuc980_pins,
+	.npins = ARRAY_SIZE(nuc980_pins),
+	.pctlops = &nuc980_pctrl_ops,
+	.pmxops = &nuc980_pmxops,
+	.owner = THIS_MODULE,
+};
+
+static const struct pinctrl_map nuc980_pinmap[] = {
+	{
+		.dev_name = "nuc980-nadc",
+		.name = "nadc",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "nadc",
+		.data.mux.group = "nadc_grp",
+	},
+	{
+		.dev_name = "nuc980-emac0",
+		.name = PINCTRL_STATE_DEFAULT,
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "emac0",
+		.data.mux.group = "emac0_grp",
+	},
+	{
+		.dev_name = "nuc980-emac1",
+		.name = PINCTRL_STATE_DEFAULT,
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "emac1",
+		.data.mux.group = "emac1_grp",
+	},
+//  {
+//      .dev_name = "nuc980-emac0",
+//      .name = "pps0",
+//      .type = PIN_MAP_TYPE_MUX_GROUP,
+//      .ctrl_dev_name = "pinctrl-nuc980",
+//      .data.mux.function = "pps0",
+//      .data.mux.group = "pps0_grp",
+//  },
+//  {
+//      .dev_name = "nuc980-emac1",
+//      .name = "pps1",
+//      .type = PIN_MAP_TYPE_MUX_GROUP,
+//      .ctrl_dev_name = "pinctrl-nuc980",
+//      .data.mux.function = "pps1",
+//      .data.mux.group = "pps1_grp",
+//  },
+	{
+		.dev_name = "nuc980-videoin0",
+		.name = "vcap0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "vcap0",
+		.data.mux.group = "vcap0_grp",
+	},
+	{
+		.dev_name = "nuc980-videoin1",
+		.name = "vcap1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "vcap1",
+		.data.mux.group = "vcap1_grp",
+	},
+	{
+		.dev_name = "nuc980-fmi",
+		.name = "sd0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "sd0",
+		.data.mux.group = "sd0_grp",
+	},
+	{
+		.dev_name = "nuc980-sdh",
+		.name = "sd1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "sd1",
+		.data.mux.group = "sd1_grp",
+	},
+	{
+		.dev_name = "nuc980-fmi",
+		.name = "nand",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "nand",
+		.data.mux.group = "nand_grp",
+	},
+	{
+		.dev_name = "nuc980-usbdev",
+		.name = "usbd-vbusvld",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbd",
+		.data.mux.group = "usbd_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c0",
+		.name = "i2c0-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c0",
+		.data.mux.group = "i2c0_0_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c0",
+		.name = "i2c0-PA_PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c0",
+		.data.mux.group = "i2c0_1_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c0",
+		.name = "i2c0-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c0",
+		.data.mux.group = "i2c0_2_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c1",
+		.name = "i2c1-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c1",
+		.data.mux.group = "i2c1_0_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c1",
+		.name = "i2c1-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c1",
+		.data.mux.group = "i2c1_1_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c1",
+		.name = "i2c1-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c1",
+		.data.mux.group = "i2c1_2_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c2",
+		.name = "i2c2-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c2",
+		.data.mux.group = "i2c2_0_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c2",
+		.name = "i2c2-PB_PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c2",
+		.data.mux.group = "i2c2_1_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c3",
+		.name = "i2c3-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c3",
+		.data.mux.group = "i2c3_0_grp",
+	},
+	{
+		.dev_name = "nuc980-i2c3",
+		.name = "i2c3-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2c3",
+		.data.mux.group = "i2c3_1_grp",
+	},
+	{
+		.dev_name = "nuc980-audio-i2s",
+		.name = "i2s-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2s",
+		.data.mux.group = "i2s_0_grp",
+	},
+	{
+		.dev_name = "nuc980-audio-i2s",
+		.name = "i2s-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "i2s",
+		.data.mux.group = "i2s_1_grp",
+	},
+	// {
+	// .dev_name = "nuc980-uart0",
+	// .name = PINCTRL_STATE_DEFAULT,
+	// .type = PIN_MAP_TYPE_MUX_GROUP,
+	// .ctrl_dev_name = "pinctrl-nuc980",
+	// .data.mux.function = "uart0",
+	// .data.mux.group = "uart0_grp",
+	// },
+	PIN_MAP_MUX_GROUP_HOG_DEFAULT("nuc980-uart.0", "uart0_grp", "uart0"),  // hog
+	{
+		.dev_name = "nuc980-uart.1",
+		.name = "uart1-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart1",
+		.data.mux.group = "uart1_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.1",
+		.name = "uart1-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart1",
+		.data.mux.group = "uart1_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.1",
+		.name = "uart1-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart1",
+		.data.mux.group = "uart1_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.1",
+		.name = "uart1-fc-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart1",
+		.data.mux.group = "uart1_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.1",
+		.name = "uart1-fc-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart1_fc",
+		.data.mux.group = "uart1_2_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.1",
+		.name = "uart1-fc-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart1",
+		.data.mux.group = "uart1_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.1",
+		.name = "uart1-fc-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart1_fc",
+		.data.mux.group = "uart1_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.2",
+		.name = "uart2-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart2",
+		.data.mux.group = "uart2_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.2",
+		.name = "uart2-PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart2",
+		.data.mux.group = "uart2_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.2",
+		.name = "uart2-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart2",
+		.data.mux.group = "uart2_5_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.2",
+		.name = "uart2-fc-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart2",
+		.data.mux.group = "uart2_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.2",
+		.name = "uart2-fc-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart2_fc",
+		.data.mux.group = "uart2_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.2",
+		.name = "uart2-fc-PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart2",
+		.data.mux.group = "uart2_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.2",
+		.name = "uart2-fc-PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart2_fc",
+		.data.mux.group = "uart2_2_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.2",
+		.name = "uart2-fc-PA_PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart2",
+		.data.mux.group = "uart2_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.2",
+		.name = "uart2-fc-PA_PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart2_fc",
+		.data.mux.group = "uart2_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3",
+		.data.mux.group = "uart3_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3",
+		.data.mux.group = "uart3_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3",
+		.data.mux.group = "uart3_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-PB_PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3",
+		.data.mux.group = "uart3_6_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3",
+		.data.mux.group = "uart3_7_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-fc-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3",
+		.data.mux.group = "uart3_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-fc-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3_fc",
+		.data.mux.group = "uart3_2_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-fc-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3",
+		.data.mux.group = "uart3_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-fc-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3_fc",
+		.data.mux.group = "uart3_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-fc-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3",
+		.data.mux.group = "uart3_7_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.3",
+		.name = "uart3-fc-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart3_fc",
+		.data.mux.group = "uart3_5_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.4",
+		.name = "uart4-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart4",
+		.data.mux.group = "uart4_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.4",
+		.name = "uart4-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart4",
+		.data.mux.group = "uart4_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.4",
+		.name = "uart4-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart4",
+		.data.mux.group = "uart4_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.4",
+		.name = "uart4-fc-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart4",
+		.data.mux.group = "uart4_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.4",
+		.name = "uart4-fc-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart4_fc",
+		.data.mux.group = "uart4_2_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.4",
+		.name = "uart4-fc-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart4",
+		.data.mux.group = "uart4_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.4",
+		.name = "uart4-fc-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart4_fc",
+		.data.mux.group = "uart4_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.5",
+		.name = "uart5-PG_0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart5",
+		.data.mux.group = "uart5_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.5",
+		.name = "uart5-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart5",
+		.data.mux.group = "uart5_2_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.5",
+		.name = "uart5-PG_1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart5",
+		.data.mux.group = "uart5_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.5",
+		.name = "uart5-fc-PG_0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart5",
+		.data.mux.group = "uart5_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.5",
+		.name = "uart5-fc-PG_0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart5_fc",
+		.data.mux.group = "uart5_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.5",
+		.name = "uart5-fc-PG_1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart5",
+		.data.mux.group = "uart5_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.5",
+		.name = "uart5-fc-PG_1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart5_fc",
+		.data.mux.group = "uart5_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.6",
+		.name = "uart6-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart6",
+		.data.mux.group = "uart6_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.6",
+		.name = "uart6-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart6",
+		.data.mux.group = "uart6_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.6",
+		.name = "uart6-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart6",
+		.data.mux.group = "uart6_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.6",
+		.name = "uart6-fc-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart6",
+		.data.mux.group = "uart6_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.6",
+		.name = "uart6-fc-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart6_fc",
+		.data.mux.group = "uart6_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.6",
+		.name = "uart6-fc-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart6",
+		.data.mux.group = "uart6_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.6",
+		.name = "uart6-fc-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart6_fc",
+		.data.mux.group = "uart6_2_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.7",
+		.name = "uart7-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart7",
+		.data.mux.group = "uart7_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.7",
+		.name = "uart7-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart7",
+		.data.mux.group = "uart7_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.7",
+		.name = "uart7-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart7",
+		.data.mux.group = "uart7_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.7",
+		.name = "uart7-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart7",
+		.data.mux.group = "uart7_5_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.7",
+		.name = "uart7-fc-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart7",
+		.data.mux.group = "uart7_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.7",
+		.name = "uart7-fc-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart7_fc",
+		.data.mux.group = "uart7_2_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.7",
+		.name = "uart7-fc-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart7",
+		.data.mux.group = "uart7_5_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.7",
+		.name = "uart7-fc-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart7_fc",
+		.data.mux.group = "uart7_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.8",
+		.name = "uart8-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart8",
+		.data.mux.group = "uart8_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.8",
+		.name = "uart8-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart8",
+		.data.mux.group = "uart8_2_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.8",
+		.name = "uart8-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart8",
+		.data.mux.group = "uart8_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.8",
+		.name = "uart8-fc-PA_PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart8",
+		.data.mux.group = "uart8_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.8",
+		.name = "uart8-fc-PA_PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart8_fc",
+		.data.mux.group = "uart8_1_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.8",
+		.name = "uart8-fc-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart8",
+		.data.mux.group = "uart8_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.8",
+		.name = "uart8-fc-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart8_fc",
+		.data.mux.group = "uart8_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.9",
+		.name = "uart9-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart9",
+		.data.mux.group = "uart9_0_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.9",
+		.name = "uart9-PE_0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart9",
+		.data.mux.group = "uart9_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.9",
+		.name = "uart9-PE_1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart9",
+		.data.mux.group = "uart9_4_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.9",
+		.name = "uart9-fc-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart9",
+		.data.mux.group = "uart9_3_grp",
+	},
+	{
+		.dev_name = "nuc980-uart.9",
+		.name = "uart9-fc-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "uart9_fc",
+		.data.mux.group = "uart9_2_grp",
+	},
+	{
+		.dev_name = "nuc980-sc.0",
+		.name = "sc0-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "sc0",
+		.data.mux.group = "sc0_0_grp",
+	},
+	{
+		.dev_name = "nuc980-sc.0",
+		.name = "sc0-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "sc0",
+		.data.mux.group = "sc0_1_grp",
+	},
+	{
+		.dev_name = "nuc980-sc.0",
+		.name = "scuart0-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "scuart0",
+		.data.mux.group = "sc0_2_grp",
+	},
+	{
+		.dev_name = "nuc980-sc.0",
+		.name = "scuart0-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "scuart0",
+		.data.mux.group = "sc0_3_grp",
+	},
+	{
+		.dev_name = "nuc980-sc.1",
+		.name = "sc1-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "sc1",
+		.data.mux.group = "sc1_0_grp",
+	},
+	{
+		.dev_name = "nuc980-sc.1",
+		.name = "sc1-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "sc1",
+		.data.mux.group = "sc1_1_grp",
+	},
+	{
+		.dev_name = "nuc980-sc.1",
+		.name = "scuart1-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "scuart1",
+		.data.mux.group = "sc1_2_grp",
+	},
+	{
+		.dev_name = "nuc980-sc.1",
+		.name = "scuart1-PF",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "scuart1",
+		.data.mux.group = "sc1_3_grp",
+	},
+	{
+		.dev_name = "nuc980-qspi0.0",
+		.name = "qspi0-normal",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "qspi0",
+		.data.mux.group = "qspi0_3_grp",
+	},
+	{
+		.dev_name = "nuc980-qspi0.0",
+		.name = "qspi0-quad",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "qspi0_quad",
+		.data.mux.group = "qspi0_2_grp",
+	},
+	{
+		.dev_name = "nuc980-qspi0.0",
+		.name = "qspi0-ss1-PA0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "qspi0_ss1",
+		.data.mux.group = "qspi0_0_grp",
+	},
+	{
+		.dev_name = "nuc980-qspi0.0",
+		.name = "qspi0-ss1-PD0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "qspi0_ss1",
+		.data.mux.group = "qspi0_1_grp",
+	},
+	{
+		.dev_name = "nuc980-qspi0.0",
+		.name = "qspi0-quad-ss1-PA0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "qspi0_quad_ss1",
+		.data.mux.group = "qspi0_4_grp",
+	},
+	{
+		.dev_name = "nuc980-qspi0.0",
+		.name = "qspi0-quad-ss1-PD0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "qspi0_quad_ss1",
+		.data.mux.group = "qspi0_5_grp",
+	},
+	{
+		.dev_name = "nuc980-spi0.0",
+		.name = "spi0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi0",
+		.data.mux.group = "spi0_0_grp",
+	},
+	{
+		.dev_name = "nuc980-spi0.0",
+		.name = "spi0-ss1-PD1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi0_ss1",
+		.data.mux.group = "spi0_1_grp",
+	},
+	{
+		.dev_name = "nuc980-spi0.0",
+		.name = "spi0-ss1-PG15",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi0_ss1",
+		.data.mux.group = "spi0_2_grp",
+	},
+	{
+		.dev_name = "nuc980-spi0.0",
+		.name = "spi0-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi0",
+		.data.mux.group = "spi0_3_grp",
+	},
+	{
+		.dev_name = "nuc980-spi0.0",
+		.name = "spi0-ss1-PC0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi0_ss1",
+		.data.mux.group = "spi0_4_grp",
+	},
+	{
+		.dev_name = "nuc980-spi1.0",
+		.name = "spi1-PB9_12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi1",
+		.data.mux.group = "spi1_0_grp",
+	},
+	{
+		.dev_name = "nuc980-spi1.0",
+		.name = "spi1-PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi1",
+		.data.mux.group = "spi1_1_grp",
+	},
+	{
+		.dev_name = "nuc980-spi1.0",
+		.name = "spi1-PG-ss1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi1_ss1",
+		.data.mux.group = "spi1_2_grp",
+	},
+	{
+		.dev_name = "nuc980-spi1.0",
+		.name = "spi1-PB4_7",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi1",
+		.data.mux.group = "spi1_3_grp",
+	},
+	{
+		.dev_name = "nuc980-spi1.0",
+		.name = "spi1-PB4_7-ss1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "spi1_ss1",
+		.data.mux.group = "spi1_4_grp",
+	},
+	{
+		.dev_name = "nuc980-can0",
+		.name = "can0-PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can0",
+		.data.mux.group = "can0_0_grp",
+	},
+	{
+		.dev_name = "nuc980-can0",
+		.name = "can0-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can0",
+		.data.mux.group = "can0_1_grp",
+	},
+	{
+		.dev_name = "nuc980-can0",
+		.name = "can0-PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can0",
+		.data.mux.group = "can0_2_grp",
+	},
+	{
+		.dev_name = "nuc980-can0",
+		.name = "can0-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can0",
+		.data.mux.group = "can0_3_grp",
+	},
+	{
+		.dev_name = "nuc980-can1",
+		.name = "can1-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can1",
+		.data.mux.group = "can1_0_grp",
+	},
+	{
+		.dev_name = "nuc980-can1",
+		.name = "can1-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can1",
+		.data.mux.group = "can1_1_grp",
+	},
+	{
+		.dev_name = "nuc980-can1",
+		.name = "can1-PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can1",
+		.data.mux.group = "can1_2_grp",
+	},
+	{
+		.dev_name = "nuc980-can1",
+		.name = "can1-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can1",
+		.data.mux.group = "can1_3_grp",
+	},
+	{
+		.dev_name = "nuc980-can2",
+		.name = "can2-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can2",
+		.data.mux.group = "can2_0_grp",
+	},
+	{
+		.dev_name = "nuc980-can2",
+		.name = "can2-PB",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can2",
+		.data.mux.group = "can2_1_grp",
+	},
+	{
+		.dev_name = "nuc980-can2",
+		.name = "can2-PB_PC",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can2",
+		.data.mux.group = "can2_2_grp",
+	},
+	{
+		.dev_name = "nuc980-can2",
+		.name = "can2-PD",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can2",
+		.data.mux.group = "can2_3_grp",
+	},
+	{
+		.dev_name = "nuc980-can2",
+		.name = "can2-PE",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can2",
+		.data.mux.group = "can2_4_grp",
+	},
+	{
+		.dev_name = "nuc980-can3",
+		.name = "can3-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can3",
+		.data.mux.group = "can3_0_grp",
+	},
+	{
+		.dev_name = "nuc980-can3",
+		.name = "can3-PE_0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can3",
+		.data.mux.group = "can3_1_grp",
+	},
+	{
+		.dev_name = "nuc980-can3",
+		.name = "can3-PE_1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "can3",
+		.data.mux.group = "can3_2_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.0",
+		.name = "pwm00-PG10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm00",
+		.data.mux.group = "pwm00_0_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.0",
+		.name = "pwm00-PG0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm00",
+		.data.mux.group = "pwm00_1_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.0",
+		.name = "pwm00-PD12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm00",
+		.data.mux.group = "pwm00_2_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.0",
+		.name = "pwm00-PF5",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm00",
+		.data.mux.group = "pwm00_3_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.1",
+		.name = "pwm01-PA15",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm01",
+		.data.mux.group = "pwm01_0_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.1",
+		.name = "pwm01-PG1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm01",
+		.data.mux.group = "pwm01_1_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.1",
+		.name = "pwm01-PD13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm01",
+		.data.mux.group = "pwm01_2_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.1",
+		.name = "pwm01-PF6",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm01",
+		.data.mux.group = "pwm01_3_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.2",
+		.name = "pwm02-PA14",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm02",
+		.data.mux.group = "pwm02_0_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.2",
+		.name = "pwm02-PG2",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm02",
+		.data.mux.group = "pwm02_1_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.2",
+		.name = "pwm02-PD14",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm02",
+		.data.mux.group = "pwm02_2_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.2",
+		.name = "pwm02-PF7",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm02",
+		.data.mux.group = "pwm02_3_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.2",
+		.name = "pwm02-PB13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm02",
+		.data.mux.group = "pwm02_4_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.3",
+		.name = "pwm03-PA13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm03",
+		.data.mux.group = "pwm03_0_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.3",
+		.name = "pwm03-PG3",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm03",
+		.data.mux.group = "pwm03_1_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.3",
+		.name = "pwm03-PD15",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm03",
+		.data.mux.group = "pwm03_2_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm0.3",
+		.name = "pwm03-PF8",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm03",
+		.data.mux.group = "pwm03_3_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.4",
+		.name = "pwm10-PG6",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm10",
+		.data.mux.group = "pwm10_0_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.4",
+		.name = "pwm10-PB12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm10",
+		.data.mux.group = "pwm10_1_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.4",
+		.name = "pwm10-PG11",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm10",
+		.data.mux.group = "pwm10_2_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.4",
+		.name = "pwm10-PF9",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm10",
+		.data.mux.group = "pwm10_3_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.5",
+		.name = "pwm11-PG7",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm11",
+		.data.mux.group = "pwm11_0_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.5",
+		.name = "pwm11-PB11",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm11",
+		.data.mux.group = "pwm11_1_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.5",
+		.name = "pwm11-PG12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm11",
+		.data.mux.group = "pwm11_2_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.5",
+		.name = "pwm11-PF10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm11",
+		.data.mux.group = "pwm11_3_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.6",
+		.name = "pwm12-PG8",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm12",
+		.data.mux.group = "pwm12_0_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.6",
+		.name = "pwm12-PB10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm12",
+		.data.mux.group = "pwm12_1_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.6",
+		.name = "pwm12-PG13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm12",
+		.data.mux.group = "pwm12_2_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.6",
+		.name = "pwm12-PE10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm12",
+		.data.mux.group = "pwm12_3_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.7",
+		.name = "pwm13-PG9",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm13",
+		.data.mux.group = "pwm13_0_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.7",
+		.name = "pwm13-PB9",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm13",
+		.data.mux.group = "pwm13_1_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.3",
+		.name = "pwm13-PG14",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm13",
+		.data.mux.group = "pwm13_2_grp",
+	},
+	{
+		.dev_name = "nuc980-pwm1.7",
+		.name = "pwm13-PE12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "pwm13",
+		.data.mux.group = "pwm13_3_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.0",
+		.name = "etimer0-ecnt-PA0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer0_ecnt",
+		.data.mux.group = "etimer0_0_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.0",
+		.name = "etimer0-tgl-PB3",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer0_tgl",
+		.data.mux.group = "etimer0_1_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.0",
+		.name = "etimer0-cap-PB1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer0_cap",
+		.data.mux.group = "etimer0_2_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.0",
+		.name = "etimer0-tgl-PC0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer0_tgl",
+		.data.mux.group = "etimer0_3_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.0",
+		.name = "etimer0-cap-PB8",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer0_cap",
+		.data.mux.group = "etimer0_4_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.0",
+		.name = "etimer0-tgl-PB9",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer0_tgl",
+		.data.mux.group = "etimer0_5_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.0",
+		.name = "etimer0-cap-PB10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer0_cap",
+		.data.mux.group = "etimer0_6_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.0",
+		.name = "etimer0-ecnt-PD6",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer0_ecnt",
+		.data.mux.group = "etimer0_7_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.0",
+		.name = "etimer0-ecnt-PF0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer0_ecnt",
+		.data.mux.group = "etimer0_8_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-ecnt-PA1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_ecnt",
+		.data.mux.group = "etimer1_0_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-tgl-PA14",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_tgl",
+		.data.mux.group = "etimer1_1_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-cap-PA13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_cap",
+		.data.mux.group = "etimer1_2_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-tgl-PD0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_tgl",
+		.data.mux.group = "etimer1_3_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-cap-PD1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_cap",
+		.data.mux.group = "etimer1_4_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-ecnt-PD7",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_ecnt",
+		.data.mux.group = "etimer1_5_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-tgl-PG11",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_tgl",
+		.data.mux.group = "etimer1_6_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-cap-PG12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_cap",
+		.data.mux.group = "etimer1_7_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-ecnt-PF1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_ecnt",
+		.data.mux.group = "etimer1_8_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-tgl-PF8",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_tgl",
+		.data.mux.group = "etimer1_9_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.1",
+		.name = "etimer1-cap-PF9",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer1_cap",
+		.data.mux.group = "etimer1_A_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.2",
+		.name = "etimer2-ecnt-PA2",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer2_ecnt",
+		.data.mux.group = "etimer2_0_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.2",
+		.name = "etimer2-tgl-PA10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer2_tgl",
+		.data.mux.group = "etimer2_1_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.2",
+		.name = "etimer2-cap-PA9",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer2_cap",
+		.data.mux.group = "etimer2_2_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.2",
+		.name = "etimer2-tgl-PB12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer2_tgl",
+		.data.mux.group = "etimer2_3_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.2",
+		.name = "etimer2-cap-PB11",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer2_cap",
+		.data.mux.group = "etimer2_4_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.2",
+		.name = "etimer2-ecnt-PD8",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer2_ecnt",
+		.data.mux.group = "etimer2_5_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.2",
+		.name = "etimer2-tgl-PD12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer2_tgl",
+		.data.mux.group = "etimer2_6_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.2",
+		.name = "etimer2-cap-PD13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer2_cap",
+		.data.mux.group = "etimer2_7_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.2",
+		.name = "etimer2-ecnt-PF2",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer2_ecnt",
+		.data.mux.group = "etimer2_8_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.3",
+		.name = "etimer3-ecnt-PA3",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer3_ecnt",
+		.data.mux.group = "etimer3_0_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.3",
+		.name = "etimer3-tgl-PA8",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer3_tgl",
+		.data.mux.group = "etimer3_1_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.3",
+		.name = "etimer3-cap-PA7",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer3_cap",
+		.data.mux.group = "etimer3_2_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.3",
+		.name = "etimer3-ecnt-PD9",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer3_ecnt",
+		.data.mux.group = "etimer3_3_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.3",
+		.name = "etimer3-tgl-PD14",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer3_tgl",
+		.data.mux.group = "etimer3_4_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.3",
+		.name = "etimer3-cap-PD15",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer3_cap",
+		.data.mux.group = "etimer3_5_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.3",
+		.name = "etimer3-ecnt-PF3",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer3_ecnt",
+		.data.mux.group = "etimer3_6_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.4",
+		.name = "etimer4-ecnt-PA4",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer4_ecnt",
+		.data.mux.group = "etimer4_0_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.4",
+		.name = "etimer4-tgl-PA12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer4_tgl",
+		.data.mux.group = "etimer4_1_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.4",
+		.name = "etimer4-cap-PA11",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer4_cap",
+		.data.mux.group = "etimer4_2_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.4",
+		.name = "etimer4-tgl-PD3",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer4_tgl",
+		.data.mux.group = "etimer4_3_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.4",
+		.name = "etimer4-cap-PD2",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer4_cap",
+		.data.mux.group = "etimer4_4_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.4",
+		.name = "etimer4-ecnt-PD10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer4_ecnt",
+		.data.mux.group = "etimer4_5_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.4",
+		.name = "etimer4-ecnt-PF4",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer4_ecnt",
+		.data.mux.group = "etimer4_6_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.4",
+		.name = "etimer4-tgl-PB13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer4_tgl",
+		.data.mux.group = "etimer4_7_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.4",
+		.name = "etimer4-cap-PF6",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer4_cap",
+		.data.mux.group = "etimer4_8_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.5",
+		.name = "etimer5-ecnt-PA5",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer5_ecnt",
+		.data.mux.group = "etimer5_0_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.5",
+		.name = "etimer5-tgl-PG10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer5_tgl",
+		.data.mux.group = "etimer5_1_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.5",
+		.name = "etimer5-cap-PA15",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer5_cap",
+		.data.mux.group = "etimer5_2_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.5",
+		.name = "etimer5-tgl-PD5",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer5_tgl",
+		.data.mux.group = "etimer5_3_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.5",
+		.name = "etimer5-cap-PD4",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer5_cap",
+		.data.mux.group = "etimer5_4_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.5",
+		.name = "etimer5-ecnt-PD11",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer5_ecnt",
+		.data.mux.group = "etimer5_5_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.5",
+		.name = "etimer5-ecnt-PF5",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer5_ecnt",
+		.data.mux.group = "etimer5_6_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.5",
+		.name = "etimer5-tgl-PF10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer5_tgl",
+		.data.mux.group = "etimer5_7_grp",
+	},
+	{
+		.dev_name = "nuc980-timer.5",
+		.name = "etimer5-cap-PF7",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "etimer5_cap",
+		.data.mux.group = "etimer5_8_grp",
+	},
+	{
+		.dev_name = "nuc980-jtag",
+		.name = "jtag0-PG",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "jtag0",
+		.data.mux.group = "jtag0_grp",
+	},
+	{
+		.dev_name = "nuc980-jtag",
+		.name = "jtag1-PA",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "jtag1",
+		.data.mux.group = "jtag1_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.1",
+		.name = "eint0-PA0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint0",
+		.data.mux.group = "eint0_0_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.1",
+		.name = "eint0-PA13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint0",
+		.data.mux.group = "eint0_1_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.2",
+		.name = "eint1-PA1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint1",
+		.data.mux.group = "eint1_0_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.2",
+		.name = "eint1-PA14",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint1",
+		.data.mux.group = "eint1_1_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.3",
+		.name = "eint2-PD0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint2",
+		.data.mux.group = "eint2_0_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.3",
+		.name = "eint2-PE10",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint2",
+		.data.mux.group = "eint2_1_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.3",
+		.name = "eint2-PB3",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint2",
+		.data.mux.group = "eint2_2_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.3",
+		.name = "eint2-PB13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint2",
+		.data.mux.group = "eint2_3_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.4",
+		.name = "eint3-PD1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint3",
+		.data.mux.group = "eint3_0_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.4",
+		.name = "eint3-PE12",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint3",
+		.data.mux.group = "eint3_1_grp",
+	},
+	{
+		.dev_name = "nuc980-gpio.4",
+		.name = "eint3-PG15",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "eint3",
+		.data.mux.group = "eint3_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-8bit-0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_8_0",
+		.data.mux.group = "ebi8_0_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-8bit-1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_8_1",
+		.data.mux.group = "ebi8_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-8bit-2",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_8_2",
+		.data.mux.group = "ebi8_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-8bit-3",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_8_3",
+		.data.mux.group = "ebi8_3_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-8bit-4",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_8_4",
+		.data.mux.group = "ebi8_4_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-8bit-5",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_8_5",
+		.data.mux.group = "ebi8_5_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-16bit-0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_16_0",
+		.data.mux.group = "ebi16_0_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-16bit-1",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_16_1",
+		.data.mux.group = "ebi16_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-16bit-2",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_16_2",
+		.data.mux.group = "ebi16_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-16bit-3",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_16_3",
+		.data.mux.group = "ebi16_3_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-16bit-4",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_16_4",
+		.data.mux.group = "ebi16_4_grp",
+	},
+	{
+		.dev_name = "nuc980-ebi",
+		.name = "ebi-16bit-5",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "ebi_16_5",
+		.data.mux.group = "ebi16_5_grp",
+	},
+	{
+		.dev_name = "nuc980-ehci",
+		.name = "usbh_pwren_ovc_on",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_pwren_ovc",
+		.data.mux.group = "usbh_power_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ehci",
+		.name = "usbh_pwren_on",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_pwren_ovc",
+		.data.mux.group = "usbh_power_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ehci",
+		.name = "usbh_ovc_on",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_pwren_ovc",
+		.data.mux.group = "usbh_power_3_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.0",
+		.name = "usbh_pwren_ovc_on",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_pwren_ovc",
+		.data.mux.group = "usbh_power_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.0",
+		.name = "usbh_pwren_on",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_pwren_ovc",
+		.data.mux.group = "usbh_power_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.0",
+		.name = "usbh_ovc_on",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_pwren_ovc",
+		.data.mux.group = "usbh_power_3_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.1",
+		.name = "usbh_lite0_pb4_pb6",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite0_dp_dm",
+		.data.mux.group = "usbh_lite0_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.1",
+		.name = "usbh_lite0_pb5_pb7",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite0_dp_dm",
+		.data.mux.group = "usbh_lite0_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.1",
+		.name = "usbh_lite0_pb10_pb9",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite0_dp_dm",
+		.data.mux.group = "usbh_lite0_3_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.1",
+		.name = "usbh_lite0_pd15_pd14",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite0_dp_dm",
+		.data.mux.group = "usbh_lite0_4_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.2",
+		.name = "usbh_lite1_pe1_pe0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite1_dp_dm",
+		.data.mux.group = "usbh_lite1_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.2",
+		.name = "usbh_lite1_pf1_pf0",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite1_dp_dm",
+		.data.mux.group = "usbh_lite1_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.3",
+		.name = "usbh_lite2_pe3_pe2",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite2_dp_dm",
+		.data.mux.group = "usbh_lite2_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.3",
+		.name = "usbh_lite2_pf3_pf2",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite2_dp_dm",
+		.data.mux.group = "usbh_lite2_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.4",
+		.name = "usbh_lite3_pe5_pe4",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite3_dp_dm",
+		.data.mux.group = "usbh_lite3_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.4",
+		.name = "usbh_lite3_pf5_pf4",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite3_dp_dm",
+		.data.mux.group = "usbh_lite3_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.5",
+		.name = "usbh_lite4_pe7_pe6",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite4_dp_dm",
+		.data.mux.group = "usbh_lite4_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.5",
+		.name = "usbh_lite4_pf7_pf6",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite4_dp_dm",
+		.data.mux.group = "usbh_lite4_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.5",
+		.name = "usbh_lite4_pg10_pa15",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite4_dp_dm",
+		.data.mux.group = "usbh_lite4_3_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.5",
+		.name = "usbh_lite4_pb13_pf6",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite4_dp_dm",
+		.data.mux.group = "usbh_lite4_4_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.6",
+		.name = "usbh_lite5_pe9_pe8",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite5_dp_dm",
+		.data.mux.group = "usbh_lite5_1_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.6",
+		.name = "usbh_lite5_pf9_pf8",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite5_dp_dm",
+		.data.mux.group = "usbh_lite5_2_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.6",
+		.name = "usbh_lite5_pa14_pa13",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite5_dp_dm",
+		.data.mux.group = "usbh_lite5_3_grp",
+	},
+	{
+		.dev_name = "nuc980-ohci.6",
+		.name = "usbh_lite5_pb12_pb11",
+		.type = PIN_MAP_TYPE_MUX_GROUP,
+		.ctrl_dev_name = "pinctrl-nuc980",
+		.data.mux.function = "usbh_lite5_dp_dm",
+		.data.mux.group = "usbh_lite5_4_grp",
+	},
+};
+
+
+static int nuc980_pinctrl_probe(struct platform_device *pdev)
+{
+	struct pinctrl_dev *pctl;
+
+	pctl = pinctrl_register(&nuc980_pinctrl_desc, &pdev->dev, NULL);
+	if (IS_ERR(pctl)) {
+		pr_err("could not register nuc980 pin driver\n");
+	}
+
+	platform_set_drvdata(pdev, pctl);
+
+	return pinctrl_register_mappings(nuc980_pinmap, ARRAY_SIZE(nuc980_pinmap));
+
+}
+
+static int nuc980_pinctrl_remove(struct platform_device *pdev)
+{
+	struct pinctrl_dev *pctl = platform_get_drvdata(pdev);
+
+	pinctrl_unregister(pctl);
+
+	return 0;
+}
+
+
+static struct platform_driver nuc980_pinctrl_driver = {
+	.driver = {
+		.name = "pinctrl-nuc980",
+		.owner = THIS_MODULE,
+	},
+	.probe = nuc980_pinctrl_probe,
+	.remove = nuc980_pinctrl_remove,
+};
+
+
+static int __init nuc980_pinctrl_init(void)
+{
+	return platform_driver_register(&nuc980_pinctrl_driver);
+}
+arch_initcall(nuc980_pinctrl_init);
+
+static void __exit nuc980_pinctrl_exit(void)
+{
+	platform_driver_unregister(&nuc980_pinctrl_driver);
+}
+
+module_exit(nuc980_pinctrl_exit);
+
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/pinctrl/pinctrl-nuc980-dt.c NUC980-linux-4.4.194/drivers/pinctrl/pinctrl-nuc980-dt.c
--- linux-4.4.194/drivers/pinctrl/pinctrl-nuc980-dt.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/pinctrl/pinctrl-nuc980-dt.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,682 @@
+/*
+ * Copyright (c) 2017 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/clk.h>
+#include <linux/err.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/irqdomain.h>
+#include <linux/irqchip/chained_irq.h>
+#include <linux/io.h>
+#include <linux/gpio.h>
+#include <linux/pinctrl/machine.h>
+#include <linux/pinctrl/pinconf.h>
+#include <linux/pinctrl/pinctrl.h>
+#include <linux/pinctrl/pinmux.h>
+#include <linux/pinctrl/consumer.h>
+
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+#include "core.h"
+
+#define DEBUG
+
+#define MAX_NB_GPIO_PER_BANK        16
+
+// The numbering is not related to actual layout.
+const struct pinctrl_pin_desc nuc980_pins[] = {
+	PINCTRL_PIN(0x00, "PA0"),
+	PINCTRL_PIN(0x01, "PA1"),
+	PINCTRL_PIN(0x02, "PA2"),
+	PINCTRL_PIN(0x03, "PA3"),
+	PINCTRL_PIN(0x04, "PA4"),
+	PINCTRL_PIN(0x05, "PA5"),
+	PINCTRL_PIN(0x06, "PA6"),
+	PINCTRL_PIN(0x07, "PA7"),
+	PINCTRL_PIN(0x08, "PA8"),
+	PINCTRL_PIN(0x09, "PA9"),
+	PINCTRL_PIN(0x0A, "PA10"),
+	PINCTRL_PIN(0x0B, "PA11"),
+	PINCTRL_PIN(0x0C, "PA12"),
+	PINCTRL_PIN(0x0D, "PA13"),
+	PINCTRL_PIN(0x0E, "PA14"),
+	PINCTRL_PIN(0x0F, "PA15"),
+	PINCTRL_PIN(0x10, "PB0"),
+	PINCTRL_PIN(0x11, "PB1"),
+	PINCTRL_PIN(0x12, "PB2"),
+	PINCTRL_PIN(0x13, "PB3"),
+	PINCTRL_PIN(0x14, "PB4"),
+	PINCTRL_PIN(0x15, "PB5"),
+	PINCTRL_PIN(0x16, "PB6"),
+	PINCTRL_PIN(0x17, "PB7"),
+	PINCTRL_PIN(0x18, "PB8"),
+	PINCTRL_PIN(0x19, "PB9"),
+	PINCTRL_PIN(0x1A, "PB10"),
+	PINCTRL_PIN(0x1B, "PB11"),
+	PINCTRL_PIN(0x1C, "PB12"),
+	PINCTRL_PIN(0x1D, "PB13"),
+	PINCTRL_PIN(0x1E, "PB14"),
+	PINCTRL_PIN(0x1F, "PB15"),
+	PINCTRL_PIN(0x20, "PC0"),
+	PINCTRL_PIN(0x21, "PC1"),
+	PINCTRL_PIN(0x22, "PC2"),
+	PINCTRL_PIN(0x23, "PC3"),
+	PINCTRL_PIN(0x24, "PC4"),
+	PINCTRL_PIN(0x25, "PC5"),
+	PINCTRL_PIN(0x26, "PC6"),
+	PINCTRL_PIN(0x27, "PC7"),
+	PINCTRL_PIN(0x28, "PC8"),
+	PINCTRL_PIN(0x29, "PC9"),
+	PINCTRL_PIN(0x2A, "PC10"),
+	PINCTRL_PIN(0x2B, "PC11"),
+	PINCTRL_PIN(0x2C, "PC12"),
+	PINCTRL_PIN(0x2D, "PC13"),
+	PINCTRL_PIN(0x2E, "PC14"),
+	PINCTRL_PIN(0x2F, "PC15"),
+	PINCTRL_PIN(0x30, "PD0"),
+	PINCTRL_PIN(0x31, "PD1"),
+	PINCTRL_PIN(0x32, "PD2"),
+	PINCTRL_PIN(0x33, "PD3"),
+	PINCTRL_PIN(0x34, "PD4"),
+	PINCTRL_PIN(0x35, "PD5"),
+	PINCTRL_PIN(0x36, "PD6"),
+	PINCTRL_PIN(0x37, "PD7"),
+	PINCTRL_PIN(0x38, "PD8"),
+	PINCTRL_PIN(0x39, "PD9"),
+	PINCTRL_PIN(0x3A, "PD10"),
+	PINCTRL_PIN(0x3B, "PD11"),
+	PINCTRL_PIN(0x3C, "PD12"),
+	PINCTRL_PIN(0x3D, "PD13"),
+	PINCTRL_PIN(0x3E, "PD14"),
+	PINCTRL_PIN(0x3F, "PD15"),
+	PINCTRL_PIN(0x40, "PE0"),
+	PINCTRL_PIN(0x41, "PE1"),
+	PINCTRL_PIN(0x42, "PE2"),
+	PINCTRL_PIN(0x43, "PE3"),
+	PINCTRL_PIN(0x44, "PE4"),
+	PINCTRL_PIN(0x45, "PE5"),
+	PINCTRL_PIN(0x46, "PE6"),
+	PINCTRL_PIN(0x47, "PE7"),
+	PINCTRL_PIN(0x48, "PE8"),
+	PINCTRL_PIN(0x49, "PE9"),
+	PINCTRL_PIN(0x4A, "PE10"),
+	PINCTRL_PIN(0x4B, "PE11"),
+	PINCTRL_PIN(0x4C, "PE12"),
+	PINCTRL_PIN(0x4D, "PE13"),
+	PINCTRL_PIN(0x4E, "PE14"),
+	PINCTRL_PIN(0x4F, "PE15"),
+	PINCTRL_PIN(0x50, "PF0"),
+	PINCTRL_PIN(0x51, "PF1"),
+	PINCTRL_PIN(0x52, "PF2"),
+	PINCTRL_PIN(0x53, "PF3"),
+	PINCTRL_PIN(0x54, "PF4"),
+	PINCTRL_PIN(0x55, "PF5"),
+	PINCTRL_PIN(0x56, "PF6"),
+	PINCTRL_PIN(0x57, "PF7"),
+	PINCTRL_PIN(0x58, "PF8"),
+	PINCTRL_PIN(0x59, "PF9"),
+	PINCTRL_PIN(0x5A, "PF10"),
+	PINCTRL_PIN(0x5B, "PF11"),
+	PINCTRL_PIN(0x5C, "PF12"),
+	PINCTRL_PIN(0x5D, "PF13"),
+	PINCTRL_PIN(0x5E, "PF14"),
+	PINCTRL_PIN(0x5F, "PF15"),
+	PINCTRL_PIN(0x60, "PG0"),
+	PINCTRL_PIN(0x61, "PG1"),
+	PINCTRL_PIN(0x62, "PG2"),
+	PINCTRL_PIN(0x63, "PG3"),
+	PINCTRL_PIN(0x64, "PG4"),
+	PINCTRL_PIN(0x65, "PG5"),
+	PINCTRL_PIN(0x66, "PG6"),
+	PINCTRL_PIN(0x67, "PG7"),
+	PINCTRL_PIN(0x68, "PG8"),
+	PINCTRL_PIN(0x69, "PG9"),
+	PINCTRL_PIN(0x6A, "PG10"),
+	PINCTRL_PIN(0x6B, "PG11"),
+	PINCTRL_PIN(0x6C, "PG12"),
+	PINCTRL_PIN(0x6D, "PG13"),
+	PINCTRL_PIN(0x6E, "PG14"),
+	PINCTRL_PIN(0x6F, "PG15"),
+};
+
+/**
+ * struct nuc980_pmx_pin - describes an NUC980 pin multi-function
+ * @bank: the bank of the pin (0 for PA, 1 for PB...)
+ * @pin: pin number (0 ~ 0xf)
+ * @func: multi-function pin setting value
+ * @conf: reserved for GPIO mode
+ */
+struct nuc980_pmx_pin {
+	uint32_t    bank;
+	uint32_t    pin;
+	uint32_t    func;
+	unsigned long  conf;
+};
+
+/**
+ * struct nuc980_pmx_func - describes NUC980 pinmux functions
+ * @name: the name of this specific function
+ * @groups: corresponding pin groups
+ * @ngroups: the number of groups
+ */
+struct nuc980_pmx_func {
+	const char  *name;
+	const char  **groups;
+	unsigned    ngroups;
+};
+
+
+/**
+ * struct nuc980_pin_group - describes an NUC980 pin group
+ * @name: the name of this specific pin group
+ * @pins_conf: the mux mode for each pin in this group. The size of this
+ *  array is the same as pins.
+ * @pins: an array of discrete physical pins used in this group, taken
+ *  from the driver-local pin enumeration space
+ * @npins: the number of pins in this group array, i.e. the number of
+ *  elements in .pins so we can iterate over that array
+ */
+struct nuc980_pin_group {
+	const char      *name;
+	struct nuc980_pmx_pin   *pins_conf;
+	unsigned int    *pins;
+	unsigned        npins;
+};
+
+struct nuc980_pinctrl {
+	struct device       *dev;
+	struct pinctrl_dev  *pctl;
+	int         nbanks;
+
+	struct nuc980_pmx_func  *functions;
+	int         nfunctions;
+
+	struct nuc980_pin_group *groups;
+	int         ngroups;
+};
+
+static const inline struct nuc980_pin_group *nuc980_pinctrl_find_group_by_name(
+    const struct nuc980_pinctrl *info,
+    const char *name)
+{
+	const struct nuc980_pin_group *grp = NULL;
+	int i;
+
+	for (i = 0; i < info->ngroups; i++) {
+		if (strcmp(info->groups[i].name, name)) {
+			continue;
+		}
+
+		grp = &info->groups[i];
+		dev_dbg(info->dev, "%s: %d 0:%d\n", name, grp->npins, grp->pins[0]);
+		break;
+	}
+
+	return grp;
+}
+
+static int nuc980_get_groups_count(struct pinctrl_dev *pctldev)
+{
+	struct nuc980_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	return info->ngroups;
+}
+
+static const char *nuc980_get_group_name(struct pinctrl_dev *pctldev,
+        unsigned selector)
+{
+	struct nuc980_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	return info->groups[selector].name;
+}
+
+static int nuc980_get_group_pins(struct pinctrl_dev *pctldev, unsigned selector,
+                                 const unsigned **pins,
+                                 unsigned *npins)
+{
+	struct nuc980_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	if (selector >= info->ngroups) {
+		return -EINVAL;
+	}
+
+	*pins = info->groups[selector].pins;
+	*npins = info->groups[selector].npins;
+
+	return 0;
+}
+
+static int nuc980_dt_node_to_map(struct pinctrl_dev *pctldev,
+                                 struct device_node *np,
+                                 struct pinctrl_map **map, unsigned *num_maps)
+{
+	struct nuc980_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+	const struct nuc980_pin_group *grp;
+	struct pinctrl_map *new_map;
+	struct device_node *parent;
+	int map_num = 1;
+	int i;
+
+	/*
+	 * first find the group of this node and check if we need create
+	 * config maps for pins
+	 */
+	grp = nuc980_pinctrl_find_group_by_name(info, np->name);
+	if (!grp) {
+		dev_err(info->dev, "unable to find group for node %s\n",
+		        np->name);
+		return -EINVAL;
+	}
+
+	map_num += grp->npins;
+	new_map = devm_kzalloc(pctldev->dev, sizeof(*new_map) * map_num, GFP_KERNEL);
+	if (!new_map) {
+		return -ENOMEM;
+	}
+
+	*map = new_map;
+	*num_maps = map_num;
+
+	/* create mux map */
+	parent = of_get_parent(np);
+	if (!parent) {
+		devm_kfree(pctldev->dev, new_map);
+		return -EINVAL;
+	}
+	new_map[0].type = PIN_MAP_TYPE_MUX_GROUP;
+	new_map[0].data.mux.function = parent->name;
+	new_map[0].data.mux.group = np->name;
+	of_node_put(parent);
+
+	/* create config map */
+	new_map++;
+	for (i = 0; i < grp->npins; i++) {
+		new_map[i].type = PIN_MAP_TYPE_CONFIGS_PIN;
+		new_map[i].data.configs.group_or_pin = pin_get_name(pctldev, grp->pins[i]);
+		new_map[i].data.configs.configs = &grp->pins_conf[i].conf;
+		new_map[i].data.configs.num_configs = 1;
+	}
+
+	dev_dbg(pctldev->dev, "maps: function %s group %s num %d\n",
+	        (*map)->data.mux.function, (*map)->data.mux.group, map_num);
+
+	return 0;
+}
+
+static void nuc980_dt_free_map(struct pinctrl_dev *pctldev,
+                               struct pinctrl_map *map, unsigned num_maps)
+{
+}
+
+static const struct pinctrl_ops nuc980_pctrl_ops = {
+	.get_groups_count   = nuc980_get_groups_count,
+	.get_group_name     = nuc980_get_group_name,
+	.get_group_pins     = nuc980_get_group_pins,
+	.dt_node_to_map     = nuc980_dt_node_to_map,
+	.dt_free_map        = nuc980_dt_free_map,
+};
+
+static void nuc980_pin_dbg(const struct device *dev, const struct nuc980_pmx_pin *pin)
+{
+	dev_dbg(dev, "P%c.%d: func=%d\n", pin->bank+'A', pin->pin, pin->func);
+}
+
+static int pin_check_config(struct nuc980_pinctrl *info, const char *name,
+                            int index, const struct nuc980_pmx_pin *pin)
+{
+	/* check if it's a valid config */
+	if (pin->bank >= info->nbanks) {
+		dev_err(info->dev, "%s: pin conf %d bank_id %d >= nbanks %d\n",
+		        name, index, pin->bank, info->nbanks);
+		return -EINVAL;
+	}
+
+	if (pin->pin >= MAX_NB_GPIO_PER_BANK) {
+		dev_err(info->dev, "%s: pin conf %d pin_bank_id %d >= %d\n",
+		        name, index, pin->pin, MAX_NB_GPIO_PER_BANK);
+		return -EINVAL;
+	}
+
+	if (pin->func > 0xf) {
+		dev_err(info->dev, "%s: invalid pin function setting %d!\n", name, pin->func);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+
+static int nuc980_pmx_get_funcs_count(struct pinctrl_dev *pctldev)
+{
+	struct nuc980_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	return info->nfunctions;
+}
+
+static const char *nuc980_pmx_get_func_name(struct pinctrl_dev *pctldev,
+        unsigned selector)
+{
+	struct nuc980_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	return info->functions[selector].name;
+}
+
+static int nuc980_pmx_get_groups(struct pinctrl_dev *pctldev, unsigned selector,
+                                 const char * const **groups,
+                                 unsigned * const num_groups)
+{
+	struct nuc980_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	*groups = info->functions[selector].groups;
+	*num_groups = info->functions[selector].ngroups;
+
+	return 0;
+}
+
+/*
+ * selector = data.nux.func, which is entry number in nuc980_functions,
+ * and group = data.mux.group, which is entry number in nuc980_pmx_func
+ * group is not used since some function use different setting between
+ * different ports. for example UART....
+ */
+int nuc980_pmx_set_mux(struct pinctrl_dev *pctldev, unsigned selector,
+                  unsigned group)
+{
+	struct nuc980_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+	const struct nuc980_pmx_pin *pins_conf = info->groups[group].pins_conf;
+	const struct nuc980_pmx_pin *pin;
+	uint32_t npins = info->groups[group].npins;
+	unsigned int i, ret;
+	unsigned int reg, offset;
+
+	/* first check that all the pins of the group are valid with a valid
+	 * paramter */
+	for (i = 0; i < npins; i++) {
+		pin = &pins_conf[i];
+		ret = pin_check_config(info, info->groups[group].name, i, pin);
+		if (ret) {
+			return ret;
+		}
+	}
+
+	for (i = 0; i < npins; i++) {
+		pin = &pins_conf[i];
+		offset = (pin->bank * 8) + ((pin->pin > 7) ? 4 : 0);
+		reg = __raw_readl(REG_MFP_GPA_L + offset);
+
+		reg = (reg & ~(0xF << ((pin->pin & 0x7) * 4))) | (pin->func << ((pin->pin & 0x7) * 4));
+
+		__raw_writel(reg, REG_MFP_GPA_L + offset);
+	}
+	return 0;
+}
+
+static const struct pinmux_ops nuc980_pmx_ops = {
+	.get_functions_count  = nuc980_pmx_get_funcs_count,
+	.get_function_name    = nuc980_pmx_get_func_name,
+	.get_function_groups  = nuc980_pmx_get_groups,
+	.set_mux = nuc980_pmx_set_mux,
+};
+
+static int nuc980_pinconf_get(struct pinctrl_dev *pctldev,
+                              unsigned pin_id, unsigned long *config)
+{
+	return 0;
+}
+
+static int nuc980_pinconf_set(struct pinctrl_dev *pctldev,
+                              unsigned pin_id, unsigned long *configs, unsigned num_configs)
+{
+	return 0;
+}
+
+static const struct pinconf_ops nuc980_pinconf_ops = {
+	.pin_config_get         = nuc980_pinconf_get,
+	.pin_config_set         = nuc980_pinconf_set,
+};
+
+static struct pinctrl_desc nuc980_pinctrl_desc = {
+	.pins     = nuc980_pins,
+	.npins    = ARRAY_SIZE(nuc980_pins),
+	.pctlops  = &nuc980_pctrl_ops,
+	.pmxops   = &nuc980_pmx_ops,
+	.confops  = &nuc980_pinconf_ops,
+	.owner    = THIS_MODULE,
+};
+
+
+static void nuc980_pinctrl_child_count(struct nuc980_pinctrl *info,
+                                       struct device_node *np)
+{
+	struct device_node *child;
+
+	for_each_child_of_node(np, child) {
+		info->nfunctions++;
+		info->ngroups += of_get_child_count(child);
+	}
+}
+
+static int nuc980_pinctrl_parse_groups(struct device_node *np,
+                                       struct nuc980_pin_group *grp,
+                                       struct nuc980_pinctrl *info, u32 index)
+{
+	struct nuc980_pmx_pin *pin;
+	int size;
+	const __be32 *list;
+	int i, j;
+
+	dev_dbg(info->dev, "group(%d): %s\n", index, np->name);
+
+	/* Initialise group */
+	grp->name = np->name;
+
+	/*
+	 * the binding format is nuvoton,pins = <bank pin pin-function>,
+	 * do sanity check and calculate pins number
+	 */
+	list = of_get_property(np, "nuvoton,pins", &size);
+	/* we do not check return since it's safe node passed down */
+	size /= sizeof(*list);
+	if (!size || size % 4) {
+		dev_err(info->dev, "wrong setting!\n");
+		return -EINVAL;
+	}
+
+	grp->npins = size / 4;
+	pin = grp->pins_conf = devm_kzalloc(info->dev, grp->npins * sizeof(struct nuc980_pmx_pin), GFP_KERNEL);
+	grp->pins = devm_kzalloc(info->dev, grp->npins * sizeof(unsigned int), GFP_KERNEL);
+	if (!grp->pins_conf || !grp->pins) {
+		return -ENOMEM;
+	}
+
+	for (i = 0, j = 0; i < size; i += 4, j++) {
+		pin->bank = be32_to_cpu(*list++);
+		pin->pin = be32_to_cpu(*list++);
+		grp->pins[j] = pin->bank * MAX_NB_GPIO_PER_BANK + pin->pin;
+		pin->func = be32_to_cpu(*list++);
+		pin->conf = be32_to_cpu(*list++);
+
+		nuc980_pin_dbg(info->dev, pin);
+		pin++;
+	}
+
+	return 0;
+}
+
+static int nuc980_pinctrl_parse_functions(struct device_node *np,
+        struct nuc980_pinctrl *info, u32 index)
+{
+	struct device_node *child;
+	struct nuc980_pmx_func *func;
+	struct nuc980_pin_group *grp;
+	int ret;
+	static u32 grp_index;
+	u32 i = 0;
+
+	dev_dbg(info->dev, "parse function(%d): %s\n", index, np->name);
+
+	func = &info->functions[index];
+
+	/* Initialise function */
+	func->name = np->name;
+	func->ngroups = of_get_child_count(np);
+	if (func->ngroups <= 0) {
+		dev_err(info->dev, "no groups defined\n");
+		return -EINVAL;
+	}
+	func->groups = devm_kzalloc(info->dev,
+	                            func->ngroups * sizeof(char *), GFP_KERNEL);
+	if (!func->groups) {
+		return -ENOMEM;
+	}
+
+	for_each_child_of_node(np, child) {
+		func->groups[i] = child->name;
+		grp = &info->groups[grp_index++];
+		ret = nuc980_pinctrl_parse_groups(child, grp, info, i++);
+		if (ret) {
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static struct of_device_id nuc980_pinctrl_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-pinctrl", NULL },
+	{ /* sentinel */ }
+};
+
+static int nuc980_pinctrl_probe_dt(struct platform_device *pdev,
+                                   struct nuc980_pinctrl *info)
+{
+	int ret = 0;
+	int i;
+	struct device_node *np = pdev->dev.of_node;
+	struct device_node *child;
+
+	if (!np) {
+		return -ENODEV;
+	}
+
+	info->dev = &pdev->dev;
+	info->nbanks = 7;  /* PA ~ PG */
+	nuc980_pinctrl_child_count(info, np);
+
+	info->functions = devm_kzalloc(&pdev->dev, info->nfunctions * sizeof(struct nuc980_pmx_func),
+	                               GFP_KERNEL);
+	if (!info->functions) {
+		return -ENOMEM;
+	}
+
+	info->groups = devm_kzalloc(&pdev->dev, info->ngroups * sizeof(struct nuc980_pin_group),
+	                            GFP_KERNEL);
+	if (!info->groups) {
+		return -ENOMEM;
+	}
+
+	dev_dbg(&pdev->dev, "nfunctions = %d\n", info->nfunctions);
+	dev_dbg(&pdev->dev, "ngroups = %d\n", info->ngroups);
+
+	i = 0;
+
+	for_each_child_of_node(np, child) {
+		ret = nuc980_pinctrl_parse_functions(child, info, i++);
+		if (ret) {
+			dev_err(&pdev->dev, "failed to parse function\n");
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int nuc980_pinctrl_probe(struct platform_device *pdev)
+{
+	struct nuc980_pinctrl *info;
+	int ret;
+
+	info = devm_kzalloc(&pdev->dev, sizeof(*info), GFP_KERNEL);
+	if (!info) {
+		return -ENOMEM;
+	}
+
+	ret = nuc980_pinctrl_probe_dt(pdev, info);
+	if (ret) {
+		return ret;
+	}
+
+	nuc980_pinctrl_desc.name = dev_name(&pdev->dev);
+
+//  for (i = 0 , k = 0; i < info->nbanks; i++) {
+//      for (j = 0; j < MAX_NB_GPIO_PER_BANK; j++, k++) {
+//          pdesc->number = k;
+//          pdesc->name = kasprintf(GFP_KERNEL, "pio%c%d", i + 'A', j);
+//          pdesc++;
+//      }
+//  }
+
+	platform_set_drvdata(pdev, info);
+	info->pctl = pinctrl_register(&nuc980_pinctrl_desc, &pdev->dev, info);
+
+	if (!info->pctl) {
+		dev_err(&pdev->dev, "could not register NUC980 pinctrl driver\n");
+		ret = -EINVAL;
+		goto err;
+	}
+
+	dev_info(&pdev->dev, "initialized NUC980 pinctrl driver\n");
+
+	return 0;
+
+err:
+	return ret;
+}
+
+static int nuc980_pinctrl_remove(struct platform_device *pdev)
+{
+	struct nuc980_pinctrl *info = platform_get_drvdata(pdev);
+
+	pinctrl_unregister(info->pctl);
+
+	return 0;
+}
+
+static struct platform_driver nuc980_pinctrl_driver = {
+	.driver = {
+		.name = "pinctrl-nuc980",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_pinctrl_of_match),
+	},
+	.probe = nuc980_pinctrl_probe,
+	.remove = nuc980_pinctrl_remove,
+};
+
+static int __init nuc980_pinctrl_init(void)
+{
+	return platform_driver_register(&nuc980_pinctrl_driver);
+}
+arch_initcall(nuc980_pinctrl_init);
+
+static void __exit nuc980_pinctrl_exit(void)
+{
+	platform_driver_unregister(&nuc980_pinctrl_driver);
+}
+
+module_exit(nuc980_pinctrl_exit);
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_DESCRIPTION("Nuvoton NUC980 SOC series pinctrl driver");
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/pwm/Kconfig NUC980-linux-4.4.194/drivers/pwm/Kconfig
--- linux-4.4.194/drivers/pwm/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/pwm/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -270,6 +270,218 @@ config PWM_MXS
 	  To compile this driver as a module, choose M here: the module
 	  will be called pwm-mxs.
 
+config PWM_NUC980_PWM0
+        tristate "NUC980 PWM0 support"
+        depends on ARCH_NUC980
+        help
+          Generic PWM framework driver for Nuvoton NUC980 Series MCU.
+
+          To compile this driver as a module, choose M here: the module
+          will be called pwm-nuc970-pwm0.
+
+choice
+        prompt "NUC980 PWM0 channel 0 output pin"
+        default NUC980_PWM0_CH0_NONE
+        depends on PWM_NUC980_PWM0
+        help
+          Select PWM0 channel 0 output pin.
+
+        config NUC980_PWM0_CH0_NONE
+                bool "No output"
+
+        config NUC980_PWM0_CH0_PF5
+                bool "Output from PF5"
+
+        config NUC980_PWM0_CH0_PG0
+                bool "Output from PG0"
+
+        config NUC980_PWM0_CH0_PD12
+                bool "Output from PD12"
+
+        config NUC980_PWM0_CH0_PG10
+                bool "Output from PG10"
+
+endchoice
+
+choice
+        prompt "NUC980 PWM0 channel 1 output pin"
+        default NUC980_PWM0_CH1_NONE
+        depends on PWM_NUC980_PWM0
+        help
+          Select PWM0 channel 1 output pin.
+
+        config NUC980_PWM0_CH1_NONE
+                bool "No output"
+
+        config NUC980_PWM0_CH1_PF6
+                bool "Output from PF6"
+
+        config NUC980_PWM0_CH1_PG1
+                bool "Output from PG1"
+
+        config NUC980_PWM0_CH1_PD13
+                bool "Output from PD13"
+
+        config NUC980_PWM0_CH1_PA15
+                bool "Output from PA15"
+endchoice
+
+choice
+        prompt "NUC980 PWM0 channel 2 output pin"
+        default NUC980_PWM0_CH2_NONE
+        depends on PWM_NUC980_PWM0
+        help
+          Select PWM0 channel 2 output pin.
+
+        config NUC980_PWM0_CH2_NONE
+                bool "No output"
+
+        config NUC980_PWM0_CH2_PF7
+                bool "Output from PF7"
+
+        config NUC980_PWM0_CH2_PG2
+                bool "Output from PG2"
+
+        config NUC980_PWM0_CH2_PD14
+                bool "Output from PD14"
+
+        config NUC980_PWM0_CH2_PA14
+                bool "Output from PA14"
+
+        config NUC980_PWM0_CH2_PB13
+                bool "Output from PB13"
+
+endchoice
+
+choice
+        prompt "NUC980 PWM0 channel 3 output pin"
+        default NUC980_PWM0_CH3_NONE
+        depends on PWM_NUC980_PWM0
+        help
+          Select PWM0 channel 3 output pin.
+
+        config NUC980_PWM0_CH3_NONE
+                bool "No output"
+
+        config NUC980_PWM0_CH3_PF8
+                bool "Output from PF8"
+
+        config NUC980_PWM0_CH3_PG3
+                bool "Output from PG3"
+
+        config NUC980_PWM0_CH3_PD15
+                bool "Output from PD15"
+
+        config NUC980_PWM0_CH3_PA13
+                bool "Output from PA13"
+
+endchoice
+
+config PWM_NUC980_PWM1
+        tristate "NUC980 PWM1 support"
+        depends on ARCH_NUC980
+        help
+          Generic PWM framework driver for Nuvoton NUC980 Series MCU.
+
+          To compile this driver as a module, choose M here: the module
+          will be called pwm-nuc970-pwm1.
+
+choice
+        prompt "NUC980 PWM1 channel 0 output pin"
+        default NUC970_PWM1_CH0_NONE
+        depends on PWM_NUC980_PWM1
+        help
+          Select PWM1 channel 0 output pin.
+
+        config NUC980_PWM1_CH0_NONE
+                bool "No output"
+
+        config NUC980_PWM1_CH0_PB12
+                bool "Output from PB12"
+
+        config NUC980_PWM1_CH0_PG6
+                bool "Output from PG6"
+
+        config NUC980_PWM1_CH0_PG11
+                bool "Output from PG11"
+
+        config NUC980_PWM1_CH0_PF9
+                bool "Output from PF9"
+
+endchoice
+
+choice
+        prompt "NUC980 PWM1 channel 1 output pin"
+        default NUC980_PWM1_CH1_NONE
+        depends on PWM_NUC980_PWM1
+        help
+          Select PWM1 channel 1 output pin.
+
+        config NUC980_PWM1_CH1_NONE
+                bool "No output"
+
+        config NUC980_PWM1_CH1_PB11
+                bool "Output from PB11"
+
+        config NUC980_PWM1_CH1_PG7
+                bool "Output from PG7"
+
+        config NUC980_PWM1_CH1_PG12
+                bool "Output from PG12"
+
+        config NUC980_PWM1_CH1_PF10
+                bool "Output from PF10"
+endchoice
+
+choice
+        prompt "NUC980 PWM1 channel 2 output pin"
+        default NUC980_PWM1_CH2_NONE
+        depends on PWM_NUC980_PWM1
+        help
+          Select PWM1 channel 2 output pin.
+
+        config NUC980_PWM1_CH2_NONE
+                bool "No output"
+
+        config NUC980_PWM1_CH2_PB10
+                bool "Output from PB10"
+
+        config NUC980_PWM1_CH2_PG8
+                bool "Output from PG8"
+
+        config NUC980_PWM1_CH2_PG13
+                bool "Output from PG13"
+
+        config NUC980_PWM1_CH2_PE10
+                bool "Output from PE10"
+
+endchoice
+
+choice
+        prompt "NUC980 PWM1 channel 3 output pin"
+        default NUC980_PWM1_CH3_NONE
+        depends on PWM_NUC980_PWM1
+        help
+          Select PWM1 channel 3 output pin.
+
+        config NUC980_PWM1_CH3_NONE
+                bool "No output"
+
+        config NUC980_PWM1_CH3_PB9
+                bool "Output from PB9"
+
+        config NUC980_PWM1_CH3_PG9
+                bool "Output from PG9"
+
+        config NUC980_PWM1_CH3_PG14
+                bool "Output from PG14"
+
+        config NUC980_PWM1_CH3_PE12
+                bool "Output from PE12"
+
+endchoice
+
+
 config PWM_PCA9685
 	tristate "NXP PCA9685 PWM driver"
 	depends on I2C
diff -uprN linux-4.4.194/drivers/pwm/Makefile NUC980-linux-4.4.194/drivers/pwm/Makefile
--- linux-4.4.194/drivers/pwm/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/pwm/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -41,3 +41,5 @@ obj-$(CONFIG_PWM_TIPWMSS)	+= pwm-tipwmss
 obj-$(CONFIG_PWM_TWL)		+= pwm-twl.o
 obj-$(CONFIG_PWM_TWL_LED)	+= pwm-twl-led.o
 obj-$(CONFIG_PWM_VT8500)	+= pwm-vt8500.o
+obj-$(CONFIG_PWM_NUC980_PWM0)   += pwm-nuc980-pwm0.o
+obj-$(CONFIG_PWM_NUC980_PWM1)   += pwm-nuc980-pwm1.o
diff -uprN linux-4.4.194/drivers/pwm/pwm-nuc980-pwm0.c NUC980-linux-4.4.194/drivers/pwm/pwm-nuc980-pwm0.c
--- linux-4.4.194/drivers/pwm/pwm-nuc980-pwm0.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/pwm/pwm-nuc980-pwm0.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,423 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * NUC980 Series PWM driver
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License.
+*/
+
+
+#include <linux/export.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/err.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/io.h>
+#include <linux/pwm.h>
+
+#include <mach/map.h>
+#include <mach/regs-pwm0.h>
+#include <mach/regs-clock.h>
+
+//#define DEBIG_PWM
+
+struct nuc980_chip {
+	struct platform_device	*pdev;
+	struct clk		*clk;
+	struct pwm_chip		 chip;
+};
+
+#define to_nuc980_chip(chip)	container_of(chip, struct nuc980_chip, chip)
+
+#ifdef DEBUG_PWM
+static void pwm_dbg(void)
+{
+
+	printk("%08x\n", __raw_readl(REG_PWM_PPR));
+	printk("%08x\n", __raw_readl(REG_PWM_CSR));
+	printk("%08x\n", __raw_readl(REG_PWM_PCR));
+	printk("%08x\n", __raw_readl(REG_PWM_CNR0));
+	printk("%08x\n", __raw_readl(REG_PWM_CMR0));
+	printk("%08x\n", __raw_readl(REG_PWM_CNR1));
+	printk("%08x\n", __raw_readl(REG_PWM_CMR1));
+	printk("%08x\n", __raw_readl(REG_PWM_CNR2));
+	printk("%08x\n", __raw_readl(REG_PWM_CMR2));
+	printk("%08x\n", __raw_readl(REG_PWM_CNR3));
+	printk("%08x\n", __raw_readl(REG_PWM_CMR3));
+	printk("%08x\n", __raw_readl(REG_PWM_PIER));
+	printk("%08x\n", __raw_readl(REG_PWM_PIIR));
+
+}
+#endif
+
+static int nuc980_pwm_enable(struct pwm_chip *chip, struct pwm_device *pwm)
+{
+	//struct nuc980_chip *nuc980 = to_nuc980_chip(chip);
+	int ch = pwm->hwpwm + chip->base;
+	unsigned long flags, cnr, cmr;
+
+	local_irq_save(flags);
+
+	if(ch == 0) {
+		cnr = __raw_readl(REG_PWM_CNR0);
+		cmr = __raw_readl(REG_PWM_CMR0);
+		__raw_writel(__raw_readl(REG_PWM_PCR) | (9), REG_PWM_PCR);
+		__raw_writel(cnr, REG_PWM_CNR0);
+		__raw_writel(cmr, REG_PWM_CMR0);
+	} else if(ch == 1) {
+		cnr = __raw_readl(REG_PWM_CNR1);
+		cmr = __raw_readl(REG_PWM_CMR1);
+		__raw_writel(__raw_readl(REG_PWM_PCR) | (9 << 8), REG_PWM_PCR);
+		__raw_writel(cnr, REG_PWM_CNR1);
+		__raw_writel(cmr, REG_PWM_CMR1);
+	} else if (ch == 2) {
+		cnr = __raw_readl(REG_PWM_CNR2);
+		cmr = __raw_readl(REG_PWM_CMR2);
+		__raw_writel(__raw_readl(REG_PWM_PCR) | (9 << 12), REG_PWM_PCR);
+		__raw_writel(cnr, REG_PWM_CNR2);
+		__raw_writel(cmr, REG_PWM_CMR2);
+	} else {	/* ch 3 */
+		cnr = __raw_readl(REG_PWM_CNR3);
+		cmr = __raw_readl(REG_PWM_CMR3);
+		__raw_writel(__raw_readl(REG_PWM_PCR) | (9 << 16), REG_PWM_PCR);
+		__raw_writel(cnr, REG_PWM_CNR3);
+		__raw_writel(cmr, REG_PWM_CMR3);
+	}
+
+	local_irq_restore(flags);
+#ifdef DEBUG_PWM
+	pwm_dbg();
+#endif
+	return 0;
+}
+
+static void nuc980_pwm_disable(struct pwm_chip *chip, struct pwm_device *pwm)
+{
+	//struct nuc980_chip *nuc980 = to_nuc980_chip(chip);
+	int ch = pwm->hwpwm + chip->base;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	if(ch == 0)
+		__raw_writel(__raw_readl(REG_PWM_PCR) & ~(1), REG_PWM_PCR);
+	else if(ch == 1)
+		__raw_writel(__raw_readl(REG_PWM_PCR) & ~(1 << 8), REG_PWM_PCR);
+	else if (ch == 2)
+		__raw_writel(__raw_readl(REG_PWM_PCR) & ~(1 << 12), REG_PWM_PCR);
+	else	/* ch 3 */
+		__raw_writel(__raw_readl(REG_PWM_PCR) & ~(1 << 16), REG_PWM_PCR);
+
+	local_irq_restore(flags);
+#ifdef DEBUG_PWM
+	pwm_dbg();
+#endif
+}
+
+
+
+static int nuc980_pwm_config(struct pwm_chip *chip, struct pwm_device *pwm,
+                             int duty_ns, int period_ns)
+{
+	struct nuc980_chip *nuc980 = to_nuc980_chip(chip);
+	unsigned long period, duty, prescale;
+	unsigned long flags;
+	int ch = pwm->hwpwm + chip->base;
+
+	// Get PCLK, calculate valid parameter range.
+	prescale = clk_get_rate(nuc980->clk) / 1000000 - 1;
+
+	// now pwm time unit is 1000ns.
+	period = (period_ns + 500) / 1000;
+	duty = (duty_ns + 500) / 1000;
+
+	// don't want the minus 1 below change the value to -1 (0xFFFF)
+	if(period == 0)
+		period = 1;
+	if(duty == 0)
+		duty = 1;
+
+	local_irq_save(flags);
+	// Set prescale for all pwm channels
+	__raw_writel(prescale | (prescale << 8), REG_PWM_PPR);
+
+	if(ch == 0) {
+		__raw_writel(period - 1, REG_PWM_CNR0);
+		__raw_writel(duty - 1, REG_PWM_CMR0);
+	} else if(ch == 1) {
+		__raw_writel(period - 1, REG_PWM_CNR1);
+		__raw_writel(duty - 1, REG_PWM_CMR1);
+	} else if (ch == 2) {
+		__raw_writel(period - 1, REG_PWM_CNR2);
+		__raw_writel(duty - 1, REG_PWM_CMR2);
+	} else {/* ch 3 */
+		__raw_writel(period - 1, REG_PWM_CNR3);
+		__raw_writel(duty - 1, REG_PWM_CMR3);
+	}
+
+	local_irq_restore(flags);
+
+#ifdef DEBUG_PWM
+	pwm_dbg();
+#endif
+
+	return 0;
+}
+
+static struct pwm_ops nuc980_pwm_ops = {
+	.enable = nuc980_pwm_enable,
+	.disable = nuc980_pwm_disable,
+	.config = nuc980_pwm_config,
+	.owner = THIS_MODULE,
+};
+
+static int nuc980_pwm_probe(struct platform_device *pdev)
+{
+
+	struct nuc980_chip *nuc980;
+	struct pinctrl *p;
+	int ret;
+#if defined(CONFIG_USE_OF)
+	u32 id;
+#endif
+
+	nuc980 = devm_kzalloc(&pdev->dev, sizeof(*nuc980), GFP_KERNEL);
+	if (nuc980 == NULL) {
+		dev_err(&pdev->dev, "failed to allocate memory for pwm_device\n");
+		return -ENOMEM;
+	}
+	/* calculate base of control bits in TCON */
+
+	nuc980->chip.dev = &pdev->dev;
+	nuc980->chip.ops = &nuc980_pwm_ops;
+	//nuc980->chip.of_xlate = of_pwm_xlate_with_flags;
+	//nuc980->chip.of_pwm_n_cells = 3;
+	nuc980->chip.base = pdev->id;
+	nuc980->chip.npwm = 1;
+
+	nuc980->clk = clk_get(NULL, "pwm0");
+	if (IS_ERR(nuc980->clk)) {
+		dev_err(&pdev->dev, "failed to get pwm clock\n");
+		ret = PTR_ERR(nuc980->clk);
+		return ret;
+	}
+
+	clk_prepare(nuc980->clk);
+	clk_enable(nuc980->clk);
+	// all channel prescale output div by 1
+	__raw_writel(0x4444, REG_PWM_CSR);
+
+#if defined(CONFIG_USE_OF)
+	if (of_property_read_u32(pdev->dev.of_node, "id", &id)) {
+		printk("can't get pwm id from dt\n");
+	} else {
+		pdev->id = id;
+	}
+#endif
+
+	if(pdev->id == 0) {
+#if defined(CONFIG_USE_OF)
+		p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined (CONFIG_NUC980_PWM0_CH0_PF5)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm00-PF5");
+#elif defined (CONFIG_NUC980_PWM0_CH0_PG0)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm00-PG0");
+#elif defined (CONFIG_NUC980_PWM0_CH0_PD12)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm00-PD12");
+#elif defined (CONFIG_NUC980_PWM0_CH0_PG10)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm00-PG10");
+#endif
+
+#ifndef CONFIG_NUC980_PWM0_CH0_NONE
+		if(IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve output pin\n");
+
+		}
+#endif
+#endif
+	}
+	if(pdev->id == 1) {
+#if defined(CONFIG_USE_OF)
+		p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined (CONFIG_NUC980_PWM0_CH1_PF6)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm01-PF6");
+#elif defined (CONFIG_NUC980_PWM0_CH1_PG1)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm01-PG1");
+#elif defined (CONFIG_NUC980_PWM0_CH1_PD13)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm01-PD13");
+#elif defined (CONFIG_NUC980_PWM0_CH1_PA15)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm01-PA15");
+#endif
+
+#ifndef CONFIG_NUC980_PWM0_CH1_NONE
+		if(IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve output pin\n");
+		}
+#endif
+#endif
+	}
+	if(pdev->id == 2) {
+#if defined(CONFIG_USE_OF)
+		p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined (CONFIG_NUC980_PWM0_CH2_PF7)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm02-PF7");
+#elif defined (CONFIG_NUC980_PWM0_CH2_PG2)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm02-PG2");
+#elif defined (CONFIG_NUC980_PWM0_CH2_PD14)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm02-PD14");
+#elif defined (CONFIG_NUC980_PWM0_CH2_PA14)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm02-PA14");
+#elif defined (CONFIG_NUC980_PWM0_CH2_PB13)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm02-PB13");
+#endif
+
+#ifndef CONFIG_NUC980_PWM0_CH2_NONE
+		if(IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve output pin\n");
+		}
+#endif
+#endif
+	}
+	if(pdev->id == 3) {
+#if defined(CONFIG_USE_OF)
+		p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined (CONFIG_NUC980_PWM0_CH3_PF8)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm03-PF8");
+#elif defined (CONFIG_NUC980_PWM0_CH3_PG3)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm03-PG3");
+#elif defined (CONFIG_NUC980_PWM0_CH3_PD15)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm03-PD15");
+#elif defined (CONFIG_NUC980_PWM0_CH3_PA13)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm03-PA13");
+#endif
+
+#ifndef CONFIG_NUC980_PWM0_CH3_NONE
+		if(IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve output pin\n");
+		}
+#endif
+#endif
+	}
+
+	ret = pwmchip_add(&nuc980->chip);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "failed to register pwm\n");
+		goto err;
+	}
+
+	platform_set_drvdata(pdev, nuc980);
+
+	return 0;
+
+err:
+	//clk_disable(nuc980->clk);
+	return ret;
+}
+
+static int nuc980_pwm_remove(struct platform_device *pdev)
+{
+	struct nuc980_chip *nuc980 = platform_get_drvdata(pdev);
+
+	clk_disable(nuc980->clk);
+	return pwmchip_remove(&nuc980->chip);
+}
+
+#ifdef CONFIG_PM
+static u32 pcr_save, cnr0_save, cnr1_save, cnr2_save, cnr3_save;
+static int nuc980_pwm_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	//struct nuc980_chip *chip = dev_get_drvdata(dev);
+
+	if (pdev->id == 3) {
+		pcr_save = __raw_readl(REG_PWM_PCR);
+
+		cnr3_save = __raw_readl(REG_PWM_CNR3);
+		__raw_writel(0, REG_PWM_CNR3);
+		while(__raw_readl(REG_PWM_PDR3));
+	} else if (pdev->id == 2) {
+		cnr2_save = __raw_readl(REG_PWM_CNR2);
+		__raw_writel(0, REG_PWM_CNR2);
+		while(__raw_readl(REG_PWM_PDR2));
+	} else if (pdev->id == 1) {
+		cnr1_save = __raw_readl(REG_PWM_CNR1);
+		__raw_writel(0, REG_PWM_CNR1);
+		while(__raw_readl(REG_PWM_PDR1));
+	}
+	if (pdev->id == 0) {
+		cnr0_save = __raw_readl(REG_PWM_CNR0);
+		__raw_writel(0, REG_PWM_CNR0);
+		while(__raw_readl(REG_PWM_PDR0));
+
+		__raw_writel( __raw_readl(REG_PWM_PCR) & ~0x11101, REG_PWM_PCR);
+	}
+
+
+	return 0;
+}
+
+static int nuc980_pwm_resume(struct platform_device *pdev)
+{
+	//struct nuc980_chip *chip = dev_get_drvdata(dev);
+
+	if (pdev->id == 0) {
+		__raw_writel(cnr0_save, REG_PWM_CNR0);
+	} else if (pdev->id == 1) {
+		__raw_writel(cnr1_save, REG_PWM_CNR1);
+	} else if (pdev->id == 2) {
+		__raw_writel(cnr2_save, REG_PWM_CNR2);
+	} else if (pdev->id == 3) {
+		__raw_writel(cnr3_save, REG_PWM_CNR3);
+
+		__raw_writel(pcr_save, REG_PWM_PCR);
+	}
+
+	return 0;
+}
+
+//static SIMPLE_DEV_PM_OPS(nuc980_pwm_pm_ops, nuc980_pwm_suspend, nuc980_pwm_resume);
+#else
+#define nuc980_pwm_suspend NULL
+#define nuc980_pwm_resume  NULL
+#endif
+
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_pwm0_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-pwm0" } ,
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_pwm0_of_match);
+#endif
+
+static struct platform_driver nuc980_pwm0_driver = {
+	.driver		= {
+		.name	= "nuc980-pwm0",
+		.owner	= THIS_MODULE,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_pwm0_of_match),
+#endif
+//#ifdef CONFIG_PM
+//		.pm	= &nuc980_pwm_pm_ops,
+//#endif
+	},
+	.probe		= nuc980_pwm_probe,
+	.remove		= nuc980_pwm_remove,
+	.suspend        = nuc980_pwm_suspend,
+	.resume         = nuc980_pwm_resume,
+};
+
+
+
+module_platform_driver(nuc980_pwm0_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_ALIAS("platform:nuc980-pwm0");
diff -uprN linux-4.4.194/drivers/pwm/pwm-nuc980-pwm1.c NUC980-linux-4.4.194/drivers/pwm/pwm-nuc980-pwm1.c
--- linux-4.4.194/drivers/pwm/pwm-nuc980-pwm1.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/pwm/pwm-nuc980-pwm1.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,421 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * NUC980 Series PWM driver
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License.
+*/
+
+
+#include <linux/export.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/err.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/io.h>
+#include <linux/pwm.h>
+
+#include <mach/map.h>
+#include <mach/regs-pwm1.h>
+#include <mach/regs-clock.h>
+
+//#define DEBIG_PWM
+
+struct nuc980_chip {
+	struct platform_device	*pdev;
+	struct clk		*clk;
+	struct pwm_chip		 chip;
+};
+
+#define to_nuc980_chip(chip)	container_of(chip, struct nuc980_chip, chip)
+
+#ifdef DEBUG_PWM
+static void pwm_dbg(void)
+{
+
+	printk("%08x\n", __raw_readl(REG_PWM_PPR));
+	printk("%08x\n", __raw_readl(REG_PWM_CSR));
+	printk("%08x\n", __raw_readl(REG_PWM_PCR));
+	printk("%08x\n", __raw_readl(REG_PWM_CNR0));
+	printk("%08x\n", __raw_readl(REG_PWM_CMR0));
+	printk("%08x\n", __raw_readl(REG_PWM_CNR1));
+	printk("%08x\n", __raw_readl(REG_PWM_CMR1));
+	printk("%08x\n", __raw_readl(REG_PWM_CNR2));
+	printk("%08x\n", __raw_readl(REG_PWM_CMR2));
+	printk("%08x\n", __raw_readl(REG_PWM_CNR3));
+	printk("%08x\n", __raw_readl(REG_PWM_CMR3));
+	printk("%08x\n", __raw_readl(REG_PWM_PIER));
+	printk("%08x\n", __raw_readl(REG_PWM_PIIR));
+
+}
+#endif
+
+static int nuc980_pwm_enable(struct pwm_chip *chip, struct pwm_device *pwm)
+{
+	//struct nuc980_chip *nuc980 = to_nuc980_chip(chip);
+	int ch = pwm->hwpwm + chip->base;
+	unsigned long flags, cnr, cmr;
+
+	local_irq_save(flags);
+
+	if(ch == 4) {
+		cnr = __raw_readl(REG_PWM_CNR0);
+		cmr = __raw_readl(REG_PWM_CMR0);
+		__raw_writel(__raw_readl(REG_PWM_PCR) | (9), REG_PWM_PCR);
+		__raw_writel(cnr, REG_PWM_CNR0);
+		__raw_writel(cmr, REG_PWM_CMR0);
+	} else if(ch == 5) {
+		cnr = __raw_readl(REG_PWM_CNR1);
+		cmr = __raw_readl(REG_PWM_CMR1);
+		__raw_writel(__raw_readl(REG_PWM_PCR) | (9 << 8), REG_PWM_PCR);
+		__raw_writel(cnr, REG_PWM_CNR1);
+		__raw_writel(cmr, REG_PWM_CMR1);
+	} else if (ch == 6) {
+		cnr = __raw_readl(REG_PWM_CNR2);
+		cmr = __raw_readl(REG_PWM_CMR2);
+		__raw_writel(__raw_readl(REG_PWM_PCR) | (9 << 12), REG_PWM_PCR);
+		__raw_writel(cnr, REG_PWM_CNR2);
+		__raw_writel(cmr, REG_PWM_CMR2);
+	} else {	/* ch 3 */
+		cnr = __raw_readl(REG_PWM_CNR3);
+		cmr = __raw_readl(REG_PWM_CMR3);
+		__raw_writel(__raw_readl(REG_PWM_PCR) | (9 << 16), REG_PWM_PCR);
+		__raw_writel(cnr, REG_PWM_CNR3);
+		__raw_writel(cmr, REG_PWM_CMR3);
+	}
+
+	local_irq_restore(flags);
+#ifdef DEBUG_PWM
+	pwm_dbg();
+#endif
+	return 0;
+}
+
+static void nuc980_pwm_disable(struct pwm_chip *chip, struct pwm_device *pwm)
+{
+	//struct nuc980_chip *nuc980 = to_nuc980_chip(chip);
+	int ch = pwm->hwpwm + chip->base;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	if(ch == 4)
+		__raw_writel(__raw_readl(REG_PWM_PCR) & ~(1), REG_PWM_PCR);
+	else if(ch == 5)
+		__raw_writel(__raw_readl(REG_PWM_PCR) & ~(1 << 8), REG_PWM_PCR);
+	else if (ch == 6)
+		__raw_writel(__raw_readl(REG_PWM_PCR) & ~(1 << 12), REG_PWM_PCR);
+	else	/* ch 3 */
+		__raw_writel(__raw_readl(REG_PWM_PCR) & ~(1 << 16), REG_PWM_PCR);
+
+	local_irq_restore(flags);
+#ifdef DEBUG_PWM
+	pwm_dbg();
+#endif
+}
+
+
+
+static int nuc980_pwm_config(struct pwm_chip *chip, struct pwm_device *pwm,
+                             int duty_ns, int period_ns)
+{
+	struct nuc980_chip *nuc980 = to_nuc980_chip(chip);
+	unsigned long period, duty, prescale;
+	unsigned long flags;
+	int ch = pwm->hwpwm + chip->base;
+
+	// Get PCLK, calculate valid parameter range.
+	prescale = clk_get_rate(nuc980->clk) / 1000000 - 1;
+
+	// now pwm time unit is 1000ns.
+	period = (period_ns + 500) / 1000;
+	duty = (duty_ns + 500) / 1000;
+
+	// don't want the minus 1 below change the value to -1 (0xFFFF)
+	if(period == 0)
+		period = 1;
+	if(duty == 0)
+		duty = 1;
+
+	local_irq_save(flags);
+	// Set prescale for all pwm channels
+	__raw_writel(prescale | (prescale << 8), REG_PWM_PPR);
+
+	if(ch == 4) {
+		__raw_writel(period - 1, REG_PWM_CNR0);
+		__raw_writel(duty - 1, REG_PWM_CMR0);
+	} else if(ch == 5) {
+		__raw_writel(period - 1, REG_PWM_CNR1);
+		__raw_writel(duty - 1, REG_PWM_CMR1);
+	} else if (ch == 6) {
+		__raw_writel(period - 1, REG_PWM_CNR2);
+		__raw_writel(duty - 1, REG_PWM_CMR2);
+	} else {/* ch 3 */
+		__raw_writel(period - 1, REG_PWM_CNR3);
+		__raw_writel(duty - 1, REG_PWM_CMR3);
+	}
+
+	local_irq_restore(flags);
+
+#ifdef DEBUG_PWM
+	pwm_dbg();
+#endif
+
+	return 0;
+}
+
+static struct pwm_ops nuc980_pwm_ops = {
+	.enable = nuc980_pwm_enable,
+	.disable = nuc980_pwm_disable,
+	.config = nuc980_pwm_config,
+	.owner = THIS_MODULE,
+};
+
+static int nuc980_pwm_probe(struct platform_device *pdev)
+{
+
+	struct nuc980_chip *nuc980;
+	struct pinctrl *p;
+	int ret;
+#if defined(CONFIG_USE_OF)
+	u32 id;
+#endif
+
+	nuc980 = devm_kzalloc(&pdev->dev, sizeof(*nuc980), GFP_KERNEL);
+	if (nuc980 == NULL) {
+		dev_err(&pdev->dev, "failed to allocate memory for pwm_device\n");
+		return -ENOMEM;
+	}
+	/* calculate base of control bits in TCON */
+
+	nuc980->chip.dev = &pdev->dev;
+	nuc980->chip.ops = &nuc980_pwm_ops;
+	//nuc980->chip.of_xlate = of_pwm_xlate_with_flags;
+	//nuc980->chip.of_pwm_n_cells = 3;
+	nuc980->chip.base = pdev->id;
+	nuc980->chip.npwm = 1;
+
+	nuc980->clk = clk_get(NULL, "pwm1");
+	if (IS_ERR(nuc980->clk)) {
+		dev_err(&pdev->dev, "failed to get pwm clock\n");
+		ret = PTR_ERR(nuc980->clk);
+		return ret;
+	}
+
+	clk_prepare(nuc980->clk);
+	clk_enable(nuc980->clk);
+	// all channel prescale output div by 1
+	__raw_writel(0x4444, REG_PWM_CSR);
+
+#if defined(CONFIG_USE_OF)
+	if (of_property_read_u32(pdev->dev.of_node, "id", &id)) {
+		printk("can't get pwm id from dt\n");
+	} else {
+		pdev->id = id;
+	}
+#endif
+
+	if(pdev->id == 4) {
+#if defined(CONFIG_USE_OF)
+		p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined (CONFIG_NUC980_PWM1_CH0_PB12)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm10-PB12");
+#elif defined (CONFIG_NUC980_PWM1_CH0_PG6)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm10-PG6");
+#elif defined (CONFIG_NUC980_PWM1_CH0_PG11)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm10-PG11");
+#elif defined (CONFIG_NUC980_PWM1_CH0_PF9)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm10-PF9");
+#endif
+
+#ifndef CONFIG_NUC980_PWM1_CH0_NONE
+		if(IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve output pin\n");
+
+		}
+#endif
+#endif
+	}
+	if(pdev->id == 5) {
+#if defined(CONFIG_USE_OF)
+		p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined (CONFIG_NUC980_PWM1_CH1_PB11)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm11-PB11");
+#elif defined (CONFIG_NUC980_PWM1_CH1_PG7)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm11-PG7");
+#elif defined (CONFIG_NUC980_PWM1_CH1_PG12)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm11-PG12");
+#elif defined (CONFIG_NUC980_PWM1_CH1_PF10)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm11-PF10");
+#endif
+
+#ifndef CONFIG_NUC980_PWM1_CH1_NONE
+		if(IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve output pin\n");
+		}
+#endif
+#endif
+	}
+	if(pdev->id == 6) {
+#if defined(CONFIG_USE_OF)
+		p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined (CONFIG_NUC980_PWM1_CH2_PB10)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm12-PB10");
+#elif defined (CONFIG_NUC980_PWM1_CH2_PG8)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm12-PG8");
+#elif defined (CONFIG_NUC980_PWM1_CH2_PG13)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm12-PG13");
+#elif defined (CONFIG_NUC980_PWM1_CH2_PE10)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm12-PE10");
+#endif
+
+#ifndef CONFIG_NUC980_PWM1_CH2_NONE
+		if(IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve output pin\n");
+		}
+#endif
+#endif
+	}
+	if(pdev->id == 7) {
+#if defined(CONFIG_USE_OF)
+		p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined (CONFIG_NUC980_PWM1_CH3_PB9)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm13-PB9");
+#elif defined (CONFIG_NUC980_PWM1_CH3_PG9)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm13-PG9");
+#elif defined (CONFIG_NUC980_PWM1_CH3_PG14)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm13-PG14");
+#elif defined (CONFIG_NUC980_PWM1_CH3_PE12)
+		p = devm_pinctrl_get_select(&pdev->dev, "pwm13-PE12");
+#endif
+
+#ifndef CONFIG_NUC980_PWM1_CH3_NONE
+		if(IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve output pin\n");
+		}
+#endif
+#endif
+	}
+
+	ret = pwmchip_add(&nuc980->chip);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "failed to register pwm\n");
+		goto err;
+	}
+
+	platform_set_drvdata(pdev, nuc980);
+
+	return 0;
+
+err:
+	//clk_disable(nuc980->clk);
+	return ret;
+}
+
+static int nuc980_pwm_remove(struct platform_device *pdev)
+{
+	struct nuc980_chip *nuc980 = platform_get_drvdata(pdev);
+
+	clk_disable(nuc980->clk);
+	return pwmchip_remove(&nuc980->chip);
+}
+
+#ifdef CONFIG_PM
+static u32 pcr_save, cnr0_save, cnr1_save, cnr2_save, cnr3_save;
+static int nuc980_pwm_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	//struct nuc980_chip *chip = dev_get_drvdata(dev);
+
+	if (pdev->id == 7) {
+		pcr_save = __raw_readl(REG_PWM_PCR);
+
+		cnr3_save = __raw_readl(REG_PWM_CNR3);
+		__raw_writel(0, REG_PWM_CNR3);
+		while(__raw_readl(REG_PWM_PDR3));
+	} else if (pdev->id == 6) {
+		cnr2_save = __raw_readl(REG_PWM_CNR2);
+		__raw_writel(0, REG_PWM_CNR2);
+		while(__raw_readl(REG_PWM_PDR2));
+	} else if (pdev->id == 5) {
+		cnr1_save = __raw_readl(REG_PWM_CNR1);
+		__raw_writel(0, REG_PWM_CNR1);
+		while(__raw_readl(REG_PWM_PDR1));
+	}
+	if (pdev->id == 4) {
+		cnr0_save = __raw_readl(REG_PWM_CNR0);
+		__raw_writel(0, REG_PWM_CNR0);
+		while(__raw_readl(REG_PWM_PDR0));
+
+		__raw_writel( __raw_readl(REG_PWM_PCR) & ~0x11101, REG_PWM_PCR);
+	}
+
+
+	return 0;
+}
+
+static int nuc980_pwm_resume(struct platform_device *pdev)
+{
+	//struct nuc980_chip *chip = dev_get_drvdata(dev);
+
+	if (pdev->id == 4) {
+		__raw_writel(cnr0_save, REG_PWM_CNR0);
+	} else if (pdev->id == 5) {
+		__raw_writel(cnr1_save, REG_PWM_CNR1);
+	} else if (pdev->id == 6) {
+		__raw_writel(cnr2_save, REG_PWM_CNR2);
+	} else if (pdev->id == 7) {
+		__raw_writel(cnr3_save, REG_PWM_CNR3);
+
+		__raw_writel(pcr_save, REG_PWM_PCR);
+	}
+
+	return 0;
+}
+
+//static SIMPLE_DEV_PM_OPS(nuc980_pwm_pm_ops, nuc980_pwm_suspend, nuc980_pwm_resume);
+#else
+#define nuc980_pwm_suspend NULL
+#define nuc980_pwm_resume  NULL
+#endif
+
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_pwm1_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-pwm1" } ,
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_pwm1_of_match);
+#endif
+
+static struct platform_driver nuc980_pwm1_driver = {
+	.driver		= {
+		.name	= "nuc980-pwm1",
+		.owner	= THIS_MODULE,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_pwm1_of_match),
+#endif
+//#ifdef CONFIG_PM
+//		.pm	= &nuc980_pwm_pm_ops,
+//#endif
+	},
+	.probe		= nuc980_pwm_probe,
+	.remove		= nuc980_pwm_remove,
+	.suspend        = nuc980_pwm_suspend,
+	.resume         = nuc980_pwm_resume,
+};
+
+
+
+module_platform_driver(nuc980_pwm1_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Nuvoton Technology Corp.");
+MODULE_ALIAS("platform:nuc980-pwm1");
diff -uprN linux-4.4.194/drivers/rtc/Kconfig NUC980-linux-4.4.194/drivers/rtc/Kconfig
--- linux-4.4.194/drivers/rtc/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/rtc/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -1114,6 +1114,18 @@ config RTC_DRV_NUC900
 	  If you say yes here you get support for the RTC subsystem of the
 	  NUC910/NUC920 used in embedded systems.
 
+config RTC_DRV_NUC980
+	tristate "NUC980 RTC driver"
+	help
+	  If you say yes here you get support for the RTC subsystem of the
+	  NUC980 used in embedded systems.
+
+config ENABLE_RTC_WAKEUP
+	bool "Enable RTC wake-up function"
+	depends on RTC_DRV_NUC980
+	help
+	  This selects NUC980 RTC wake-up function
+
 config RTC_DRV_OPAL
 	tristate "IBM OPAL RTC driver"
 	depends on PPC_POWERNV
diff -uprN linux-4.4.194/drivers/rtc/Makefile NUC980-linux-4.4.194/drivers/rtc/Makefile
--- linux-4.4.194/drivers/rtc/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/rtc/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -101,6 +101,7 @@ obj-$(CONFIG_RTC_DRV_MT6397)	+= rtc-mt63
 obj-$(CONFIG_RTC_DRV_MV)	+= rtc-mv.o
 obj-$(CONFIG_RTC_DRV_MXC)	+= rtc-mxc.o
 obj-$(CONFIG_RTC_DRV_NUC900)	+= rtc-nuc900.o
+obj-$(CONFIG_RTC_DRV_NUC980)	+= rtc-nuc980.o
 obj-$(CONFIG_RTC_DRV_OMAP)	+= rtc-omap.o
 obj-$(CONFIG_RTC_DRV_OPAL)	+= rtc-opal.o
 obj-$(CONFIG_RTC_DRV_PALMAS)	+= rtc-palmas.o
diff -uprN linux-4.4.194/drivers/rtc/rtc-nuc980.c NUC980-linux-4.4.194/drivers/rtc/rtc-nuc980.c
--- linux-4.4.194/drivers/rtc/rtc-nuc980.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/rtc/rtc-nuc980.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,426 @@
+/*
+ * Copyright (c) 2014 Nuvoton technology corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/rtc.h>
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/bcd.h>
+#include <linux/clk.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_irq.h>
+
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+
+
+/* RTC Control Registers */
+#define REG_RTC_INIR		0x00
+#define REG_RTC_AER		0x04
+#define REG_RTC_FCR		0x08
+#define REG_RTC_TLR		0x0C
+#define REG_RTC_CLR		0x10
+#define REG_RTC_TSSR		0x14
+#define REG_RTC_DWR		0x18
+#define REG_RTC_TAR		0x1C
+#define REG_RTC_CAR		0x20
+#define REG_RTC_LIR		0x24
+#define REG_RTC_RIER		0x28
+#define REG_RTC_RIIR		0x2C
+#define REG_RTC_TTR		0x30
+#define REG_RTC_PWRCTL		0x34
+
+
+#define RTCSET			0x01
+#define AERRWENB		0x10000
+#define INIRRESET		0xa5eb1357
+#define AERPOWERON		0xA965
+#define AERPOWEROFF		0x0000
+#define LEAPYEAR		0x0001
+#define TICKENB			0x80
+#define TICKINTENB		0x0002
+#define ALARMINTENB		0x0001
+#define MODE24			0x0001
+
+struct clk *rtc_clk;
+
+struct nuc980_rtc {
+	int			irq_num;
+	void __iomem		*rtc_reg;
+	struct rtc_device	*rtcdev;
+};
+
+struct nuc980_bcd_time {
+	int bcd_sec;
+	int bcd_min;
+	int bcd_hour;
+	int bcd_mday;
+	int bcd_mon;
+	int bcd_year;
+};
+
+static inline unsigned int rtc_reg_read(struct nuc980_rtc *p, int offset)
+{
+	return(__raw_readl(p->rtc_reg + offset));
+}
+
+static inline void rtc_reg_write(struct nuc980_rtc *p, int offset, int value)
+{
+	unsigned int writetimeout = 0x400;
+
+	__raw_writel(value, p->rtc_reg + offset);
+
+	// wait rtc register write finish
+	while((__raw_readl(p->rtc_reg + REG_RTC_RIIR) & (1 << 31)) && writetimeout--)
+		udelay(1);
+}
+
+static irqreturn_t nuc980_rtc_interrupt(int irq, void *_rtc)
+{
+	struct nuc980_rtc *rtc = _rtc;
+	unsigned long events = 0, rtc_irq;
+
+	rtc_irq = __raw_readl(rtc->rtc_reg + REG_RTC_RIIR);
+
+	if (rtc_irq & ALARMINTENB) {
+		rtc_reg_write(rtc, REG_RTC_RIIR, ALARMINTENB);
+		events |= RTC_AF | RTC_IRQF;
+	}
+
+	if (rtc_irq & TICKINTENB) {
+		rtc_reg_write(rtc, REG_RTC_RIIR, TICKINTENB);
+		events |= RTC_UF | RTC_IRQF;
+	}
+
+	rtc_update_irq(rtc->rtcdev, 1, events);
+
+	return IRQ_HANDLED;
+}
+
+static int *check_rtc_access_enable(struct nuc980_rtc *nuc980_rtc)
+{
+	unsigned int timeout = 0x800;
+
+	rtc_reg_write(nuc980_rtc, REG_RTC_INIR, INIRRESET);
+
+	mdelay(10);
+
+	rtc_reg_write(nuc980_rtc, REG_RTC_AER, AERPOWERON);
+
+	while (!(__raw_readl(nuc980_rtc->rtc_reg + REG_RTC_AER) & AERRWENB)
+								&& timeout--)
+		mdelay(1);
+
+	if (!timeout)
+		return ERR_PTR(-EPERM);
+
+	return 0;
+}
+
+static int nuc980_rtc_bcd2bin(unsigned int timereg,
+				unsigned int calreg, unsigned int wdayreg, struct rtc_time *tm)
+{
+	tm->tm_mday	= bcd2bin(calreg >> 0);
+	tm->tm_mon	= bcd2bin(calreg >> 8);
+	tm->tm_mon	= tm->tm_mon - 1;
+
+	tm->tm_year	= bcd2bin(calreg >> 16) + 100;
+
+	tm->tm_sec	= bcd2bin(timereg >> 0);
+	tm->tm_min	= bcd2bin(timereg >> 8);
+	tm->tm_hour	= bcd2bin(timereg >> 16);
+
+	tm->tm_wday = wdayreg;
+
+	return rtc_valid_tm(tm);
+}
+
+static int nuc980_rtc_alarm_bcd2bin(unsigned int timereg,
+				unsigned int calreg, struct rtc_time *tm)
+{
+	tm->tm_mday	= bcd2bin(calreg >> 0);
+	tm->tm_mon	= bcd2bin(calreg >> 8);
+	tm->tm_mon	= tm->tm_mon - 1;
+
+	tm->tm_year	= bcd2bin(calreg >> 16) + 100;
+
+	tm->tm_sec	= bcd2bin(timereg >> 0);
+	tm->tm_min	= bcd2bin(timereg >> 8);
+	tm->tm_hour	= bcd2bin(timereg >> 16);
+
+	return rtc_valid_tm(tm);
+}
+
+static void nuc980_rtc_bin2bcd(struct device *dev, struct rtc_time *settm,
+						struct nuc980_bcd_time *gettm)
+{
+	gettm->bcd_mday = bin2bcd(settm->tm_mday) << 0;
+	gettm->bcd_mon  = bin2bcd((settm->tm_mon + 1)) << 8;
+
+	if (settm->tm_year < 100) {
+		dev_warn(dev, "The year will be between 1970-1999, right?\n");
+		gettm->bcd_year = bin2bcd(settm->tm_year) << 16;
+	} else {
+		gettm->bcd_year = bin2bcd(settm->tm_year - 100) << 16;
+	}
+
+	gettm->bcd_sec  = bin2bcd(settm->tm_sec) << 0;
+	gettm->bcd_min  = bin2bcd(settm->tm_min) << 8;
+	gettm->bcd_hour = bin2bcd(settm->tm_hour) << 16;
+}
+
+static int nuc980_alarm_irq_enable(struct device *dev, unsigned int enabled)
+{
+	struct nuc980_rtc *rtc = dev_get_drvdata(dev);
+
+	if (enabled)
+		rtc_reg_write(rtc, REG_RTC_RIER, (__raw_readl(rtc->rtc_reg + REG_RTC_RIER)|(ALARMINTENB)));
+	else
+		rtc_reg_write(rtc, REG_RTC_RIER, (__raw_readl(rtc->rtc_reg + REG_RTC_RIER)&(~ALARMINTENB)));
+	return 0;
+}
+
+static int nuc980_rtc_read_time(struct device *dev, struct rtc_time *tm)
+{
+	struct nuc980_rtc *rtc = dev_get_drvdata(dev);
+	unsigned int timeval, clrval, wdayval;
+
+	timeval = __raw_readl(rtc->rtc_reg + REG_RTC_TLR);
+	clrval  = __raw_readl(rtc->rtc_reg + REG_RTC_CLR);
+	wdayval = __raw_readl(rtc->rtc_reg + REG_RTC_DWR);
+
+	return nuc980_rtc_bcd2bin(timeval, clrval, wdayval, tm);
+}
+
+static int nuc980_rtc_set_time(struct device *dev, struct rtc_time *tm)
+{
+	struct nuc980_rtc *rtc = dev_get_drvdata(dev);
+	struct nuc980_bcd_time gettm;
+	unsigned long val;
+	int *err;
+
+	nuc980_rtc_bin2bcd(dev, tm, &gettm);
+
+	err = check_rtc_access_enable(rtc);
+	if (IS_ERR(err))
+		return PTR_ERR(err);
+
+	val = gettm.bcd_mday | gettm.bcd_mon | gettm.bcd_year;
+	rtc_reg_write(rtc, REG_RTC_CLR, val);
+
+	val = gettm.bcd_sec | gettm.bcd_min | gettm.bcd_hour;
+	rtc_reg_write(rtc, REG_RTC_TLR, val);
+
+	val = tm->tm_wday;
+	rtc_reg_write(rtc, REG_RTC_DWR, val);
+
+	return 0;
+}
+
+static int nuc980_rtc_read_alarm(struct device *dev, struct rtc_wkalrm *alrm)
+{
+	struct nuc980_rtc *rtc = dev_get_drvdata(dev);
+	unsigned int timeval, carval;
+
+	timeval = __raw_readl(rtc->rtc_reg + REG_RTC_TAR);
+	carval  = __raw_readl(rtc->rtc_reg + REG_RTC_CAR);
+
+	return nuc980_rtc_alarm_bcd2bin(timeval, carval, &alrm->time);
+}
+
+static int nuc980_rtc_set_alarm(struct device *dev, struct rtc_wkalrm *alrm)
+{
+	struct nuc980_rtc *rtc = dev_get_drvdata(dev);
+	struct nuc980_bcd_time tm;
+	unsigned long val;
+	int *err;
+
+	nuc980_rtc_bin2bcd(dev, &alrm->time, &tm);
+
+	err = check_rtc_access_enable(rtc);
+	if (IS_ERR(err))
+		return PTR_ERR(err);
+
+	val = tm.bcd_mday | tm.bcd_mon | tm.bcd_year;
+	val |= (1 << 31); // mask alarm week day
+	rtc_reg_write(rtc, REG_RTC_CAR, val);
+
+	val = tm.bcd_sec | tm.bcd_min | tm.bcd_hour;
+	rtc_reg_write(rtc, REG_RTC_TAR, val);
+
+	rtc_reg_write(rtc, REG_RTC_PWRCTL, (__raw_readl(rtc->rtc_reg + REG_RTC_PWRCTL) | (1 << 3)));
+
+	return 0;
+}
+
+static int nuc980_ioctl(struct device *dev, unsigned int cmd, unsigned long arg)
+{
+	struct nuc980_rtc *rtc = dev_get_drvdata(dev);
+	unsigned int spare_data[16], i;
+	int *err;
+
+	switch(cmd)
+	{
+		case RTC_GET_SPARE_DATA:
+			err = check_rtc_access_enable(rtc);
+			if (IS_ERR(err))
+				return PTR_ERR(err);
+
+			for(i = 0; i < 16; i++)
+			{
+				spare_data[i] =  __raw_readl(rtc->rtc_reg + (0x40+(i*4)));
+			}
+
+			if(copy_to_user((void*)arg, (void *)&spare_data[0], sizeof(spare_data)))
+			{
+				return -EFAULT;
+			}
+
+		break;
+
+		case RTC_SET_SPARE_DATA:
+			if(copy_from_user((void *)&spare_data[0], (void*)arg, sizeof(spare_data)))
+			{
+				return -EFAULT;
+			}
+
+			err = check_rtc_access_enable(rtc);
+			if (IS_ERR(err))
+				return PTR_ERR(err);
+
+			for(i = 0; i < 16; i++)
+			{
+				rtc_reg_write(rtc, (0x40+(i*4)), spare_data[i]);
+			}
+
+		break;
+
+		default:
+			return -ENOIOCTLCMD;
+	}
+
+	return 0;
+}
+
+static struct rtc_class_ops nuc980_rtc_ops = {
+	.read_time = nuc980_rtc_read_time,
+	.set_time = nuc980_rtc_set_time,
+	.read_alarm = nuc980_rtc_read_alarm,
+	.set_alarm = nuc980_rtc_set_alarm,
+	.alarm_irq_enable = nuc980_alarm_irq_enable,
+	.ioctl = nuc980_ioctl,
+};
+
+static int nuc980_rtc_probe(struct platform_device *pdev)
+{
+	struct resource *res;
+	struct nuc980_rtc *nuc980_rtc;
+
+	rtc_clk = clk_get(NULL, "rtc");
+	clk_prepare(rtc_clk);
+	clk_enable(rtc_clk);
+
+	nuc980_rtc = devm_kzalloc(&pdev->dev, sizeof(struct nuc980_rtc),
+				GFP_KERNEL);
+	if (!nuc980_rtc) {
+		dev_err(&pdev->dev, "kzalloc nuc900_rtc failed\n");
+		return -ENOMEM;
+	}
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	nuc980_rtc->rtc_reg = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(nuc980_rtc->rtc_reg))
+		return PTR_ERR(nuc980_rtc->rtc_reg);
+
+	platform_set_drvdata(pdev, nuc980_rtc);
+
+	nuc980_rtc->rtcdev = devm_rtc_device_register(&pdev->dev, pdev->name,
+						&nuc980_rtc_ops, THIS_MODULE);
+	if (IS_ERR(nuc980_rtc->rtcdev)) {
+		dev_err(&pdev->dev, "rtc device register failed\n");
+		return PTR_ERR(nuc980_rtc->rtcdev);
+	}
+
+	rtc_reg_write(nuc980_rtc, REG_RTC_TSSR, (__raw_readl(nuc980_rtc->rtc_reg + REG_RTC_TSSR) | MODE24));
+
+	nuc980_rtc->irq_num = platform_get_irq(pdev, 0);
+
+	if (devm_request_irq(&pdev->dev, nuc980_rtc->irq_num,
+			nuc980_rtc_interrupt, IRQF_NO_SUSPEND, "nuc980rtc", nuc980_rtc)) {
+		dev_err(&pdev->dev, "NUC980 RTC request irq failed\n");
+		return -EBUSY;
+	}
+
+	rtc_reg_write(nuc980_rtc, REG_RTC_RIER, (__raw_readl(nuc980_rtc->rtc_reg + REG_RTC_RIER) | TICKINTENB));
+
+	#ifdef CONFIG_ENABLE_RTC_WAKEUP
+	__raw_writel((1<<7) | __raw_readl(REG_WKUPSER1),REG_WKUPSER1);
+	enable_irq_wake(nuc980_rtc->irq_num);
+	#endif
+
+	return 0;
+}
+
+static int __exit nuc980_rtc_remove(struct platform_device *pdev)
+{
+	platform_set_drvdata(pdev, NULL);
+
+	return 0;
+}
+
+static int nuc980_rtc_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct nuc980_rtc *nuc980_rtc = platform_get_drvdata(pdev);
+
+	rtc_reg_write(nuc980_rtc, REG_RTC_RIER, (__raw_readl(nuc980_rtc->rtc_reg + REG_RTC_RIER) &~ TICKINTENB));
+
+	return 0;
+}
+
+static int nuc980_rtc_resume(struct platform_device *pdev)
+{
+	struct nuc980_rtc *nuc980_rtc = platform_get_drvdata(pdev);
+
+	rtc_reg_write(nuc980_rtc, REG_RTC_RIER, (__raw_readl(nuc980_rtc->rtc_reg + REG_RTC_RIER) | TICKINTENB));
+
+	return 0;
+}
+
+#ifdef CONFIG_USE_OF
+static const struct of_device_id nuc980_rtc_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-rtc"},
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_rtc_of_match);
+#else
+#define nuc980_rtc_of_match NULL
+#endif
+
+static struct platform_driver nuc980_rtc_driver = {
+	.remove     = __exit_p(nuc980_rtc_remove),
+	.suspend    = nuc980_rtc_suspend,
+	.resume     = nuc980_rtc_resume,
+	.probe      = nuc980_rtc_probe,
+	.driver		= {
+		.name	= "nuc980-rtc",
+		.owner	= THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_rtc_of_match),
+	},
+};
+
+module_platform_driver(nuc980_rtc_driver);
+
+MODULE_AUTHOR("nuvoton");
+MODULE_DESCRIPTION("nuc980 RTC driver");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-rtc");
diff -uprN linux-4.4.194/drivers/spi/Kconfig NUC980-linux-4.4.194/drivers/spi/Kconfig
--- linux-4.4.194/drivers/spi/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/spi/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -346,6 +346,177 @@ config SPI_MT65XX
 	  say Y or M here.If you are not sure, say N.
 	  SPI drivers for Mediatek MT65XX and MT81XX series ARM SoCs.
 
+config SPI_NUC980_QSPI0
+	tristate "Nuvoton NUC980 Series QSPI Port 0"
+	depends on ARCH_NUC980
+	select SPI_BITBANG
+	help
+	  SPI driver for Nuvoton NUC980 Series ARM SoCs
+
+choice
+	prompt "QSPI0 pin selection by transfer mode"
+	default SPI_NUC970_QSPI0_NORMAL
+	depends on SPI_NUC980_QSPI0
+	help
+	  Select QSPI0 multi-function pin.
+	  Can be PD2 ~ PD5 or additional PD6 and PD7 for quad mode.
+
+config SPI_NUC980_QSPI0_NORMAL
+	bool "Normal mode"
+config SPI_NUC980_QSPI0_QUAD
+	bool "Quad mode"
+endchoice
+
+choice
+	prompt "QSPI0 TX/RX by PDMA or not"
+	default SPI_NUC980_QSPI0_PDMA
+	depends on SPI_NUC980_QSPI0
+	help
+	  Select QSPI0 enable or disable PDMA.
+
+config SPI_NUC980_QSPI0_PDMA
+	bool "Use PDMA"
+config SPI_NUC980_QSPI0_NO_PDMA
+	bool "No PDMA"
+endchoice
+
+config SPI_NUC980_QSPI0_SS1
+	tristate "QSPI0 enable pin for the second chip select"
+	depends on SPI_NUC980_QSPI0
+	help
+	  Enable the second chip select pin for QSPI0.
+
+choice
+	prompt "Pin selection"
+	default SPI_NUC980_QSPI0_SS1_PD0
+	depends on SPI_NUC980_QSPI0_SS1
+	help
+	  Select QSPI0 second chip select pin . Can be PD0 or PA0.
+
+config SPI_NUC980_QSPI0_SS1_PD0
+	bool "Use SS1 (PD0)"
+config SPI_NUC980_QSPI0_SS1_PA0
+	bool "Use SS1 (PA0)"
+
+endchoice
+
+config SPI_NUC980_SPI0
+	tristate "Nuvoton NUC980 Series SPI Port 0"
+	depends on ARCH_NUC980
+	select SPI_BITBANG
+	help
+	  SPI driver for Nuvoton NUC980 Series ARM SoCs
+
+choice
+	prompt "SPI0 IO port selection"
+	default SPI_NUC980_SPI0_PD
+	depends on SPI_NUC980_SPI0
+
+config SPI_NUC980_SPI0_PD
+	bool "Port D"
+config SPI_NUC980_SPI0_PC
+	bool "Port C"
+endchoice
+
+choice
+	prompt "SPI0 TX/RX by PDMA or not"
+	default SPI_NUC980_SPI0_PDMA
+	depends on SPI_NUC980_SPI0
+	help
+	  Select SPI0 enable or disable PDMA.
+
+config SPI_NUC980_SPI0_PDMA
+	bool "Use PDMA"
+config SPI_NUC980_SPI0_NO_PDMA
+	bool "No PDMA"
+endchoice
+
+config SPI_NUC980_SPI0_SS1
+	tristate "SPI0 enable pin for the second chip select"
+	depends on SPI_NUC980_SPI0
+	help
+	  Enable the second chip select pin for SPI0.
+
+choice
+	prompt "Pin selection"
+	default SPI_NUC980_SPI0_SS1_PD1
+	depends on SPI_NUC980_SPI0_SS1 && SPI_NUC980_SPI0_PD
+	help
+	  Select SPI0 second chip select pin . Can be PD1 or PG15.
+
+config SPI_NUC980_SPI0_SS1_PD1
+	bool "Use SS1 (PD1)"
+config SPI_NUC980_SPI0_SS1_PG15
+	bool "Use SS1 (PG15)"
+
+endchoice
+
+choice
+	prompt "Pin selection"
+	default SPI_NUC980_SPI0_SS1_PC0
+	depends on SPI_NUC980_SPI0_SS1 && SPI_NUC980_SPI0_PC
+	help
+	  Select SPI0 second chip select pin . Can be PD1 or PG15.
+
+config SPI_NUC980_SPI0_SS1_PC0
+	bool "Use SS1 (PC0)"
+
+endchoice
+
+config SPI_NUC980_SPI1
+	tristate "Nuvoton NUC980 Series SPI Port 1"
+	depends on ARCH_NUC980
+	select SPI_BITBANG
+	help
+	  SPI driver for Nuvoton NUC980 Series ARM SoCs
+
+choice
+	prompt "SPI1 IO port selection"
+	default SPI_NUC980_SPI1_PB
+	depends on SPI_NUC980_SPI1
+
+config SPI_NUC980_SPI1_PB9_12
+	bool "Port B9 ~ B12"
+config SPI_NUC980_SPI1_PB4_7
+	bool "Port B4 ~ B7"
+config SPI_NUC980_SPI1_PG
+	bool "Port G"
+endchoice
+
+choice
+	prompt "SPI1 TX/RX by PDMA or not"
+	default SPI_NUC980_SPI1_PDMA
+	depends on SPI_NUC980_SPI1
+	help
+	  SPI1 enable or disable PDMA.
+
+config SPI_NUC980_SPI1_PDMA
+	bool "Use PDMA"
+config SPI_NUC980_SPI1_NO_PDMA
+	bool "No PDMA"
+endchoice
+
+config SPI_NUC980_SPI1_SS1
+	tristate "SPI1 enable pin for the second chip select"
+	depends on SPI_NUC980_SPI1
+	help
+	  Enable the second chip select pin for SPI1.
+
+choice
+	prompt "Pin selection"
+	default SPI_NUC980_SPI1_SS1_PB1
+	depends on SPI_NUC980_SPI1_SS1
+	help
+	  Select SPI1 second chip select pin . Can be PB1 or PG15.
+
+config SPI_NUC980_SPI1_SS1_PB1
+	bool "Use SS1 (PB1)"
+config SPI_NUC980_SPI1_SS1_PG15
+	bool "Use SS1 (PG15)"
+
+endchoice
+
+
 config SPI_OC_TINY
 	tristate "OpenCores tiny SPI"
 	depends on GPIOLIB || COMPILE_TEST
diff -uprN linux-4.4.194/drivers/spi/Makefile NUC980-linux-4.4.194/drivers/spi/Makefile
--- linux-4.4.194/drivers/spi/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/spi/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -93,3 +93,6 @@ obj-$(CONFIG_SPI_XILINX)		+= spi-xilinx.
 obj-$(CONFIG_SPI_XLP)			+= spi-xlp.o
 obj-$(CONFIG_SPI_XTENSA_XTFPGA)		+= spi-xtensa-xtfpga.o
 obj-$(CONFIG_SPI_ZYNQMP_GQSPI)		+= spi-zynqmp-gqspi.o
+obj-$(CONFIG_SPI_NUC980_QSPI0)          += spi-nuc980-qspi0.o
+obj-$(CONFIG_SPI_NUC980_SPI0)           += spi-nuc980-spi0.o
+obj-$(CONFIG_SPI_NUC980_SPI1)           += spi-nuc980-spi1.o
diff -uprN linux-4.4.194/drivers/spi/spi-nuc980-qspi0.c NUC980-linux-4.4.194/drivers/spi/spi-nuc980-qspi0.c
--- linux-4.4.194/drivers/spi/spi-nuc980-qspi0.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/spi/spi-nuc980-qspi0.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1002 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/gpio.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+
+#include <linux/spi/spi.h>
+#include <linux/spi/spi_bitbang.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/spi-nuc980.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/map.h>
+#include <asm/mach/irq.h>
+#include <asm/irq.h>
+
+#include <mach/hardware.h>
+#include <mach/regs-gcr.h>
+
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <mach/regs-pdma.h>
+
+#include <linux/platform_data/dma-nuc980.h>
+
+#include <mach/map.h>
+
+/* spi registers offset */
+#define REG_CTL		0x00
+#define REG_CLKDIV	0x04
+#define REG_SSCTL	0x08
+#define REG_PDMACTL	0x0C
+#define REG_FIFOCTL	0x10
+#define REG_STATUS	0x14
+#define REG_TX		0x20
+#define REG_RX		0x30
+
+/* spi register bit */
+#define UNITIEN		(0x01 << 17)
+#define TXNEG		(0x01 << 2)
+#define RXNEG		(0x01 << 1)
+#define LSB		(0x01 << 13)
+#define SELECTLEV	(0x01 << 2)
+#define SELECTPOL	(0x01 << 3)
+#define SELECTSLAVE0	0x01
+#define SELECTSLAVE1	0x02
+#define SPIEN		0x01
+
+/* define for PDMA */
+#define SPIx_TX NUC980_PA_SPI0 + 0x20
+#define SPIx_RX NUC980_PA_SPI0 + 0x30
+#define PDMA_SPIx_TX PDMA_SPI0_TX
+#define PDMA_SPIx_RX PDMA_SPI0_RX
+
+static int is_spidev = 0;
+
+#if defined(CONFIG_SPI_NUC980_QSPI0_PDMA)
+static char dummy_buf[4096];
+static volatile int qspi0_slave_done_state=0;
+static DECLARE_WAIT_QUEUE_HEAD(qspi0_slave_done);
+
+struct nuc980_ip_dma {
+	struct dma_chan                 *chan_rx;
+	struct dma_chan         *chan_tx;
+	struct scatterlist              sgrx;
+	struct scatterlist              sgtx;
+	struct dma_async_tx_descriptor  *rxdesc;
+	struct dma_async_tx_descriptor  *txdesc;
+	struct dma_slave_config slave_config;
+};
+
+static struct nuc980_ip_dma dma;
+struct nuc980_mem_alloc qspi0_src_mem_p;
+struct nuc980_mem_alloc qspi0_dest_mem_p;
+
+struct nuc980_dma_done  qspi0_dma_slave_done;
+#endif
+
+struct nuc980_spi {
+	struct spi_bitbang	bitbang;
+	struct completion	done;
+	void __iomem		*regs;
+	int			irq;
+	unsigned int 		len;
+	unsigned int		count;
+	const void		*tx;
+	void			*rx;
+	struct clk		*clk;
+	struct resource		*ioarea;
+	struct spi_master	*master;
+	struct spi_device	*curdev;
+	struct device		*dev;
+	struct nuc980_spi_info *pdata;
+	spinlock_t		lock;
+	struct resource		*res;
+};
+
+#if defined(CONFIG_SPI_NUC980_QSPI0_PDMA)
+static void qspi0_nuc980_slave_dma_callback(void *arg)
+{
+	struct nuc980_dma_done *done = arg;
+
+	done->done = true;
+	qspi0_slave_done_state = 1;
+	//wake_up_interruptible(&qspi0_slave_done);
+
+	return;
+}
+#endif
+
+static inline struct nuc980_spi0 *to_hw(struct spi_device *sdev) {
+	return spi_master_get_devdata(sdev->master);
+}
+
+static inline void nuc980_slave_select(struct spi_device *spi, unsigned int ssr)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int val;
+	unsigned int cs = spi->mode & SPI_CS_HIGH ? 1 : 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_SSCTL);
+
+	if (!cs)
+		val &= ~SELECTLEV;
+	else
+		val |= SELECTLEV;
+
+	if(spi->chip_select == 0) {
+		if (!ssr)
+			val &= ~SELECTSLAVE0;
+		else
+			val |= SELECTSLAVE0;
+	} else {
+		if (!ssr)
+			val &= ~SELECTSLAVE1;
+		else
+			val |= SELECTSLAVE1;
+	}
+
+	while (__raw_readl(hw->regs + REG_STATUS) & 1); //wait busy
+
+	__raw_writel(val, hw->regs + REG_SSCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_qspi0_chipsel(struct spi_device *spi, int value)
+{
+	switch (value) {
+	case BITBANG_CS_INACTIVE:
+		nuc980_slave_select(spi, 0);
+		break;
+
+	case BITBANG_CS_ACTIVE:
+		nuc980_slave_select(spi, 1);
+		break;
+	}
+}
+
+static inline void nuc980_qspi0_setup_txbitlen(struct nuc980_spi *hw,
+                unsigned int txbitlen)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+	val &= ~0x1f00;
+	if(txbitlen != 32)
+		val |= (txbitlen << 8);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline unsigned int hw_tx(struct nuc980_spi *hw, unsigned int count)
+{
+	const unsigned char *tx_byte = hw->tx;
+	const unsigned short *tx_short = hw->tx;
+	const unsigned int *tx_int = hw->tx;
+	int bwp = hw->pdata->txbitlen;
+
+	if(bwp <= 8)
+		return tx_byte ? tx_byte[count] : 0;
+	else if(bwp <= 16)
+		return tx_short ? tx_short[count] : 0;
+	else
+		return tx_int ? tx_int[count] : 0;
+}
+
+static inline void hw_rx(struct nuc980_spi *hw, unsigned int data, int count)
+{
+	unsigned char *rx_byte = hw->rx;
+	unsigned short *rx_short = hw->rx;
+	unsigned int *rx_int = hw->rx;
+	int bwp = hw->pdata->txbitlen;
+
+	if(bwp <= 8)
+		rx_byte[count] = data;
+	else if(bwp <= 16)
+		rx_short[count] = data;
+	else
+		rx_int[count] = data;
+}
+
+static int nuc980_qspi0_txrx(struct spi_device *spi, struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+#if defined(CONFIG_SPI_NUC980_QSPI0_PDMA)
+	struct nuc980_ip_dma *pdma=&dma;
+	struct nuc980_dma_config dma_crx,dma_ctx;
+	dma_cookie_t            cookie;
+#elif defined(CONFIG_SPI_NUC980_QSPI0_NO_PDMA)
+	unsigned int	i;
+
+	hw->tx = t->tx_buf;
+	hw->rx = t->rx_buf;
+#endif
+
+	__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //CWWeng : RXRST & TXRST
+	while (__raw_readl(hw->regs + REG_STATUS) & (1<<23)); //TXRXRST
+#if defined(CONFIG_SPI_NUC980_QSPI0_PDMA)
+
+	/* For short length transmission, using CPU instead */
+	if ((t->len < 100)) {
+		unsigned int	i;
+
+		hw->tx = t->tx_buf;
+		hw->rx = t->rx_buf;
+
+		if(t->rx_nbits & SPI_NBITS_QUAD) {
+			__raw_writel(((__raw_readl(hw->regs + REG_CTL)|0x400000) & ~0x100000), hw->regs + REG_CTL);//Enable Quad mode, direction input
+		}
+
+		if (hw->rx) {
+			for(i = 0; i < t->len; i++) {
+				__raw_writel(hw_tx(hw, i), hw->regs + REG_TX);
+				while (((__raw_readl(hw->regs + REG_STATUS) & 0x100) == 0x100)); //RXEMPTY
+				hw_rx(hw, __raw_readl(hw->regs + REG_RX), i);
+			}
+		} else {
+			for(i = 0; i < t->len; i++) {
+				while (((__raw_readl(hw->regs + REG_STATUS) & 0x20000) == 0x20000)); //TXFULL
+				__raw_writel(hw_tx(hw, i), hw->regs + REG_TX);
+			}
+		}
+
+		__raw_writel((__raw_readl(hw->regs + REG_CTL) & ~0x700000), hw->regs + REG_CTL);//Restore to single mode, direction input
+
+
+	} else {
+
+		if (t->rx_buf) {
+			if(t->rx_nbits & SPI_NBITS_QUAD) {
+				__raw_writel(((__raw_readl(hw->regs + REG_CTL)|0x400000) & ~0x100000), hw->regs + REG_CTL);//Enable Quad mode, direction input
+			}
+
+			/* prepare the RX dma transfer */
+			sg_init_table(&pdma->sgrx, 1);
+			pdma->slave_config.src_addr = SPIx_RX;
+			if (!is_spidev && !(t->len % 4) && !(((int)t->rx_buf) % 4)) {
+				__raw_writel((__raw_readl(hw->regs + REG_CTL)&~(0x1F00))|(0x80000), hw->regs + REG_CTL);//32 bits,byte reorder
+				pdma->slave_config.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
+				pdma->sgrx.length=t->len/4;
+			} else {
+				pdma->slave_config.src_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+				pdma->sgrx.length=t->len;
+			}
+			pdma->slave_config.src_maxburst = 1;
+			pdma->slave_config.direction = DMA_DEV_TO_MEM;
+			pdma->slave_config.device_fc = false;
+			dmaengine_slave_config(pdma->chan_rx,&(pdma->slave_config));
+
+			pdma->sgrx.dma_address = dma_map_single(hw->dev,
+			                                        (void *)t->rx_buf,
+			                                        t->len, DMA_FROM_DEVICE);
+			if (dma_mapping_error(hw->dev, pdma->sgrx.dma_address)) {
+				dev_err(hw->dev, "tx dma map error\n");
+			}
+
+			dma_crx.reqsel = PDMA_SPIx_RX;
+			dma_crx.timeout_counter = 0;
+			dma_crx.timeout_prescaler = 0;
+			dma_crx.en_sc = 0;
+			pdma->rxdesc=pdma->chan_rx->device->device_prep_slave_sg(pdma->chan_rx,
+			                &pdma->sgrx,
+			                1,
+			                DMA_FROM_DEVICE,
+			                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+			                (void *)&dma_crx); //PDMA Request Source Select
+			if (!pdma->rxdesc) {
+				printk("pdma->rxdesc=NULL\n");
+				BUG();
+			}
+			qspi0_dma_slave_done.done = false;
+			pdma->rxdesc->callback = qspi0_nuc980_slave_dma_callback;
+			pdma->rxdesc->callback_param = &qspi0_dma_slave_done;
+			cookie = pdma->rxdesc->tx_submit(pdma->rxdesc);
+			if (dma_submit_error(cookie)) {
+				printk("rx cookie=%d\n",cookie);
+				BUG();
+			}
+		}
+
+		/* prepare the TX dma transfer */
+		sg_init_table(&pdma->sgtx, 1);
+		pdma->slave_config.dst_addr = SPIx_TX;
+
+		if (!is_spidev && !(t->len % 4) && !(((int)t->tx_buf) % 4)) {
+			__raw_writel((__raw_readl(hw->regs + REG_CTL)&~(0x1F00))|(0x80000), hw->regs + REG_CTL);//32 bits,byte reorder
+			pdma->slave_config.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
+			pdma->sgtx.length=t->len/4;
+		} else {
+			pdma->slave_config.dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+			pdma->sgtx.length=t->len;
+		}
+
+		pdma->slave_config.dst_maxburst = 1;
+		pdma->slave_config.direction = DMA_MEM_TO_DEV;
+		dmaengine_slave_config(pdma->chan_tx,&(pdma->slave_config));
+
+		if (t->tx_buf) {
+			pdma->sgtx.dma_address = dma_map_single(hw->dev,
+			                                        (void *)t->tx_buf,
+			                                        t->len, DMA_TO_DEVICE);
+			if (dma_mapping_error(hw->dev, pdma->sgtx.dma_address)) {
+				dev_err(hw->dev, "tx dma map error\n");
+			}
+		} else {
+			pdma->sgtx.dma_address=virt_to_phys(dummy_buf);
+		}
+
+		dma_ctx.reqsel = PDMA_SPIx_TX;
+		dma_ctx.timeout_counter = 0;
+		dma_ctx.timeout_prescaler = 0;
+		dma_ctx.en_sc = 0;
+		pdma->txdesc=pdma->chan_tx->device->device_prep_slave_sg(pdma->chan_tx,
+		                &pdma->sgtx,
+		                1,
+		                DMA_TO_DEVICE,
+		                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+		                (void *)&dma_ctx);
+		if (!pdma->txdesc) {
+			printk("pdma->txdex=NULL\n");
+			BUG();
+		}
+
+		if (!t->rx_buf) {
+			pdma->txdesc->callback = qspi0_nuc980_slave_dma_callback;
+			pdma->txdesc->callback_param = &qspi0_dma_slave_done;
+		} else {
+			pdma->txdesc->callback = NULL;
+			pdma->txdesc->callback_param = NULL;
+		}
+
+		cookie = pdma->txdesc->tx_submit(pdma->txdesc);
+		if (dma_submit_error(cookie)) {
+			printk("tx cookie=%d\n",cookie);
+			BUG();
+		}
+
+
+		if (t->rx_buf)
+			__raw_writel(__raw_readl(hw->regs + REG_PDMACTL)|(0x3), hw->regs + REG_PDMACTL); //Enable SPIx TX/RX PDMA
+		else
+			__raw_writel(__raw_readl(hw->regs + REG_PDMACTL)|(0x1), hw->regs + REG_PDMACTL); //Enable SPIx TX PDMA
+
+		//wait_event_interruptible(qspi0_slave_done, (qspi0_slave_done_state != 0));
+		while (qspi0_slave_done_state == 0);
+
+		qspi0_slave_done_state=0;
+
+#if 0 //QUAD + byte reorder issue
+		while (__raw_readl(hw->regs + REG_STATUS) & 1); //wait busy
+#else
+		__raw_writel((__raw_readl(hw->regs + REG_CTL) & ~SPIEN), hw->regs + REG_CTL); //Disable SPIEN
+		__raw_writel(__raw_readl(hw->regs + REG_PDMACTL)&~(0x3), hw->regs + REG_PDMACTL); //Disable SPIx TX/RX PDMA
+		__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //RXRST & TXRST
+		while (__raw_readl(hw->regs + REG_STATUS) & 0x800000); //TXRXRST
+		__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x300, hw->regs + REG_FIFOCTL); //TXFBCLR/RXFBCLR
+		__raw_writel((__raw_readl(hw->regs + REG_CTL) | SPIEN), hw->regs + REG_CTL); //Enable SPIEN
+#endif
+
+		__raw_writel(((__raw_readl(hw->regs + REG_CTL) & ~(0x81F00))|0x800), hw->regs + REG_CTL); //restore to 8 bits, no byte reorder
+		__raw_writel(((__raw_readl(hw->regs + REG_CTL) & ~(0x400000)) & ~0x100000), hw->regs + REG_CTL);//Disable Quad mode, direction input
+
+
+		/* unmap buffers if mapped above */
+		if (t->rx_buf)
+			dma_unmap_single(hw->dev, pdma->sgrx.dma_address, t->len,
+			                 DMA_FROM_DEVICE);
+		if (t->tx_buf)
+			dma_unmap_single(hw->dev, pdma->sgtx.dma_address, t->len,
+			                 DMA_TO_DEVICE);
+
+	}
+
+#elif defined(CONFIG_SPI_NUC980_QSPI0_NO_PDMA)
+
+	if(t->rx_nbits & SPI_NBITS_QUAD) {
+		__raw_writel(((__raw_readl(hw->regs + REG_CTL)|0x400000) & ~0x100000), hw->regs + REG_CTL);//Enable Quad mode, direction input
+	}
+
+	if (hw->rx) {
+		for(i = 0; i < t->len; i++) {
+			__raw_writel(hw_tx(hw, i), hw->regs + REG_TX);
+			while (((__raw_readl(hw->regs + REG_STATUS) & 0x100) == 0x100)); //RXEMPTY
+			hw_rx(hw, __raw_readl(hw->regs + REG_RX), i);
+		}
+	} else {
+		for(i = 0; i < t->len; i++) {
+			while (((__raw_readl(hw->regs + REG_STATUS) & 0x20000) == 0x20000)); //TXFULL
+			__raw_writel(hw_tx(hw, i), hw->regs + REG_TX);
+		}
+	}
+
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) & ~0x700000), hw->regs + REG_CTL);//Restore to single mode, direction input
+#endif
+
+	return t->len;
+}
+
+
+static inline void nuc980_set_clock_polarity(struct nuc980_spi *hw, unsigned int polarity)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (polarity)
+		val |= SELECTPOL;
+	else
+		val &= ~SELECTPOL;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_tx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= TXNEG;
+	else
+		val &= ~TXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_rx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= RXNEG;
+	else
+		val &= ~RXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_send_first(struct nuc980_spi *hw, unsigned int lsb)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (lsb)
+		val |= LSB;
+	else
+		val &= ~LSB;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_set_sleep(struct nuc980_spi *hw, unsigned int sleep)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	val &= ~(0x0f << 4);
+
+	if (sleep)
+		val |= (sleep << 4);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+
+static inline void nuc980_set_divider(struct nuc980_spi *hw)
+{
+	__raw_writel(hw->pdata->divider, hw->regs + REG_CLKDIV);
+}
+
+static int nuc980_qspi0_update_state(struct spi_device *spi,
+                                     struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int clk;
+	unsigned int div;
+	unsigned int bpw;
+	unsigned int hz;
+	unsigned char spimode;
+
+	if (strcmp(spi->modalias,"spidev")) {
+		is_spidev = 0;
+	} else {
+		is_spidev = 1;
+	}
+
+	bpw = t ? t->bits_per_word : spi->bits_per_word;
+	hz  = t ? t->speed_hz : spi->max_speed_hz;
+
+	if(hw->pdata->txbitlen != bpw)
+		hw->pdata->txbitlen = bpw;
+
+	if(hw->pdata->hz != hz) {
+		clk = clk_get_rate(hw->clk);
+		div = DIV_ROUND_UP(clk, hz) - 1;
+		hw->pdata->hz = hz;
+		hw->pdata->divider = div;
+	}
+
+	//Mode 0: CPOL=0, CPHA=0; active high
+	//Mode 1: CPOL=0, CPHA=1 ;active low
+	//Mode 2: CPOL=1, CPHA=0 ;active low
+	//Mode 3: POL=1, CPHA=1;active high
+	if (spi->mode & SPI_CPOL)
+		hw->pdata->clkpol = 1;
+	else
+		hw->pdata->clkpol = 0;
+
+	spimode = spi->mode & 0xff; //remove dual/quad bit
+
+	if ((spimode == SPI_MODE_0) || (spimode == SPI_MODE_3)) {
+		hw->pdata->txneg = 1;
+		hw->pdata->rxneg = 0;
+	} else {
+		hw->pdata->txneg = 0;
+		hw->pdata->rxneg = 1;
+	}
+
+	if (spi->mode & SPI_LSB_FIRST)
+		hw->pdata->lsb = 1;
+	else
+		hw->pdata->lsb = 0;
+
+	return 0;
+}
+
+static int nuc980_qspi0_setupxfer(struct spi_device *spi,
+                                  struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_qspi0_update_state(spi, t);
+	if (ret)
+		return ret;
+
+	nuc980_qspi0_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_divider(hw);
+
+	return 0;
+}
+
+static int nuc980_qspi0_setup(struct spi_device *spi)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_qspi0_update_state(spi, NULL);
+	if (ret)
+		return ret;
+
+	mutex_lock(&hw->bitbang.lock);
+	if (!hw->bitbang.busy) {
+		nuc980_set_divider(hw);
+		nuc980_slave_select(spi, 0);
+	}
+	mutex_unlock(&hw->bitbang.lock);
+
+	return 0;
+}
+
+static void nuc980_init_spi(struct nuc980_spi *hw)
+{
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	spin_lock_init(&hw->lock);
+
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_sleep(hw, hw->pdata->sleep);
+	nuc980_qspi0_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_set_divider(hw);
+}
+
+#ifdef CONFIG_USE_OF
+static struct nuc980_spi_info *nuc980_qspi0_parse_dt(struct device *dev) {
+	struct nuc980_spi_info *sci;
+	u32 temp;
+
+	sci = devm_kzalloc(dev, sizeof(*sci), GFP_KERNEL);
+	if (!sci) {
+		dev_err(dev, "memory allocation for spi_info failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	if (of_property_read_u32(dev->of_node, "num_cs", &temp)) {
+		dev_warn(dev, "can't get num_cs from dt\n");
+		sci->num_cs = 2;
+	} else {
+		sci->num_cs = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "lsb", &temp)) {
+		dev_warn(dev, "can't get lsb from dt\n");
+		sci->lsb = 0;
+	} else {
+		sci->lsb = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txneg", &temp)) {
+		dev_warn(dev, "can't get txneg from dt\n");
+		sci->txneg = 1;
+	} else {
+		sci->txneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "clkpol", &temp)) {
+		dev_warn(dev, "can't get clkpol from dt\n");
+		sci->clkpol = 0;
+	} else {
+		sci->clkpol = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "rxneg", &temp)) {
+		dev_warn(dev, "can't get rxneg from dt\n");
+		sci->rxneg = 0;
+	} else {
+		sci->rxneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "divider", &temp)) {
+		dev_warn(dev, "can't get divider from dt\n");
+		sci->divider = 4;
+	} else {
+		sci->divider = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "sleep", &temp)) {
+		dev_warn(dev, "can't get sleep from dt\n");
+		sci->sleep = 0;
+	} else {
+		sci->sleep = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txbitlen", &temp)) {
+		dev_warn(dev, "can't get txbitlen from dt\n");
+		sci->txbitlen = 8;
+	} else {
+		sci->txbitlen = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "bus_num", &temp)) {
+		dev_warn(dev, "can't get bus_num from dt\n");
+		sci->bus_num = 0;
+	} else {
+		sci->bus_num = temp;
+	}
+
+	return sci;
+}
+#else
+static struct nuc980_spi_info *nuc980_qspi0_parse_dt(struct device *dev) {
+	return dev->platform_data;
+}
+#endif
+
+static int nuc980_qspi0_probe(struct platform_device *pdev)
+{
+#if defined(CONFIG_SPI_NUC980_QSPI0_PDMA)
+	struct nuc980_ip_dma *pdma=&dma;
+	dma_cap_mask_t mask;
+#endif
+	struct nuc980_spi *hw;
+	struct spi_master *master;
+	int err = 0;
+	struct pinctrl *p;
+
+#if defined(CONFIG_SPI_NUC980_QSPI0_PDMA)
+	/* Zero out the capability mask then initialize it for a slave channel that is
+	 * private.
+	 */
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_SLAVE, mask);
+	dma_cap_set(DMA_PRIVATE, mask);
+
+	/* Request the DMA channel from the DMA engine and then use the device from
+	 * the channel for the proxy channel also.
+	 */
+	pdma->chan_rx = dma_request_channel(mask, NULL, NULL);
+	if (!pdma->chan_rx) {
+		printk("RX DMA channel request error\n");
+		return -1;
+	}
+	pdma->chan_rx->private=(void *)1;
+	printk("RX %s: %s module removed\n",__func__, dma_chan_name(pdma->chan_rx));
+
+	pdma->chan_tx = dma_request_channel(mask, NULL, NULL);
+	if (!pdma->chan_tx) {
+		printk("TX DMA channel request error\n");
+		return -1;
+	}
+	pdma->chan_tx->private=(void *)1;
+	printk("TX %s: %s module removed\n",__func__, dma_chan_name(pdma->chan_tx));
+#endif
+
+	master = spi_alloc_master(&pdev->dev, sizeof(struct nuc980_spi));
+	if (master == NULL) {
+		dev_err(&pdev->dev, "No memory for spi_master\n");
+		err = -ENOMEM;
+		goto err_nomem;
+	}
+
+	hw = spi_master_get_devdata(master);
+	hw->master = spi_master_get(master);
+	hw->pdata = nuc980_qspi0_parse_dt(&pdev->dev);
+	hw->dev = &pdev->dev;
+
+	if (hw->pdata == NULL) {
+		dev_err(&pdev->dev, "No platform data supplied\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+	platform_set_drvdata(pdev, hw);
+	init_completion(&hw->done);
+#if defined(CONFIG_SPI_NUC980_QSPI0_NORMAL)
+	master->mode_bits          = (SPI_MODE_0 | SPI_TX_DUAL | SPI_RX_DUAL | SPI_CS_HIGH | SPI_LSB_FIRST | SPI_CPHA | SPI_CPOL);
+#elif defined(CONFIG_SPI_NUC980_QSPI0_QUAD)
+	master->mode_bits          = (SPI_MODE_0 | SPI_TX_DUAL | SPI_RX_DUAL | SPI_TX_QUAD | SPI_RX_QUAD | SPI_CS_HIGH | SPI_LSB_FIRST | SPI_CPHA | SPI_CPOL);
+#endif
+	master->dev.of_node        = pdev->dev.of_node;
+	master->num_chipselect     = hw->pdata->num_cs;
+	master->bus_num            = hw->pdata->bus_num;
+	hw->bitbang.master         = hw->master;
+	hw->bitbang.setup_transfer = nuc980_qspi0_setupxfer;
+	hw->bitbang.chipselect     = nuc980_qspi0_chipsel;
+	hw->bitbang.txrx_bufs      = nuc980_qspi0_txrx;
+	hw->bitbang.master->setup  = nuc980_qspi0_setup;
+
+	hw->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (hw->res == NULL) {
+		dev_err(&pdev->dev, "Cannot get IORESOURCE_MEM\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+#if defined(CONFIG_USE_OF)
+	hw->regs = devm_ioremap_resource(&pdev->dev, hw->res);
+#else
+	hw->ioarea = request_mem_region(hw->res->start,
+	                                resource_size(hw->res), pdev->name);
+
+	if (hw->ioarea == NULL) {
+		dev_err(&pdev->dev, "Cannot reserve region\n");
+		err = -ENXIO;
+		goto err_pdata;
+	}
+
+	hw->regs = ioremap(hw->res->start, resource_size(hw->res));
+	if (hw->regs == NULL) {
+		dev_err(&pdev->dev, "Cannot map IO\n");
+		err = -ENXIO;
+		goto err_iomap;
+	}
+#endif
+
+	hw->irq = platform_get_irq(pdev, 0);
+	if (hw->irq < 0) {
+		dev_err(&pdev->dev, "No IRQ specified\n");
+		err = -ENOENT;
+		goto err_irq;
+	}
+
+	hw->clk = clk_get(NULL, "qspi0_eclk");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	hw->clk = clk_get(NULL, "qspi0");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+
+#if defined(CONFIG_USE_OF)
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined(CONFIG_SPI_NUC980_QSPI0_NORMAL) && !defined(CONFIG_SPI_NUC980_QSPI0_SS1)
+	p = devm_pinctrl_get_select(&pdev->dev, "qspi0-normal");
+#elif defined(CONFIG_SPI_NUC980_QSPI0_NORMAL) && defined(CONFIG_SPI_NUC980_QSPI0_SS1_PD0)
+	p = devm_pinctrl_get_select(&pdev->dev, "qspi0-ss1-PD0");
+#elif defined(CONFIG_SPI_NUC980_QSPI0_NORMAL) && defined(CONFIG_SPI_NUC980_QSPI0_SS1_PA0)
+	p = devm_pinctrl_get_select(&pdev->dev, "qspi0-ss1-PA0");
+#elif defined(CONFIG_SPI_NUC980_QSPI0_QUAD) && !defined(CONFIG_SPI_NUC980_QSPI0_SS1)
+	p = devm_pinctrl_get_select(&pdev->dev, "qspi0-quad");
+#elif defined(CONFIG_SPI_NUC980_QSPI0_QUAD) && defined(CONFIG_SPI_NUC980_QSPI0_SS1_PD0)
+	p = devm_pinctrl_get_select(&pdev->dev, "qspi0-quad-ss1-PD0");
+#elif defined(CONFIG_SPI_NUC980_QSPI0_QUAD) && defined(CONFIG_SPI_NUC980_QSPI0_SS1_PA0)
+	p = devm_pinctrl_get_select(&pdev->dev, "qspi0-quad-ss1-PA0");
+#endif
+#endif
+	if(IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve spi pin by mode\n");
+		err = PTR_ERR(p);
+		goto err_register;
+	}
+
+	nuc980_init_spi(hw);
+
+	__raw_writel(__raw_readl(hw->regs + REG_CTL) | SPIEN, hw->regs + REG_CTL); /* enable SPI */
+
+	err = spi_bitbang_start(&hw->bitbang);
+	if (err) {
+		dev_err(&pdev->dev, "Failed to register SPI master\n");
+		goto err_register;
+	}
+
+	return 0;
+
+err_register:
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+err_clk:
+	free_irq(hw->irq, hw);
+err_irq:
+	iounmap(hw->regs);
+#ifndef CONFIG_USE_OF
+err_iomap:
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#endif
+err_pdata:
+	spi_master_put(hw->master);
+
+err_nomem:
+	return err;
+}
+
+static int nuc980_qspi0_remove(struct platform_device *dev)
+{
+	struct nuc980_spi *hw = platform_get_drvdata(dev);
+
+	free_irq(hw->irq, hw);
+	platform_set_drvdata(dev, NULL);
+	spi_bitbang_stop(&hw->bitbang);
+
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+
+	iounmap(hw->regs);
+
+#ifndef CONFIG_USE_OF
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#else
+	kfree(hw->pdata);
+#endif
+
+	spi_master_put(hw->master);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_qspi0_suspend(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	while (__raw_readl(hw->regs + REG_STATUS) & 1) //wait busy
+		msleep(1);
+
+	// disable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) & ~0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static int nuc980_qspi0_resume(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	// enable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) | 0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_qspi0_pmops = {
+	.suspend    = nuc980_qspi0_suspend,
+	.resume     = nuc980_qspi0_resume,
+};
+
+#define NUC980_QSPI0_PMOPS (&nuc980_qspi0_pmops)
+
+#else
+#define NUC980_QSPI0_PMOPS NULL
+#endif
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_qspi0_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-qspi0" } ,
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_qspi0_of_match);
+#endif
+
+static struct platform_driver nuc980_qspi0_driver = {
+	.probe      = nuc980_qspi0_probe,
+	.remove     = nuc980_qspi0_remove,
+	.driver     = {
+		.name   = "nuc980-qspi0",
+		.owner  = THIS_MODULE,
+		.pm	= NUC980_QSPI0_PMOPS,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_qspi0_of_match),
+#endif
+	},
+};
+module_platform_driver(nuc980_qspi0_driver);
+
+MODULE_DESCRIPTION("nuc980 spi driver!");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-qspi0");
diff -uprN linux-4.4.194/drivers/spi/spi-nuc980-spi0.c NUC980-linux-4.4.194/drivers/spi/spi-nuc980-spi0.c
--- linux-4.4.194/drivers/spi/spi-nuc980-spi0.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/spi/spi-nuc980-spi0.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,937 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/gpio.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+
+#include <linux/spi/spi.h>
+#include <linux/spi/spi_bitbang.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/spi-nuc980.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/map.h>
+#include <asm/mach/irq.h>
+#include <asm/irq.h>
+
+#include <mach/hardware.h>
+#include <mach/regs-gcr.h>
+
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <mach/regs-pdma.h>
+
+#include <linux/platform_data/dma-nuc980.h>
+
+/* spi registers offset */
+#define REG_CTL		0x00
+#define REG_CLKDIV	0x04
+#define REG_SSCTL	0x08
+#define REG_PDMACTL	0x0C
+#define REG_FIFOCTL	0x10
+#define REG_STATUS	0x14
+#define REG_TX		0x20
+#define REG_RX		0x30
+
+/* spi register bit */
+#define UNITIEN		(0x01 << 17)
+#define TXNEG		(0x01 << 2)
+#define RXNEG		(0x01 << 1)
+#define LSB		(0x01 << 13)
+#define SELECTLEV	(0x01 << 2)
+#define SELECTPOL	(0x01 << 3)
+#define SELECTSLAVE0	0x01
+#define SELECTSLAVE1	0x02
+#define SPIEN		0x01
+
+/* define for PDMA */
+#define SPIx_TX NUC980_PA_SPI1 + 0x20
+#define SPIx_RX NUC980_PA_SPI1 + 0x30
+#define PDMA_SPIx_TX PDMA_SPI1_TX
+#define PDMA_SPIx_RX PDMA_SPI1_RX
+
+static int is_spidev = 0;
+
+#if defined(CONFIG_SPI_NUC980_SPI0_PDMA)
+static char dummy_buf[4096];
+static volatile int spi0_slave_done_state=0;
+static DECLARE_WAIT_QUEUE_HEAD(spi0_slave_done);
+
+struct nuc980_ip_dma {
+	struct dma_chan                 *chan_rx;
+	struct dma_chan         *chan_tx;
+	struct scatterlist              sgrx;
+	struct scatterlist              sgtx;
+	struct dma_async_tx_descriptor  *rxdesc;
+	struct dma_async_tx_descriptor  *txdesc;
+	struct dma_slave_config slave_config;
+};
+
+static struct nuc980_ip_dma dma;
+struct nuc980_mem_alloc spi0_src_mem_p;
+struct nuc980_mem_alloc spi0_dest_mem_p;
+
+struct nuc980_dma_done  spi0_dma_slave_done;
+#endif
+
+struct nuc980_spi {
+	struct spi_bitbang	bitbang;
+	struct completion	done;
+	void __iomem		*regs;
+	int			irq;
+	unsigned int 		len;
+	unsigned int		count;
+	const void		*tx;
+	void			*rx;
+	struct clk		*clk;
+	struct resource		*ioarea;
+	struct spi_master	*master;
+	struct spi_device	*curdev;
+	struct device		*dev;
+	struct nuc980_spi_info *pdata;
+	spinlock_t		lock;
+	struct resource		*res;
+};
+
+
+#if defined(CONFIG_SPI_NUC980_SPI0_PDMA)
+static void spi0_nuc980_slave_dma_callback(void *arg)
+{
+	struct nuc980_dma_done *done = arg;
+
+	done->done = true;
+	spi0_slave_done_state = 1;
+	wake_up_interruptible(&spi0_slave_done);
+	return;
+}
+#endif
+
+static inline struct nuc980_spi0 *to_hw(struct spi_device *sdev) {
+	return spi_master_get_devdata(sdev->master);
+}
+
+static inline void nuc980_slave_select(struct spi_device *spi, unsigned int ssr)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int val;
+	unsigned int cs = spi->mode & SPI_CS_HIGH ? 1 : 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_SSCTL);
+
+	if (!cs)
+		val &= ~SELECTLEV;
+	else
+		val |= SELECTLEV;
+
+	if(spi->chip_select == 0) {
+		if (!ssr)
+			val &= ~SELECTSLAVE0;
+		else
+			val |= SELECTSLAVE0;
+	} else {
+		if (!ssr)
+			val &= ~SELECTSLAVE1;
+		else
+			val |= SELECTSLAVE1;
+	}
+
+	__raw_writel(val, hw->regs + REG_SSCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_spi0_chipsel(struct spi_device *spi, int value)
+{
+	switch (value) {
+	case BITBANG_CS_INACTIVE:
+		nuc980_slave_select(spi, 0);
+		break;
+
+	case BITBANG_CS_ACTIVE:
+		nuc980_slave_select(spi, 1);
+		break;
+	}
+}
+
+static inline void nuc980_spi0_setup_txbitlen(struct nuc980_spi *hw,
+                unsigned int txbitlen)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+	val &= ~0x1f00;
+	if(txbitlen != 32)
+		val |= (txbitlen << 8);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline unsigned int hw_tx(struct nuc980_spi *hw, unsigned int count)
+{
+	const unsigned char *tx_byte = hw->tx;
+	const unsigned short *tx_short = hw->tx;
+	const unsigned int *tx_int = hw->tx;
+	int bwp = hw->pdata->txbitlen;
+
+	if(bwp <= 8)
+		return tx_byte ? tx_byte[count] : 0;
+	else if(bwp <= 16)
+		return tx_short ? tx_short[count] : 0;
+	else
+		return tx_int ? tx_int[count] : 0;
+}
+
+static inline void hw_rx(struct nuc980_spi *hw, unsigned int data, int count)
+{
+	unsigned char *rx_byte = hw->rx;
+	unsigned short *rx_short = hw->rx;
+	unsigned int *rx_int = hw->rx;
+	int bwp = hw->pdata->txbitlen;
+
+	if(bwp <= 8)
+		rx_byte[count] = data;
+	else if(bwp <= 16)
+		rx_short[count] = data;
+	else
+		rx_int[count] = data;
+}
+
+static int nuc980_spi0_txrx(struct spi_device *spi, struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+#if defined(CONFIG_SPI_NUC980_SPI0_PDMA)
+	struct nuc980_ip_dma *pdma=&dma;
+	struct nuc980_dma_config dma_crx,dma_ctx;
+	dma_cookie_t            cookie;
+#elif defined(CONFIG_SPI_NUC980_SPI0_NO_PDMA)
+	unsigned int    i;
+
+	hw->tx = t->tx_buf;
+	hw->rx = t->rx_buf;
+#endif
+
+	__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //CWWeng : RXRST & TXRST
+	while (__raw_readl(hw->regs + REG_STATUS) & (1<<23)); //TXRXRST
+
+#if defined(CONFIG_SPI_NUC980_SPI0_PDMA)
+	__raw_writel(__raw_readl(hw->regs + REG_PDMACTL)&~(0x3), hw->regs + REG_PDMACTL); //Disable SPIx TX/RX PDMA
+
+	if (t->rx_buf) {
+		/* prepare the RX dma transfer */
+		sg_init_table(&pdma->sgrx, 1);
+		pdma->slave_config.src_addr = SPIx_RX;
+		if (!is_spidev && !(t->len % 4) && !(((int)t->rx_buf) % 4)) {
+			__raw_writel((__raw_readl(hw->regs + REG_CTL)&~(0x1F00))|(0x80000), hw->regs + REG_CTL);//32 bits,byte reorder
+			pdma->slave_config.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
+			pdma->sgrx.length=t->len/4;
+		} else {
+			pdma->slave_config.src_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+			pdma->sgrx.length=t->len;
+		}
+		pdma->slave_config.src_maxburst = 1;
+		pdma->slave_config.direction = DMA_DEV_TO_MEM;
+		pdma->slave_config.device_fc = false;
+		dmaengine_slave_config(pdma->chan_rx,&(pdma->slave_config));
+
+		pdma->sgrx.dma_address = dma_map_single(hw->dev,
+		                                        (void *)t->rx_buf,
+		                                        t->len, DMA_FROM_DEVICE);
+		if (dma_mapping_error(hw->dev, pdma->sgrx.dma_address)) {
+			dev_err(hw->dev, "tx dma map error\n");
+		}
+
+		dma_crx.reqsel = PDMA_SPIx_RX;
+		dma_crx.timeout_counter = 0;
+		dma_crx.timeout_prescaler = 0;
+		dma_crx.en_sc = 0;
+		pdma->rxdesc=pdma->chan_rx->device->device_prep_slave_sg(pdma->chan_rx,
+		                &pdma->sgrx,
+		                1,
+		                DMA_FROM_DEVICE,
+		                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+		                (void *)&dma_crx); //PDMA Request Source Select
+		if (!pdma->rxdesc) {
+			printk("pdma->rxdesc=NULL\n");
+			BUG();
+		}
+		spi0_dma_slave_done.done = false;
+		pdma->rxdesc->callback = spi0_nuc980_slave_dma_callback;
+		pdma->rxdesc->callback_param = &spi0_dma_slave_done;
+		cookie = pdma->rxdesc->tx_submit(pdma->rxdesc);
+		if (dma_submit_error(cookie)) {
+			printk("rx cookie=%d\n",cookie);
+			BUG();
+		}
+	}
+
+	/* prepare the TX dma transfer */
+	sg_init_table(&pdma->sgtx, 1);
+	pdma->slave_config.dst_addr = SPIx_TX;
+	if (!is_spidev && !(t->len % 4) && !(((int)t->tx_buf) % 4)) {
+		__raw_writel((__raw_readl(hw->regs + REG_CTL)&~(0x1F00))|(0x80000), hw->regs + REG_CTL);//32 bits,byte reorder
+		pdma->slave_config.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
+		pdma->sgtx.length=t->len/4;
+	} else {
+		pdma->slave_config.dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+		pdma->sgtx.length=t->len;
+	}
+	pdma->slave_config.dst_maxburst = 1;
+	pdma->slave_config.direction = DMA_MEM_TO_DEV;
+	dmaengine_slave_config(pdma->chan_tx,&(pdma->slave_config));
+	if (t->tx_buf) {
+		pdma->sgtx.dma_address = dma_map_single(hw->dev,
+		                                        (void *)t->tx_buf,
+		                                        t->len, DMA_TO_DEVICE);
+		if (dma_mapping_error(hw->dev, pdma->sgtx.dma_address)) {
+			dev_err(hw->dev, "tx dma map error\n");
+		}
+	} else {
+		pdma->sgtx.dma_address=virt_to_phys(dummy_buf);
+	}
+
+	dma_ctx.reqsel = PDMA_SPIx_TX;
+	dma_ctx.timeout_counter = 0;
+	dma_ctx.timeout_prescaler = 0;
+	dma_ctx.en_sc = 0;
+	pdma->txdesc=pdma->chan_tx->device->device_prep_slave_sg(pdma->chan_tx,
+	                &pdma->sgtx,
+	                1,
+	                DMA_TO_DEVICE,
+	                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+	                (void *)&dma_ctx);
+	if (!pdma->txdesc) {
+		printk("pdma->txdex=NULL\n");
+		BUG();
+	}
+
+	if (!t->rx_buf) {
+		pdma->txdesc->callback = spi0_nuc980_slave_dma_callback;
+		pdma->txdesc->callback_param = &spi0_dma_slave_done;
+	} else {
+		pdma->txdesc->callback = NULL;
+		pdma->txdesc->callback_param = NULL;
+	}
+
+	cookie = pdma->txdesc->tx_submit(pdma->txdesc);
+	if (dma_submit_error(cookie)) {
+		printk("tx cookie=%d\n",cookie);
+		BUG();
+	}
+
+	if (t->rx_buf)
+		__raw_writel(__raw_readl(hw->regs + REG_PDMACTL)|(0x3), hw->regs + REG_PDMACTL); //Enable SPIx TX/RX PDMA
+	else
+		__raw_writel(__raw_readl(hw->regs + REG_PDMACTL)|(0x1), hw->regs + REG_PDMACTL); //Enable SPIx TX PDMA
+
+	wait_event_interruptible(spi0_slave_done, (spi0_slave_done_state != 0));
+	spi0_slave_done_state=0;
+
+	while(__raw_readl(hw->regs + REG_STATUS) & 1); //wait busy
+
+	/* unmap buffers if mapped above */
+	if (t->rx_buf)
+		dma_unmap_single(hw->dev, pdma->sgrx.dma_address, t->len,
+		                 DMA_FROM_DEVICE);
+	if (t->tx_buf)
+		dma_unmap_single(hw->dev, pdma->sgtx.dma_address, t->len,
+		                 DMA_TO_DEVICE);
+
+	__raw_writel(((__raw_readl(hw->regs + REG_CTL) & ~(0x81F00))|0x800), hw->regs + REG_CTL); //restore to 8 bits, no byte reorder
+
+
+#elif defined(CONFIG_SPI_NUC980_SPI0_NO_PDMA)
+	if (hw->rx) {
+		for(i = 0; i < t->len; i++) {
+			__raw_writel(hw_tx(hw, i), hw->regs + REG_TX);
+			while (((__raw_readl(hw->regs + REG_STATUS) & 0x100) == 0x100)); //RXEMPTY
+			hw_rx(hw, __raw_readl(hw->regs + REG_RX), i);
+		}
+	} else {
+		for(i = 0; i < t->len; i++) {
+			while (((__raw_readl(hw->regs + REG_STATUS) & 0x20000) == 0x20000)); //TXFULL
+			__raw_writel(hw_tx(hw, i), hw->regs + REG_TX);
+		}
+	}
+
+#endif
+
+	return t->len;
+}
+
+
+static inline void nuc980_set_clock_polarity(struct nuc980_spi *hw, unsigned int polarity)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (polarity)
+		val |= SELECTPOL;
+	else
+		val &= ~SELECTPOL;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_tx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= TXNEG;
+	else
+		val &= ~TXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_rx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= RXNEG;
+	else
+		val &= ~RXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_send_first(struct nuc980_spi *hw, unsigned int lsb)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (lsb)
+		val |= LSB;
+	else
+		val &= ~LSB;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_set_sleep(struct nuc980_spi *hw, unsigned int sleep)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	val &= ~(0x0f << 4);
+
+	if (sleep)
+		val |= (sleep << 4);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+
+static inline void nuc980_set_divider(struct nuc980_spi *hw)
+{
+	__raw_writel(hw->pdata->divider, hw->regs + REG_CLKDIV);
+}
+
+static int nuc980_spi0_update_state(struct spi_device *spi,
+                                    struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int clk;
+	unsigned int div;
+	unsigned int bpw;
+	unsigned int hz;
+	unsigned char spimode;
+
+	if (strcmp(spi->modalias,"spidev")) {
+		is_spidev = 0;
+	} else {
+		is_spidev = 1;
+	}
+
+	bpw = t ? t->bits_per_word : spi->bits_per_word;
+	hz  = t ? t->speed_hz : spi->max_speed_hz;
+
+	if(hw->pdata->txbitlen != bpw)
+		hw->pdata->txbitlen = bpw;
+
+	if(hw->pdata->hz != hz) {
+		clk = clk_get_rate(hw->clk);
+		div = DIV_ROUND_UP(clk, hz) - 1;
+		hw->pdata->hz = hz;
+		hw->pdata->divider = div;
+	}
+
+	//Mode 0: CPOL=0, CPHA=0; active high
+	//Mode 1: CPOL=0, CPHA=1 ;active low
+	//Mode 2: CPOL=1, CPHA=0 ;active low
+	//Mode 3: POL=1, CPHA=1;active high
+	if (spi->mode & SPI_CPOL)
+		hw->pdata->clkpol = 1;
+	else
+		hw->pdata->clkpol = 0;
+
+	spimode = spi->mode & 0xff; //remove dual/quad bit
+
+	if ((spimode == SPI_MODE_0) || (spimode == SPI_MODE_3)) {
+		hw->pdata->txneg = 1;
+		hw->pdata->rxneg = 0;
+	} else {
+		hw->pdata->txneg = 0;
+		hw->pdata->rxneg = 1;
+	}
+
+	if (spi->mode & SPI_LSB_FIRST)
+		hw->pdata->lsb = 1;
+	else
+		hw->pdata->lsb = 0;
+
+	return 0;
+}
+
+static int nuc980_spi0_setupxfer(struct spi_device *spi,
+                                 struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_spi0_update_state(spi, t);
+	if (ret)
+		return ret;
+
+	nuc980_set_divider(hw);
+	nuc980_spi0_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_divider(hw);
+
+	return 0;
+}
+
+static int nuc980_spi0_setup(struct spi_device *spi)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_spi0_update_state(spi, NULL);
+	if (ret)
+		return ret;
+
+	mutex_lock(&hw->bitbang.lock);
+	if (!hw->bitbang.busy) {
+		nuc980_set_divider(hw);
+		nuc980_slave_select(spi, 0);
+	}
+	mutex_unlock(&hw->bitbang.lock);
+
+	return 0;
+}
+
+static void nuc980_init_spi(struct nuc980_spi *hw)
+{
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	spin_lock_init(&hw->lock);
+
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_sleep(hw, hw->pdata->sleep);
+	nuc980_spi0_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_set_divider(hw);
+}
+
+#ifdef CONFIG_USE_OF
+static struct nuc980_spi_info *nuc980_spi0_parse_dt(struct device *dev) {
+	struct nuc980_spi_info *sci;
+	u32 temp;
+
+	sci = devm_kzalloc(dev, sizeof(*sci), GFP_KERNEL);
+	if (!sci) {
+		dev_err(dev, "memory allocation for spi_info failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	if (of_property_read_u32(dev->of_node, "num_cs", &temp)) {
+		dev_warn(dev, "can't get num_cs from dt\n");
+		sci->num_cs = 2;
+	} else {
+		sci->num_cs = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "lsb", &temp)) {
+		dev_warn(dev, "can't get lsb from dt\n");
+		sci->lsb = 0;
+	} else {
+		sci->lsb = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txneg", &temp)) {
+		dev_warn(dev, "can't get txneg from dt\n");
+		sci->txneg = 1;
+	} else {
+		sci->txneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "clkpol", &temp)) {
+		dev_warn(dev, "can't get clkpol from dt\n");
+		sci->clkpol = 0;
+	} else {
+		sci->clkpol = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "rxneg", &temp)) {
+		dev_warn(dev, "can't get rxneg from dt\n");
+		sci->rxneg = 0;
+	} else {
+		sci->rxneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "divider", &temp)) {
+		dev_warn(dev, "can't get divider from dt\n");
+		sci->divider = 4;
+	} else {
+		sci->divider = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "sleep", &temp)) {
+		dev_warn(dev, "can't get sleep from dt\n");
+		sci->sleep = 0;
+	} else {
+		sci->sleep = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txbitlen", &temp)) {
+		dev_warn(dev, "can't get txbitlen from dt\n");
+		sci->txbitlen = 8;
+	} else {
+		sci->txbitlen = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "bus_num", &temp)) {
+		dev_warn(dev, "can't get bus_num from dt\n");
+		sci->bus_num = 0;
+	} else {
+		sci->bus_num = temp;
+	}
+
+	return sci;
+}
+#else
+static struct nuc980_spi_info *nuc980_spi0_parse_dt(struct device *dev) {
+	return dev->platform_data;
+}
+#endif
+
+static int nuc980_spi0_probe(struct platform_device *pdev)
+{
+#if defined(CONFIG_SPI_NUC980_SPI0_PDMA)
+	struct nuc980_ip_dma *pdma=&dma;
+	dma_cap_mask_t mask;
+#endif
+	struct nuc980_spi *hw;
+	struct spi_master *master;
+	int err = 0;
+	struct pinctrl *p;
+
+#if defined(CONFIG_SPI_NUC980_SPI0_PDMA)
+	/* Zero out the capability mask then initialize it for a slave channel that is
+	 * private.
+	 */
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_SLAVE, mask);
+	dma_cap_set(DMA_PRIVATE, mask);
+
+	/* Request the DMA channel from the DMA engine and then use the device from
+	 * the channel for the proxy channel also.
+	 */
+	pdma->chan_rx = dma_request_channel(mask, NULL, NULL);
+	if (!pdma->chan_rx) {
+		printk("RX DMA channel request error\n");
+		return -1;
+	}
+	pdma->chan_rx->private=(void *)1;
+	printk("RX %s: %s module removed\n",__func__, dma_chan_name(pdma->chan_rx));
+
+	pdma->chan_tx = dma_request_channel(mask, NULL, NULL);
+	if (!pdma->chan_tx) {
+		printk("TX DMA channel request error\n");
+		return -1;
+	}
+	pdma->chan_tx->private=(void *)1;
+	printk("TX %s: %s module removed\n",__func__, dma_chan_name(pdma->chan_tx));
+#endif
+
+	master = spi_alloc_master(&pdev->dev, sizeof(struct nuc980_spi));
+	if (master == NULL) {
+		dev_err(&pdev->dev, "No memory for spi_master\n");
+		err = -ENOMEM;
+		goto err_nomem;
+	}
+
+	hw = spi_master_get_devdata(master);
+	hw->master = spi_master_get(master);
+	hw->pdata = nuc980_spi0_parse_dt(&pdev->dev);
+	hw->dev = &pdev->dev;
+
+	if (hw->pdata == NULL) {
+		dev_err(&pdev->dev, "No platform data supplied\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+	platform_set_drvdata(pdev, hw);
+	init_completion(&hw->done);
+	master->mode_bits          = (SPI_MODE_0 | SPI_CS_HIGH | SPI_LSB_FIRST | SPI_CPHA | SPI_CPOL);
+	master->dev.of_node        = pdev->dev.of_node;
+	master->num_chipselect     = hw->pdata->num_cs;
+	master->bus_num            = hw->pdata->bus_num;
+	hw->bitbang.master         = hw->master;
+	hw->bitbang.setup_transfer = nuc980_spi0_setupxfer;
+	hw->bitbang.chipselect     = nuc980_spi0_chipsel;
+	hw->bitbang.txrx_bufs      = nuc980_spi0_txrx;
+	hw->bitbang.master->setup  = nuc980_spi0_setup;
+
+	hw->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (hw->res == NULL) {
+		dev_err(&pdev->dev, "Cannot get IORESOURCE_MEM\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+#if defined(CONFIG_USE_OF)
+	hw->regs = devm_ioremap_resource(&pdev->dev, hw->res);
+#else
+	hw->ioarea = request_mem_region(hw->res->start,
+	                                resource_size(hw->res), pdev->name);
+
+	if (hw->ioarea == NULL) {
+		dev_err(&pdev->dev, "Cannot reserve region\n");
+		err = -ENXIO;
+		goto err_pdata;
+	}
+
+	hw->regs = ioremap(hw->res->start, resource_size(hw->res));
+	if (hw->regs == NULL) {
+		dev_err(&pdev->dev, "Cannot map IO\n");
+		err = -ENXIO;
+		goto err_iomap;
+	}
+#endif
+
+	hw->irq = platform_get_irq(pdev, 0);
+	if (hw->irq < 0) {
+		dev_err(&pdev->dev, "No IRQ specified\n");
+		err = -ENOENT;
+		goto err_irq;
+	}
+
+	hw->clk = clk_get(NULL, "spi0_eclk");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	hw->clk = clk_get(NULL, "spi0");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+#if defined(CONFIG_USE_OF)
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined(CONFIG_SPI_NUC980_SPI0_PD) && !defined(CONFIG_SPI_NUC980_SPI0_SS1)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi0");
+#elif defined(CONFIG_SPI_NUC980_SPI0_PD) && defined(CONFIG_SPI_NUC980_SPI0_SS1_PD1)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi0-ss1-PD1");
+#elif defined(CONFIG_SPI_NUC980_SPI0_PD) && defined(CONFIG_SPI_NUC980_SPI0_SS1_PG15)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi0-ss1-PG15");
+#elif defined(CONFIG_SPI_NUC980_SPI0_PC) && !defined(CONFIG_SPI_NUC980_SPI0_SS1)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi0-PC");
+#elif defined(CONFIG_SPI_NUC980_SPI0_PD) && defined(CONFIG_SPI_NUC980_SPI0_SS1_PC0)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi0-ss1-PC0");
+#endif
+#endif
+	if(IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve spi pin by mode\n");
+		err = PTR_ERR(p);
+		goto err_register;
+	}
+
+	nuc980_init_spi(hw);
+
+	__raw_writel(__raw_readl(hw->regs + REG_CTL) | SPIEN, hw->regs + REG_CTL); /* enable SPI */
+
+	err = spi_bitbang_start(&hw->bitbang);
+	if (err) {
+		dev_err(&pdev->dev, "Failed to register SPI master\n");
+		goto err_register;
+	}
+
+	return 0;
+
+err_register:
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+err_clk:
+	free_irq(hw->irq, hw);
+err_irq:
+	iounmap(hw->regs);
+#ifndef CONFIG_USE_OF
+err_iomap:
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#endif
+err_pdata:
+	spi_master_put(hw->master);
+
+err_nomem:
+	return err;
+}
+
+static int nuc980_spi0_remove(struct platform_device *dev)
+{
+	struct nuc980_spi *hw = platform_get_drvdata(dev);
+
+	free_irq(hw->irq, hw);
+	platform_set_drvdata(dev, NULL);
+	spi_bitbang_stop(&hw->bitbang);
+
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+
+	iounmap(hw->regs);
+
+#ifndef CONFIG_USE_OF
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#else
+	kfree(hw->pdata);
+#endif
+
+	spi_master_put(hw->master);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_spi0_suspend(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	while(__raw_readl(hw->regs + REG_STATUS) & 1) //wait busy
+		msleep(1);
+
+	// disable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) & ~0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static int nuc980_spi0_resume(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	// enable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) | 0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_spi0_pmops = {
+	.suspend    = nuc980_spi0_suspend,
+	.resume     = nuc980_spi0_resume,
+};
+
+#define NUC980_SPI0_PMOPS (&nuc980_spi0_pmops)
+
+#else
+#define NUC980_SPI0_PMOPS NULL
+#endif
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_spi0_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-spi0" } ,
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_spi0_of_match);
+#endif
+
+static struct platform_driver nuc980_spi0_driver = {
+	.probe      = nuc980_spi0_probe,
+	.remove     = nuc980_spi0_remove,
+	.driver     = {
+		.name   = "nuc980-spi0",
+		.owner  = THIS_MODULE,
+		.pm	= NUC980_SPI0_PMOPS,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_spi0_of_match),
+#endif
+	},
+};
+module_platform_driver(nuc980_spi0_driver);
+
+MODULE_DESCRIPTION("nuc980 spi driver!");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-spi0");
diff -uprN linux-4.4.194/drivers/spi/spi-nuc980-spi1.c NUC980-linux-4.4.194/drivers/spi/spi-nuc980-spi1.c
--- linux-4.4.194/drivers/spi/spi-nuc980-spi1.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/spi/spi-nuc980-spi1.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,935 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/gpio.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+
+#include <linux/spi/spi.h>
+#include <linux/spi/spi_bitbang.h>
+
+#include <mach/mfp.h>
+#include <linux/platform_data/spi-nuc980.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/map.h>
+#include <asm/mach/irq.h>
+#include <asm/irq.h>
+
+#include <mach/hardware.h>
+#include <mach/regs-gcr.h>
+
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <mach/regs-pdma.h>
+
+#include <linux/platform_data/dma-nuc980.h>
+
+/* spi registers offset */
+#define REG_CTL		0x00
+#define REG_CLKDIV	0x04
+#define REG_SSCTL	0x08
+#define REG_PDMACTL	0x0C
+#define REG_FIFOCTL	0x10
+#define REG_STATUS	0x14
+#define REG_TX		0x20
+#define REG_RX		0x30
+
+/* spi register bit */
+#define UNITIEN		(0x01 << 17)
+#define TXNEG		(0x01 << 2)
+#define RXNEG		(0x01 << 1)
+#define LSB		(0x01 << 13)
+#define SELECTLEV	(0x01 << 2)
+#define SELECTPOL	(0x01 << 3)
+#define SELECTSLAVE0	0x01
+#define SELECTSLAVE1	0x02
+#define SPIEN		0x01
+
+/* define for PDMA */
+#define SPIx_TX NUC980_PA_SPI2 + 0x20
+#define SPIx_RX NUC980_PA_SPI2 + 0x30
+#define PDMA_SPIx_TX PDMA_SPI2_TX
+#define PDMA_SPIx_RX PDMA_SPI2_RX
+
+static int is_spidev = 0;
+
+#if defined(CONFIG_SPI_NUC980_SPI1_PDMA)
+static char dummy_buf[4096];
+static volatile int spi1_slave_done_state=0;
+static DECLARE_WAIT_QUEUE_HEAD(spi1_slave_done);
+
+struct nuc980_ip_dma {
+	struct dma_chan                 *chan_rx;
+	struct dma_chan                 *chan_tx;
+	struct scatterlist              sgrx;
+	struct scatterlist              sgtx;
+	struct dma_async_tx_descriptor  *rxdesc;
+	struct dma_async_tx_descriptor  *txdesc;
+	struct dma_slave_config slave_config;
+};
+
+static struct nuc980_ip_dma dma;
+struct nuc980_mem_alloc spi1_src_mem_p;
+struct nuc980_mem_alloc spi1_dest_mem_p;
+
+struct nuc980_dma_done  spi1_dma_slave_done;
+#endif
+
+struct nuc980_spi {
+	struct spi_bitbang	bitbang;
+	struct completion	done;
+	void __iomem		*regs;
+	int			irq;
+	unsigned int 		len;
+	unsigned int		count;
+	const void		*tx;
+	void			*rx;
+	struct clk		*clk;
+	struct resource		*ioarea;
+	struct spi_master	*master;
+	struct spi_device	*curdev;
+	struct device		*dev;
+	struct nuc980_spi_info *pdata;
+	spinlock_t		lock;
+	struct resource		*res;
+};
+
+#if defined(CONFIG_SPI_NUC980_SPI1_PDMA)
+static void spi1_nuc980_slave_dma_callback(void *arg)
+{
+	struct nuc980_dma_done *done = arg;
+
+	done->done = true;
+	spi1_slave_done_state = 1;
+	wake_up_interruptible(&spi1_slave_done);
+	return;
+}
+#endif
+
+static inline struct nuc980_spi1 *to_hw(struct spi_device *sdev) {
+	return spi_master_get_devdata(sdev->master);
+}
+
+static inline void nuc980_slave_select(struct spi_device *spi, unsigned int ssr)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int val;
+	unsigned int cs = spi->mode & SPI_CS_HIGH ? 1 : 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_SSCTL);
+
+	if (!cs)
+		val &= ~SELECTLEV;
+	else
+		val |= SELECTLEV;
+
+	if(spi->chip_select == 0) {
+		if (!ssr)
+			val &= ~SELECTSLAVE0;
+		else
+			val |= SELECTSLAVE0;
+	} else {
+		if (!ssr)
+			val &= ~SELECTSLAVE1;
+		else
+			val |= SELECTSLAVE1;
+	}
+
+	__raw_writel(val, hw->regs + REG_SSCTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_spi1_chipsel(struct spi_device *spi, int value)
+{
+	switch (value) {
+	case BITBANG_CS_INACTIVE:
+		nuc980_slave_select(spi, 0);
+		break;
+
+	case BITBANG_CS_ACTIVE:
+		nuc980_slave_select(spi, 1);
+		break;
+	}
+}
+
+static inline void nuc980_spi1_setup_txbitlen(struct nuc980_spi *hw,
+                unsigned int txbitlen)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+	val &= ~0x1f00;
+	if(txbitlen != 32)
+		val |= (txbitlen << 8);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline unsigned int hw_tx(struct nuc980_spi *hw, unsigned int count)
+{
+	const unsigned char *tx_byte = hw->tx;
+	const unsigned short *tx_short = hw->tx;
+	const unsigned int *tx_int = hw->tx;
+	int bwp = hw->pdata->txbitlen;
+
+	if(bwp <= 8)
+		return tx_byte ? tx_byte[count] : 0;
+	else if(bwp <= 16)
+		return tx_short ? tx_short[count] : 0;
+	else
+		return tx_int ? tx_int[count] : 0;
+}
+
+static inline void hw_rx(struct nuc980_spi *hw, unsigned int data, int count)
+{
+	unsigned char *rx_byte = hw->rx;
+	unsigned short *rx_short = hw->rx;
+	unsigned int *rx_int = hw->rx;
+	int bwp = hw->pdata->txbitlen;
+
+	if(bwp <= 8)
+		rx_byte[count] = data;
+	else if(bwp <= 16)
+		rx_short[count] = data;
+	else
+		rx_int[count] = data;
+}
+
+static int nuc980_spi1_txrx(struct spi_device *spi, struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+#if defined(CONFIG_SPI_NUC980_SPI1_PDMA)
+	struct nuc980_ip_dma *pdma=&dma;
+	struct nuc980_dma_config dma_crx,dma_ctx;
+	dma_cookie_t            cookie;
+#elif defined(CONFIG_SPI_NUC980_SPI1_NO_PDMA)
+	unsigned int    i;
+
+	hw->tx = t->tx_buf;
+	hw->rx = t->rx_buf;
+#endif
+
+	__raw_writel(__raw_readl(hw->regs + REG_FIFOCTL) | 0x3, hw->regs + REG_FIFOCTL); //CWWeng : RXRST & TXRST
+	while (__raw_readl(hw->regs + REG_STATUS) & (1<<23)); //TXRXRST
+
+#if defined(CONFIG_SPI_NUC980_SPI1_PDMA)
+	__raw_writel(__raw_readl(hw->regs + REG_PDMACTL)&~(0x3), hw->regs + REG_PDMACTL); //Disable SPIx TX/RX PDMA
+
+	if (t->rx_buf) {
+		/* prepare the RX dma transfer */
+		sg_init_table(&pdma->sgrx, 1);
+		pdma->slave_config.src_addr = SPIx_RX;
+		if (!is_spidev && !(t->len % 4) && !(((int)t->rx_buf) % 4)) {
+			__raw_writel((__raw_readl(hw->regs + REG_CTL)&~(0x1F00))|(0x80000), hw->regs + REG_CTL);//32 bits,byte reorder
+			pdma->slave_config.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
+			pdma->sgrx.length=t->len/4;
+		} else {
+			pdma->slave_config.src_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+			pdma->sgrx.length=t->len;
+		}
+		pdma->slave_config.src_maxburst = 1;
+		pdma->slave_config.direction = DMA_DEV_TO_MEM;
+		pdma->slave_config.device_fc = false;
+		dmaengine_slave_config(pdma->chan_rx,&(pdma->slave_config));
+
+		pdma->sgrx.dma_address = dma_map_single(hw->dev,
+		                                        (void *)t->rx_buf,
+		                                        t->len, DMA_FROM_DEVICE);
+		if (dma_mapping_error(hw->dev, pdma->sgrx.dma_address)) {
+			dev_err(hw->dev, "tx dma map error\n");
+		}
+
+		dma_crx.reqsel = PDMA_SPIx_RX;
+		dma_crx.timeout_counter = 0;
+		dma_crx.timeout_prescaler = 0;
+		dma_crx.en_sc = 0;
+		pdma->rxdesc=pdma->chan_rx->device->device_prep_slave_sg(pdma->chan_rx,
+		                &pdma->sgrx,
+		                1,
+		                DMA_FROM_DEVICE,
+		                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+		                (void *)&dma_crx); //PDMA Request Source Select
+		if (!pdma->rxdesc) {
+			printk("pdma->rxdesc=NULL\n");
+			BUG();
+		}
+		spi1_dma_slave_done.done = false;
+		pdma->rxdesc->callback = spi1_nuc980_slave_dma_callback;
+		pdma->rxdesc->callback_param = &spi1_dma_slave_done;
+		cookie = pdma->rxdesc->tx_submit(pdma->rxdesc);
+		if (dma_submit_error(cookie)) {
+			printk("rx cookie=%d\n",cookie);
+			BUG();
+		}
+	}
+
+	/* prepare the TX dma transfer */
+	sg_init_table(&pdma->sgtx, 1);
+	pdma->slave_config.dst_addr = SPIx_TX;
+	if (!is_spidev && !(t->len % 4) && !(((int)t->tx_buf) % 4)) {
+		__raw_writel((__raw_readl(hw->regs + REG_CTL)&~(0x1F00))|(0x80000), hw->regs + REG_CTL);//32 bits,byte reorder
+		pdma->slave_config.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
+		pdma->sgtx.length=t->len/4;
+	} else {
+		pdma->slave_config.dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+		pdma->sgtx.length=t->len;
+	}
+	pdma->slave_config.dst_maxburst = 1;
+	pdma->slave_config.direction = DMA_MEM_TO_DEV;
+	dmaengine_slave_config(pdma->chan_tx,&(pdma->slave_config));
+	if (t->tx_buf) {
+		pdma->sgtx.dma_address = dma_map_single(hw->dev,
+		                                        (void *)t->tx_buf,
+		                                        t->len, DMA_TO_DEVICE);
+		if (dma_mapping_error(hw->dev, pdma->sgtx.dma_address)) {
+			dev_err(hw->dev, "tx dma map error\n");
+		}
+	} else {
+		pdma->sgtx.dma_address=virt_to_phys(dummy_buf);
+	}
+
+	dma_ctx.reqsel = PDMA_SPIx_TX;
+	dma_ctx.timeout_counter = 0;
+	dma_ctx.timeout_prescaler = 0;
+	dma_ctx.en_sc = 0;
+	pdma->txdesc=pdma->chan_tx->device->device_prep_slave_sg(pdma->chan_tx,
+	                &pdma->sgtx,
+	                1,
+	                DMA_TO_DEVICE,
+	                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+	                (void *)&dma_ctx);
+	if (!pdma->txdesc) {
+		printk("pdma->txdex=NULL\n");
+		BUG();
+	}
+
+	if (!t->rx_buf) {
+		pdma->txdesc->callback = spi1_nuc980_slave_dma_callback;
+		pdma->txdesc->callback_param = &spi1_dma_slave_done;
+	} else {
+		pdma->txdesc->callback = NULL;
+		pdma->txdesc->callback_param = NULL;
+	}
+
+	cookie = pdma->txdesc->tx_submit(pdma->txdesc);
+	if (dma_submit_error(cookie)) {
+		printk("tx cookie=%d\n",cookie);
+		BUG();
+	}
+
+	if (t->rx_buf)
+		__raw_writel(__raw_readl(hw->regs + REG_PDMACTL)|(0x3), hw->regs + REG_PDMACTL); //Enable SPIx TX/RX PDMA
+	else
+		__raw_writel(__raw_readl(hw->regs + REG_PDMACTL)|(0x1), hw->regs + REG_PDMACTL); //Enable SPIx TX PDMA
+
+	wait_event_interruptible(spi1_slave_done, (spi1_slave_done_state != 0));
+	spi1_slave_done_state=0;
+
+	while(__raw_readl(hw->regs + REG_STATUS) & 1); //wait busy
+
+	/* unmap buffers if mapped above */
+	if (t->rx_buf)
+		dma_unmap_single(hw->dev, pdma->sgrx.dma_address, t->len,
+		                 DMA_FROM_DEVICE);
+	if (t->tx_buf)
+		dma_unmap_single(hw->dev, pdma->sgtx.dma_address, t->len,
+		                 DMA_TO_DEVICE);
+
+	__raw_writel(((__raw_readl(hw->regs + REG_CTL) & ~(0x81F00))|0x800), hw->regs + REG_CTL); //restore to 8 bits, no byte reorder
+
+
+#elif defined(CONFIG_SPI_NUC980_SPI1_NO_PDMA)
+	if (hw->rx) {
+		for(i = 0; i < t->len; i++) {
+			__raw_writel(hw_tx(hw, i), hw->regs + REG_TX);
+			while (((__raw_readl(hw->regs + REG_STATUS) & 0x100) == 0x100)); //RXEMPTY
+			hw_rx(hw, __raw_readl(hw->regs + REG_RX), i);
+		}
+	} else {
+		for(i = 0; i < t->len; i++) {
+			while (((__raw_readl(hw->regs + REG_STATUS) & 0x20000) == 0x20000)); //TXFULL
+			__raw_writel(hw_tx(hw, i), hw->regs + REG_TX);
+		}
+	}
+
+#endif
+
+	return t->len;
+}
+
+
+static inline void nuc980_set_clock_polarity(struct nuc980_spi *hw, unsigned int polarity)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (polarity)
+		val |= SELECTPOL;
+	else
+		val &= ~SELECTPOL;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_tx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= TXNEG;
+	else
+		val &= ~TXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_rx_edge(struct nuc980_spi *hw, unsigned int edge)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (edge)
+		val |= RXNEG;
+	else
+		val &= ~RXNEG;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_send_first(struct nuc980_spi *hw, unsigned int lsb)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	if (lsb)
+		val |= LSB;
+	else
+		val &= ~LSB;
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+static inline void nuc980_set_sleep(struct nuc980_spi *hw, unsigned int sleep)
+{
+	unsigned int val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&hw->lock, flags);
+
+	val = __raw_readl(hw->regs + REG_CTL);
+
+	val &= ~(0x0f << 4);
+
+	if (sleep)
+		val |= (sleep << 4);
+
+	__raw_writel(val, hw->regs + REG_CTL);
+
+	spin_unlock_irqrestore(&hw->lock, flags);
+}
+
+
+static inline void nuc980_set_divider(struct nuc980_spi *hw)
+{
+	__raw_writel(hw->pdata->divider, hw->regs + REG_CLKDIV);
+}
+
+static int nuc980_spi1_update_state(struct spi_device *spi,
+                                    struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	unsigned int clk;
+	unsigned int div;
+	unsigned int bpw;
+	unsigned int hz;
+	unsigned char spimode;
+
+	if (strcmp(spi->modalias,"spidev")) {
+		is_spidev = 0;
+	} else {
+		is_spidev = 1;
+	}
+
+	bpw = t ? t->bits_per_word : spi->bits_per_word;
+	hz  = t ? t->speed_hz : spi->max_speed_hz;
+
+	if(hw->pdata->txbitlen != bpw)
+		hw->pdata->txbitlen = bpw;
+
+	if(hw->pdata->hz != hz) {
+		clk = clk_get_rate(hw->clk);
+		div = DIV_ROUND_UP(clk, hz) - 1;
+		hw->pdata->hz = hz;
+		hw->pdata->divider = div;
+	}
+
+	//Mode 0: CPOL=0, CPHA=0; active high
+	//Mode 1: CPOL=0, CPHA=1 ;active low
+	//Mode 2: CPOL=1, CPHA=0 ;active low
+	//Mode 3: POL=1, CPHA=1;active high
+	if (spi->mode & SPI_CPOL)
+		hw->pdata->clkpol = 1;
+	else
+		hw->pdata->clkpol = 0;
+
+	spimode = spi->mode & 0xff; //remove dual/quad bit
+
+	if ((spimode == SPI_MODE_0) || (spimode == SPI_MODE_3)) {
+		hw->pdata->txneg = 1;
+		hw->pdata->rxneg = 0;
+	} else {
+		hw->pdata->txneg = 0;
+		hw->pdata->rxneg = 1;
+	}
+
+	if (spi->mode & SPI_LSB_FIRST)
+		hw->pdata->lsb = 1;
+	else
+		hw->pdata->lsb = 0;
+
+	return 0;
+}
+
+static int nuc980_spi1_setupxfer(struct spi_device *spi,
+                                 struct spi_transfer *t)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_spi1_update_state(spi, t);
+	if (ret)
+		return ret;
+
+	nuc980_set_divider(hw);
+	nuc980_spi1_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_divider(hw);
+
+	return 0;
+}
+
+static int nuc980_spi1_setup(struct spi_device *spi)
+{
+	struct nuc980_spi *hw = (struct nuc980_spi *)to_hw(spi);
+	int ret;
+
+	ret = nuc980_spi1_update_state(spi, NULL);
+	if (ret)
+		return ret;
+
+	mutex_lock(&hw->bitbang.lock);
+	if (!hw->bitbang.busy) {
+		nuc980_set_divider(hw);
+		nuc980_slave_select(spi, 0);
+	}
+	mutex_unlock(&hw->bitbang.lock);
+
+	return 0;
+}
+
+static void nuc980_init_spi(struct nuc980_spi *hw)
+{
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	spin_lock_init(&hw->lock);
+
+	nuc980_tx_edge(hw, hw->pdata->txneg);
+	nuc980_rx_edge(hw, hw->pdata->rxneg);
+	nuc980_send_first(hw, hw->pdata->lsb);
+	nuc980_set_sleep(hw, hw->pdata->sleep);
+	nuc980_spi1_setup_txbitlen(hw, hw->pdata->txbitlen);
+	nuc980_set_clock_polarity(hw, hw->pdata->clkpol);
+	nuc980_set_divider(hw);
+}
+
+#ifdef CONFIG_USE_OF
+static struct nuc980_spi_info *nuc980_spi1_parse_dt(struct device *dev) {
+	struct nuc980_spi_info *sci;
+	u32 temp;
+
+	sci = devm_kzalloc(dev, sizeof(*sci), GFP_KERNEL);
+	if (!sci) {
+		dev_err(dev, "memory allocation for spi_info failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	if (of_property_read_u32(dev->of_node, "num_cs", &temp)) {
+		dev_warn(dev, "can't get num_cs from dt\n");
+		sci->num_cs = 2;
+	} else {
+		sci->num_cs = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "lsb", &temp)) {
+		dev_warn(dev, "can't get lsb from dt\n");
+		sci->lsb = 0;
+	} else {
+		sci->lsb = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txneg", &temp)) {
+		dev_warn(dev, "can't get txneg from dt\n");
+		sci->txneg = 1;
+	} else {
+		sci->txneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "clkpol", &temp)) {
+		dev_warn(dev, "can't get clkpol from dt\n");
+		sci->clkpol = 0;
+	} else {
+		sci->clkpol = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "rxneg", &temp)) {
+		dev_warn(dev, "can't get rxneg from dt\n");
+		sci->rxneg = 0;
+	} else {
+		sci->rxneg = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "divider", &temp)) {
+		dev_warn(dev, "can't get divider from dt\n");
+		sci->divider = 4;
+	} else {
+		sci->divider = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "sleep", &temp)) {
+		dev_warn(dev, "can't get sleep from dt\n");
+		sci->sleep = 0;
+	} else {
+		sci->sleep = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "txbitlen", &temp)) {
+		dev_warn(dev, "can't get txbitlen from dt\n");
+		sci->txbitlen = 8;
+	} else {
+		sci->txbitlen = temp;
+	}
+
+	if (of_property_read_u32(dev->of_node, "bus_num", &temp)) {
+		dev_warn(dev, "can't get bus_num from dt\n");
+		sci->bus_num = 0;
+	} else {
+		sci->bus_num = temp;
+	}
+
+	return sci;
+}
+#else
+static struct nuc980_spi_info *nuc980_spi1_parse_dt(struct device *dev) {
+	return dev->platform_data;
+}
+#endif
+
+static int nuc980_spi1_probe(struct platform_device *pdev)
+{
+#if defined(CONFIG_SPI_NUC980_SPI1_PDMA)
+	struct nuc980_ip_dma *pdma=&dma;
+	dma_cap_mask_t mask;
+#endif
+	struct nuc980_spi *hw;
+	struct spi_master *master;
+	int err = 0;
+	struct pinctrl *p;
+
+#if defined(CONFIG_SPI_NUC980_SPI1_PDMA)
+	/* Zero out the capability mask then initialize it for a slave channel that is
+	 * private.
+	 */
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_SLAVE, mask);
+	dma_cap_set(DMA_PRIVATE, mask);
+
+	/* Request the DMA channel from the DMA engine and then use the device from
+	 * the channel for the proxy channel also.
+	 */
+	pdma->chan_rx = dma_request_channel(mask, NULL, NULL);
+	if (!pdma->chan_rx) {
+		printk("RX DMA channel request error\n");
+		return -1;
+	}
+	pdma->chan_rx->private=(void *)1;
+	printk("RX %s: %s module removed\n",__func__, dma_chan_name(pdma->chan_rx));
+
+	pdma->chan_tx = dma_request_channel(mask, NULL, NULL);
+	if (!pdma->chan_tx) {
+		printk("TX DMA channel request error\n");
+		return -1;
+	}
+	pdma->chan_tx->private=(void *)1;
+	printk("TX %s: %s module removed\n",__func__, dma_chan_name(pdma->chan_tx));
+#endif
+
+	master = spi_alloc_master(&pdev->dev, sizeof(struct nuc980_spi));
+	if (master == NULL) {
+		dev_err(&pdev->dev, "No memory for spi_master\n");
+		err = -ENOMEM;
+		goto err_nomem;
+	}
+
+	hw = spi_master_get_devdata(master);
+	hw->master = spi_master_get(master);
+	hw->pdata = nuc980_spi1_parse_dt(&pdev->dev);
+	hw->dev = &pdev->dev;
+
+	if (hw->pdata == NULL) {
+		dev_err(&pdev->dev, "No platform data supplied\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+	platform_set_drvdata(pdev, hw);
+	init_completion(&hw->done);
+	master->mode_bits          = (SPI_MODE_0 | SPI_CS_HIGH | SPI_LSB_FIRST | SPI_CPHA | SPI_CPOL);
+	master->dev.of_node        = pdev->dev.of_node;
+	master->num_chipselect     = hw->pdata->num_cs;
+	master->bus_num            = hw->pdata->bus_num;
+	hw->bitbang.master         = hw->master;
+	hw->bitbang.setup_transfer = nuc980_spi1_setupxfer;
+	hw->bitbang.chipselect     = nuc980_spi1_chipsel;
+	hw->bitbang.txrx_bufs      = nuc980_spi1_txrx;
+	hw->bitbang.master->setup  = nuc980_spi1_setup;
+
+	hw->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (hw->res == NULL) {
+		dev_err(&pdev->dev, "Cannot get IORESOURCE_MEM\n");
+		err = -ENOENT;
+		goto err_pdata;
+	}
+
+#if defined(CONFIG_USE_OF)
+	hw->regs = devm_ioremap_resource(&pdev->dev, hw->res);
+#else
+	hw->ioarea = request_mem_region(hw->res->start,
+	                                resource_size(hw->res), pdev->name);
+
+	if (hw->ioarea == NULL) {
+		dev_err(&pdev->dev, "Cannot reserve region\n");
+		err = -ENXIO;
+		goto err_pdata;
+	}
+
+	hw->regs = ioremap(hw->res->start, resource_size(hw->res));
+	if (hw->regs == NULL) {
+		dev_err(&pdev->dev, "Cannot map IO\n");
+		err = -ENXIO;
+		goto err_iomap;
+	}
+#endif
+
+	hw->irq = platform_get_irq(pdev, 0);
+	if (hw->irq < 0) {
+		dev_err(&pdev->dev, "No IRQ specified\n");
+		err = -ENOENT;
+		goto err_irq;
+	}
+
+	hw->clk = clk_get(NULL, "spi1_eclk");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+	hw->clk = clk_get(NULL, "spi1");
+	if (IS_ERR(hw->clk)) {
+		dev_err(&pdev->dev, "No clock for device\n");
+		err = PTR_ERR(hw->clk);
+		goto err_clk;
+	}
+	clk_prepare(hw->clk);
+	clk_enable(hw->clk);
+
+#if defined(CONFIG_USE_OF)
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+#if defined(CONFIG_SPI_NUC980_SPI1_PB9_12) && !defined(CONFIG_SPI_NUC980_SPI1_SS1)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi1-PB9_12");
+#elif defined(CONFIG_SPI_NUC980_SPI1_PG) && !defined(CONFIG_SPI_NUC980_SPI1_SS1)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi1-PG");
+#elif defined(CONFIG_SPI_NUC980_SPI1_PG) && defined(CONFIG_SPI_NUC980_SPI1_SS1_PG15)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi1-PG-ss1");
+#elif defined(CONFIG_SPI_NUC980_SPI1_PB4_7) && !defined(CONFIG_SPI_NUC980_SPI1_SS1)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi1-PB4_7");
+#elif defined(CONFIG_SPI_NUC980_SPI1_PB4_7) && defined(CONFIG_SPI_NUC980_SPI1_SS1_PB1)
+	p = devm_pinctrl_get_select(&pdev->dev, "spi1-PB4_7-ss1");
+#endif
+#endif
+	if(IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve spi pin by mode\n");
+		err = PTR_ERR(p);
+		goto err_register;
+	}
+
+	nuc980_init_spi(hw);
+
+	__raw_writel(__raw_readl(hw->regs + REG_CTL) | SPIEN, hw->regs + REG_CTL); /* enable SPI */
+
+	err = spi_bitbang_start(&hw->bitbang);
+	if (err) {
+		dev_err(&pdev->dev, "Failed to register SPI master\n");
+		goto err_register;
+	}
+
+	return 0;
+
+err_register:
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+err_clk:
+	free_irq(hw->irq, hw);
+err_irq:
+	iounmap(hw->regs);
+#ifndef CONFIG_USE_OF
+err_iomap:
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#endif
+err_pdata:
+	spi_master_put(hw->master);
+
+err_nomem:
+	return err;
+}
+
+static int nuc980_spi1_remove(struct platform_device *dev)
+{
+	struct nuc980_spi *hw = platform_get_drvdata(dev);
+
+	free_irq(hw->irq, hw);
+	platform_set_drvdata(dev, NULL);
+	spi_bitbang_stop(&hw->bitbang);
+
+	clk_disable(hw->clk);
+	clk_put(hw->clk);
+
+	iounmap(hw->regs);
+
+#ifndef CONFIG_USE_OF
+	release_mem_region(hw->res->start, resource_size(hw->res));
+	kfree(hw->ioarea);
+#else
+	kfree(hw->pdata);
+#endif
+
+	spi_master_put(hw->master);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_spi1_suspend(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	while(__raw_readl(hw->regs + REG_STATUS) & 1) //wait busy
+		msleep(1);
+
+	// disable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) & ~0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static int nuc980_spi1_resume(struct device *dev)
+{
+	struct nuc980_spi *hw = dev_get_drvdata(dev);
+
+	// enable interrupt
+	__raw_writel((__raw_readl(hw->regs + REG_CTL) | 0x20000), hw->regs + REG_CTL);
+
+	return 0;
+}
+
+static const struct dev_pm_ops nuc980_spi1_pmops = {
+	.suspend    = nuc980_spi1_suspend,
+	.resume     = nuc980_spi1_resume,
+};
+
+#define NUC980_SPI1_PMOPS (&nuc980_spi1_pmops)
+
+#else
+#define NUC980_SPI1_PMOPS NULL
+#endif
+
+#if defined(CONFIG_USE_OF)
+static const struct of_device_id nuc980_spi1_of_match[] = {
+	{   .compatible = "nuvoton,nuc980-spi1" } ,
+	{	},
+};
+MODULE_DEVICE_TABLE(of, nuc980_spi1_of_match);
+#endif
+
+static struct platform_driver nuc980_spi1_driver = {
+	.probe      = nuc980_spi1_probe,
+	.remove     = nuc980_spi1_remove,
+	.driver     = {
+		.name   = "nuc980-spi1",
+		.owner  = THIS_MODULE,
+		.pm	= NUC980_SPI1_PMOPS,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_spi1_of_match),
+#endif
+	},
+};
+module_platform_driver(nuc980_spi1_driver);
+
+MODULE_DESCRIPTION("nuc980 spi driver!");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:nuc980-spi1");
diff -uprN linux-4.4.194/drivers/staging/mt29f_spinand/giga_spinand.c NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/giga_spinand.c
--- linux-4.4.194/drivers/staging/mt29f_spinand/giga_spinand.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/giga_spinand.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,176 @@
+/* Copyright (c) 2015, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/mtd/nand.h>
+#include <linux/spi/spi.h>
+#include "giga_spinand.h"
+
+
+void gigadevice_set_defaults(struct spi_device *spi_nand)
+{
+	struct mtd_info *mtd = (struct mtd_info *)dev_get_drvdata
+	                       (&spi_nand->dev);
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+
+	chip->ecc.size	= 0x800;
+	chip->ecc.bytes	= 0x0;
+	chip->ecc.steps	= 0x0;
+
+	chip->ecc.strength = 1;
+	chip->ecc.total	= 0;
+	chip->ecc.layout = NULL;
+}
+
+void gigadevice_read_cmd(struct spinand_cmd *cmd, u32 page_id)
+{
+	cmd->addr[0] = (u8) (page_id >> 16);
+	cmd->addr[1] = (u8) (page_id >> 8);
+	cmd->addr[2] = (u8) (page_id);
+
+}
+
+void gigadevice_read_data(struct spinand_cmd *cmd, u16 column, u32 page_id)
+{
+	cmd->addr[1] = (u8)(column >> 8);
+	cmd->addr[2] = (u8)(column);
+}
+
+void macronix_read_data(struct spinand_cmd *cmd, u16 column, u32 page_id)
+{
+	cmd->addr[0] = ((u8)(column >> 8) & MACRONIX_NORM_RW_MASK);
+	cmd->addr[1] = (u8)(column);
+}
+
+void winbond_read_data(struct spinand_cmd *cmd, u16 column, u32 page_id)
+{
+	cmd->addr[0] = (u8)(column >> 8);
+	cmd->addr[1] = (u8)(column);
+}
+
+void gigadevice_write_cmd(struct spinand_cmd *cmd, u32 page_id)
+{
+	cmd->addr[0] = (u8)(page_id >> 16);
+	cmd->addr[1] = (u8)(page_id >> 8);
+	cmd->addr[2] = (u8)(page_id);
+}
+
+void gigadevice_write_data(struct spinand_cmd *cmd, u16 column, u32 page_id)
+{
+	cmd->addr[1] = (u8)(column >> 8);
+	cmd->addr[2] = (u8)(column);
+}
+
+void macronix_write_data(struct spinand_cmd *cmd, u16 column, u32 page_id)
+{
+	cmd->addr[0] = ((u8)(column >> 8) & MACRONIX_NORM_RW_MASK);
+	cmd->addr[1] = (u8)(column);
+}
+
+void winbond_write_data(struct spinand_cmd *cmd, u16 column, u32 page_id)
+{
+	cmd->addr[0] = (u8)(column >> 8);
+	cmd->addr[1] = (u8)(column);
+}
+
+void gigadevice_erase_blk(struct spinand_cmd *cmd, u32 page_id)
+{
+	cmd->addr[0] = (u8)(page_id >> 16);
+	cmd->addr[1] = (u8)(page_id >> 8);
+	cmd->addr[2] = (u8)(page_id);
+}
+
+int gigadevice_verify_ecc(u8 status)
+{
+	int ecc_status = (status & STATUS_ECC_MASK_GIGA);
+
+	if (ecc_status == STATUS_ECC_ERROR_GIGA)
+		return SPINAND_ECC_ERROR;
+	else if (ecc_status)
+		return SPINAND_ECC_CORRECTED;
+	else
+		return 0;
+}
+
+int macronix_verify_ecc(u8 status)
+{
+	int ecc_status = (status & STATUS_ECC_MASK_MACRONIX);
+
+	if ((ecc_status == STATUS_ECC_ERROR_MACRONIX) ||
+	    (ecc_status == STATUS_ECC_MASK_MACRONIX))
+		return SPINAND_ECC_ERROR;
+	else if (ecc_status)
+		return SPINAND_ECC_CORRECTED;
+	else
+		return 0;
+}
+
+int dummy_verify_ecc(u8 status)
+{
+	return 0;
+}
+
+
+int gigadevice_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id)
+{
+	if (nand_id[0] != NAND_MFR_GIGA && nand_id[0] != NAND_MFR_ATO)
+		return -EINVAL;
+
+	if (nand_id[0] == NAND_MFR_GIGA) {
+		id[0] = nand_id[0];
+		id[1] = nand_id[1];
+	}
+
+	return 0;
+}
+
+
+int macronix_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id)
+{
+	if (nand_id[1] != NAND_MFR_MACRONIX)
+		return -EINVAL;
+
+	return 0;
+}
+
+int xtx_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id)
+{
+	if (nand_id[1] != NAND_MFR_XTX)
+		return -EINVAL;
+
+	return 0;
+}
+
+int mk_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id)
+{
+	if (nand_id[1] != NAND_MFR_MK)
+		return -EINVAL;
+
+	return 0;
+}
+
+int winbond_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id)
+{
+	if (nand_id[1] != NAND_MFR_WINBOND)
+		return -EINVAL;
+
+	return 0;
+}
+
+
+MODULE_DESCRIPTION("SPI NAND driver for Gigadevice and Macronix");
diff -uprN linux-4.4.194/drivers/staging/mt29f_spinand/giga_spinand.h NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/giga_spinand.h
--- linux-4.4.194/drivers/staging/mt29f_spinand/giga_spinand.h	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/giga_spinand.h	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,61 @@
+
+/* Copyright (c) 2015, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ */
+
+#ifndef __GIGA_SPI_NAND_H
+#define __GIGA__SPI_NAND_H
+
+#include "mt29f_spinand.h"
+
+void gigadevice_set_defaults(struct spi_device *spi_nand);
+
+void gigadevice_read_cmd(struct spinand_cmd *cmd, u32 page_id);
+
+void gigadevice_read_data(struct spinand_cmd *cmd, u16 column, u32 page_id);
+
+void gigadevice_write_cmd(struct spinand_cmd *cmd, u32 column);
+
+void gigadevice_write_data(struct spinand_cmd *cmd, u16 column, u32 page_id);
+
+void gigadevice_erase_blk(struct spinand_cmd *cmd, u32 page_id);
+
+int gigadevice_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id);
+
+int gigadevice_verify_ecc(u8 status);
+
+int dummy_verify_ecc(u8 status);
+
+void macronix_read_data(struct spinand_cmd *cmd, u16 column, u32 page_id);
+
+void macronix_write_data(struct spinand_cmd *cmd, u16 column, u32 page_id);
+
+int macronix_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id);
+
+int macronix_verify_ecc(u8 status);
+
+int xtx_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id);
+
+int mk_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id);
+
+void winbond_read_data(struct spinand_cmd *cmd, u16 column, u32 page_id);
+
+void winbond_write_data(struct spinand_cmd *cmd, u16 column, u32 page_id);
+
+int winbond_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id);
+
+/* Macronix Specfic defines */
+#define MACRONIX_NORM_RW_MASK	0x0F
+#endif /* __GIGA_SPI_NAND_H */
diff -uprN linux-4.4.194/drivers/staging/mt29f_spinand/Kconfig NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/Kconfig
--- linux-4.4.194/drivers/staging/mt29f_spinand/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -1,16 +1,25 @@
 config MTD_SPINAND_MT29F
-	tristate "SPINAND Device Support for Micron"
+	tristate "SPINAND Device Support"
 	depends on MTD_NAND && SPI
 	help
-	  This enables support for accessing Micron SPI NAND flash
+	  This enables support for accessing SPI NAND flash
 	  devices.
-	  If you have Micron SPI NAND chip say yes.
+	  If you have SPI NAND chip say yes.
 
 	  If unsure, say no here.
 
 config MTD_SPINAND_ONDIEECC
-	bool "Use SPINAND internal ECC"
+	bool
+	default y if MTD_SPINAND_MT29F
+
+config MTD_SPINAND_GIGADEVICE
+	bool
+	default y if MTD_SPINAND_MT29F
+
+
+config WINBOND_MULTIDIE
+	tristate "Winbond Multi-Die SPI NAND Support"
 	depends on MTD_SPINAND_MT29F
 	help
-	  Internal ECC.
-	  Enables Hardware ECC support for Micron SPI NAND.
+	  This enables support for Winbond multi-die SPI NAND flash.
+	  For instance, Winbond W25N02GV SPI NAND flash.
diff -uprN linux-4.4.194/drivers/staging/mt29f_spinand/Makefile NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/Makefile
--- linux-4.4.194/drivers/staging/mt29f_spinand/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -1 +1,2 @@
 obj-$(CONFIG_MTD_SPINAND_MT29F) += mt29f_spinand.o
+obj-$(CONFIG_MTD_SPINAND_GIGADEVICE)  += giga_spinand.o
diff -uprN linux-4.4.194/drivers/staging/mt29f_spinand/mt29f_spinand.c NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/mt29f_spinand.c
--- linux-4.4.194/drivers/staging/mt29f_spinand/mt29f_spinand.c	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/mt29f_spinand.c	2019-12-29 19:12:21.000000000 -0800
@@ -22,15 +22,263 @@
 #include <linux/spi/spi.h>
 
 #include "mt29f_spinand.h"
+#include "giga_spinand.h"
 
 #define BUFSIZE (10 * 64 * 2048)
 #define CACHE_BUF 2112
+
+struct mtd_partition spinand_partitions[] = {
+	{
+		.name = "u-boot",
+		.offset = 0,
+		.size = 2 * 1024 * 1024,
+	},
+	{
+		.name = "Kernel",
+		.size = 20 * 1024 * 1024,
+		.offset = MTDPART_OFS_APPEND,
+	},
+	{
+		.name = "user",
+		.offset = MTDPART_OFS_APPEND,
+		.size = MTDPART_SIZ_FULL
+	}
+};
+
+static int is_set_spinand_quad = 0;
+
+static u8 nand_id[3];
+
+static int spinand_cmd(struct spi_device *spi, struct spinand_cmd *cmd);
+
+
+struct spinand_ops spinand_dev[] = {
+#ifdef CONFIG_MTD_SPINAND_GIGADEVICE
+	{
+		NAND_MFR_GIGA,
+		0xb1,
+		gigadevice_set_defaults,
+		gigadevice_read_cmd,
+		gigadevice_read_data,
+		gigadevice_write_cmd,
+		gigadevice_write_data,
+		gigadevice_erase_blk,
+		gigadevice_parse_id,
+		gigadevice_verify_ecc,
+	},
+	{
+		NAND_MFR_GIGA,
+		0xa1,
+		gigadevice_set_defaults,
+		gigadevice_read_cmd,
+		gigadevice_read_data,
+		gigadevice_write_cmd,
+		gigadevice_write_data,
+		gigadevice_erase_blk,
+		gigadevice_parse_id,
+		gigadevice_verify_ecc,
+	},
+	{
+		NAND_MFR_ATO,
+		0x12,
+		gigadevice_set_defaults,
+		gigadevice_read_cmd,
+		gigadevice_read_data,
+		gigadevice_write_cmd,
+		gigadevice_write_data,
+		gigadevice_erase_blk,
+		gigadevice_parse_id,
+		dummy_verify_ecc,
+	},
+#endif
+	{
+		NAND_MFR_MACRONIX,
+		0x12,
+		gigadevice_set_defaults,
+		gigadevice_read_cmd,
+		macronix_read_data,
+		gigadevice_write_cmd,
+		macronix_write_data,
+		gigadevice_erase_blk,
+		macronix_parse_id,
+		macronix_verify_ecc,
+	},
+	{
+		NAND_MFR_XTX,
+		0x0b,
+		gigadevice_set_defaults,
+		gigadevice_read_cmd,
+		macronix_read_data,
+		gigadevice_write_cmd,
+		macronix_write_data,
+		gigadevice_erase_blk,
+		xtx_parse_id,
+		macronix_verify_ecc,
+	},
+	{
+		NAND_MFR_MK,
+		0xd5,
+		gigadevice_set_defaults,
+		gigadevice_read_cmd,
+		macronix_read_data,
+		gigadevice_write_cmd,
+		macronix_write_data,
+		gigadevice_erase_blk,
+		mk_parse_id,
+		macronix_verify_ecc,
+	},
+	{
+		NAND_MFR_WINBOND,
+		0xaa,
+		gigadevice_set_defaults,
+		gigadevice_read_cmd,
+		winbond_read_data,
+		gigadevice_write_cmd,
+		winbond_write_data,
+		gigadevice_erase_blk,
+		winbond_parse_id,
+		macronix_verify_ecc,
+	},
+	{
+		NAND_MFR_WINBOND,
+		0xab,
+		gigadevice_set_defaults,
+		gigadevice_read_cmd,
+		winbond_read_data,
+		gigadevice_write_cmd,
+		winbond_write_data,
+		gigadevice_erase_blk,
+		winbond_parse_id,
+		macronix_verify_ecc,
+	},
+	{ },
+};
+
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+/**
+ * WB_spinand_die_select- send command 0xc2 to select die
+ * Description:
+ *   Select die function.
+ *   Select die #1, set the bit to 1
+ *   Select die #0, clear the bit to 0
+ */
+static int WB_spinand_die_select(struct spi_device *spi_nand, u8 dieid)
+{
+	int retval;
+	struct spinand_cmd cmd = {0};
+
+	cmd.cmd = WB_MULTI_DIESELECT,
+	    cmd.n_addr = 1,
+	        cmd.addr[0] = dieid,
+
+
+	                      retval = spinand_cmd(spi_nand, &cmd);
+	if (retval < 0)
+		dev_err(&spi_nand->dev, "error %d set otp\n", retval);
+
+	return retval;
+}
+#endif
+
+
+void mt29f_read_page_to_cache(struct spinand_cmd *cmd, u32 page_id)
+{
+	cmd->addr[1] = (u8)((page_id & 0xff00) >> 8);
+	cmd->addr[2] = (u8)(page_id & 0x00ff);
+
+}
+
+void mt29f_read_from_cache(struct spinand_cmd *cmd, u16 column, u32 page_id)
+{
+	cmd->addr[0] = (u8)((column & 0xff00) >> 8);
+	cmd->addr[0] |= (u8)(((page_id >> 6) & 0x1) << 4);
+	cmd->addr[1] = (u8)(column & 0x00ff);
+	cmd->addr[2] = (u8)(0xff);
+}
+
+void mt29f_program_data_to_cache(struct spinand_cmd *cmd, u16 column,
+                                 u32 page_id)
+{
+	cmd->addr[0] = (u8)((column & 0xff00) >> 8);
+	cmd->addr[0] |= (u8)(((page_id >> 6) & 0x1) << 4);
+	cmd->addr[1] = (u8)(column & 0x00ff);
+}
+
+void mt29f_program_execute(struct spinand_cmd *cmd, u32 column)
+{
+	cmd->addr[1] = (u8)((column & 0xff00) >> 8);
+	cmd->addr[2] = (u8)(column & 0x00ff);
+}
+
+void mt29f_erase_block_erase(struct spinand_cmd *cmd, u32 page_id)
+{
+	cmd->addr[1] = (u8)((page_id & 0xff00) >> 8);
+	cmd->addr[2] = (u8)(page_id & 0x00ff);
+}
+
+int mt29f_verify_ecc(u8 status)
+{
+	int ecc_status = (status & STATUS_ECC_MASK);
+
+	if (ecc_status == STATUS_ECC_ERROR)
+		return SPINAND_ECC_ERROR;
+	else if (ecc_status == STATUS_ECC_1BIT_CORRECTED)
+		return SPINAND_ECC_CORRECTED;
+	else
+		return 0;
+}
+
+struct spinand_ops mt29f_spinand_ops = {
+	NAND_MFR_MICRON,
+	0x0,
+	NULL,
+	mt29f_read_page_to_cache,
+	mt29f_read_from_cache,
+	mt29f_program_execute,
+	mt29f_program_data_to_cache,
+	mt29f_erase_block_erase,
+	NULL,
+	mt29f_verify_ecc,
+};
+
+
+static inline struct spinand_ops *get_dev_ops(struct spi_device *spi_nand) {
+	struct mtd_info *mtd = (struct mtd_info *)dev_get_drvdata
+	                       (&spi_nand->dev);
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct spinand_info *info = (struct spinand_info *)chip->priv;
+	struct spinand_ops *dev_ops = info->dev_ops;
+
+	return dev_ops;
+}
+
+void spinand_parse_id(struct spi_device *spi_nand, u8 *nand_id, u8 *id)
+{
+	int tmp;
+	struct spinand_ops *tmp_ops;
+	struct mtd_info *mtd = (struct mtd_info *)
+	                       dev_get_drvdata(&spi_nand->dev);
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct spinand_info *info = (struct spinand_info *)chip->priv;
+
+	for (tmp = 0; tmp < ARRAY_SIZE(spinand_dev) - 1; tmp++) {
+		tmp_ops = &spinand_dev[tmp];
+		if (tmp_ops->spinand_parse_id(spi_nand, nand_id, id) == 0) {
+			info->dev_ops = &spinand_dev[tmp];
+			info->dev_ops->spinand_set_defaults(spi_nand);
+			return;
+		}
+	}
+	info->dev_ops = &mt29f_spinand_ops;
+	return;
+}
+
 /*
  * OOB area specification layout:  Total 32 available free bytes.
  */
 
-static inline struct spinand_state *mtd_to_state(struct mtd_info *mtd)
-{
+static inline struct spinand_state *mtd_to_state(struct mtd_info *mtd) {
 	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
 	struct spinand_info *info = (struct spinand_info *)chip->priv;
 	struct spinand_state *state = (struct spinand_state *)info->priv;
@@ -39,8 +287,8 @@ static inline struct spinand_state *mtd_
 }
 
 #ifdef CONFIG_MTD_SPINAND_ONDIEECC
-static int enable_hw_ecc;
-static int enable_read_hw_ecc;
+//static int enable_hw_ecc;
+//static int enable_read_hw_ecc;
 
 static struct nand_ecclayout spinand_oob_64 = {
 	.eccbytes = 24,
@@ -48,17 +296,26 @@ static struct nand_ecclayout spinand_oob
 		1, 2, 3, 4, 5, 6,
 		17, 18, 19, 20, 21, 22,
 		33, 34, 35, 36, 37, 38,
-		49, 50, 51, 52, 53, 54, },
+		49, 50, 51, 52, 53, 54,
+	},
 	.oobavail = 32,
 	.oobfree = {
-		{.offset = 8,
-			.length = 8},
-		{.offset = 24,
-			.length = 8},
-		{.offset = 40,
-			.length = 8},
-		{.offset = 56,
-			.length = 8},
+		{
+			.offset = 8,
+			.length = 8
+		},
+		{
+			.offset = 24,
+			.length = 8
+		},
+		{
+			.offset = 40,
+			.length = 8
+		},
+		{
+			.offset = 56,
+			.length = 8
+		},
 	}
 };
 #endif
@@ -104,6 +361,11 @@ static int spinand_cmd(struct spi_device
 	if (cmd->n_rx) {
 		x[3].len = cmd->n_rx;
 		x[3].rx_buf = cmd->rx_buf;
+		if (cmd->cmd == CMD_READ_QUAD) {
+			x[3].rx_nbits = 4;
+		} else {
+			x[3].rx_nbits = 1;
+		}
 		spi_message_add_tail(&x[3], &message);
 	}
 
@@ -118,7 +380,6 @@ static int spinand_cmd(struct spi_device
 static int spinand_read_id(struct spi_device *spi_nand, u8 *id)
 {
 	int retval;
-	u8 nand_id[3];
 	struct spinand_cmd cmd = {0};
 
 	cmd.cmd = CMD_READ_ID;
@@ -132,6 +393,7 @@ static int spinand_read_id(struct spi_de
 	}
 	id[0] = nand_id[1];
 	id[1] = nand_id[2];
+	spinand_parse_id(spi_nand, nand_id, id);
 	return retval;
 }
 
@@ -145,7 +407,7 @@ static int spinand_read_id(struct spi_de
  *    Once the status turns to be ready, the other status bits also are
  *    valid status bits.
  */
-static int spinand_read_status(struct spi_device *spi_nand, u8 *status)
+static int spinand_read_status(struct spi_device *spi_nand, uint8_t *status)
 {
 	struct spinand_cmd cmd = {0};
 	int ret;
@@ -178,7 +440,10 @@ static int wait_till_ready(struct spi_de
 		else if (!(stat & 0x1))
 			break;
 
-		cond_resched();
+		/* For SPI NAND performance issue, remark cond_resched() that yields CPU
+		 * to other process. Hence, it may influence other process's performance.
+		 */
+		//	cond_resched();
 	} while (!time_after_eq(jiffies, deadline));
 
 	if ((stat & 0x1) == 0)
@@ -186,7 +451,6 @@ static int wait_till_ready(struct spi_de
 
 	return -1;
 }
-
 /**
  * spinand_get_otp- send command 0xf to read the SPI Nand OTP register
  * Description:
@@ -224,12 +488,12 @@ static int spinand_set_otp(struct spi_de
 	struct spinand_cmd cmd = {0};
 
 	cmd.cmd = CMD_WRITE_REG,
-	cmd.n_addr = 1,
-	cmd.addr[0] = REG_OTP,
-	cmd.n_tx = 1,
-	cmd.tx_buf = otp,
+	    cmd.n_addr = 1,
+	        cmd.addr[0] = REG_OTP,
+	                      cmd.n_tx = 1,
+	                          cmd.tx_buf = otp,
 
-	retval = spinand_cmd(spi_nand, &cmd);
+	                              retval = spinand_cmd(spi_nand, &cmd);
 	if (retval < 0)
 		dev_err(&spi_nand->dev, "error %d set otp\n", retval);
 
@@ -249,17 +513,42 @@ static int spinand_enable_ecc(struct spi
 	int retval;
 	u8 otp = 0;
 
+#ifdef CONFIG_WINBOND_MULTIDIE
+	WB_spinand_die_select(spi_nand, 0);
+#endif
+
 	retval = spinand_get_otp(spi_nand, &otp);
 	if (retval < 0)
 		return retval;
 
-	if ((otp & OTP_ECC_MASK) == OTP_ECC_MASK)
-		return 0;
-	otp |= OTP_ECC_MASK;
-	retval = spinand_set_otp(spi_nand, &otp);
+	if ((otp & OTP_ECC_MASK) == OTP_ECC_MASK) {
+		//return 0;
+	} else {
+		otp |= OTP_ECC_MASK;
+		retval = spinand_set_otp(spi_nand, &otp);
+		if (retval < 0)
+			return retval;
+		return spinand_get_otp(spi_nand, &otp);
+	}
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+	WB_spinand_die_select(spi_nand, 1);
+#endif
+
+	retval = spinand_get_otp(spi_nand, &otp);
 	if (retval < 0)
 		return retval;
-	return spinand_get_otp(spi_nand, &otp);
+
+	if ((otp & OTP_ECC_MASK) == OTP_ECC_MASK) {
+		//return 0;
+	} else {
+		otp |= OTP_ECC_MASK;
+		retval = spinand_set_otp(spi_nand, &otp);
+		if (retval < 0)
+			return retval;
+		return spinand_get_otp(spi_nand, &otp);
+	}
+	return 0;
 }
 #endif
 
@@ -268,6 +557,11 @@ static int spinand_disable_ecc(struct sp
 	int retval;
 	u8 otp = 0;
 
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+	WB_spinand_die_select(spi_nand, 0);
+#endif
+
 	retval = spinand_get_otp(spi_nand, &otp);
 	if (retval < 0)
 		return retval;
@@ -278,6 +572,26 @@ static int spinand_disable_ecc(struct sp
 		if (retval < 0)
 			return retval;
 		return spinand_get_otp(spi_nand, &otp);
+	} else {
+		//return 0;
+	}
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+	WB_spinand_die_select(spi_nand, 1);
+#endif
+
+	retval = spinand_get_otp(spi_nand, &otp);
+	if (retval < 0)
+		return retval;
+
+	if ((otp & OTP_ECC_MASK) == OTP_ECC_MASK) {
+		otp &= ~OTP_ECC_MASK;
+		retval = spinand_set_otp(spi_nand, &otp);
+		if (retval < 0)
+			return retval;
+		return spinand_get_otp(spi_nand, &otp);
+	} else {
+		//return 0;
 	}
 	return 0;
 }
@@ -295,20 +609,54 @@ static int spinand_write_enable(struct s
 {
 	struct spinand_cmd cmd = {0};
 
+#ifdef CONFIG_WINBOND_MULTIDIE
+	WB_spinand_die_select(spi_nand, 0);
+#endif
+
 	cmd.cmd = CMD_WR_ENABLE;
+
+	spinand_cmd(spi_nand, &cmd);
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+	WB_spinand_die_select(spi_nand, 1);
+#endif
+
 	return spinand_cmd(spi_nand, &cmd);
 }
 
-static int spinand_read_page_to_cache(struct spi_device *spi_nand, u16 page_id)
+/**
+ * spinand_write_disable- send command 0x04 to disable write or erase the
+ * Nand cells
+ * Description:
+ *   After write and erase the Nand cells, the write enable has to be disabled.
+ */
+//static int spinand_write_disable(struct spi_device *spi_nand)
+//{
+//	struct spinand_cmd cmd = {0};
+
+//	cmd.cmd = CMD_WR_DISABLE;
+
+//	spinand_cmd(spi_nand, &cmd);
+
+//	return spinand_cmd(spi_nand, &cmd);
+//}
+
+static int spinand_read_page_to_cache(struct spi_device *spi_nand, u32 page_id)
 {
 	struct spinand_cmd cmd = {0};
 	u16 row;
+	struct spinand_ops *dev_ops = get_dev_ops(spi_nand);
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+	u8 dieid;
+	dieid = (int)(page_id>>16);
+	WB_spinand_die_select(spi_nand, dieid);
+#endif
 
 	row = page_id;
 	cmd.cmd = CMD_READ;
 	cmd.n_addr = 3;
-	cmd.addr[1] = (u8)((row & 0xff00) >> 8);
-	cmd.addr[2] = (u8)(row & 0x00ff);
+	dev_ops->spinand_read_cmd(&cmd, row);
 
 	return spinand_cmd(spi_nand, &cmd);
 }
@@ -321,19 +669,23 @@ static int spinand_read_page_to_cache(st
  *   locations.
  *   No tRd delay.
  */
-static int spinand_read_from_cache(struct spi_device *spi_nand, u16 page_id,
-				   u16 byte_id, u16 len, u8 *rbuf)
+static int spinand_read_from_cache(struct spi_device *spi_nand, u32 page_id,
+                                   u16 byte_id, u16 len, u8 *rbuf)
 {
 	struct spinand_cmd cmd = {0};
 	u16 column;
+	struct spinand_ops *dev_ops = get_dev_ops(spi_nand);
 
 	column = byte_id;
+
+#ifdef CONFIG_SPI_NUC980_QSPI0_QUAD
+	cmd.cmd = CMD_READ_QUAD;
+#else
 	cmd.cmd = CMD_READ_RDM;
+#endif
+
 	cmd.n_addr = 3;
-	cmd.addr[0] = (u8)((column & 0xff00) >> 8);
-	cmd.addr[0] |= (u8)(((page_id >> 6) & 0x1) << 4);
-	cmd.addr[1] = (u8)(column & 0x00ff);
-	cmd.addr[2] = (u8)(0xff);
+	dev_ops->spinand_read_data(&cmd, column, page_id);
 	cmd.n_dummy = 0;
 	cmd.n_rx = len;
 	cmd.rx_buf = rbuf;
@@ -341,6 +693,34 @@ static int spinand_read_from_cache(struc
 	return spinand_cmd(spi_nand, &cmd);
 }
 
+static int spinand_set_quad_mode(struct spi_device *spi_nand, u8 enable)
+{
+	int retval;
+	u8 otp = 0;
+
+	retval = spinand_get_otp(spi_nand, &otp);
+	if (retval < 0)
+		return retval;
+
+	if (enable) {
+		otp |= 1;
+		retval = spinand_set_otp(spi_nand, &otp);
+		if (retval < 0)
+			return retval;
+	} else {
+		otp &= ~1;
+		retval = spinand_set_otp(spi_nand, &otp);
+		if (retval < 0)
+			return retval;
+	}
+
+	retval = spinand_get_otp(spi_nand, &otp);
+	if (retval < 0)
+		return retval;
+
+	return 0;
+}
+
 /*
  * spinand_read_page-to read a page with:
  * @page_id: the physical page number
@@ -352,14 +732,17 @@ static int spinand_read_from_cache(struc
  *   The read includes two commands to the Nand: 0x13 and 0x03 commands
  *   Poll to read status to wait for tRD time.
  */
-static int spinand_read_page(struct spi_device *spi_nand, u16 page_id,
-			     u16 offset, u16 len, u8 *rbuf)
+static int spinand_read_page(struct spi_device *spi_nand, u32 page_id,
+                             u16 offset, u16 len, u8 *rbuf)
 {
-	int ret;
+	int ret, ecc_error = 0, ecc_corrected = 0;
 	u8 status = 0;
+	struct spinand_ops *dev_ops = get_dev_ops(spi_nand);
+	struct mtd_info *mtd = (struct mtd_info *)
+	                       dev_get_drvdata(&spi_nand->dev);
 
 #ifdef CONFIG_MTD_SPINAND_ONDIEECC
-	if (enable_read_hw_ecc) {
+	if (0) { //(enable_read_hw_ecc) {
 		if (spinand_enable_ecc(spi_nand) < 0)
 			dev_err(&spi_nand->dev, "enable HW ECC failed!");
 	}
@@ -368,43 +751,74 @@ static int spinand_read_page(struct spi_
 	if (ret < 0)
 		return ret;
 
-	if (wait_till_ready(spi_nand))
-		dev_err(&spi_nand->dev, "WAIT timedout!!!\n");
+//	if (wait_till_ready(spi_nand))
+//		dev_err(&spi_nand->dev, "WAIT timedout!!!\n");
 
 	while (1) {
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+		u8 dieid;
+		dieid = (int)(page_id>>16);
+		WB_spinand_die_select(spi_nand, dieid);
+#endif
+
 		ret = spinand_read_status(spi_nand, &status);
 		if (ret < 0) {
 			dev_err(&spi_nand->dev,
-				"err %d read status register\n", ret);
+			        "err %d read status register\n", ret);
 			return ret;
 		}
 
 		if ((status & STATUS_OIP_MASK) == STATUS_READY) {
-			if ((status & STATUS_ECC_MASK) == STATUS_ECC_ERROR) {
+			ret = dev_ops->spinand_verify_ecc(status);
+			if (ret == SPINAND_ECC_ERROR) {
 				dev_err(&spi_nand->dev, "ecc error, page=%d\n",
-					page_id);
-				return 0;
+				        page_id);
+				mtd->ecc_stats.failed++;
+				ecc_error = 1;
+			} else if (ret == SPINAND_ECC_CORRECTED) {
+				mtd->ecc_stats.corrected++;
+				ecc_corrected = 1;
 			}
 			break;
 		}
 	}
 
+#ifdef CONFIG_SPI_NUC980_QSPI0_QUAD
+	if (!is_set_spinand_quad) {
+		if ((nand_id[1] == NAND_MFR_MACRONIX) || (nand_id[1] == NAND_MFR_XTX) || (nand_id[1] == NAND_MFR_MK)) {
+			ret = spinand_set_quad_mode(spi_nand, 1);
+			if (ret < 0) {
+				dev_err(&spi_nand->dev, "enable quad mode failed!!\n");
+				return ret;
+			}
+		}
+		is_set_spinand_quad = 1;
+	}
+#endif
+
 	ret = spinand_read_from_cache(spi_nand, page_id, offset, len, rbuf);
 	if (ret < 0) {
 		dev_err(&spi_nand->dev, "read from cache failed!!\n");
 		return ret;
 	}
 
+
 #ifdef CONFIG_MTD_SPINAND_ONDIEECC
-	if (enable_read_hw_ecc) {
+	if (0) { //(enable_read_hw_ecc) {
 		ret = spinand_disable_ecc(spi_nand);
 		if (ret < 0) {
 			dev_err(&spi_nand->dev, "disable ecc failed!!\n");
 			return ret;
 		}
-		enable_read_hw_ecc = 0;
+		//enable_read_hw_ecc = 0;
 	}
 #endif
+	if (ecc_error)
+		ret = -EBADMSG;
+	else if (ecc_corrected)
+		ret = -EUCLEAN;
+
 	return ret;
 }
 
@@ -420,18 +834,22 @@ static int spinand_read_page(struct spi_
  *   Since it is writing the data to cache, there is no tPROG time.
  */
 static int spinand_program_data_to_cache(struct spi_device *spi_nand,
-					 u16 page_id, u16 byte_id,
-					 u16 len, u8 *wbuf)
+                u32 page_id, u16 byte_id, u16 len, u8 *wbuf)
 {
 	struct spinand_cmd cmd = {0};
 	u16 column;
+	struct spinand_ops *dev_ops = get_dev_ops(spi_nand);
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+	u8 dieid;
+	dieid = (int)(page_id>>16);
+	WB_spinand_die_select(spi_nand, dieid);
+#endif
 
 	column = byte_id;
 	cmd.cmd = CMD_PROG_PAGE_CLRCACHE;
 	cmd.n_addr = 2;
-	cmd.addr[0] = (u8)((column & 0xff00) >> 8);
-	cmd.addr[0] |= (u8)(((page_id >> 6) & 0x1) << 4);
-	cmd.addr[1] = (u8)(column & 0x00ff);
+	dev_ops->spinand_write_data(&cmd, column, page_id);
 	cmd.n_tx = len;
 	cmd.tx_buf = wbuf;
 
@@ -447,16 +865,22 @@ static int spinand_program_data_to_cache
  *   the Nand array.
  *   Need to wait for tPROG time to finish the transaction.
  */
-static int spinand_program_execute(struct spi_device *spi_nand, u16 page_id)
+static int spinand_program_execute(struct spi_device *spi_nand, u32 page_id)
 {
 	struct spinand_cmd cmd = {0};
 	u16 row;
+	struct spinand_ops *dev_ops = get_dev_ops(spi_nand);
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+	u8 dieid;
+	dieid = (int)(page_id>>16);
+	WB_spinand_die_select(spi_nand, dieid);
+#endif
 
 	row = page_id;
 	cmd.cmd = CMD_PROG_PAGE_EXC;
 	cmd.n_addr = 3;
-	cmd.addr[1] = (u8)((row & 0xff00) >> 8);
-	cmd.addr[2] = (u8)(row & 0x00ff);
+	dev_ops->spinand_write_cmd(&cmd, row);
 
 	return spinand_cmd(spi_nand, &cmd);
 }
@@ -475,26 +899,29 @@ static int spinand_program_execute(struc
  *   Poll to wait for the tPROG time to finish the transaction.
  */
 static int spinand_program_page(struct spi_device *spi_nand,
-				u16 page_id, u16 offset, u16 len, u8 *buf)
+                                u32 page_id, u16 offset, u16 len, u8 *buf)
 {
-	int retval;
+	int retval = 0;
 	u8 status = 0;
-	u8 *wbuf;
+//	uint8_t *wbuf;
 #ifdef CONFIG_MTD_SPINAND_ONDIEECC
-	unsigned int i, j;
+//	unsigned int i, j;
+
+	//enable_read_hw_ecc = 0;
+//	wbuf = kzalloc(CACHE_BUF, GFP_KERNEL);
+//	if (!wbuf)
+//		return -ENOMEM;
 
-	enable_read_hw_ecc = 0;
-	wbuf = devm_kzalloc(&spi_nand->dev, CACHE_BUF, GFP_KERNEL);
-	spinand_read_page(spi_nand, page_id, 0, CACHE_BUF, wbuf);
+//	spinand_read_page(spi_nand, page_id, 0, CACHE_BUF, wbuf);
 
-	for (i = offset, j = 0; i < len; i++, j++)
-		wbuf[i] &= buf[j];
+//	for (i = offset, j = 0; i < len; i++, j++)
+//		wbuf[i] &= buf[j];
 
-	if (enable_hw_ecc) {
+	if (0) { //(enable_hw_ecc) {
 		retval = spinand_enable_ecc(spi_nand);
 		if (retval < 0) {
 			dev_err(&spi_nand->dev, "enable ecc failed!!\n");
-			return retval;
+			goto exit;
 		}
 	}
 #else
@@ -503,47 +930,70 @@ static int spinand_program_page(struct s
 	retval = spinand_write_enable(spi_nand);
 	if (retval < 0) {
 		dev_err(&spi_nand->dev, "write enable failed!!\n");
-		return retval;
+		goto exit;
 	}
 	if (wait_till_ready(spi_nand))
 		dev_err(&spi_nand->dev, "wait timedout!!!\n");
 
 	retval = spinand_program_data_to_cache(spi_nand, page_id,
-					       offset, len, wbuf);
+//	                                       offset, len, wbuf);
+	                                       offset, len, buf);
 	if (retval < 0)
-		return retval;
+		goto exit;
+
 	retval = spinand_program_execute(spi_nand, page_id);
 	if (retval < 0)
-		return retval;
+		goto exit;
+
 	while (1) {
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+		u8 dieid;
+		dieid = (int)(page_id>>16);
+		WB_spinand_die_select(spi_nand, dieid);
+#endif
+
 		retval = spinand_read_status(spi_nand, &status);
 		if (retval < 0) {
 			dev_err(&spi_nand->dev,
-				"error %d reading status register\n", retval);
-			return retval;
+			        "error %d reading status register\n",
+			        retval);
+			goto exit;
 		}
 
 		if ((status & STATUS_OIP_MASK) == STATUS_READY) {
 			if ((status & STATUS_P_FAIL_MASK) == STATUS_P_FAIL) {
 				dev_err(&spi_nand->dev,
-					"program error, page %d\n", page_id);
-				return -1;
-			}
-			break;
+				        "program error, page %d\n", page_id);
+				retval = -1;
+				goto exit;
+			} else
+				break;
 		}
 	}
 #ifdef CONFIG_MTD_SPINAND_ONDIEECC
-	if (enable_hw_ecc) {
+	if (0) { //(enable_hw_ecc) {
 		retval = spinand_disable_ecc(spi_nand);
 		if (retval < 0) {
 			dev_err(&spi_nand->dev, "disable ecc failed!!\n");
-			return retval;
+			goto exit;
 		}
-		enable_hw_ecc = 0;
+		//enable_hw_ecc = 0;
 	}
 #endif
+//	retval = spinand_write_disable(spi_nand);
+//	if (retval < 0) {
+//		dev_err(&spi_nand->dev, "write disable failed!!\n");
+//		goto exit;
+//	}
+//	if (wait_till_ready(spi_nand))
+//		dev_err(&spi_nand->dev, "wait timedout!!!\n");
 
-	return 0;
+exit:
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+//	kfree(wbuf);
+#endif
+	return retval;
 }
 
 /**
@@ -559,12 +1009,18 @@ static int spinand_erase_block_erase(str
 {
 	struct spinand_cmd cmd = {0};
 	u16 row;
+	struct spinand_ops *dev_ops = get_dev_ops(spi_nand);
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+	u8 dieid;
+	dieid = (int)(block_id>>10);
+	WB_spinand_die_select(spi_nand, dieid);
+#endif
 
 	row = block_id;
 	cmd.cmd = CMD_ERASE_BLK;
 	cmd.n_addr = 3;
-	cmd.addr[1] = (u8)((row & 0xff00) >> 8);
-	cmd.addr[2] = (u8)(row & 0x00ff);
+	dev_ops->spinand_erase_blk(&cmd, row);
 
 	return spinand_cmd(spi_nand, &cmd);
 }
@@ -586,56 +1042,73 @@ static int spinand_erase_block(struct sp
 	u8 status = 0;
 
 	retval = spinand_write_enable(spi_nand);
+	if (retval < 0) {
+		dev_err(&spi_nand->dev, "write enable failed!!\n");
+		return retval;
+	}
 	if (wait_till_ready(spi_nand))
 		dev_err(&spi_nand->dev, "wait timedout!!!\n");
 
 	retval = spinand_erase_block_erase(spi_nand, block_id);
 	while (1) {
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+		u8 dieid;
+		dieid = (int)(block_id>>10);
+		WB_spinand_die_select(spi_nand, dieid);
+#endif
+
 		retval = spinand_read_status(spi_nand, &status);
 		if (retval < 0) {
 			dev_err(&spi_nand->dev,
-				"error %d reading status register\n", retval);
+			        "error %d reading status register\n",
+			        (int) retval);
 			return retval;
 		}
 
 		if ((status & STATUS_OIP_MASK) == STATUS_READY) {
 			if ((status & STATUS_E_FAIL_MASK) == STATUS_E_FAIL) {
 				dev_err(&spi_nand->dev,
-					"erase error, block %d\n", block_id);
+				        "erase error, block %d\n", block_id);
 				return -1;
-			}
-			break;
+			} else
+				break;
 		}
 	}
+//	retval = spinand_write_disable(spi_nand);
+//	if (retval < 0) {
+//		dev_err(&spi_nand->dev, "write disable failed!!\n");
+//		return retval;
+//	}
+//	if (wait_till_ready(spi_nand))
+//		dev_err(&spi_nand->dev, "wait timedout!!!\n");
 	return 0;
 }
 
 #ifdef CONFIG_MTD_SPINAND_ONDIEECC
 static int spinand_write_page_hwecc(struct mtd_info *mtd,
-				    struct nand_chip *chip,
-				    const u8 *buf, int oob_required,
-				    int page)
+                                    struct nand_chip *chip, const uint8_t *buf, int oob_required, int page)
 {
-	const u8 *p = buf;
+	const uint8_t *p = buf;
 	int eccsize = chip->ecc.size;
 	int eccsteps = chip->ecc.steps;
 
-	enable_hw_ecc = 1;
+	//enable_hw_ecc = 1;
 	chip->write_buf(mtd, p, eccsize * eccsteps);
 	return 0;
 }
 
 static int spinand_read_page_hwecc(struct mtd_info *mtd, struct nand_chip *chip,
-				   u8 *buf, int oob_required, int page)
+                                   uint8_t *buf, int oob_required, int page)
 {
-	int retval;
-	u8 status;
-	u8 *p = buf;
+	u8 retval, status = 0;
+	uint8_t *p = buf;
 	int eccsize = chip->ecc.size;
 	int eccsteps = chip->ecc.steps;
 	struct spinand_info *info = (struct spinand_info *)chip->priv;
+	struct spinand_ops *dev_ops = info->dev_ops;
 
-	enable_read_hw_ecc = 1;
+	//enable_read_hw_ecc = 1;
 
 	chip->read_buf(mtd, p, eccsize * eccsteps);
 	if (oob_required)
@@ -643,23 +1116,21 @@ static int spinand_read_page_hwecc(struc
 
 	while (1) {
 		retval = spinand_read_status(info->spi, &status);
-		if (retval < 0) {
-			dev_err(&mtd->dev,
-				"error %d reading status register\n", retval);
-			return retval;
-		}
-
 		if ((status & STATUS_OIP_MASK) == STATUS_READY) {
-			if ((status & STATUS_ECC_MASK) == STATUS_ECC_ERROR) {
+			retval = dev_ops->spinand_verify_ecc(status);
+			if (retval == SPINAND_ECC_ERROR) {
 				pr_info("spinand: ECC error\n");
 				mtd->ecc_stats.failed++;
-			} else if ((status & STATUS_ECC_MASK) ==
-					STATUS_ECC_1BIT_CORRECTED)
+				retval = -EBADMSG;
+			} else if (retval == SPINAND_ECC_CORRECTED) {
 				mtd->ecc_stats.corrected++;
+				retval = -EUCLEAN;
+			}
 			break;
 		}
 	}
-	return 0;
+	return retval;
+
 }
 #endif
 
@@ -667,7 +1138,7 @@ static void spinand_select_chip(struct m
 {
 }
 
-static u8 spinand_read_byte(struct mtd_info *mtd)
+static uint8_t spinand_read_byte(struct mtd_info *mtd)
 {
 	struct spinand_state *state = mtd_to_state(mtd);
 	u8 data;
@@ -677,13 +1148,14 @@ static u8 spinand_read_byte(struct mtd_i
 	return data;
 }
 
+
 static int spinand_wait(struct mtd_info *mtd, struct nand_chip *chip)
 {
 	struct spinand_info *info = (struct spinand_info *)chip->priv;
 
 	unsigned long timeo = jiffies;
 	int retval, state = chip->state;
-	u8 status;
+	u8 status = 0;
 
 	if (state == FL_ERASING)
 		timeo += (HZ * 400) / 1000;
@@ -692,32 +1164,28 @@ static int spinand_wait(struct mtd_info
 
 	while (time_before(jiffies, timeo)) {
 		retval = spinand_read_status(info->spi, &status);
-		if (retval < 0) {
-			dev_err(&mtd->dev,
-				"error %d reading status register\n", retval);
-			return retval;
-		}
-
 		if ((status & STATUS_OIP_MASK) == STATUS_READY)
 			return 0;
 
-		cond_resched();
+		/* For SPI NAND performance issue, remark cond_resched() that yields CPU
+		 * to other process. Hence, it may influence other process's performance.
+		 */
+		//cond_resched();
 	}
 	return 0;
 }
 
-static void spinand_write_buf(struct mtd_info *mtd, const u8 *buf, int len)
+static void spinand_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
 {
-	struct spinand_state *state = mtd_to_state(mtd);
 
+	struct spinand_state *state = mtd_to_state(mtd);
 	memcpy(state->buf + state->buf_ptr, buf, len);
 	state->buf_ptr += len;
 }
 
-static void spinand_read_buf(struct mtd_info *mtd, u8 *buf, int len)
+static void spinand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
 {
 	struct spinand_state *state = mtd_to_state(mtd);
-
 	memcpy(buf, state->buf + state->buf_ptr, len);
 	state->buf_ptr += len;
 }
@@ -735,60 +1203,62 @@ static void spinand_reset(struct spi_dev
 		pr_info("spinand reset failed!\n");
 
 	/* elapse 1ms before issuing any other command */
-	usleep_range(1000, 2000);
+	udelay(1000);
 
 	if (wait_till_ready(spi_nand))
 		dev_err(&spi_nand->dev, "wait timedout!\n");
 }
 
 static void spinand_cmdfunc(struct mtd_info *mtd, unsigned int command,
-			    int column, int page)
+                            int column, int page)
 {
 	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
 	struct spinand_info *info = (struct spinand_info *)chip->priv;
 	struct spinand_state *state = (struct spinand_state *)info->priv;
 
 	switch (command) {
-	/*
-	 * READ0 - read in first  0x800 bytes
-	 */
+		/*
+		 * READ0 - read in first  0x800 bytes
+		 */
 	case NAND_CMD_READ1:
 	case NAND_CMD_READ0:
 		state->buf_ptr = 0;
-		spinand_read_page(info->spi, page, 0x0, 0x840, state->buf);
+		spinand_read_page(info->spi, page, 0x0,
+		                  (mtd->writesize + mtd->oobsize), state->buf);
 		break;
-	/* READOOB reads only the OOB because no ECC is performed. */
+		/* READOOB reads only the OOB because no ECC is performed. */
 	case NAND_CMD_READOOB:
 		state->buf_ptr = 0;
-		spinand_read_page(info->spi, page, 0x800, 0x40, state->buf);
+		spinand_read_page(info->spi, page,
+		                  (mtd->writesize + column), mtd->oobsize, state->buf);
 		break;
 	case NAND_CMD_RNDOUT:
 		state->buf_ptr = column;
 		break;
 	case NAND_CMD_READID:
 		state->buf_ptr = 0;
-		spinand_read_id(info->spi, state->buf);
+		spinand_read_id(info->spi, (u8 *)state->buf);
 		break;
 	case NAND_CMD_PARAM:
 		state->buf_ptr = 0;
 		break;
-	/* ERASE1 stores the block and page address */
+		/* ERASE1 stores the block and page address */
 	case NAND_CMD_ERASE1:
 		spinand_erase_block(info->spi, page);
 		break;
-	/* ERASE2 uses the block and page address from ERASE1 */
+		/* ERASE2 uses the block and page address from ERASE1 */
 	case NAND_CMD_ERASE2:
 		break;
-	/* SEQIN sets up the addr buffer and all registers except the length */
+		/* SEQIN sets up the addr buffer and all registers except the length */
 	case NAND_CMD_SEQIN:
 		state->col = column;
 		state->row = page;
 		state->buf_ptr = 0;
 		break;
-	/* PAGEPROG reuses all of the setup from SEQIN and adds the length */
+		/* PAGEPROG reuses all of the setup from SEQIN and adds the length */
 	case NAND_CMD_PAGEPROG:
 		spinand_program_page(info->spi, state->row, state->col,
-				     state->buf_ptr, state->buf);
+		                     state->buf_ptr, state->buf);
 		break;
 	case NAND_CMD_STATUS:
 		spinand_get_otp(info->spi, state->buf);
@@ -796,12 +1266,12 @@ static void spinand_cmdfunc(struct mtd_i
 			state->buf[0] = 0x80;
 		state->buf_ptr = 0;
 		break;
-	/* RESET command */
+		/* RESET command */
 	case NAND_CMD_RESET:
 		if (wait_till_ready(info->spi))
 			dev_err(&info->spi->dev, "WAIT timedout!!!\n");
 		/* a minimum of 250us must elapse before issuing RESET cmd*/
-		usleep_range(250, 1000);
+		udelay(250);
 		spinand_reset(info->spi);
 		break;
 	default:
@@ -822,6 +1292,26 @@ static int spinand_lock_block(struct spi
 	int ret;
 	u8 otp = 0;
 
+#ifdef CONFIG_WINBOND_MULTIDIE
+	WB_spinand_die_select(spi_nand, 0);
+#endif
+
+	ret = spinand_get_otp(spi_nand, &otp);
+
+	cmd.cmd = CMD_WRITE_REG;
+	cmd.n_addr = 1;
+	cmd.addr[0] = REG_BLOCK_LOCK;
+	cmd.n_tx = 1;
+	cmd.tx_buf = &lock;
+
+	ret = spinand_cmd(spi_nand, &cmd);
+	if (ret < 0)
+		dev_err(&spi_nand->dev, "error %d lock block\n", ret);
+
+#ifdef CONFIG_WINBOND_MULTIDIE
+	WB_spinand_die_select(spi_nand, 1);
+#endif
+
 	ret = spinand_get_otp(spi_nand, &otp);
 
 	cmd.cmd = CMD_WRITE_REG;
@@ -836,7 +1326,6 @@ static int spinand_lock_block(struct spi
 
 	return ret;
 }
-
 /*
  * spinand_probe - [spinand Interface]
  * @spi_nand: registered device driver.
@@ -853,7 +1342,7 @@ static int spinand_probe(struct spi_devi
 	struct mtd_part_parser_data ppdata;
 
 	info  = devm_kzalloc(&spi_nand->dev, sizeof(struct spinand_info),
-			     GFP_KERNEL);
+	                     GFP_KERNEL);
 	if (!info)
 		return -ENOMEM;
 
@@ -862,7 +1351,7 @@ static int spinand_probe(struct spi_devi
 	spinand_lock_block(spi_nand, BL_ALL_UNLOCKED);
 
 	state = devm_kzalloc(&spi_nand->dev, sizeof(struct spinand_state),
-			     GFP_KERNEL);
+	                     GFP_KERNEL);
 	if (!state)
 		return -ENOMEM;
 
@@ -873,7 +1362,7 @@ static int spinand_probe(struct spi_devi
 		return -ENOMEM;
 
 	chip = devm_kzalloc(&spi_nand->dev, sizeof(struct nand_chip),
-			    GFP_KERNEL);
+	                    GFP_KERNEL);
 	if (!chip)
 		return -ENOMEM;
 
@@ -910,14 +1399,29 @@ static int spinand_probe(struct spi_devi
 	dev_set_drvdata(&spi_nand->dev, mtd);
 
 	mtd->priv = chip;
-	mtd->dev.parent = &spi_nand->dev;
+	mtd->name = dev_name(&spi_nand->dev);
+	mtd->owner = THIS_MODULE;
 	mtd->oobsize = 64;
 
 	if (nand_scan(mtd, 1))
 		return -ENXIO;
 
+	/* add mtd-id. The string should same as uboot definition */
+	mtd->name = "nand0";
 	ppdata.of_node = spi_nand->dev.of_node;
-	return mtd_device_parse_register(mtd, NULL, &ppdata, NULL, 0);
+
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+	if (spinand_enable_ecc(spi_nand) < 0)
+		dev_err(&spi_nand->dev, "enable HW ECC failed!");
+#endif
+
+#ifndef CONFIG_MTD_CMDLINE_PARTS
+	info->parts = (struct mtd_partition*)spinand_partitions;
+	info->nr_parts = ARRAY_SIZE(spinand_partitions);
+#endif
+
+	//return mtd_device_parse_register(mtd, NULL, &ppdata, spinand_partitions, ARRAY_SIZE(spinand_partitions));
+	return mtd_device_parse_register(mtd, NULL, &ppdata, info->parts, info->nr_parts);
 }
 
 /*
@@ -938,7 +1442,6 @@ static const struct of_device_id spinand
 	{ .compatible = "spinand,mt29f", },
 	{}
 };
-MODULE_DEVICE_TABLE(of, spinand_dt);
 
 /*
  * Device name structure description
@@ -946,6 +1449,8 @@ MODULE_DEVICE_TABLE(of, spinand_dt);
 static struct spi_driver spinand_driver = {
 	.driver = {
 		.name		= "mt29f",
+		.bus		= &spi_bus_type,
+		.owner		= THIS_MODULE,
 		.of_match_table	= spinand_dt,
 	},
 	.probe		= spinand_probe,
diff -uprN linux-4.4.194/drivers/staging/mt29f_spinand/mt29f_spinand.h NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/mt29f_spinand.h
--- linux-4.4.194/drivers/staging/mt29f_spinand/mt29f_spinand.h	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/staging/mt29f_spinand/mt29f_spinand.h	2019-12-29 19:12:21.000000000 -0800
@@ -26,6 +26,7 @@
 /* cmd */
 #define CMD_READ			0x13
 #define CMD_READ_RDM			0x03
+#define CMD_READ_QUAD			0x6B
 #define CMD_PROG_PAGE_CLRCACHE		0x02
 #define CMD_PROG_PAGE			0x84
 #define CMD_PROG_PAGE_EXC		0x10
@@ -44,19 +45,26 @@
 
 /* status */
 #define STATUS_OIP_MASK			0x01
-#define STATUS_READY			0
-#define STATUS_BUSY			BIT(0)
+#define STATUS_READY			(0 << 0)
+#define STATUS_BUSY			(1 << 0)
 
 #define STATUS_E_FAIL_MASK		0x04
-#define STATUS_E_FAIL			BIT(2)
+#define STATUS_E_FAIL			(1 << 2)
 
 #define STATUS_P_FAIL_MASK		0x08
-#define STATUS_P_FAIL			BIT(3)
+#define STATUS_P_FAIL			(1 << 3)
 
 #define STATUS_ECC_MASK			0x30
-#define STATUS_ECC_1BIT_CORRECTED	BIT(4)
-#define STATUS_ECC_ERROR		BIT(5)
-#define STATUS_ECC_RESERVED		(BIT(5) | BIT(4))
+#define STATUS_ECC_1BIT_CORRECTED	(1 << 4)
+#define STATUS_ECC_ERROR		(2 << 4)
+#define STATUS_ECC_RESERVED		(3 << 4)
+
+#define STATUS_ECC_MASK_GIGA		0x70
+#define STATUS_ECC_ERROR_GIGA		0x70
+#define STATUS_ECC_MASK_MACRONIX	0x30
+#define STATUS_ECC_ERROR_MACRONIX	0x20
+#define SPINAND_ECC_ERROR		0x1
+#define SPINAND_ECC_CORRECTED		0x2
 
 /*ECC enable defines*/
 #define OTP_ECC_MASK			0x10
@@ -77,18 +85,9 @@
 #define BL_1_64_LOCKED     0x08
 #define BL_ALL_UNLOCKED    0
 
-struct spinand_info {
-	struct nand_ecclayout *ecclayout;
-	struct spi_device *spi;
-	void *priv;
-};
+/* wb multi die */
+#define WB_MULTI_DIESELECT      0xC2
 
-struct spinand_state {
-	u32	col;
-	u32	row;
-	int		buf_ptr;
-	u8		*buf;
-};
 
 struct spinand_cmd {
 	u8		cmd;
@@ -101,7 +100,39 @@ struct spinand_cmd {
 	u8		*rx_buf;	/* Rx buf */
 };
 
-int spinand_mtd(struct mtd_info *mtd);
-void spinand_mtd_release(struct mtd_info *mtd);
+struct spinand_ops {
+	u8   maf_id;
+	u16   dev_id;
+	void (*spinand_set_defaults)(struct spi_device *spi_nand);
+	void (*spinand_read_cmd)(struct spinand_cmd *cmd, u32 page_id);
+	void (*spinand_read_data)(struct spinand_cmd *cmd, u16 column,
+	                          u32 page_id);
+	void (*spinand_write_cmd)(struct spinand_cmd *cmd, u32 page_id);
+	void (*spinand_write_data)(struct spinand_cmd *cmd, u16 column,
+	                           u32 page_id);
+	void (*spinand_erase_blk)(struct spinand_cmd *cmd, u32 page_id);
+	int (*spinand_parse_id)(struct spi_device *spi_nand, u8 *nand_id,
+	                        u8 *id);
+	int (*spinand_verify_ecc)(u8 status);
+};
+
+struct spinand_info {
+	struct nand_ecclayout *ecclayout;
+	struct spi_device *spi;
+	void *priv;
+	struct spinand_ops *dev_ops;
+	struct mtd_partition    *parts;     // mtd partition
+	int                     nr_parts;   // mtd partition number
+};
+
+struct spinand_state {
+	uint32_t	col;
+	uint32_t	row;
+	int		buf_ptr;
+	u8		*buf;
+};
+
+extern int spinand_mtd(struct mtd_info *mtd);
+extern void spinand_mtd_release(struct mtd_info *mtd);
 
 #endif /* __LINUX_MTD_SPI_NAND_H */
diff -uprN linux-4.4.194/drivers/tty/serial/Kconfig NUC980-linux-4.4.194/drivers/tty/serial/Kconfig
--- linux-4.4.194/drivers/tty/serial/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/tty/serial/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -18,6 +18,431 @@ source "drivers/tty/serial/8250/Kconfig"
 
 comment "Non-8250 serial port support"
 
+config SERIAL_NUC980
+		bool "NUC980 serial support"
+		depends on ARCH_NUC980
+		select SERIAL_CORE
+		---help---
+			This selects NUC980 serial driver.
+
+config SERIAL_NUC980_CONSOLE
+		bool "Console on NUC980 serial port"
+		depends on SERIAL_NUC980=y
+		select SERIAL_CORE_CONSOLE
+		---help---
+		If you say Y here, it will be possible to use a serial port as the
+			system console.
+
+config ENABLE_UART_PDMA
+	bool "ENABLE UART PDMA"
+	depends on ENABLE_UART1_PDMA || ENABLE_UART2_PDMA || ENABLE_UART3_PDMA || ENABLE_UART4_PDMA || ENABLE_UART5_PDMA || ENABLE_UART6_PDMA || ENABLE_UART7_PDMA || ENABLE_UART8_PDMA || ENABLE_UART9_PDMA
+
+
+config NUC980_UART1
+	bool "NUC980 UART1 support"
+	depends on SERIAL_NUC980=y
+	help
+	  This selects NUC980 uart1 driver
+
+config ENABLE_UART1_CTS_WAKEUP
+	bool "Enable UART1 CTS wake-up function"
+	depends on NUC980_UART1
+	help
+	  This selects NUC980 uart1 CTS wake-up function
+
+config ENABLE_UART1_PDMA
+	bool "Enable UART1 PDMA function"
+	select ENABLE_UART_PDMA
+	depends on NUC980_UART1
+	help
+	  This selects NUC980 uart1 PDMA function
+
+choice
+	prompt "NUC980 UART1 pin selection"
+	default NUC980_UART1_PA
+	depends on NUC980_UART1
+	depends on !USE_OF
+	help
+	  Select UART1 multi-function pin.
+
+	config NUC980_UART1_PA
+		bool "Rx:PA0, Tx:PA1"
+	config NUC980_UART1_PC
+		bool "Rx:PC6, Tx:PC5"
+	config NUC980_UART1_PF
+		bool "Rx:PF9, Tx:PF10"
+	config NUC980_UART1_FC_PC
+		bool "Rx:PC6, Tx:PC5, RTS:PC7, CTS:PC8"
+	config NUC980_UART1_FC_PF
+		bool "Rx:PF9, Tx:PF10, RTS:PF8, CTS:PF7"
+endchoice
+
+
+config NUC980_UART2
+	bool "NUC980 UART2 support"
+	depends on SERIAL_NUC980=y
+	help
+	  This selects NUC980 uart2 driver
+
+config ENABLE_UART2_CTS_WAKEUP
+	bool "Enable UART2 CTS wake-up function"
+	depends on NUC980_UART2
+	help
+	  This selects NUC980 uart2 CTS wake-up function
+
+config ENABLE_UART2_PDMA
+	bool "Enable UART2 PDMA function"
+	select ENABLE_UART_PDMA
+	depends on NUC980_UART2
+	help
+	  This selects NUC980 uart2 PDMA function
+
+choice
+	prompt "NUC980 UART2 pin selection"
+	default NUC980_UART2_PA
+	depends on NUC980_UART2
+	depends on !USE_OF
+	help
+	  Select UART2 multi-function pin.
+
+	config NUC980_UART2_PA
+		bool "Rx:PA9, Tx:PA10"
+	config NUC980_UART1_PG
+		bool "Rx:PG0, Tx:PG1"
+	config NUC980_UART2_PD
+		bool "Rx:PD7, Tx:PD6"
+	config NUC980_UART2_FC_PA
+		bool "Rx:PA9, Tx:PA10, RTS:PA8, CTS:PA7"
+	config NUC980_UART2_FC_PG
+		bool "Rx:PG0, Tx:PG1, RTS:PG3, CTS:PG2"
+	config NUC980_UART2_FC_PA_PB
+		bool "Rx:PA9, Tx:PA10, RTS:PA8, CTS:PB0"
+endchoice
+
+config NUC980_UART3
+	bool "NUC980 UART3 support"
+	depends on SERIAL_NUC980=y
+	help
+	  This selects NUC980 uart3 driver
+
+config ENABLE_UART3_CTS_WAKEUP
+	bool "Enable UART3 CTS wake-up function"
+	depends on NUC980_UART3
+	help
+	  This selects NUC980 uart3 CTS wake-up function
+
+config ENABLE_UART3_PDMA
+	bool "Enable UART3 PDMA function"
+	select ENABLE_UART_PDMA
+	depends on NUC980_UART3
+	help
+	  This selects NUC980 uart3 PDMA function
+
+choice
+	prompt "NUC980 UART3 pin selection"
+	default NUC980_UART3_PC
+	depends on NUC980_UART3
+	depends on !USE_OF
+	help
+	  Select UART3 multi-function pin.
+
+	config NUC980_UART3_PC
+		bool "Rx:PC4, Tx:PC3"
+	config NUC980_UART3_PB
+		bool "Rx:PB10, Tx:PB9"
+	config NUC980_UART3_PD
+		bool "Rx:PD3, Tx:PD2"
+	config NUC980_UART3_PB_PF
+		bool "Rx:PF6, Tx:PB13"
+	config NUC980_UART3_PF
+		bool "Rx:PF6, Tx:PF7"
+	config NUC980_UART3_FC_PB
+		bool "Rx:PB10, Tx:PB9, RTS:PB11, CTS:PB12"
+	config NUC980_UART3_FC_PD
+		bool "Rx:PD3, Tx:PD2, RTS:PD4, CTS:PD5"
+	config NUC980_UART3_FC_PF
+		bool "Rx:PF6, Tx:PF7, RTS:PF5, CTS:PF4"
+endchoice
+
+config NUC980_UART4
+	bool "NUC980 UART4 support"
+	depends on SERIAL_NUC980=y
+	help
+	  This selects NUC980 uart4 driver
+
+config ENABLE_UART4_CTS_WAKEUP
+	bool "Enable UART4 CTS wake-up function"
+	depends on NUC980_UART4
+	help
+	  This selects NUC980 uart4 CTS wake-up function
+
+config ENABLE_UART4_PDMA
+	bool "Enable UART4 PDMA function"
+	select ENABLE_UART_PDMA
+	depends on NUC980_UART4
+	help
+	  This selects NUC980 uart4 PDMA function
+
+choice
+	prompt "NUC980 UART4 pin selection"
+	default NUC980_UART4_PC
+	depends on NUC980_UART4
+	depends on !USE_OF
+	help
+	  Select UART4 multi-function pin.
+
+	config NUC980_UART4_PC
+		bool "Rx:PC10, Tx:PC9"
+	config NUC980_UART4_PD
+		bool "Rx:PD13, Tx:PD12"
+	config NUC980_UART4_PE
+		bool "Rx:PE2, Tx:PE3"
+	config NUC980_UART4_FC_PD
+		bool "Rx:PD13, Tx:PD12, RTS:PD14, CTS:PD15"
+	config NUC980_UART4_FC_PE
+		bool "Rx:PE2, Tx:PE3, RTS:PE1, CTS:PE0"
+endchoice
+
+
+config NUC980_UART5
+	bool "NUC980 UART5 support"
+	depends on SERIAL_NUC980=y
+	help
+	  This selects NUC980 uart5 driver
+
+config ENABLE_UART5_CTS_WAKEUP
+	bool "Enable UART5 CTS wake-up function"
+	depends on NUC980_UART5
+	help
+	  This selects NUC980 uart5 CTS wake-up function
+
+config ENABLE_UART5_PDMA
+	bool "Enable UART5 PDMA function"
+	select ENABLE_UART_PDMA
+	depends on NUC980_UART5
+	help
+	  This selects NUC980 uart5 PDMA function
+
+choice
+	prompt "NUC980 UART5 pin selection"
+	default NUC980_UART5_PG_0
+	depends on NUC980_UART5
+	depends on !USE_OF
+	help
+	  Select UART5 multi-function pin.
+
+	config NUC980_UART5_PG_0
+		bool "Rx:PG6, Tx:PG7"
+	config NUC980_UART5_PD
+		bool "Rx:PD1, Tx:PD0"
+	config NUC980_UART5_PG_1
+		bool "Rx:PG13, Tx:PG14"
+	config NUC980_UART5_FC_PG_0
+		bool "Rx:PG6, Tx:PG7, RTS:PG5, CTS:PG4"
+	config NUC980_UART5_FC_PG_1
+		bool "Rx:PG13, Tx:PG14, RTS:PG12, CTS:PG11"
+endchoice
+
+config NUC980_UART6
+	bool "NUC980 UART6 support"
+	depends on SERIAL_NUC980=y
+	help
+	  This selects NUC980 uart6 driver
+
+config ENABLE_UART6_CTS_WAKEUP
+	bool "Enable UART6 CTS wake-up function"
+	depends on NUC980_UART6
+	help
+	  This selects NUC980 uart6 CTS wake-up function
+
+config ENABLE_UART6_PDMA
+	bool "Enable UART6 PDMA function"
+	select ENABLE_UART_PDMA
+	depends on NUC980_UART6
+	help
+	  This selects NUC980 uart6 PDMA function
+
+choice
+	prompt "NUC980 UART6 pin selection"
+	default NUC980_UART6_PA
+	depends on NUC980_UART6
+	depends on !USE_OF
+	help
+	  Select UART6 multi-function pin.
+
+	config NUC980_UART6_PA
+		bool "Rx:PA4, Tx:PA5"
+	config NUC980_UART6_PD
+		bool "Rx:PD11, Tx:PD10"
+	config NUC980_UART6_PE
+		bool "Rx:PE8, Tx:PE9"
+	config NUC980_UART6_FC_PA
+		bool "Rx:PA4, Tx:PA5, RTS:PA3, CTS:PA2"
+	config NUC980_UART6_FC_PD
+		bool "Rx:PD11, Tx:PD10, RTS:PD9, CTS:PD8"
+endchoice
+
+config NUC980_UART7
+	bool "NUC980 UART7 support"
+	depends on SERIAL_NUC980=y
+	help
+	  This selects NUC980 uart7 driver
+
+config ENABLE_UART7_CTS_WAKEUP
+	bool "Enable UART7 CTS wake-up function"
+	depends on NUC980_UART7
+	help
+	  This selects NUC980 uart7 CTS wake-up function
+
+config ENABLE_UART7_PDMA
+	bool "Enable UART7 PDMA function"
+	select ENABLE_UART_PDMA
+	depends on NUC980_UART7
+	help
+	  This selects NUC980 uart7 PDMA function
+
+choice
+	prompt "NUC980 UART7 pin selection"
+	default NUC980_UART7_PA
+	depends on NUC980_UART7
+	depends on !USE_OF
+	help
+	  Select UART7 multi-function pin.
+
+	config NUC980_UART7_PA
+		bool "Rx:PA14, Tx:PA13"
+	config NUC980_UART7_PB
+		bool "Rx:PB4, Tx:PB6"
+	config NUC980_UART7_PC
+		bool "Rx:PC2, Tx:PC1"
+	config NUC980_UART7_PF
+		bool "Rx:PF2, Tx:PF3"
+	config NUC980_UART7_FC_PB
+		bool "Rx:PB4, Tx:PB6, RTS:PB5, CTS:PB7"
+	config NUC980_UART7_FC_PF
+		bool "Rx:PF2, Tx:PF3, RTS:PF1, CTS:PF0"
+endchoice
+
+config NUC980_UART8
+	bool "NUC970 UART8 support"
+	depends on SERIAL_NUC980=y
+	help
+	  This selects NUC980 uart8 driver
+
+config ENABLE_UART8_CTS_WAKEUP
+	bool "Enable UART8 CTS wake-up function"
+	depends on NUC980_UART8
+	help
+	  This selects NUC980 uart8 CTS wake-up function
+
+config ENABLE_UART8_PDMA
+	bool "Enable UART8 PDMA function"
+	select ENABLE_UART_PDMA
+	depends on NUC980_UART8
+	help
+	  This selects NUC980 uart8 PDMA function
+
+choice
+	prompt "NUC980 UART8 pin selection"
+	default NUC980_UART8_PA
+	depends on NUC980_UART8
+	depends on !USE_OF
+	help
+	  Select UART8 multi-function pin.
+
+	config NUC980_UART8_PA
+		bool "Rx:PA11, Tx:PA12"
+	config NUC980_UART8_PB
+		bool "Rx:PC0, Tx:PB8"
+	config NUC980_UART8_PC
+		bool "Rx:PC13, Tx:PC12"
+	config NUC980_UART8_FC_PA_PG
+		bool "Rx:PA11, Tx:PA12, RTS:PG8, CTS:PG9"
+	config NUC980_UART8_FC_PC
+		bool "Rx:PC13, Tx:PC12, RTS:PC14, CTS:PC15"
+endchoice
+
+config NUC980_UART9
+	bool "NUC980 UART9 support"
+	depends on SERIAL_NUC980=y
+	help
+	  This selects NUC980 uart9 driver
+
+config ENABLE_UART9_CTS_WAKEUP
+	bool "Enable UART9 CTS wake-up function"
+	depends on NUC980_UART9
+	help
+	  This selects NUC980 uart9 CTS wake-up function
+
+config ENABLE_UART9_PDMA
+	bool "Enable UART9 PDMA function"
+	select ENABLE_UART_PDMA
+	depends on NUC980_UART9
+	help
+	  This selects NUC980 uart9 PDMA function
+
+choice
+	prompt "NUC980 UART9 pin selection"
+	default NUC980_UART9_PB
+	depends on NUC980_UART9
+	depends on !USE_OF
+	help
+	  Select UART9 multi-function pin.
+
+	config NUC980_UART9_PB
+		bool "Rx:PB3, Tx:PB1"
+	config NUC980_UART9_PE_0
+		bool "Rx:PE6, Tx:PE7"
+	config NUC980_UART9_PE_1
+		bool "Rx:PE10, Tx:PE12"
+	config NUC980_UART9_FC_PE
+		bool "Rx:PE6, Tx:PE7, RTS:PE5, CTS:PE4"
+endchoice
+
+config SCUART_NUC980
+		bool "NUC980 Smartcard UART Mode support"
+		depends on ARCH_NUC980
+		select SERIAL_CORE
+		---help---
+		This selects NUC980 smartcard uart mode driver.
+
+config NUC980_SCUART0
+	bool "NUC980 SCUART0 support"
+	depends on ARCH_NUC980
+	depends on SCUART_NUC980=y && !USE_OF
+	help
+	  This selects NUC980 scuart0 driver
+choice
+	prompt "NUC980 SCUART0 pin selection"
+	default NUC980_SCUART0_PA
+	depends on NUC980_SCUART0
+	help
+	  Select SCUART0 multi-function pin.
+
+	config NUC980_SCUART0_PA
+		bool "Tx:PA5, Rx:PA4"
+	config NUC980_SCUART0_PC
+		bool "Tx:PC12, Rx:PC13"
+endchoice
+
+config NUC980_SCUART1
+	bool "NUC980 SCUART1 support"
+	depends on SCUART_NUC980=y && !USE_OF
+	help
+	  This selects NUC980 scuart1 driver
+choice
+	prompt "NUC980 SCUART1 pin selection"
+	default NUC980_SCUART1_PC
+	depends on NUC980_SCUART1
+	help
+	  Select SCUART1 multi-function pin.
+
+	config NUC980_SCUART1_PC
+		bool "Tx:PC7, Rx:PC8"
+	config NUC980_SCUART1_PF
+		bool "Tx:PF1, Rx:PF2"
+endchoice
+
 config SERIAL_AMBA_PL010
 	tristate "ARM AMBA PL010 serial port support"
 	depends on ARM_AMBA
diff -uprN linux-4.4.194/drivers/tty/serial/Makefile NUC980-linux-4.4.194/drivers/tty/serial/Makefile
--- linux-4.4.194/drivers/tty/serial/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/tty/serial/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -96,3 +96,5 @@ obj-$(CONFIG_SERIAL_STM32)	+= stm32-usar
 
 # GPIOLIB helpers for modem control lines
 obj-$(CONFIG_SERIAL_MCTRL_GPIO)	+= serial_mctrl_gpio.o
+obj-$(CONFIG_SERIAL_NUC980)  += nuc980_serial.o
+obj-$(CONFIG_SCUART_NUC980)  += nuc980_scuart.o
diff -uprN linux-4.4.194/drivers/tty/serial/nuc980_scuart.c NUC980-linux-4.4.194/drivers/tty/serial/nuc980_scuart.c
--- linux-4.4.194/drivers/tty/serial/nuc980_scuart.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/tty/serial/nuc980_scuart.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,735 @@
+/*
+ *  linux/drivers/tty/serial/nuc980_scuart.c
+ *
+ *  NUC980 Smartcard UART mode driver
+ *
+ *
+ *  Copyright (C) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+
+#include <linux/export.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/ioport.h>
+#include <linux/init.h>
+#include <linux/console.h>
+#include <linux/sysrq.h>
+#include <linux/delay.h>
+#include <linux/platform_device.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/clk.h>
+#include <linux/serial_core.h>
+#include <linux/serial.h>
+#include <linux/nmi.h>
+#include <linux/mutex.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/serial.h>
+
+#include <mach/map.h>
+#include <mach/regs-sc.h>
+#include <mach/regs-gcr.h>
+#include <mach/mfp.h>
+
+
+#define SCUART_NR 2
+static struct uart_driver nuc980serial_reg;
+struct plat_nuc980serial_port {
+	unsigned long	iobase;		/* io base address */
+	void __iomem	*membase;	/* ioremap cookie or NULL */
+	resource_size_t	mapbase;	/* resource base */
+	unsigned int	irq;		/* interrupt number */
+	unsigned int	uartclk;	/* UART clock rate */
+	void            *private_data;
+	unsigned int	(*serial_in)(struct uart_port *, int);
+	void		(*serial_out)(struct uart_port *, int, int);
+};
+
+
+struct uart_nuc980_port {
+	struct uart_port	port;
+	/*
+	 * We provide a per-port pm hook.
+	 */
+	void			(*pm)(struct uart_port *port,
+				      unsigned int state, unsigned int old);
+};
+
+static struct uart_nuc980_port nuc980serial_ports[SCUART_NR];
+
+static inline struct uart_nuc980_port *
+to_nuc980_uart_port(struct uart_port *uart)
+{
+	return container_of(uart, struct uart_nuc980_port, port);
+}
+
+static inline unsigned int serial_in(struct uart_nuc980_port *p, int offset)
+{
+	return(__raw_readl(p->port.membase + offset));
+}
+
+static inline void serial_out(struct uart_nuc980_port *p, int offset, int value)
+{
+	__raw_writel(value, p->port.membase + offset);
+}
+
+
+static inline void __stop_tx(struct uart_nuc980_port *p)
+{
+	unsigned int ier;
+
+	if ((ier = serial_in(p, REG_SC_INTEN)) & SC_INTEN_TBEIEN) {
+		serial_out(p, REG_SC_INTEN, ier & ~SC_INTEN_TBEIEN);
+	}
+}
+
+static void nuc980serial_stop_tx(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+
+	__stop_tx(up);
+
+}
+
+static void transmit_chars(struct uart_nuc980_port *up);
+
+static void nuc980serial_start_tx(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	unsigned int ier;
+
+
+	if (!((ier = serial_in(up, REG_SC_INTEN)) & SC_INTEN_TBEIEN)) {
+		ier |= SC_INTEN_TBEIEN;
+		serial_out(up, REG_SC_INTEN, ier);
+	}
+
+}
+
+static void nuc980serial_stop_rx(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+
+	serial_out(up, REG_SC_INTEN, serial_in(up, REG_SC_INTEN) & ~SC_INTEN_RDAIEN);
+}
+
+static void nuc980serial_enable_ms(struct uart_port *port)
+{
+
+}
+
+static void receive_chars(struct uart_nuc980_port *up)
+{
+	unsigned char ch;
+	unsigned int status;
+	int max_count = 256;
+	char flag;
+
+	do {
+		ch = (unsigned char)serial_in(up, REG_SC_DAT);
+		status = serial_in(up, REG_SC_STATUS);
+		flag = TTY_NORMAL;
+		up->port.icount.rx++;
+
+		if (unlikely(status & (SC_STATUS_BEF | SC_STATUS_FEF | SC_STATUS_PEF | SC_STATUS_RXOV))) {
+			if (status & SC_STATUS_BEF) {
+				serial_out(up, REG_SC_STATUS, SC_STATUS_BEF);
+				up->port.icount.brk++;
+				if (uart_handle_break(&up->port))
+					continue;
+			}
+
+			if (status & SC_STATUS_FEF) {
+				serial_out(up, REG_SC_STATUS, SC_STATUS_FEF);
+				up->port.icount.parity++;
+			}
+
+			if (status & SC_STATUS_PEF) {
+				serial_out(up, REG_SC_STATUS, SC_STATUS_PEF);
+				up->port.icount.frame++;
+			}
+
+			if (status & SC_STATUS_RXOV) {
+				serial_out(up, REG_SC_STATUS, SC_STATUS_RXOV);
+				up->port.icount.overrun++;
+			}
+			// FIXME: check port->read_status_mask to determin report flags
+			if (status & SC_STATUS_BEF)
+				flag = TTY_BREAK;
+			if (status & SC_STATUS_PEF)
+				flag = TTY_PARITY;
+			if (status & SC_STATUS_FEF)
+				flag = TTY_FRAME;
+		}
+
+		if (uart_handle_sysrq_char(&up->port, ch))
+			continue;
+
+		uart_insert_char(&up->port, status, SC_STATUS_RXOV, ch, flag);
+
+	} while (!(status & SC_STATUS_RXEMPTY) && (max_count-- > 0));
+
+	tty_flip_buffer_push(&up->port.state->port);
+}
+
+static void transmit_chars(struct uart_nuc980_port *up)
+{
+	struct circ_buf *xmit = &up->port.state->xmit;
+	int count = 4;	// SCUART FIFO depath is 4 bytes
+
+	if (up->port.x_char) {
+		while(serial_in(up, REG_SC_STATUS) & SC_STATUS_TXFULL);
+		serial_out(up, REG_SC_DAT, up->port.x_char);
+		up->port.icount.tx++;
+		up->port.x_char = 0;
+		return;
+	}
+	if (uart_tx_stopped(&up->port)) {
+		nuc980serial_stop_tx(&up->port);
+		return;
+	}
+
+	if (uart_circ_empty(xmit)) {
+		__stop_tx(up);
+		return;
+	}
+
+	do {
+		serial_out(up, REG_SC_DAT, xmit->buf[xmit->tail]);
+		xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
+		up->port.icount.tx++;
+		if (uart_circ_empty(xmit))
+			break;
+	} while (--count > 0);
+
+	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
+		uart_write_wakeup(&up->port);
+
+	if (uart_circ_empty(xmit))
+		__stop_tx(up);
+}
+
+
+static irqreturn_t nuc980serial_interrupt(int irq, void *dev_id)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)dev_id;
+	unsigned int isr, ier;
+
+	isr = serial_in(up, REG_SC_INTSTS);
+	ier = serial_in(up, REG_SC_INTEN);
+
+	if (isr & (SC_INTSTS_RXTOIF | SC_INTSTS_RDAIF))
+		receive_chars(up);
+
+	if ((isr & SC_INTSTS_TBEIF) && (ier & SC_INTEN_TBEIEN))
+		transmit_chars(up);
+
+	return IRQ_HANDLED;
+}
+
+static unsigned int nuc980serial_tx_empty(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	unsigned long flags;
+	unsigned int status;
+
+	spin_lock_irqsave(&up->port.lock, flags);
+	status = serial_in(up, REG_SC_STATUS);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+
+	return (status & SC_STATUS_TXEMPTY) ? TIOCSER_TEMT : 0;
+}
+
+static unsigned int nuc980serial_get_mctrl(struct uart_port *port)
+{
+
+	return 0;
+}
+
+static void nuc980serial_set_mctrl(struct uart_port *port, unsigned int mctrl)
+{
+
+}
+
+static void nuc980serial_break_ctl(struct uart_port *port, int break_state)
+{
+
+}
+
+static int nuc980serial_startup(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	struct tty_struct *tty = port->state->port.tty;
+	int retval;
+
+	/* Reset FIFO */
+	serial_out(up, REG_SC_ALTCTL, SC_ALTCTL_RXRST| SC_ALTCTL_TXRST);
+
+	/* Clear pending interrupts (not every bit are write 1 clear though...) */
+	serial_out(up, REG_SC_INTSTS, 0xFFFFFFFF);
+
+	retval = request_irq(port->irq, nuc980serial_interrupt, 0,
+			tty ? tty->name : "nuc980_scuart", port);
+
+	if (retval) {
+		printk("request irq failed...\n");
+		return retval;
+	}
+
+	/*
+	 * Now, initialize the UART
+	 */
+	serial_out(up, REG_SC_CTL, 0x41);	// enable SC engine, trigger level 2 bytes
+	serial_out(up, REG_SC_UARTCTL, serial_in(up, REG_SC_UARTCTL) | 1);	// enable UART mode
+	serial_out(up, REG_SC_RXTOUT, 0x40);
+	serial_out(up, REG_SC_INTEN, SC_INTEN_RXTOIEN | SC_INTEN_RDAIEN);
+
+	return 0;
+}
+
+static void nuc980serial_shutdown(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	//unsigned long flags;
+
+	/*
+	 * Disable interrupts from this port
+	 */
+	serial_out(up, REG_SC_INTEN, 0);
+	serial_out(up, REG_SC_ALTCTL, SC_ALTCTL_RXRST| SC_ALTCTL_TXRST);
+	free_irq(port->irq, port);
+
+}
+
+static unsigned int nuc980serial_get_divisor(struct uart_port *port, unsigned int baud)
+{
+	unsigned int quot;
+
+	quot = ((port->uartclk + baud / 2) / baud) - 1;
+
+	return quot;
+}
+
+static void nuc980serial_set_termios(struct uart_port *port, struct ktermios *termios,
+		       struct ktermios *old)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	unsigned int uartctl = 1, ctl;	// 1 is for enable UART mode
+	unsigned long flags;
+	unsigned int baud, quot;
+
+
+	switch (termios->c_cflag & CSIZE) {
+	case CS5:
+		uartctl |= 0x30;
+		break;
+	case CS6:
+		uartctl |= 0x20;
+		break;
+	case CS7:
+		uartctl |= 0x10;
+		break;
+	default:
+	case CS8:
+		uartctl |= 0;
+		break;
+	}
+
+	if (termios->c_cflag & PARENB)
+		uartctl &= ~0x40;
+	else
+		uartctl |= 0x40;
+	if (termios->c_cflag & PARODD)
+		uartctl |= 0x80;
+
+
+	baud = uart_get_baud_rate(port, termios, old,
+				  port->uartclk / 0xFFF,
+				  port->uartclk / 5);	// 4 < bauddate divider <= 0xFFF
+
+	quot = nuc980serial_get_divisor(port, baud);
+
+	/*
+	 * Ok, we're now changing the port state.  Do it with
+	 * interrupts disabled.
+	 */
+	spin_lock_irqsave(&up->port.lock, flags);
+
+	up->port.read_status_mask = SC_STATUS_RXOV;
+	if (termios->c_iflag & INPCK)
+		up->port.read_status_mask |= SC_STATUS_FEF | SC_STATUS_PEF;
+	if (termios->c_iflag & (BRKINT | PARMRK))
+		up->port.read_status_mask |= SC_STATUS_BEF;
+
+	/*
+	 * Characteres to ignore
+	 */
+	up->port.ignore_status_mask = 0;
+	if (termios->c_iflag & IGNPAR)
+		up->port.ignore_status_mask |= SC_STATUS_FEF | SC_STATUS_PEF;
+	if (termios->c_iflag & IGNBRK) {
+		up->port.ignore_status_mask |= SC_STATUS_BEF;
+		/*
+		 * If we're ignoring parity and break indicators,
+		 * ignore overruns too (for real raw support).
+		 */
+		if (termios->c_iflag & IGNPAR)
+			up->port.ignore_status_mask |= SC_STATUS_RXOV;
+	}
+
+	serial_out(up, REG_SC_ETUCTL, quot);
+	serial_out(up, REG_SC_UARTCTL, uartctl);
+
+	ctl = serial_in(up, REG_SC_CTL);
+
+	if (termios->c_cflag & CSTOPB)
+		ctl &= ~SC_CTL_NSB;
+	else
+		ctl |= SC_CTL_NSB;
+	serial_out(up, REG_SC_CTL, ctl);
+
+
+	spin_unlock_irqrestore(&up->port.lock, flags);
+
+}
+
+static void nuc980serial_set_ldisc(struct uart_port *port, struct ktermios *termios)
+{
+	return;
+
+}
+
+static void nuc980serial_pm(struct uart_port *port, unsigned int state,
+	      unsigned int oldstate)
+{
+	struct uart_nuc980_port *p = (struct uart_nuc980_port *)port;
+
+
+	if (p->pm)
+		p->pm(port, state, oldstate);
+}
+
+static void nuc980serial_release_port(struct uart_port *port)
+{
+	struct platform_device *pdev = to_platform_device(port->dev);
+	int size = pdev->resource[0].end - pdev->resource[0].start + 1;
+
+	release_mem_region(port->mapbase, size);
+
+	iounmap(port->membase);
+	port->membase = NULL;
+
+
+}
+
+static int nuc980serial_request_port(struct uart_port *port)
+{
+	return 0;
+}
+
+static void nuc980serial_config_port(struct uart_port *port, int flags)
+{
+	int ret;
+
+	/*
+	 * Find the region that we can probe for.  This in turn
+	 * tells us whether we can probe for the type of port.
+	 */
+	ret = nuc980serial_request_port(port);
+	if (ret < 0)
+		return;
+	port->type = PORT_NUC980;
+
+}
+
+static int
+nuc980serial_verify_port(struct uart_port *port, struct serial_struct *ser)
+{
+	if (ser->type != PORT_UNKNOWN && ser->type != PORT_NUC980)
+		return -EINVAL;
+	return 0;
+}
+
+static const char *
+nuc980serial_type(struct uart_port *port)
+{
+
+	return (port->type == PORT_NUC980) ? "NUC980" : NULL;
+}
+
+static struct uart_ops nuc980serial_ops = {
+	.tx_empty	= nuc980serial_tx_empty,
+	.set_mctrl	= nuc980serial_set_mctrl,
+	.get_mctrl	= nuc980serial_get_mctrl,
+	.stop_tx	= nuc980serial_stop_tx,
+	.start_tx	= nuc980serial_start_tx,
+	.stop_rx	= nuc980serial_stop_rx,
+	.enable_ms	= nuc980serial_enable_ms,
+	.break_ctl	= nuc980serial_break_ctl,
+	.startup	= nuc980serial_startup,
+	.shutdown	= nuc980serial_shutdown,
+	.set_termios	= nuc980serial_set_termios,
+	.set_ldisc	= nuc980serial_set_ldisc,
+	.pm		= nuc980serial_pm,
+	.type		= nuc980serial_type,
+	.release_port	= nuc980serial_release_port,
+	.request_port	= nuc980serial_request_port,
+	.config_port	= nuc980serial_config_port,
+	.verify_port	= nuc980serial_verify_port,
+
+};
+
+static void __init nuc980serial_init_ports(void)
+{
+	int i;
+
+	for (i = 0; i < SCUART_NR; i++) {
+		struct uart_nuc980_port *up = &nuc980serial_ports[i];
+		up->port.line = i;
+		spin_lock_init(&up->port.lock);
+
+		up->port.ops = &nuc980serial_ops;
+		up->port.iobase = (long)(NUC980_VA_SC0 + (i * 0x1000));
+		up->port.membase = NUC980_VA_SC0 + (i * 0x1000);
+		up->port.uartclk = 12000000;
+
+	}
+}
+
+static struct uart_driver nuc980serial_reg = {
+	.owner			= THIS_MODULE,
+	.driver_name		= "sc_serial",
+	.dev_name		= "ttySCU",
+	.major			= TTY_MAJOR,
+	.minor			= 80,//64,  reserve at least 11 for real UART
+	.nr			= SCUART_NR,
+};
+
+
+/**
+ *
+ *	Suspend one serial port.
+ */
+static void nuc980scuart_suspend_port(int line)
+{
+	uart_suspend_port(&nuc980serial_reg, &nuc980serial_ports[line].port);
+}
+
+/**
+ *
+ *	Resume one serial port.
+ */
+static void nuc980scuart_resume_port(int line)
+{
+	struct uart_nuc980_port *up = &nuc980serial_ports[line];
+
+	uart_resume_port(&nuc980serial_reg, &up->port);
+}
+
+static int nuc980serial_pinctrl(struct platform_device *pdev)
+{
+	struct pinctrl *p = NULL;
+	int retval = 0;
+
+#ifdef CONFIG_USE_OF
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+#else
+	if(pdev->id == 0) {
+#	if defined (CONFIG_NUC980_SCUART0_PA)
+		p = devm_pinctrl_get_select(&pdev->dev, "scuart0-PA");
+#	elif defined (CONFIG_NUC980_SCUART0_PC)
+		p = devm_pinctrl_get_select(&pdev->dev, "scuart0-PC");
+#	endif
+	} else { // if(pdev->id == 1)
+#	if defined (CONFIG_NUC980_SCUART1_PC)
+		p = devm_pinctrl_get_select(&pdev->dev, "scuart1-PC");
+#	elif defined (CONFIG_NUC980_SCUART1_PF)
+		p = devm_pinctrl_get_select(&pdev->dev, "scuart1-PF");
+#	endif
+	}
+#endif
+	if (IS_ERR(p)) {
+		dev_err(&pdev->dev, "Unable to reserve SC%d pin", pdev->id);
+		retval = PTR_ERR(p);
+	}
+
+	return retval;
+}
+
+static void nuc980serial_set_clock(int id)
+{
+	struct clk *clk;
+
+	if(id == 0) {
+		clk = clk_get(NULL, "smc0");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "smc0_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+	} else {
+		clk = clk_get(NULL, "smc1");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "smc1_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+	}
+
+}
+
+static const struct of_device_id nuc980_sc_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-scuart" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_sc_of_match);
+
+/*
+ * Register a set of serial devices attached to a platform device.  The
+ * list is terminated with a zero flags entry, which means we expect
+ * all entries to have at least UPF_BOOT_AUTOCONF set.
+ */
+static int nuc980serial_probe(struct platform_device *pdev)
+{
+#ifndef CONFIG_USE_OF
+	struct plat_nuc980serial_port *p = pdev->dev.platform_data;
+#endif
+	struct uart_nuc980_port *up;
+	int retval;
+
+#ifdef CONFIG_USE_OF
+	int i;
+
+	if(!of_match_device(nuc980_sc_of_match, &pdev->dev)) {
+		dev_err(&pdev->dev, "Failed to find matching device\n");
+		return -EINVAL;
+	}
+	of_property_read_u32_array(pdev->dev.of_node, "port-number", &i, 1);
+	pdev->id = i;
+#endif
+	retval = nuc980serial_pinctrl(pdev);
+	if(retval != 0)
+		return retval;
+
+	nuc980serial_set_clock(pdev->id);
+
+	up = &nuc980serial_ports[pdev->id];
+	up->port.line 		= pdev->id;
+#ifdef CONFIG_USE_OF
+	of_property_read_u32_array(pdev->dev.of_node, "reg", &i, 1);
+	up->port.iobase 	= (long)i;
+	up->port.membase      	= (void *)i;
+	up->port.irq = platform_get_irq(pdev, 0);
+	up->port.uartclk 	= 12000000;
+	of_property_read_u32_array(pdev->dev.of_node, "map-addr", &up->port.mapbase, 1);
+#else
+	up->port.iobase       	= (long)p->membase;
+	up->port.membase      	= p->membase;
+	up->port.irq          	= p->irq;
+	up->port.uartclk      	= p->uartclk;
+	up->port.mapbase     	= p->mapbase;
+	//up->port.private_data 	= p->private_data;
+#endif
+	up->port.dev 		= &pdev->dev;
+
+	up->port.flags 		= ASYNC_BOOT_AUTOCONF;
+	up->port.ops = &nuc980serial_ops;
+
+	spin_lock_init(&up->port.lock);
+
+
+	return uart_add_one_port(&nuc980serial_reg, &up->port);
+}
+
+/*
+ * Remove serial ports registered against a platform device.
+ */
+static int nuc980serial_remove(struct platform_device *pdev)
+{
+	struct uart_nuc980_port *up = &nuc980serial_ports[pdev->id];
+
+	uart_remove_one_port(&nuc980serial_reg, &up->port);
+	return 0;
+}
+
+static int nuc980serial_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct uart_nuc980_port *up = &nuc980serial_ports[pdev->id];
+
+	uart_suspend_port(&nuc980serial_reg, &up->port);
+	return 0;
+}
+
+static int nuc980serial_resume(struct platform_device *pdev)
+{
+	struct uart_nuc980_port *up = &nuc980serial_ports[pdev->id];
+
+	uart_resume_port(&nuc980serial_reg, &up->port);
+	return 0;
+}
+
+
+static struct platform_driver nuc980serial_driver = {
+	.probe		= nuc980serial_probe,
+	.remove		= nuc980serial_remove,
+	.suspend	= nuc980serial_suspend,
+	.resume		= nuc980serial_resume,
+	.driver		= {
+#ifdef CONFIG_USE_OF
+		.name	= "nuc980-scuart",
+#else
+		.name	= "nuc980-sc",		// share same dev structure with smartcard
+#endif
+		.of_match_table = of_match_ptr(nuc980_sc_of_match),
+		.owner	= THIS_MODULE,
+	},
+};
+
+static int __init nuc980serial_init(void)
+{
+	int ret;
+
+	ret = uart_register_driver(&nuc980serial_reg);
+	if (ret)
+		return ret;
+
+	ret = platform_driver_register(&nuc980serial_driver);
+	if (ret)
+		uart_unregister_driver(&nuc980serial_reg);
+
+	nuc980serial_init_ports();
+
+	return ret;
+}
+
+static void __exit nuc980serial_exit(void)
+{
+	platform_driver_unregister(&nuc980serial_driver);
+	uart_unregister_driver(&nuc980serial_reg);
+}
+
+module_init(nuc980serial_init);
+module_exit(nuc980serial_exit);
+
+EXPORT_SYMBOL(nuc980scuart_suspend_port);
+EXPORT_SYMBOL(nuc980scuart_resume_port);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("NUC980 scuart driver");
+
+MODULE_ALIAS_CHARDEV_MAJOR(TTY_MAJOR);
diff -uprN linux-4.4.194/drivers/tty/serial/nuc980_serial.c NUC980-linux-4.4.194/drivers/tty/serial/nuc980_serial.c
--- linux-4.4.194/drivers/tty/serial/nuc980_serial.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/tty/serial/nuc980_serial.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,2045 @@
+/*
+ *  linux/drivers/tty/serial/nuc980_serial.c
+ *
+ *  NUC980 serial driver
+ *
+ *
+ *  Copyright (C) 2018 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+#if defined(CONFIG_SERIAL_NUC980_CONSOLE) && defined(CONFIG_MAGIC_SYSRQ)
+#define SUPPORT_SYSRQ
+#endif
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/ioport.h>
+#include <linux/init.h>
+#include <linux/console.h>
+#include <linux/sysrq.h>
+#include <linux/delay.h>
+#include <linux/platform_device.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/clk.h>
+#include <linux/serial_reg.h>
+#include <linux/serial_core.h>
+#include <linux/serial.h>
+#include <linux/nmi.h>
+#include <linux/mutex.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <linux/of.h>
+#include <linux/of_irq.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/serial.h>
+
+#include <mach/map.h>
+#include <mach/regs-serial.h>
+#include <mach/regs-gcr.h>
+#include <mach/mfp.h>
+#include <mach/regs-pdma.h>
+#include <mach/sram.h>
+#include <linux/platform_data/dma-nuc980.h>
+
+
+#include "nuc980_serial.h"
+
+//#define USING_SRAM
+#define UART_NR 10
+#define UART_RX_BUF_SIZE 128 //bytes
+#define UART_TX_MAX_BUF_SIZE 128 //bytes
+
+//#define CONFIG_USE_DDR 1
+
+// PDMA mode time-out
+#define Time_Out_Frame_Count 2
+#define Time_Out_Low_Baudrate 115200
+
+
+static struct uart_driver nuc980serial_reg;
+
+struct clk      *clk;
+
+struct uart_nuc980_port {
+	struct uart_port    port;
+
+	unsigned short      capabilities;   /* port capabilities */
+	unsigned char       ier;
+	unsigned char       lcr;
+	unsigned char       mcr;
+	unsigned char       mcr_mask;  /* mask of user bits */
+	unsigned char       mcr_force; /* mask of forced bits */
+
+	struct serial_rs485 rs485; /* rs485 settings */
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	struct nuc980_ip_rx_dma dma_rx;
+	struct nuc980_ip_tx_dma dma_tx;
+	struct nuc980_mem_alloc src_mem_p;
+	struct nuc980_mem_alloc dest_mem_p;
+	struct nuc980_dma_done   dma_slave_done;
+
+	unsigned char PDMA_UARTx_TX;
+	unsigned char PDMA_UARTx_RX;
+
+	struct nuc980_dma_done   dma_Rx_done;
+	struct nuc980_dma_done   dma_Tx_done;
+
+	unsigned int tx_dma_len;
+
+	unsigned char uart_pdma_enable_flag;
+	unsigned char Tx_pdma_busy_flag;
+
+	unsigned int pdma_time_out_prescaler;
+	unsigned int pdma_time_out_count;
+	unsigned int baud_rate;
+#endif
+
+	/*
+	* We provide a per-port pm hook.
+	*/
+	void    (*pm)(struct uart_port *port, unsigned int state, unsigned int old);
+};
+
+static struct uart_nuc980_port nuc980serial_ports[UART_NR];
+
+
+static inline void __stop_tx(struct uart_nuc980_port *p);
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+static void nuc980_prepare_RX_dma(struct uart_nuc980_port *p);
+static void nuc980_prepare_TX_dma(struct uart_nuc980_port *p);
+#endif
+
+static inline struct uart_nuc980_port *
+to_nuc980_uart_port(struct uart_port *uart)
+{
+	return container_of(uart, struct uart_nuc980_port, port);
+}
+
+static inline unsigned int serial_in(struct uart_nuc980_port *p, int offset)
+{
+	return(__raw_readl(p->port.membase + offset));
+}
+
+static inline void serial_out(struct uart_nuc980_port *p, int offset, int value)
+{
+	__raw_writel(value, p->port.membase + offset);
+}
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+
+static void nuc980_Rx_dma_callback(void *arg)
+{
+	struct nuc980_dma_done *done = arg;
+	struct uart_nuc980_port *p = (struct uart_nuc980_port *)done->callback_param;
+	struct tty_port    *tty_port = &p->port.state->port;
+	int count;
+	int copied_count = 0;
+
+	if(done->timeout==1)
+		count = ((p->dest_mem_p.size/2) -(done->remain +1));
+	else
+		count = (p->dest_mem_p.size/2);
+
+	spin_lock(&p->port.lock);
+
+	if(done->base_addr==1)
+		copied_count = tty_insert_flip_string(tty_port, ((unsigned char *)p->dest_mem_p.vir_addr), count);
+	else
+		copied_count = tty_insert_flip_string(tty_port, ((unsigned char *)p->dest_mem_p.vir_addr+(p->dest_mem_p.size/2)), count);
+
+	if(copied_count != count) {
+		printk("\n Rx overrun: dropping %zu bytes \n", (count - copied_count));
+	}
+
+	p->port.icount.rx +=copied_count;
+
+	tty_flip_buffer_push(tty_port);
+
+	spin_unlock(&p->port.lock);
+
+	if(done->timeout==1) {
+		nuc980_prepare_RX_dma(p);
+		//Trigger Rx dma again
+		serial_out(p, UART_REG_IER, (serial_in(p, UART_REG_IER)|RXPDMAEN));
+	}
+
+	return;
+}
+
+static void nuc980_Tx_dma_callback(void *arg)
+{
+	struct nuc980_dma_done *done = arg;
+	struct uart_nuc980_port *p = (struct uart_nuc980_port *)done->callback_param;
+	struct circ_buf *xmit = &p->port.state->xmit;
+
+	spin_lock(&p->port.lock);
+
+	p->port.icount.tx += p->tx_dma_len;
+
+	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
+		uart_write_wakeup(&p->port);
+
+	if (!uart_circ_empty(xmit) && !uart_tx_stopped(&p->port)) {
+		p->Tx_pdma_busy_flag = 1;
+		nuc980_prepare_TX_dma(p);
+		// Trigger Tx dma again
+		serial_out(p, UART_REG_IER, (serial_in(p, UART_REG_IER)| TXPDMAEN));
+	} else {
+		p->Tx_pdma_busy_flag = 0;
+	}
+
+	spin_unlock(&p->port.lock);
+}
+
+static void set_pdma_flag(struct uart_nuc980_port *p, int id)
+{
+#if defined(CONFIG_ENABLE_UART1_PDMA) || defined(CONFIG_USE_OF)
+	if(id == 1) {
+		p->uart_pdma_enable_flag = 1;
+		p->PDMA_UARTx_RX = PDMA_UART1_RX;
+		p->PDMA_UARTx_TX = PDMA_UART1_TX;
+	}
+#endif
+
+#if defined(CONFIG_ENABLE_UART2_PDMA) || defined(CONFIG_USE_OF)
+	if(id == 2) {
+		p->uart_pdma_enable_flag = 1;
+		p->PDMA_UARTx_RX = PDMA_UART2_RX;
+		p->PDMA_UARTx_TX = PDMA_UART2_TX;
+	}
+#endif
+
+#if defined(CONFIG_ENABLE_UART3_PDMA) || defined(CONFIG_USE_OF)
+	if(id == 3) {
+		p->uart_pdma_enable_flag = 1;
+		p->PDMA_UARTx_RX = PDMA_UART3_RX;
+		p->PDMA_UARTx_TX = PDMA_UART3_TX;
+	}
+#endif
+
+#if defined(CONFIG_ENABLE_UART4_PDMA) || defined(CONFIG_USE_OF)
+	if(id == 4) {
+		p->uart_pdma_enable_flag = 1;
+		p->PDMA_UARTx_RX = PDMA_UART4_RX;
+		p->PDMA_UARTx_TX = PDMA_UART4_TX;
+	}
+#endif
+
+#if defined(CONFIG_ENABLE_UART5_PDMA) || defined(CONFIG_USE_OF)
+	if(id == 5) {
+		p->uart_pdma_enable_flag = 1;
+		p->PDMA_UARTx_RX = PDMA_UART5_RX;
+		p->PDMA_UARTx_TX = PDMA_UART5_TX;
+	}
+#endif
+
+#if defined(CONFIG_ENABLE_UART6_PDMA) || defined(CONFIG_USE_OF)
+	if(id == 6) {
+		p->uart_pdma_enable_flag = 1;
+		p->PDMA_UARTx_RX = PDMA_UART6_RX;
+		p->PDMA_UARTx_TX = PDMA_UART6_TX;
+	}
+#endif
+
+#if defined(CONFIG_ENABLE_UART7_PDMA) || defined(CONFIG_USE_OF)
+	if(id == 7) {
+		p->uart_pdma_enable_flag = 1;
+		p->PDMA_UARTx_RX = PDMA_UART7_RX;
+		p->PDMA_UARTx_TX = PDMA_UART7_TX;
+	}
+#endif
+
+#if defined(CONFIG_ENABLE_UART8_PDMA) || defined(CONFIG_USE_OF)
+	if(id == 8) {
+		p->uart_pdma_enable_flag = 1;
+		p->PDMA_UARTx_RX = PDMA_UART8_RX;
+		p->PDMA_UARTx_TX = PDMA_UART8_TX;
+	}
+#endif
+
+#if defined(CONFIG_ENABLE_UART9_PDMA) || defined(CONFIG_USE_OF)
+	if(id == 9) {
+		p->uart_pdma_enable_flag = 1;
+		p->PDMA_UARTx_RX = PDMA_UART9_RX;
+		p->PDMA_UARTx_TX = PDMA_UART9_TX;
+	}
+#endif
+}
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+void nuc980_uart_cal_pdma_time_out(struct uart_nuc980_port *p, unsigned int baud)
+{
+	unsigned int lcr;
+	unsigned int pdma_time_out_base = 300000000 * Time_Out_Frame_Count / 256; // 300M*Time_Out_Frame_Count/256
+	unsigned int time_out_prescaler = 0;
+	unsigned int bit_length;
+	unsigned int time_out;
+
+	if(baud > Time_Out_Low_Baudrate){
+		p->pdma_time_out_count = 255;
+		p->pdma_time_out_prescaler = 7;
+
+		return;
+	}
+
+	bit_length = 2;//1 start + 1 stop bit
+
+	lcr = serial_in(p, UART_REG_LCR);
+	switch(lcr & 0x3){
+		case 0:
+			bit_length += 5;
+
+			break;
+		case 1:
+			bit_length += 6;
+
+			break;
+		case 2:
+			bit_length += 7;
+
+			break;
+		case 3:
+			bit_length += 8;
+
+			break;
+	}
+
+	if(lcr & 0x4)
+		bit_length += 1;
+
+	if(lcr & 0x8)//Parity bit
+		bit_length += 1;
+
+	time_out = pdma_time_out_base * bit_length;
+	time_out = (time_out / baud) + 1;
+
+	while(time_out > 65535) // pdma max. time-out count is 65535
+	{
+		time_out = time_out / 2;
+		time_out_prescaler++;
+	}
+
+	if(time_out == 0) time_out = 1;
+
+	p->pdma_time_out_count = time_out;
+	p->pdma_time_out_prescaler = time_out_prescaler;
+
+	return;
+}
+#endif
+
+static void nuc980_prepare_RX_dma(struct uart_nuc980_port *p)
+{
+	struct nuc980_dma_config dma_crx;
+	struct nuc980_ip_rx_dma *pdma_rx = &(p->dma_rx);
+	dma_cookie_t cookie;
+
+	serial_out(p, UART_REG_IER, (serial_in(p, UART_REG_IER)&~ RXPDMAEN));
+
+	if(p->dest_mem_p.size == 0) {
+		// use DDR
+#ifndef USING_SRAM
+		//p->dest_mem_p.size = 256;
+		p->dest_mem_p.size = 4096*2;
+		p->dest_mem_p.vir_addr = (unsigned int)dma_alloc_writecombine(NULL,
+		                         PAGE_ALIGN(p->dest_mem_p.size),
+		                         &(p->dest_mem_p.phy_addr),
+		                         GFP_KERNEL);
+#else
+		p->dest_mem_p.size = 256; //set to 256 bytes
+		p->dest_mem_p.vir_addr =(u32)sram_alloc(p->dest_mem_p.size, &(p->dest_mem_p.phy_addr));
+#endif
+	}
+
+	pdma_rx->slave_config.src_addr = (unsigned int)(p->port.membase - 0x40000000);
+	pdma_rx->slave_config.src_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+	pdma_rx->slave_config.src_maxburst = 1;
+	pdma_rx->slave_config.direction = DMA_DEV_TO_MEM;
+	pdma_rx->slave_config.device_fc = false;
+	dmaengine_slave_config(pdma_rx->chan_rx,&(pdma_rx->slave_config));
+
+	sg_init_table(pdma_rx->sgrx, 1);
+	pdma_rx->sgrx[0].dma_address = p->dest_mem_p.phy_addr;
+	pdma_rx->sgrx[0].length = p->dest_mem_p.size;
+	dma_crx.reqsel = p->PDMA_UARTx_RX;
+
+	dma_crx.timeout_counter = p->pdma_time_out_count;
+	dma_crx.timeout_prescaler = p->pdma_time_out_prescaler;
+
+	dma_crx.en_sc = 1;
+	pdma_rx->rxdesc=pdma_rx->chan_rx->device->device_prep_slave_sg(pdma_rx->chan_rx,
+	                pdma_rx->sgrx,
+	                1,
+	                DMA_FROM_DEVICE,
+	                DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+	                (void *)&dma_crx); //PDMA Request Source Select
+	if (!pdma_rx->rxdesc) {
+		printk("pdma->rxdesc=NULL\n");
+		while(1);
+	}
+	//dma_slave_done.done = false;
+	pdma_rx->rxdesc->callback = nuc980_Rx_dma_callback;
+	p->dma_Rx_done.callback_param = p;
+	p->dma_Rx_done.base_addr = 0;
+	p->dma_Rx_done.timeout = 0;
+	pdma_rx->rxdesc->callback_param = &(p->dma_Rx_done);
+	cookie = pdma_rx->rxdesc->tx_submit(pdma_rx->rxdesc);
+	if (dma_submit_error(cookie)) {
+		printk("rx dma_submit_error  \n");
+		while(1);
+	}
+
+}
+
+static void nuc980_prepare_TX_dma(struct uart_nuc980_port *p)
+{
+	struct nuc980_dma_config dma_ctx;
+	struct nuc980_ip_tx_dma *pdma_tx = &(p->dma_tx);
+	dma_cookie_t cookie;
+	struct circ_buf *xmit = &p->port.state->xmit;
+
+	if(p->src_mem_p.size == 0) {
+		p->src_mem_p.size = UART_XMIT_SIZE;
+		p->src_mem_p.vir_addr = (unsigned int)dma_alloc_writecombine(NULL,
+		                        PAGE_ALIGN(p->src_mem_p.size),
+		                        &(p->src_mem_p.phy_addr),
+		                        GFP_KERNEL);
+	}
+
+	p->tx_dma_len = uart_circ_chars_pending(xmit);
+	if (xmit->tail < xmit->head) {
+		memcpy((unsigned char *)p->src_mem_p.vir_addr, &xmit->buf[xmit->tail], p->tx_dma_len);
+	} else {
+		size_t first = UART_XMIT_SIZE - xmit->tail;
+		size_t second = xmit->head;
+		memcpy((unsigned char *)p->src_mem_p.vir_addr, &xmit->buf[xmit->tail], first);
+		if (second)
+			memcpy((unsigned char *)p->src_mem_p.vir_addr+first, &xmit->buf[0], second);
+	}
+	xmit->tail = (xmit->tail +  p->tx_dma_len) & (UART_XMIT_SIZE - 1);
+
+	serial_out(p, UART_REG_IER, (serial_in(p, UART_REG_IER) &~ TXPDMAEN));
+	pdma_tx->slave_config.dst_addr = (unsigned int)(p->port.membase - 0x40000000);
+	pdma_tx->slave_config.dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+	pdma_tx->slave_config.dst_maxburst = 1;
+	pdma_tx->slave_config.direction = DMA_MEM_TO_DEV;
+	dmaengine_slave_config(pdma_tx->chan_tx,&(pdma_tx->slave_config));
+	sg_init_table(pdma_tx->sgtx, 1);
+	pdma_tx->sgtx[0].dma_address =p->src_mem_p.phy_addr;
+	pdma_tx->sgtx[0].length = p->tx_dma_len;
+	dma_ctx.reqsel = p->PDMA_UARTx_TX;
+	// disable time-out
+	dma_ctx.timeout_counter = 0;
+	dma_ctx.timeout_prescaler = 0;
+	dma_ctx.en_sc = 0;
+	pdma_tx->txdesc = pdma_tx->chan_tx->device->device_prep_slave_sg(pdma_tx->chan_tx,
+	                  pdma_tx->sgtx,
+	                  1,
+	                  DMA_TO_DEVICE,
+	                  DMA_PREP_INTERRUPT | DMA_CTRL_ACK,
+	                  (void *)&dma_ctx);
+	if (!pdma_tx->txdesc) {
+		printk("pdma->txdes==NULL\n");
+		while(1);
+	}
+
+	pdma_tx->txdesc->callback = nuc980_Tx_dma_callback;
+	p->dma_Tx_done.callback_param = p;
+	pdma_tx->txdesc->callback_param = &(p->dma_Tx_done);
+
+	cookie = pdma_tx->txdesc->tx_submit(pdma_tx->txdesc);
+	if (dma_submit_error(cookie)) {
+		printk("dma_submit_error\n");
+		while(1);
+	}
+}
+
+#endif
+
+
+static void rs485_start_rx(struct uart_nuc980_port *port)
+{
+#if 0  // user can enable to control RTS pin level
+	// when enable this define, user need disable auto-flow control
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+
+	if(port->rs485.flags & SER_RS485_RTS_AFTER_SEND) {
+		// Set logical level for RTS pin equal to high
+		serial_out(port, UART_REG_MCR, (serial_in(port, UART_REG_MCR) & ~0x200) );
+	} else {
+		// Set logical level for RTS pin equal to low
+		serial_out(port, UART_REG_MCR, (serial_in(port, UART_REG_MCR) | 0x200) );
+	}
+#endif
+}
+
+static void rs485_stop_rx(struct uart_nuc980_port *port)
+{
+#if 0  // user can enable to control RTS pin level
+	// when enable this define, user need disable auto-flow control
+	if(port->rs485.flags & SER_RS485_RTS_ON_SEND) {
+		// Set logical level for RTS pin equal to high
+		serial_out(port, UART_REG_MCR, (serial_in(port, UART_REG_MCR) & ~0x200) );
+	} else {
+		// Set logical level for RTS pin equal to low
+		serial_out(port, UART_REG_MCR, (serial_in(port, UART_REG_MCR) | 0x200) );
+	}
+#endif
+
+}
+
+static inline void __stop_tx(struct uart_nuc980_port *p)
+{
+	unsigned int ier;
+	struct tty_struct *tty = p->port.state->port.tty;
+
+	if ((ier = serial_in(p, UART_REG_IER)) & THRE_IEN) {
+		serial_out(p, UART_REG_IER, ier & ~THRE_IEN);
+	}
+	if (p->rs485.flags & SER_RS485_ENABLED)
+		rs485_start_rx(p);
+
+	if (tty->termios.c_line == N_IRDA) {
+		while(!(serial_in(p, UART_REG_FSR) & TX_EMPTY));
+		while(!(serial_in(p, UART_REG_FSR) & TE_FLAG));
+
+		serial_out(p, UART_REG_IRCR, (serial_in(p, UART_REG_IRCR) & ~0x2) ); // Tx disable (select Rx)
+	}
+
+}
+
+static void nuc980serial_stop_tx(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+
+	__stop_tx(up);
+}
+
+static void transmit_chars(struct uart_nuc980_port *up);
+
+static void nuc980serial_start_tx(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	unsigned int ier;
+	struct tty_struct *tty = up->port.state->port.tty;
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	struct circ_buf *xmit = &up->port.state->xmit;
+#endif
+
+	if (tty->termios.c_line == N_IRDA) {
+		serial_out(up, UART_REG_IRCR, (serial_in(up, UART_REG_IRCR) | 0x2) ); // Tx enable
+	}
+
+	if (up->rs485.flags & SER_RS485_ENABLED)
+		rs485_stop_rx(up);
+
+#if 0   // No use FIFO
+	if (!((ier = serial_in(up, UART_REG_IER)) & THRE_IEN)) {
+		ier |= THRE_IEN;
+		serial_out(up, UART_REG_IER, ier);
+	}
+#else // use FIFO
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	if(up->uart_pdma_enable_flag == 1) {
+		if(up->Tx_pdma_busy_flag == 1) {
+			return;
+		}
+
+		if (uart_circ_empty(xmit)) {
+			__stop_tx(up);
+			return;
+		}
+
+		up->Tx_pdma_busy_flag = 1;
+		nuc980_prepare_TX_dma(up);
+		serial_out(up, UART_REG_IER, (serial_in(up, UART_REG_IER)|TXPDMAEN));
+	} else
+#endif
+	{
+		struct circ_buf *xmit = &up->port.state->xmit;
+		ier = serial_in(up, UART_REG_IER);
+		serial_out(up, UART_REG_IER, ier & ~THRE_IEN);
+		if( uart_circ_chars_pending(xmit)<(16-((serial_in(up, UART_REG_FSR)>>16)&0x3F)) )
+			transmit_chars(up);
+		serial_out(up, UART_REG_IER, ier | THRE_IEN);
+	}
+#endif
+
+}
+
+static void nuc980serial_stop_rx(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+
+	serial_out(up, UART_REG_IER, serial_in(up, UART_REG_IER) & ~RDA_IEN);
+}
+
+static void nuc980serial_enable_ms(struct uart_port *port)
+{
+
+}
+
+static int max_count = 0;
+
+static void
+receive_chars(struct uart_nuc980_port *up)
+{
+	unsigned char ch;
+	unsigned int fsr;
+	unsigned int isr;
+	unsigned int dcnt;
+
+	char flag;
+	isr = serial_in(up, UART_REG_ISR);
+	fsr = serial_in(up, UART_REG_FSR);
+
+	while(!(fsr & RX_EMPTY)) {
+		//fsr = serial_in(up, UART_REG_FSR);
+		flag = TTY_NORMAL;
+		up->port.icount.rx++;
+
+		if (unlikely(fsr & (BIF | FEF | PEF | RX_OVER_IF))) {
+			if (fsr & BIF) {
+				serial_out(up, UART_REG_FSR, BIF);
+				up->port.icount.brk++;
+				if (uart_handle_break(&up->port))
+					continue;
+			}
+
+			if (fsr & FEF) {
+				serial_out(up, UART_REG_FSR, FEF);
+				up->port.icount.frame++;
+			}
+
+			if (fsr & PEF) {
+				serial_out(up, UART_REG_FSR, PEF);
+				up->port.icount.parity++;
+			}
+
+			if (fsr & RX_OVER_IF) {
+				serial_out(up, UART_REG_FSR, RX_OVER_IF);
+				up->port.icount.overrun++;
+			}
+			// FIXME: check port->read_status_mask to determin report flags
+			if (fsr & BIF)
+				flag = TTY_BREAK;
+			if (fsr & PEF)
+				flag = TTY_PARITY;
+			if (fsr & FEF)
+				flag = TTY_FRAME;
+		}
+
+		ch = (unsigned char)serial_in(up, UART_REG_RBR);
+
+		if (uart_handle_sysrq_char(&up->port, ch))
+			continue;
+
+		uart_insert_char(&up->port, fsr, RX_OVER_IF, ch, flag);
+		max_count++;
+		dcnt=(serial_in(up, UART_REG_FSR) >> 8) & 0x3f;
+		if(max_count > 1023)
+		{
+			spin_lock(&up->port.lock);
+			tty_flip_buffer_push(&up->port.state->port);
+			spin_unlock(&up->port.lock);
+			max_count=0;
+			if((isr & TOUT_IF) && (dcnt == 0))
+				goto tout_end;
+		}
+
+		if(isr & RDA_IF) {
+			if(dcnt == 1)
+				return; // have remaining data, don't reset max_count
+		}
+		fsr = serial_in(up, UART_REG_FSR);
+	}
+
+	spin_lock(&up->port.lock);
+	tty_flip_buffer_push(&up->port.state->port);
+	spin_unlock(&up->port.lock);
+tout_end:
+	max_count=0;
+	return;
+}
+
+static void transmit_chars(struct uart_nuc980_port *up)
+{
+	struct circ_buf *xmit = &up->port.state->xmit;
+	//int count = 12;
+	int count = 16 -((serial_in(up, UART_REG_FSR)>>16)&0xF);
+
+	if(serial_in(up, UART_REG_FSR) & TX_FULL){
+		count = 0;
+	}
+
+	if (up->port.x_char) {
+		while(serial_in(up, UART_REG_FSR) & TX_FULL);
+		serial_out(up, UART_REG_THR, up->port.x_char);
+		up->port.icount.tx++;
+		up->port.x_char = 0;
+		return;
+	}
+
+	if (uart_tx_stopped(&up->port)) {
+		nuc980serial_stop_tx(&up->port);
+		return;
+	}
+
+	if (uart_circ_empty(xmit)) {
+		__stop_tx(up);
+		return;
+	}
+
+	while(count > 0){
+		//while(serial_in(up, UART_REG_FSR) & TX_FULL);
+		serial_out(up, UART_REG_THR, xmit->buf[xmit->tail]);
+		xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
+		up->port.icount.tx++;
+		count--;
+		if (uart_circ_empty(xmit))
+			break;
+	}
+
+	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
+		uart_write_wakeup(&up->port);
+
+	if (uart_circ_empty(xmit))
+		__stop_tx(up);
+
+}
+
+static unsigned int check_modem_status(struct uart_nuc980_port *up)
+{
+	unsigned int status = 0;
+
+	if (0) {
+		wake_up_interruptible(&up->port.state->port.delta_msr_wait);
+	}
+
+	return status;
+}
+
+static irqreturn_t nuc980serial_interrupt(int irq, void *dev_id)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)dev_id;
+	unsigned int isr, fsr;
+
+	isr = serial_in(up, UART_REG_ISR);
+	fsr = serial_in(up, UART_REG_FSR);
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	if(up->uart_pdma_enable_flag == 1) {
+		if(fsr & (BIF | FEF | PEF | RX_OVER_IF | HWBUFE_IF | TX_OVER_IF)) {
+			serial_out(up, UART_REG_FSR, (BIF | FEF | PEF | RX_OVER_IF | TX_OVER_IF));
+		}
+	} else
+#endif
+	{
+		//isr = serial_in(up, UART_REG_ISR);
+
+		if (isr & (RDA_IF | TOUT_IF))
+			receive_chars(up);
+
+		check_modem_status(up);
+
+		if (isr & THRE_INT)
+			transmit_chars(up);
+
+		if(fsr & (BIF | FEF | PEF | RX_OVER_IF | TX_OVER_IF)) {
+			serial_out(up, UART_REG_FSR, (BIF | FEF | PEF | RX_OVER_IF | TX_OVER_IF));
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+static unsigned int nuc980serial_tx_empty(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	//unsigned long flags;
+	unsigned int fsr;
+
+	//spin_lock_irqsave(&up->port.lock, flags);
+	fsr = serial_in(up, UART_REG_FSR);
+	//spin_unlock_irqrestore(&up->port.lock, flags);
+
+	return (fsr & (TE_FLAG | TX_EMPTY)) == (TE_FLAG | TX_EMPTY) ? TIOCSER_TEMT : 0;
+}
+
+static unsigned int nuc980serial_get_mctrl(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	unsigned int status;
+	unsigned int ret = 0;
+
+	status = serial_in(up, UART_REG_MSR);;
+
+	if(!(status & 0x10))
+		ret |= TIOCM_CTS;
+
+	return ret;
+}
+
+static void nuc980serial_set_mctrl(struct uart_port *port, unsigned int mctrl)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	unsigned int mcr = 0;
+	unsigned int ier = 0;
+
+	if (mctrl & TIOCM_RTS) {
+		// set RTS high level trigger
+		mcr = serial_in(up, UART_REG_MCR);
+		mcr |= 0x200;
+		mcr &= ~(0x2);
+	}
+
+	if (up->mcr & UART_MCR_AFE) {
+		// set RTS high level trigger
+		mcr = serial_in(up, UART_REG_MCR);
+		mcr |= 0x200;
+		mcr &= ~(0x2);
+
+		// enable CTS/RTS auto-flow control
+		serial_out(up, UART_REG_IER, (serial_in(up, UART_REG_IER) | (0x3000)));
+
+		// Set hardware flow control
+		up->port.flags |= UPF_HARD_FLOW;
+	} else {
+		// disable CTS/RTS auto-flow control
+		ier = serial_in(up, UART_REG_IER);
+		ier &= ~(0x3000);
+		serial_out(up, UART_REG_IER, ier);
+
+		//un-set hardware flow control
+		up->port.flags &= ~UPF_HARD_FLOW;
+	}
+
+	// set CTS high level trigger
+	serial_out(up, UART_REG_MSR, (serial_in(up, UART_REG_MSR) | (0x100)));
+
+	serial_out(up, UART_REG_MCR, mcr);
+}
+
+static void nuc980serial_break_ctl(struct uart_port *port, int break_state)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	unsigned long flags;
+	unsigned int lcr;
+
+	spin_lock_irqsave(&up->port.lock, flags);
+	lcr = serial_in(up, UART_REG_LCR);
+	if (break_state != 0)
+		lcr |= BCB; // set break
+	else
+		lcr &= ~BCB;    // clr break
+	serial_out(up, UART_REG_LCR, lcr);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+}
+
+static int nuc980serial_startup(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	struct tty_struct *tty = port->state->port.tty;
+	int retval;
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	struct nuc980_ip_rx_dma *pdma_rx = &(up->dma_rx);
+	struct nuc980_ip_tx_dma *pdma_tx = &(up->dma_tx);
+
+	dma_cap_mask_t mask;
+#endif
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_SLAVE, mask);
+	dma_cap_set(DMA_PRIVATE, mask);
+
+	if(up->uart_pdma_enable_flag == 1) {
+		pdma_rx->chan_rx = dma_request_channel(mask, NULL, NULL);
+		if (!pdma_rx->chan_rx) {
+			printk("RX DMA channel request error\n");
+			return -1;
+		}
+		pdma_rx->chan_rx->private=(void *)1;
+
+		pdma_tx->chan_tx = dma_request_channel(mask, NULL, NULL);
+		if (!pdma_tx->chan_tx) {
+			printk("TX DMA channel request error\n");
+			return -1;
+		}
+		pdma_tx->chan_tx->private=(void *)1;
+	}
+#endif
+
+	/* Reset FIFO */
+	serial_out(up, UART_REG_FCR, TFR | RFR /* | RX_DIS */);
+
+	/* Clear pending interrupts (not every bit are write 1 clear though...) */
+	serial_out(up, UART_REG_ISR, 0xFFFFFFFF);
+
+	retval = request_irq(port->irq, nuc980serial_interrupt, IRQF_NO_SUSPEND, tty ? tty->name : "nuc980_serial", port);
+
+	if (retval) {
+		printk("request irq failed...\n");
+		return retval;
+	}
+
+	/*
+	 * Now, initialize the UART
+	 */
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	serial_out(up, UART_REG_FCR, serial_in(up, UART_REG_FCR) | 0x0); // Trigger level 1 byte
+#else
+	serial_out(up, UART_REG_FCR, serial_in(up, UART_REG_FCR) | 0x10); // Trigger level 4 byte
+#endif
+
+	serial_out(up, UART_REG_LCR, 0x7); // 8 bit
+	serial_out(up, UART_REG_TOR, 0x40);
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	if(up->uart_pdma_enable_flag == 1)
+		serial_out(up, UART_REG_IER, RLS_IEN | BUFERR_IEN);
+	else
+#endif
+		serial_out(up, UART_REG_IER, RTO_IEN | RDA_IEN | TIME_OUT_EN | BUFERR_IEN);
+	//serial_out(up, UART_REG_IER, RTO_IEN | RDA_IEN | TIME_OUT_EN);
+
+	/* 12MHz reference clock input, 115200 */
+	serial_out(up, UART_REG_BAUD, 0x30000066);
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	if(up->uart_pdma_enable_flag == 1) {
+		up->baud_rate = 0;
+	}
+#endif
+
+	return 0;
+}
+
+static void nuc980serial_shutdown(struct uart_port *port)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	struct nuc980_ip_rx_dma *pdma_rx = &(up->dma_rx);
+	struct nuc980_ip_tx_dma *pdma_tx = &(up->dma_tx);
+#endif
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	if(up->uart_pdma_enable_flag == 1) {
+		dma_release_channel(pdma_rx->chan_rx);
+		dma_release_channel(pdma_tx->chan_tx);
+
+#ifdef USING_SRAM
+		sram_free((void *)up->dest_mem_p.vir_addr, up->dest_mem_p.size);
+#else
+		if(up->dest_mem_p.size != 0)
+		{
+			dma_free_writecombine(NULL, up->dest_mem_p.size, (void *)up->dest_mem_p.vir_addr, up->dest_mem_p.phy_addr);
+		}
+#endif
+
+		if(up->src_mem_p.size != 0)
+		{
+			dma_free_writecombine(NULL, up->src_mem_p.size, (void *)up->src_mem_p.vir_addr, up->src_mem_p.phy_addr);
+		}
+
+		up->Tx_pdma_busy_flag = 0;
+		up->dest_mem_p.size = 0;
+		up->src_mem_p.size = 0;
+	}
+#endif
+
+	free_irq(port->irq, port);
+
+	/*
+	 * Disable interrupts from this port
+	 */
+	serial_out(up, UART_REG_IER, 0);
+}
+
+static unsigned int nuc980serial_get_divisor(struct uart_port *port, unsigned int baud)
+{
+	unsigned int quot;
+
+	quot = (port->uartclk / baud) - 2;
+
+	return quot;
+}
+
+static void
+nuc980serial_set_termios(struct uart_port *port, struct ktermios *termios, struct ktermios *old)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+	unsigned int lcr = 0;
+	unsigned long flags;
+	unsigned int baud, quot;
+
+	switch (termios->c_cflag & CSIZE) {
+	case CS5:
+		lcr = 0;
+		break;
+	case CS6:
+		lcr |= 1;
+		break;
+	case CS7:
+		lcr |= 2;
+		break;
+	default:
+	case CS8:
+		lcr |= 3;
+		break;
+	}
+
+	if (termios->c_cflag & CSTOPB)
+		lcr |= NSB;
+	if (termios->c_cflag & PARENB)
+		lcr |= PBE;
+	if (!(termios->c_cflag & PARODD))
+		lcr |= EPE;
+	if (termios->c_cflag & CMSPAR)
+		lcr |= SPE;
+
+	baud = uart_get_baud_rate(port, termios, old, port->uartclk / 0xffff, port->uartclk / 11);
+
+	quot = nuc980serial_get_divisor(port, baud);
+
+	/*
+	 * Ok, we're now changing the port state.  Do it with
+	 * interrupts disabled.
+	 */
+	spin_lock_irqsave(&up->port.lock, flags);
+
+	up->port.read_status_mask = RX_OVER_IF /*| UART_LSR_THRE | UART_LSR_DR*/;
+	if (termios->c_iflag & INPCK)
+		up->port.read_status_mask |= FEF | PEF;
+	if (termios->c_iflag & (BRKINT | PARMRK))
+		up->port.read_status_mask |= BIF;
+
+	/*
+	 * Characteres to ignore
+	 */
+	up->port.ignore_status_mask = 0;
+	if (termios->c_iflag & IGNPAR)
+		up->port.ignore_status_mask |= FEF | PEF;
+	if (termios->c_iflag & IGNBRK) {
+		up->port.ignore_status_mask |= BIF;
+		/*
+		 * If we're ignoring parity and break indicators,
+		 * ignore overruns too (for real raw support).
+		 */
+		if (termios->c_iflag & IGNPAR)
+			up->port.ignore_status_mask |= RX_OVER_IF;
+	}
+
+	if (termios->c_cflag & CRTSCTS)
+		up->mcr |= UART_MCR_AFE;
+	else
+		up->mcr &= ~UART_MCR_AFE;
+
+	nuc980serial_set_mctrl(&up->port, up->port.mctrl);
+
+	serial_out(up, UART_REG_BAUD, quot | 0x30000000);
+
+	serial_out(up, UART_REG_LCR, lcr);
+
+	spin_unlock_irqrestore(&up->port.lock, flags);
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+	if(up->uart_pdma_enable_flag == 1) {
+		if(up->baud_rate != baud){
+			up->baud_rate = baud;
+
+			nuc980_uart_cal_pdma_time_out(up, baud);
+
+			nuc980_prepare_RX_dma(up);
+
+			nuc980_prepare_TX_dma(up);
+
+			// trigger pdma
+			serial_out(up, UART_REG_IER, (serial_in(up, UART_REG_IER)|RXPDMAEN));
+		}
+	}
+#endif
+}
+
+static void
+nuc980serial_set_ldisc(struct uart_port *port, struct ktermios *termios)
+{
+	struct uart_nuc980_port *uart = (struct uart_nuc980_port *)port;
+	unsigned int baud;
+
+	switch (termios->c_line) {
+	case N_IRDA:
+
+		baud = serial_in(uart, UART_REG_BAUD);
+		baud = baud & (0x0000ffff);
+		baud = baud + 2;
+		baud = baud / 16;
+		baud = baud - 2;
+
+		serial_out(uart, UART_REG_BAUD, baud);
+		serial_out(uart, UART_REG_IRCR, (serial_in(uart, UART_REG_IRCR) & ~0x40) );  // Rx inverse
+
+		serial_out(uart, UART_FUN_SEL, (serial_in(uart, UART_FUN_SEL) & ~FUN_SEL_Msk) );
+		serial_out(uart, UART_FUN_SEL, (serial_in(uart, UART_FUN_SEL) | FUN_SEL_IrDA) );
+
+		break;
+	default:
+		serial_out(uart, UART_FUN_SEL, (serial_in(uart, UART_FUN_SEL) & ~FUN_SEL_Msk) );
+	}
+
+}
+
+static void
+nuc980serial_pm(struct uart_port *port, unsigned int state, unsigned int oldstate)
+{
+	struct uart_nuc980_port *p = (struct uart_nuc980_port *)port;
+
+	if (p->pm)
+		p->pm(port, state, oldstate);
+}
+
+static void nuc980serial_release_port(struct uart_port *port)
+{
+	struct platform_device *pdev = to_platform_device(port->dev);
+	int size = pdev->resource[0].end - pdev->resource[0].start + 1;
+
+	release_mem_region(port->mapbase, size);
+
+	iounmap(port->membase);
+	port->membase = NULL;
+}
+
+static int nuc980serial_request_port(struct uart_port *port)
+{
+	return 0;
+}
+
+static void nuc980serial_config_port(struct uart_port *port, int flags)
+{
+	int ret;
+
+	/*
+	 * Find the region that we can probe for.  This in turn
+	 * tells us whether we can probe for the type of port.
+	 */
+	ret = nuc980serial_request_port(port);
+	if (ret < 0)
+		return;
+	port->type = PORT_NUC980;
+}
+
+static int nuc980serial_verify_port(struct uart_port *port, struct serial_struct *ser)
+{
+	if (ser->type != PORT_UNKNOWN && ser->type != PORT_NUC980)
+		return -EINVAL;
+	return 0;
+}
+
+static const char *nuc980serial_type(struct uart_port *port)
+{
+	return (port->type == PORT_NUC980) ? "NUC980" : NULL;
+}
+
+/* Enable or disable the rs485 support */
+static int nuc980serial_config_rs485(struct uart_port *port, struct serial_rs485 *rs485conf)
+{
+	struct uart_nuc980_port *p = to_nuc980_uart_port(port);
+
+	p->rs485 = *rs485conf;
+
+	if (p->rs485.delay_rts_before_send >= 1000)
+		p->rs485.delay_rts_before_send = 1000;
+
+	serial_out(p, UART_FUN_SEL, (serial_in(p, UART_FUN_SEL) & ~FUN_SEL_Msk) );
+
+	if(rs485conf->flags & SER_RS485_ENABLED) {
+		serial_out(p, UART_FUN_SEL, (serial_in(p, UART_FUN_SEL) | FUN_SEL_RS485) );
+
+		//rs485_start_rx(p);    // stay in Rx mode
+
+		if(rs485conf->flags & SER_RS485_RTS_ON_SEND) {
+			serial_out(p, UART_REG_MCR, (serial_in(p, UART_REG_MCR) & ~0x200) );
+		} else {
+			serial_out(p, UART_REG_MCR, (serial_in(p, UART_REG_MCR) | 0x200) );
+		}
+
+		// set auto direction mode
+		serial_out(p,UART_REG_ALT_CSR,(serial_in(p, UART_REG_ALT_CSR) | (1 << 10)) );
+	}
+
+	return 0;
+}
+
+static int nuc980serial_ioctl(struct uart_port *port, unsigned int cmd, unsigned long arg)
+{
+	switch (cmd) {
+
+	default:
+		return -ENOIOCTLCMD;
+	}
+	return 0;
+}
+
+static struct uart_ops nuc980serial_ops = {
+	.tx_empty    = nuc980serial_tx_empty,
+	.set_mctrl   = nuc980serial_set_mctrl,
+	.get_mctrl   = nuc980serial_get_mctrl,
+	.stop_tx     = nuc980serial_stop_tx,
+	.start_tx    = nuc980serial_start_tx,
+	.stop_rx     = nuc980serial_stop_rx,
+	.enable_ms   = nuc980serial_enable_ms,
+	.break_ctl   = nuc980serial_break_ctl,
+	.startup     = nuc980serial_startup,
+	.shutdown    = nuc980serial_shutdown,
+	.set_termios = nuc980serial_set_termios,
+	.set_ldisc   = nuc980serial_set_ldisc,
+	.pm          = nuc980serial_pm,
+	.type        = nuc980serial_type,
+	.release_port= nuc980serial_release_port,
+	.request_port= nuc980serial_request_port,
+	.config_port = nuc980serial_config_port,
+	.verify_port = nuc980serial_verify_port,
+	.ioctl       = nuc980serial_ioctl,
+};
+
+static void __init nuc980serial_init_ports(void)
+{
+	static int first = 1;
+	int i;
+
+	// enable clock
+	clk = clk_get(NULL, "uart0");
+	clk_prepare(clk);
+	clk_enable(clk);
+
+	// UART0 multi-function  PF11,PF12
+	//__raw_writel((__raw_readl(NUC980_VA_GCR+0x9C)&0xfff00fff) | 0x11000,(NUC980_VA_GCR+0x9C));
+	if (!first)
+		return;
+	first = 0;
+
+	for (i = 0; i < UART_NR; i++) {
+		struct uart_nuc980_port *up = &nuc980serial_ports[i];
+
+		up->port.line = i;
+		spin_lock_init(&up->port.lock);
+
+		up->port.ops = &nuc980serial_ops;
+		up->port.iobase = (long)(NUC980_VA_UART0 + (i*0x1000));
+		up->port.membase = NUC980_VA_UART0 + (i*0x1000);
+		up->port.uartclk = 12000000;
+
+	}
+}
+
+#ifdef CONFIG_SERIAL_NUC980_CONSOLE
+static void nuc980serial_console_putchar(struct uart_port *port, int ch)
+{
+	struct uart_nuc980_port *up = (struct uart_nuc980_port *)port;
+
+	while(!(serial_in(up, UART_REG_FSR) & TX_EMPTY));
+	serial_out(up, UART_REG_THR, ch);
+}
+
+/*
+ *  Print a string to the serial port trying not to disturb
+ *  any possible real use of the port...
+ *
+ *  The console_lock must be held when we get here.
+ */
+static void nuc980serial_console_write(struct console *co, const char *s, unsigned int count)
+{
+	struct uart_nuc980_port *up = &nuc980serial_ports[co->index];
+	unsigned long flags;
+	unsigned int ier;
+
+	local_irq_save(flags);
+
+	/*
+	 *  First save the IER then disable the interrupts
+	 */
+	ier = serial_in(up, UART_REG_IER);
+	serial_out(up, UART_REG_IER, 0);
+
+	uart_console_write(&up->port, s, count, nuc980serial_console_putchar);
+
+	/*
+	 *  Finally, wait for transmitter to become empty
+	 *  and restore the IER
+	 */
+	while(!(serial_in(up, UART_REG_FSR) & TX_EMPTY));
+	serial_out(up, UART_REG_IER, ier);
+
+	local_irq_restore(flags);
+}
+
+static int __init nuc980serial_console_setup(struct console *co, char *options)
+{
+	struct uart_port *port;
+	int baud = 115200;
+	int bits = 8;
+	int parity = 'n';
+	int flow = 'n';
+
+	/*
+	 * Check whether an invalid uart number has been specified, and
+	 * if so, search for the first available port that does have
+	 * console support.
+	 */
+	if (co->index >= UART_NR)
+		co->index = 0;
+	port = &nuc980serial_ports[co->index].port;
+
+	if (!port->iobase && !port->membase)
+		return -ENODEV;
+
+	if (options)
+		uart_parse_options(options, &baud, &parity, &bits, &flow);
+
+	return uart_set_options(port, co, baud, parity, bits, flow);
+}
+
+
+static struct console nuc980serial_console = {
+	.name    = "ttyS",
+	.write   = nuc980serial_console_write,
+	.device  = uart_console_device,
+	.setup   = nuc980serial_console_setup,
+	.flags   = CON_PRINTBUFFER,
+	.index   = -1,
+	.data    = &nuc980serial_reg,
+};
+
+static int __init nuc980serial_console_init(void)
+{
+	nuc980serial_init_ports();
+	register_console(&nuc980serial_console);
+
+	return 0;
+}
+console_initcall(nuc980serial_console_init);
+
+#define NUC980SERIAL_CONSOLE    &nuc980serial_console
+#else
+#define NUC980SERIAL_CONSOLE    NULL
+#endif
+
+static struct uart_driver nuc980serial_reg = {
+	.owner        = THIS_MODULE,
+	.driver_name  = "serial",
+	.dev_name     = "ttyS",
+	.major        = TTY_MAJOR,
+	.minor        = 64,
+	.cons         = NUC980SERIAL_CONSOLE,
+	.nr           = UART_NR,
+};
+
+
+/**
+ *
+ *  Suspend one serial port.
+ */
+void nuc980serial_suspend_port(int line)
+{
+	uart_suspend_port(&nuc980serial_reg, &nuc980serial_ports[line].port);
+}
+
+/**
+ *
+ *  Resume one serial port.
+ */
+void nuc980serial_resume_port(int line)
+{
+	struct uart_nuc980_port *up = &nuc980serial_ports[line];
+
+	uart_resume_port(&nuc980serial_reg, &up->port);
+}
+
+#ifndef CONFIG_USE_OF
+static int nuc980serial_pinctrl(struct platform_device *pdev)
+{
+	struct pinctrl *p = NULL;
+	int retval = 0;
+
+	if(pdev->id == 1) {
+#if defined (CONFIG_NUC980_UART1_PA)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart1-PA");
+#elif defined (CONFIG_NUC980_UART1_PC)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart1-PC");
+#elif defined (CONFIG_NUC980_UART1_PF)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart1-PF");
+#elif defined (CONFIG_NUC980_UART1_FC_PC)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart1-fc-PC");
+#elif defined (CONFIG_NUC980_UART1_FC_PF)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart1-fc-PF");
+#endif
+
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve pin\n");
+			retval = PTR_ERR(p);
+		}
+	} else if(pdev->id == 2) {
+#if defined (CONFIG_NUC980_UART2_PA)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart2-PA");
+#elif defined (CONFIG_NUC980_UART2_PG)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart2-PG");
+#elif defined (CONFIG_NUC980_UART2_PD)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart2-PD");
+#elif defined (CONFIG_NUC980_UART2_FC_PA)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart2-fc-PA");
+#elif defined (CONFIG_NUC980_UART2_FC_PG)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart2-fc-PG");
+#elif defined (CONFIG_NUC980_UART2_FC_PA_PB)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart2-fc-PA_PB");
+#endif
+
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve pin\n");
+			retval = PTR_ERR(p);
+		}
+	} else if(pdev->id == 3) {
+#if defined (CONFIG_NUC980_UART3_PC)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart3-PC");
+#elif defined (CONFIG_NUC980_UART3_PB)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart3-PB");
+#elif defined (CONFIG_NUC980_UART3_PD)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart3-PD");
+#elif defined (CONFIG_NUC980_UART3_PB_PF)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart3-PB_PF");
+#elif defined (CONFIG_NUC980_UART3_PF)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart3-PF");
+#elif defined (CONFIG_NUC980_UART3_FC_PB)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart3-fc-PB");
+#elif defined (CONFIG_NUC980_UART3_FC_PD)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart3-fc-PD");
+#elif defined (CONFIG_NUC980_UART3_FC_PF)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart3-fc-PF");
+#endif
+
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve pin\n");
+			retval = PTR_ERR(p);
+		}
+	} else if(pdev->id == 4) {
+#if defined (CONFIG_NUC980_UART4_PC)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart4-PC");
+#elif defined (CONFIG_NUC980_UART4_PD)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart4-PD");
+#elif defined (CONFIG_NUC980_UART4_PE)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart4-PE");
+#elif defined (CONFIG_NUC980_UART4_FC_PD)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart4-fc-PD");
+#elif defined (CONFIG_NUC980_UART4_FC_PE)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart4-fc-PE");
+#endif
+
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve pin\n");
+			retval = PTR_ERR(p);
+		}
+	} else if(pdev->id == 5) {
+#if defined (CONFIG_NUC980_UART5_PG_0)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart5-PG_0");
+#elif defined (CONFIG_NUC980_UART5_PD)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart5-PD");
+#elif defined (CONFIG_NUC980_UART5_PG_1)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart5-PG_1");
+#elif defined (CONFIG_NUC980_UART5_FC_PG_0)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart5-fc-PG_0");
+#elif defined (CONFIG_NUC980_UART5_FC_PG_1)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart5-fc-PG_1");
+#endif
+
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve pin\n");
+			retval = PTR_ERR(p);
+		}
+	} else if(pdev->id == 6) {
+#if defined (CONFIG_NUC980_UART6_PA)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart6-PA");
+#elif defined (CONFIG_NUC980_UART6_PD)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart6-PD");
+#elif defined (CONFIG_NUC980_UART6_PE)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart6-PE");
+#elif defined (CONFIG_NUC980_UART6_FC_PA)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart6-fc-PA");
+#elif defined (CONFIG_NUC980_UART6_FC_PD)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart6-fc-PD");
+#endif
+
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve pin\n");
+			retval = PTR_ERR(p);
+		}
+	} else if(pdev->id == 7) {
+#if defined (CONFIG_NUC980_UART7_PA)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart7-PA");
+#elif defined (CONFIG_NUC980_UART7_PB)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart7-PB");
+#elif defined (CONFIG_NUC980_UART7_PC)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart7-PC");
+#elif defined (CONFIG_NUC980_UART7_PF)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart7-PF");
+#elif defined (CONFIG_NUC980_UART7_FC_PB)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart7-fc-PB");
+#elif defined (CONFIG_NUC980_UART7_FC_PF)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart7-fc-PF");
+#endif
+
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve pin\n");
+			retval = PTR_ERR(p);
+		}
+	} else if(pdev->id == 8) {
+#if defined (CONFIG_NUC980_UART8_PA)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart8-PA");
+#elif defined (CONFIG_NUC980_UART8_PB)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart8-PB");
+#elif defined (CONFIG_NUC980_UART8_PC)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart8-PC");
+#elif defined (CONFIG_NUC980_UART8_FC_PA_PG)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart8-fc-PA_PG");
+#elif defined (CONFIG_NUC980_UART8_FC_PC)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart8-fc-PC");
+#endif
+
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve pin\n");
+			retval = PTR_ERR(p);
+		}
+	} else if(pdev->id == 9) {
+#if defined (CONFIG_NUC980_UART9_PB)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart9-PB");
+#elif defined (CONFIG_NUC980_UART9_PE_0)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart9-PE_0");
+#elif defined (CONFIG_NUC980_UART9_PE_1)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart9-PE_1");
+#elif defined (CONFIG_NUC980_UART9_FC_PE)
+		p = devm_pinctrl_get_select(&pdev->dev, "uart9-fc-PE");
+#endif
+
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve pin\n");
+			retval = PTR_ERR(p);
+		}
+	}
+
+	return retval;
+}
+#endif
+
+void nuc980serial_set_clock(struct uart_nuc980_port *up)
+{
+	struct clk *clkmux;
+	struct clk *upll_clk;
+
+	if(up->port.line == 0) {
+		clk = clk_get(NULL, "uart0");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart0_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+	}
+
+#ifdef CONFIG_NUC980_UART1
+	if(up->port.line == 1) {
+		clk = clk_get(NULL, "uart1");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart1_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clkmux = clk_get(NULL, "uart1_eclk_mux");
+		upll_clk = clk_get(NULL, "upll");
+		clk_set_parent(clkmux, upll_clk);
+
+		clk = clk_get(NULL, "uart1_eclk_div");
+
+		//clk_set_rate(clk, 100000000);
+		clk_set_rate(clk, 150000000);
+		up->port.uartclk = clk_get_rate(clk);
+	}
+#endif
+
+#ifdef CONFIG_NUC980_UART2
+	if(up->port.line == 2) {
+		clk = clk_get(NULL, "uart2");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart2_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clkmux = clk_get(NULL, "uart2_eclk_mux");
+		upll_clk = clk_get(NULL, "upll");
+		clk_set_parent(clkmux, upll_clk);
+
+		clk = clk_get(NULL, "uart2_eclk_div");
+
+		//clk_set_rate(clk, 100000000);
+		clk_set_rate(clk, 150000000);
+		up->port.uartclk = clk_get_rate(clk);
+	}
+#endif
+
+#ifdef CONFIG_NUC980_UART3
+	if(up->port.line == 3) {
+		clk = clk_get(NULL, "uart3");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart3_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clkmux = clk_get(NULL, "uart3_eclk_mux");
+		upll_clk = clk_get(NULL, "upll");
+		clk_set_parent(clkmux, upll_clk);
+
+		clk = clk_get(NULL, "uart3_eclk_div");
+
+		//clk_set_rate(clk, 100000000);
+		clk_set_rate(clk, 150000000);
+		up->port.uartclk = clk_get_rate(clk);
+	}
+#endif
+
+#ifdef CONFIG_NUC980_UART4
+	if(up->port.line == 4) {
+		clk = clk_get(NULL, "uart4");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart4_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clkmux = clk_get(NULL, "uart4_eclk_mux");
+		upll_clk = clk_get(NULL, "upll");
+		clk_set_parent(clkmux, upll_clk);
+
+		clk = clk_get(NULL, "uart4_eclk_div");
+
+		//clk_set_rate(clk, 100000000);
+		clk_set_rate(clk, 150000000);
+		up->port.uartclk = clk_get_rate(clk);
+	}
+#endif
+
+#ifdef CONFIG_NUC980_UART5
+	if(up->port.line == 5) {
+		clk = clk_get(NULL, "uart5");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart5_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clkmux = clk_get(NULL, "uart5_eclk_mux");
+		upll_clk = clk_get(NULL, "upll");
+		clk_set_parent(clkmux, upll_clk);
+
+		clk = clk_get(NULL, "uart5_eclk_div");
+
+		//clk_set_rate(clk, 100000000);
+		clk_set_rate(clk, 150000000);
+		up->port.uartclk = clk_get_rate(clk);
+	}
+#endif
+
+#ifdef CONFIG_NUC980_UART6
+	if(up->port.line == 6) {
+		clk = clk_get(NULL, "uart6");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart6_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clkmux = clk_get(NULL, "uart6_eclk_mux");
+		upll_clk = clk_get(NULL, "upll");
+		clk_set_parent(clkmux, upll_clk);
+
+		clk = clk_get(NULL, "uart6_eclk_div");
+
+		//clk_set_rate(clk, 100000000);
+		clk_set_rate(clk, 150000000);
+		up->port.uartclk = clk_get_rate(clk);
+	}
+#endif
+
+#ifdef CONFIG_NUC980_UART7
+	if(up->port.line == 7) {
+		clk = clk_get(NULL, "uart7");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart7_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clkmux = clk_get(NULL, "uart7_eclk_mux");
+		upll_clk = clk_get(NULL, "upll");
+		clk_set_parent(clkmux, upll_clk);
+
+		clk = clk_get(NULL, "uart7_eclk_div");
+
+		//clk_set_rate(clk, 100000000);
+		clk_set_rate(clk, 150000000);
+		up->port.uartclk = clk_get_rate(clk);
+	}
+#endif
+
+#ifdef CONFIG_NUC980_UART8
+	if(up->port.line == 8) {
+		clk = clk_get(NULL, "uart8");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart8_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clkmux = clk_get(NULL, "uart8_eclk_mux");
+		upll_clk = clk_get(NULL, "upll");
+		clk_set_parent(clkmux, upll_clk);
+
+		clk = clk_get(NULL, "uart8_eclk_div");
+
+		//clk_set_rate(clk, 100000000);
+		clk_set_rate(clk, 150000000);
+		up->port.uartclk = clk_get_rate(clk);
+	}
+#endif
+
+#ifdef CONFIG_NUC980_UART9
+	if(up->port.line == 9) {
+		clk = clk_get(NULL, "uart9");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clk = clk_get(NULL, "uart9_eclk");
+		clk_prepare(clk);
+		clk_enable(clk);
+
+		clkmux = clk_get(NULL, "uart9_eclk_mux");
+		upll_clk = clk_get(NULL, "upll");
+		clk_set_parent(clkmux, upll_clk);
+
+		clk = clk_get(NULL, "uart9_eclk_div");
+
+		//clk_set_rate(clk, 100000000);
+		clk_set_rate(clk, 150000000);
+		up->port.uartclk = clk_get_rate(clk);
+	}
+#endif
+
+}
+
+#if defined(CONFIG_USE_OF)
+static int  get_uart_port_number(struct platform_device *pdev)
+{
+	u32   val32[2];
+
+	if (of_property_read_u32_array(pdev->dev.of_node, "port-number", val32, 1) != 0) {
+		printk("%s - can not get port-number!\n", __func__);
+		return -EINVAL;
+	}
+
+	return val32[0];
+}
+#endif
+
+/*
+ * Register a set of serial devices attached to a platform device.  The
+ * list is terminated with a zero flags entry, which means we expect
+ * all entries to have at least UPF_BOOT_AUTOCONF set.
+ */
+static int nuc980serial_probe(struct platform_device *pdev)
+{
+	struct uart_nuc980_port *up;
+
+	int ret, i;
+
+#if defined(CONFIG_USE_OF)
+	struct pinctrl *pinctrl;
+	u32   val32[2];
+#else
+	int retval;
+	struct plat_nuc980serial_port *p = pdev->dev.platform_data;
+#endif
+
+#if defined(CONFIG_USE_OF)
+	pinctrl = devm_pinctrl_get_select_default(&pdev->dev);
+	if (IS_ERR(pinctrl)) {
+		return PTR_ERR(pinctrl);
+	}
+#else
+	retval = nuc980serial_pinctrl(pdev);
+	if(retval != 0)
+		return retval;
+#endif
+
+#if defined(CONFIG_USE_OF)
+	i = get_uart_port_number(pdev);
+	if (i < 0)
+		return -EINVAL;
+#else
+	i = pdev->id;
+#endif
+
+	up = &nuc980serial_ports[i];
+
+	up->port.line = i;
+
+	nuc980serial_set_clock(up);
+
+#if defined(CONFIG_ENABLE_UART_PDMA) || defined(CONFIG_USE_OF)
+#if defined(CONFIG_USE_OF)
+	if (of_property_read_u32_array(pdev->dev.of_node, "pdma-enable", val32, 1) != 0) {
+		printk("%s - can not get map-addr!\n", __func__);
+		return -EINVAL;
+	}
+
+	if(val32[0] == 1) set_pdma_flag(up, i);
+
+#else
+	set_pdma_flag(up, i);
+#endif
+#endif
+
+#if defined(CONFIG_USE_OF)
+	/*--------------------------------------------------------------*/
+	/*  get UART register map address from DTB                      */
+	/*--------------------------------------------------------------*/
+	if (of_property_read_u32_array(pdev->dev.of_node, "map-addr", val32, 1) != 0) {
+		printk("%s - can not get map-addr!\n", __func__);
+		return -EINVAL;
+	}
+
+	up->port.membase = (unsigned char __iomem *)val32[0];
+
+	up->port.iobase         = (unsigned long)up->port.membase;
+	up->port.irq            = platform_get_irq(pdev, 0);
+	up->port.dev            = &pdev->dev;
+	up->port.flags          = ASYNC_BOOT_AUTOCONF;
+
+#else
+	up->port.membase        = p->membase;
+
+	up->port.iobase         = p->iobase;
+	up->port.irq            = p->irq;
+	//up->port.uartclk        = p->uartclk;
+	up->port.mapbase        = p->mapbase;
+	up->port.private_data   = p->private_data;
+	up->port.dev            = &pdev->dev;
+	up->port.flags          = ASYNC_BOOT_AUTOCONF;
+
+	/* Possibly override default I/O functions.  */
+	if (p->serial_in)
+		up->port.serial_in = p->serial_in;
+	if (p->serial_out)
+		up->port.serial_out = p->serial_out;
+
+#endif
+
+	up->port.rs485_config = nuc980serial_config_rs485;
+
+	ret = uart_add_one_port(&nuc980serial_reg, &up->port);
+	return 0;
+}
+
+/*
+ * Remove serial ports registered against a platform device.
+ */
+static int nuc980serial_remove(struct platform_device *dev)
+{
+	int i;
+	struct uart_port *port = platform_get_drvdata(dev);
+
+	free_irq(port->irq, port);
+
+	for (i = 0; i < UART_NR; i++) {
+		struct uart_nuc980_port *up = &nuc980serial_ports[i];
+
+		if (up->port.dev == &dev->dev)
+			uart_remove_one_port(&nuc980serial_reg, &up->port);
+	}
+	return 0;
+}
+
+static int nuc980serial_suspend(struct platform_device *dev, pm_message_t state)
+{
+	int i;
+	int wakeup_flag = 0;
+
+	struct uart_nuc980_port *up;
+
+#if defined(CONFIG_USE_OF)
+	i = get_uart_port_number(dev);
+	if (i < 0)
+		return i;
+#else
+	i = dev->id;
+#endif
+
+	up = &nuc980serial_ports[i];
+
+#ifdef CONFIG_ENABLE_UART1_CTS_WAKEUP
+	if(i == 1) {
+		__raw_writel((1<<17) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+		wakeup_flag = 1;
+	}
+#endif
+
+#ifdef CONFIG_ENABLE_UART2_CTS_WAKEUP
+	if(i == 2) {
+		__raw_writel((1<<18) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+		wakeup_flag = 1;
+	}
+#endif
+
+#ifdef CONFIG_ENABLE_UART3_CTS_WAKEUP
+	if(i == 3) {
+		__raw_writel((1<<19) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+		wakeup_flag = 1;
+	}
+#endif
+
+#ifdef CONFIG_ENABLE_UART4_CTS_WAKEUP
+	if(i == 4) {
+		__raw_writel((1<<20) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+		wakeup_flag = 1;
+	}
+#endif
+
+#ifdef CONFIG_ENABLE_UART5_CTS_WAKEUP
+	if(i == 5) {
+		__raw_writel((1<<21) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+		wakeup_flag = 1;
+	}
+#endif
+
+#ifdef CONFIG_ENABLE_UART6_CTS_WAKEUP
+	if(i == 6) {
+		__raw_writel((1<<22) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+		wakeup_flag = 1;
+	}
+#endif
+
+#ifdef CONFIG_ENABLE_UART7_CTS_WAKEUP
+	if(i == 7) {
+		__raw_writel((1<<23) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+		wakeup_flag = 1;
+	}
+#endif
+
+#ifdef CONFIG_ENABLE_UART8_CTS_WAKEUP
+	if(i == 8)
+		__raw_writel((1<<24) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+	wakeup_flag = 1;
+#endif
+
+#ifdef CONFIG_ENABLE_UART9_CTS_WAKEUP
+	if(i == 9) {
+		__raw_writel((1<<25) | __raw_readl(REG_WKUPSER0),REG_WKUPSER0);
+		wakeup_flag = 1;
+	}
+#endif
+
+	if(wakeup_flag == 1) {
+		serial_out(up, UART_REG_IER, serial_in(up, UART_REG_IER) | (0x1 << 6));
+		serial_out(up, UART_REG_WKSTS, 0x1); // Clear CTS Wakeup status
+		serial_out(up, UART_REG_WKCTL, 0x1); // Enable CTS Wakeup
+
+		enable_irq_wake(up->port.irq);
+	}
+
+	return 0;
+}
+
+static int nuc980serial_resume(struct platform_device *dev)
+{
+	int i;
+
+	for (i = 0; i < UART_NR; i++) {
+		struct uart_nuc980_port *up = &nuc980serial_ports[i];
+
+		serial_out(up, UART_REG_WKSTS, 0x1); // Clear CTS Wakeup status
+	}
+
+	return 0;
+}
+
+static const struct of_device_id nuc980_serial_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-uart" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_serial_of_match);
+
+static struct platform_driver nuc980serial_driver = {
+	.probe      = nuc980serial_probe,
+	.remove     = nuc980serial_remove,
+	.suspend    = nuc980serial_suspend,
+	.resume     = nuc980serial_resume,
+	.driver     =
+	{
+		.name   = "nuc980-uart",
+		.owner  = THIS_MODULE,
+#if defined(CONFIG_USE_OF)
+		.of_match_table = of_match_ptr(nuc980_serial_of_match),
+#endif
+	},
+};
+
+static int __init nuc980serial_init(void)
+{
+	int ret;
+
+	ret = uart_register_driver(&nuc980serial_reg);
+	if (ret)
+		return ret;
+#ifndef CONFIG_SERIAL_NUC980_CONSOLE
+	nuc980serial_init_ports();
+#endif
+	ret = platform_driver_register(&nuc980serial_driver);
+	if (ret)
+		uart_unregister_driver(&nuc980serial_reg);
+
+	return ret;
+}
+
+static void __exit nuc980serial_exit(void)
+{
+	platform_driver_unregister(&nuc980serial_driver);
+	uart_unregister_driver(&nuc980serial_reg);
+}
+
+module_init(nuc980serial_init);
+module_exit(nuc980serial_exit);
+
+EXPORT_SYMBOL(nuc980serial_suspend_port);
+EXPORT_SYMBOL(nuc980serial_resume_port);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("NUC980 serial driver");
+
+MODULE_ALIAS_CHARDEV_MAJOR(TTY_MAJOR);
diff -uprN linux-4.4.194/drivers/tty/serial/nuc980_serial.h NUC980-linux-4.4.194/drivers/tty/serial/nuc980_serial.h
--- linux-4.4.194/drivers/tty/serial/nuc980_serial.h	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/tty/serial/nuc980_serial.h	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,83 @@
+/*
+ *  linux/drivers/serial/nuc980_serial.h
+ *
+ *  NUC980 serial driver header file
+ *
+ *
+ *  Copyright (C) 2017 Nuvoton Technology Corp.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+#ifndef __NUC980_SERIAL_H__
+#define __NUC980_SERIAL_H__
+
+#define UART_REG_RBR	0x00
+#define UART_REG_THR	0x00
+
+#define UART_REG_IER	0x04
+#define RDA_IEN		0x00000001
+#define THRE_IEN	0x00000002
+#define RLS_IEN		0x00000004
+#define RTO_IEN		0x00000010
+#define BUFERR_IEN	0x00000020
+#define TIME_OUT_EN	0x00000800
+#define TXPDMAEN	0x00004000
+#define RXPDMAEN	0x00008000
+
+#define UART_REG_FCR	0x08
+#define RFR		0x00000002
+#define TFR		0x00000004
+
+#define UART_REG_LCR	0x0C
+#define	NSB		0x00000004
+#define PBE		0x00000008
+#define EPE		0x00000010
+#define SPE		0x00000020
+#define BCB		0x00000040
+
+#define UART_REG_MCR	0x10
+#define UART_REG_MSR	0x14
+
+#define UART_REG_FSR	0x18
+#define RX_OVER_IF	0x00000001
+#define TX_OVER_IF	0x01000000
+#define PEF		0x00000010
+#define FEF		0x00000020
+#define BIF		0x00000040
+#define RX_EMPTY	0x00004000
+#define TX_EMPTY	0x00400000
+#define TX_FULL		0x00800000
+#define RX_FULL		0x00008000
+#define TE_FLAG		0x10000000
+
+#define UART_REG_ISR	0x1C
+#define RDA_IF		0x00000001
+#define THRE_IF		0x00000002
+#define TOUT_IF		0x00000010
+#define THRE_INT	0x00000200
+#define HWRLS_IF	0x00040000
+#define HWBUFE_IF	0x00200000
+
+#define UART_REG_TOR	0x20
+#define UART_REG_BAUD	0x24
+
+#define UART_REG_IRCR	0x28
+
+#define UART_REG_ALT_CSR	0x2C
+
+#define UART_FUN_SEL	0x30
+#define FUN_SEL_UART	0x00000000
+#define FUN_SEL_LIN		0x00000001
+#define FUN_SEL_IrDA	0x00000002
+#define FUN_SEL_RS485	0x00000003
+#define FUN_SEL_Msk		0x00000007
+
+#define UART_REG_WKCTL	0x40
+#define UART_REG_WKSTS	0x44
+
+#endif // __NUC980_SERIAL_H__
diff -uprN linux-4.4.194/drivers/usb/gadget/udc/Kconfig NUC980-linux-4.4.194/drivers/usb/gadget/udc/Kconfig
--- linux-4.4.194/drivers/usb/gadget/udc/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/usb/gadget/udc/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -187,6 +187,12 @@ config USB_PXA27X
 	   dynamically linked module called "pxa27x_udc" and force all
 	   gadget drivers to also be dynamically linked.
 
+config USB_NUC980
+	tristate "NUC980 USB Device Controller"
+	depends on MACH_NUC980
+	help
+	  On-chip USB Device Controller of Nuvoton NUC980.
+
 config USB_S3C2410
 	tristate "S3C2410 USB Device Controller"
 	depends on ARCH_S3C24XX
diff -uprN linux-4.4.194/drivers/usb/gadget/udc/Makefile NUC980-linux-4.4.194/drivers/usb/gadget/udc/Makefile
--- linux-4.4.194/drivers/usb/gadget/udc/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/usb/gadget/udc/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -8,6 +8,7 @@ obj-$(CONFIG_USB_NET2280)	+= net2280.o
 obj-$(CONFIG_USB_AMD5536UDC)	+= amd5536udc.o
 obj-$(CONFIG_USB_PXA25X)	+= pxa25x_udc.o
 obj-$(CONFIG_USB_PXA27X)	+= pxa27x_udc.o
+obj-$(CONFIG_USB_NUC980)	+= nuc980_udc.o
 obj-$(CONFIG_USB_GOKU)		+= goku_udc.o
 obj-$(CONFIG_USB_OMAP)		+= omap_udc.o
 obj-$(CONFIG_USB_S3C2410)	+= s3c2410_udc.o
diff -uprN linux-4.4.194/drivers/usb/gadget/udc/nuc980_udc.c NUC980-linux-4.4.194/drivers/usb/gadget/udc/nuc980_udc.c
--- linux-4.4.194/drivers/usb/gadget/udc/nuc980_udc.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/usb/gadget/udc/nuc980_udc.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,1670 @@
+/*
+ * linux/drivers/usb/gadget/udc/nuc980_udc.c
+ *
+ * Nuvoton NUC980 MCU on-chip full speed USB device controllers
+ *
+ * Copyright (C) 2018 Nuvoton Technology Corp
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+
+#include <linux/proc_fs.h>
+#include <linux/prefetch.h>
+#include <linux/usb/ch9.h>
+#include <linux/of.h>
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/ioport.h>
+#include <linux/slab.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/clk.h>
+#include <linux/list.h>
+#include <linux/interrupt.h>
+#include <linux/usb/gadget.h>
+#include <linux/platform_device.h>
+#include <asm/byteorder.h>
+#include <linux/dma-mapping.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+
+#include <mach/regs-usbd.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-gpio.h>
+#include "nuc980_udc.h"
+
+//#define pr_devel printk
+
+#define DRIVER_DESC     "NUVOTON USB Device Controller Gadget"
+#define DRIVER_VERSION  "16 March 2018"
+#define DRIVER_AUTHOR   "shirley <clyu2@nuvoton.com>"
+
+u32 volatile usb_vaddr, usb_paddr;
+
+static const char gadget_name [] = "nuc980-usbdev";
+static const char driver_desc [] = DRIVER_DESC;
+
+static const struct {
+	const char *name;
+	const struct usb_ep_caps caps;
+} ep_info[] = {
+#define EP_INFO(_name, _caps) \
+	{ \
+		.name = _name, \
+		.caps = _caps, \
+	}
+
+	EP_INFO("ep0",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_CONTROL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep1",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep2",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep3",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep4",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep5",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep6",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep7",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep8",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep9",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep10",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep11",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+	EP_INFO("ep12",
+		USB_EP_CAPS(USB_EP_CAPS_TYPE_ALL, USB_EP_CAPS_DIR_ALL)),
+
+#undef EP_INFO
+};
+
+#define ep0name		ep_info[0].name
+
+#define EP0_FIFO_SIZE           64
+#define EP_FIFO_SIZE            512
+
+static void udc_isr_reset(struct nuc980_udc *udc);
+static void udc_isr_dma(struct nuc980_udc *udc);
+static void udc_isr_ctrl_pkt(struct nuc980_udc *udc);
+static void udc_isr_update_dev(struct nuc980_udc *udc);
+static void nuc980_udc_enable(struct nuc980_udc *udc);
+static void nuc980_udc_disable(struct nuc980_udc *udc);
+
+
+static void done(struct nuc980_ep *ep, struct nuc980_request *req, int status)
+{
+	struct nuc980_udc *udc = ep->dev;
+
+	list_del_init(&req->queue); //del req->queue from ep->queue
+
+	if (list_empty(&ep->queue))
+	{
+		if (ep->index)
+			__raw_writel(0, udc->base + REG_USBD_EPA_EPINTEN + 0x28*(ep->index-1));
+	}
+	else
+	{
+		__raw_writel(ep->irq_enb, udc->base + REG_USBD_EPA_EPINTEN + 0x28*(ep->index-1));
+	}
+
+	if (req->req.status == -EINPROGRESS)
+		req->req.status = status;
+	else
+		status = req->req.status;
+
+	usb_gadget_unmap_request(&udc->gadget, &req->req, ep->ep_dir);
+	req->req.complete(&ep->ep, &req->req);
+}
+
+static void nuke (struct nuc980_udc *udc, struct nuc980_ep *ep, int status)
+{
+	while (!list_empty (&ep->queue))
+	{
+		struct nuc980_request *req;
+		req = list_entry(ep->queue.next, struct nuc980_request, queue);
+		done(ep, req, status);
+	}
+}
+
+
+/*
+ *  write_packet
+ */
+static inline int write_packet(struct nuc980_ep *ep, struct nuc980_request *req)
+{
+	struct nuc980_udc *udc = ep->dev;
+	unsigned total, len;
+	u8  *buf;
+	u32 i;
+
+	buf = req->req.buf + req->req.actual;
+	prefetch(buf);
+	total = req->req.length - req->req.actual;
+	if (ep->ep.maxpacket < total)
+		len = ep->ep.maxpacket;
+	else
+		len = total;
+
+	if (ep->ep_num == 0)
+	{
+		for (i=0; i<len; i++)
+		{
+			__raw_writeb( *buf++ & 0xff, udc->base + REG_USBD_CEPDAT);
+		}
+		__raw_writel(len, udc->base + REG_USBD_CEPTXCNT);
+		req->req.actual += len;
+	}
+	else
+	{
+		usb_gadget_map_request(&udc->gadget, &req->req, ep->ep_dir);
+		buf = req->req.buf + req->req.actual;
+
+//printk("%s: len=%d, %d\n", ep->ep.name, len, total);
+		if (len == 0)
+		{
+			__raw_writel(USB_EP_RSPCTL_ZEROLEN, udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));
+		}
+		else
+		{
+			memcpy((char *)usb_vaddr, (char *)buf, len);
+			__raw_writel((__raw_readl(udc->base + REG_USBD_DMACTL)&0xe0) | 0x110 | ep->ep_num,
+						 udc->base + REG_USBD_DMACTL);// bulk in, write
+			__raw_writel(0, udc->base + REG_USBD_EPA_EPINTEN + (0x28* (ep->index-1)));
+			__raw_writel((USBD_BUSINTEN_DMADONEIEN | USBD_BUSINTEN_RSTIEN | USBD_BUSINTEN_SUSPENDIEN | USBD_BUSINTEN_VBUSDETIEN), udc->base + REG_USBD_BUSINTEN);
+			__raw_writel((u32)usb_paddr, udc->base + REG_USBD_DMAADDR);//Tell DMA the memory physcal address
+			__raw_writel(len, udc->base + REG_USBD_DMACNT);
+			__raw_writel(0x20, udc->base + REG_USBD_BUSINTSTS);
+
+//			udc->usb_dma_trigger = 1;
+//			udc->usb_dma_cnt = len;
+//			udc->usb_dma_owner = ep->index;
+//			udc->usb_less_mps = 1;
+
+			__raw_writel(__raw_readl(udc->base + REG_USBD_DMACTL)|0x00000020, udc->base + REG_USBD_DMACTL);
+			while (!(__raw_readl(udc->base + REG_USBD_BUSINTSTS) & 0x20))
+			{
+				if (!(__raw_readl(__raw_readl + REG_USBD_PHYCTL) &  0x80000000))			/* Exit when USB Un-Plug */
+					break;
+			}
+			__raw_writel(0x20, udc->base + REG_USBD_BUSINTSTS);
+		}
+		__raw_writel((__raw_readl(udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1)) & 0x16)|USB_EP_RSPCTL_SHORTTXEN, udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));
+		__raw_writel(len, udc->base + REG_USBD_EPA_EPTXCNT+0x28*(ep->index-1));
+		req->req.actual += len;
+	}
+
+	return len;
+}
+
+/*
+ *  write_fifo
+ */
+// return:  0 = still running, 1 = completed, negative = errno
+static int write_fifo(struct nuc980_ep *ep, struct nuc980_request *req)
+{
+	u32 len;
+
+	len = write_packet(ep, req);
+
+	/* last packet is often short (sometimes a zlp) */
+
+	if (req->req.length == req->req.actual/* && !req->req.zero*/)
+	{
+//printk("done\n");
+		done(ep, req, 0);
+		return 1;
+	}
+	else
+	{
+//printk("%s: %d, %d\n", ep->ep.name, req->req.length, req->req.actual);
+		return 0;
+	}
+}
+
+static inline int read_packet(struct nuc980_ep *ep,u8 *buf, struct nuc980_request *req, u16 cnt)
+{
+	struct nuc980_udc *udc = ep->dev;
+	unsigned int data, i;
+
+	if (ep->ep_num == 0)
+	{ //ctrl pipe don't use DMA
+
+		for (i=0; i<cnt; i++)
+		{
+			data = __raw_readb(udc->base + REG_USBD_CEPDAT);
+			*buf++ = data & 0xFF;
+		}
+		req->req.actual += cnt;
+	}
+	else
+	{
+		usb_gadget_map_request(&udc->gadget, &req->req, ep->ep_dir);
+//printk("%s: len=%d", ep->ep.name, cnt);
+
+		__raw_writel((__raw_readl(udc->base + REG_USBD_DMACTL) & 0xe0)|ep->ep_num, udc->base + REG_USBD_DMACTL);   //read
+		__raw_writel((u32)usb_paddr, udc->base + REG_USBD_DMAADDR);
+		__raw_writel(cnt, udc->base + REG_USBD_DMACNT);
+		__raw_writel(0x20, udc->base + REG_USBD_BUSINTSTS);
+		__raw_writel(__raw_readl(udc->base + REG_USBD_DMACTL)|0x00000020, udc->base + REG_USBD_DMACTL);
+		while (!(__raw_readl(udc->base + REG_USBD_BUSINTSTS) & 0x20))
+		{
+			if (!(__raw_readl(__raw_readl + REG_USBD_PHYCTL) &  0x80000000))			/* Exit when USB Un-Plug */
+				break;
+		}
+		__raw_writel(0x20, udc->base + REG_USBD_BUSINTSTS);
+		memcpy((char *)buf, (char *)usb_vaddr, cnt);
+		req->req.actual += cnt;
+//printk(" 0x%x\n", __raw_readl(udc->base + REG_USBD_EPA_EPDATCNT + 0x28));
+	}
+
+	return cnt;
+}
+
+// return:  0 = still running, 1 = queue empty, negative = errno
+static int read_fifo(struct nuc980_ep *ep, struct nuc980_request *req, u16 cnt)
+{
+	u8 *buf;
+	unsigned bufferspace;
+	int is_last=1;
+	int fifo_count = 0;
+
+	buf = req->req.buf + req->req.actual;
+	bufferspace = req->req.length - req->req.actual;
+
+	if (cnt > ep->ep.maxpacket)
+		cnt = ep->ep.maxpacket;
+	if (cnt > bufferspace) {
+		pr_devel("%s buffer overflow\n", ep->ep.name);
+		req->req.status = -EOVERFLOW;
+		cnt = bufferspace;
+	}
+	fifo_count = read_packet(ep, buf, req, cnt);
+
+	if (req->req.length == req->req.actual)
+		done(ep, req, 0);
+	else if (fifo_count && fifo_count < ep->ep.maxpacket)
+	{
+		done(ep, req, 0);
+		/* overflowed this request?  flush extra data */
+//		if (req->req.length != req->req.actual)
+//		{
+//			pr_devel("%s(): EOVERFLOW set\n", __FUNCTION__);
+//			if (req->req.short_not_ok)
+//				req->req.status = -EOVERFLOW;   //device read less then host write
+//		}
+	}
+	else
+		is_last = 0;
+
+	return is_last;
+}
+
+
+void paser_usb_irq(struct nuc980_udc *udc, int irq)
+{
+	__raw_writel(irq, udc->base + REG_USBD_BUSINTSTS);
+	if (irq & USBD_BUSINTSTS_RSTIF)
+	{
+		udc_isr_reset(udc);
+	}
+
+	if (irq & USBD_BUSINTSTS_RESUMEIF)
+	{
+		__raw_writel((USBD_BUSINTEN_RSTIEN|USBD_BUSINTEN_SUSPENDIEN|USBD_BUSINTEN_VBUSDETIEN), udc->base + REG_USBD_BUSINTEN);
+	}
+
+	if (irq & USBD_BUSINTSTS_SUSPENDIF)
+	{
+		__raw_writel((USBD_BUSINTEN_RSTIEN|USBD_BUSINTEN_RESUMEIEN|USBD_BUSINTEN_VBUSDETIEN), udc->base + REG_USBD_BUSINTEN);
+	}
+
+	if (irq & USBD_BUSINTSTS_HISPDIF)
+	{
+		udc->gadget.speed = USB_SPEED_HIGH;
+		udc->usb_address = 0;       //zero
+		__raw_writel(USBD_CEPINTEN_SETUPPKIEN, udc->base + REG_USBD_CEPINTEN);
+	}
+
+	if (irq & USBD_BUSINTSTS_DMADONEIF)
+	{
+		udc_isr_dma(udc);
+	}
+
+	if (irq & USBD_BUSINTSTS_VBUSDETIF)
+	{
+		if (__raw_readl(udc->base + REG_USBD_PHYCTL) & USBD_PHYCTL_VBUSDET)
+		{
+printk("plug-in\n");
+			__raw_writel(__raw_readl(udc->base + REG_USBD_CEPCTL)|USB_CEPCTL_FLUSH, udc->base + REG_USBD_CEPCTL);
+			nuc980_udc_enable(udc);
+		}
+		else
+		{
+printk("plug-out\n");
+			nuc980_udc_disable(udc);
+			nuke(udc, &udc->ep[0], -ESHUTDOWN);
+		}
+	}
+
+	return ;
+}
+
+void paser_irq_cep(struct nuc980_udc *udc, u32 irq)
+{
+	struct nuc980_ep *ep = &udc->ep[0];
+	struct nuc980_request *req;
+	int is_last = 1;
+
+	if (list_empty(&ep->queue))
+		req = 0;
+	else
+		req = list_entry(ep->queue.next, struct nuc980_request, queue);
+
+	if (irq & USBD_CEPINTSTS_SETUPPKIF)
+	{
+		udc->ep0state = EP0_IDLE;
+		udc->setup_ret = 0;
+		udc_isr_ctrl_pkt(udc);
+	}
+
+	if (irq & USBD_CEPINTSTS_RXPKIF)
+	{
+		if (udc->ep0state == EP0_OUT_DATA_PHASE)
+		{
+			if (req)
+				is_last = read_fifo(ep, req, __raw_readl(udc->base + REG_USBD_CEPDATCNT));
+
+			__raw_writel(USBD_CEPINTSTS_STSDONEIF, udc->base + REG_USBD_CEPINTSTS);
+			if (!is_last)
+			{
+				__raw_writel(USBD_CEPINTEN_SETUPPKIEN|USBD_CEPINTEN_RXPKIEN|USBD_CEPINTEN_STSDONEIEN, udc->base + REG_USBD_CEPINTEN);
+			}
+			else 
+			{
+				__raw_writel(USB_CEPCTL_NAKCLR, udc->base + REG_USBD_CEPCTL);
+				__raw_writel(USBD_CEPINTEN_SETUPPKIEN|USBD_CEPINTEN_STSDONEIEN, udc->base + REG_USBD_CEPINTEN);
+				udc->ep0state = EP0_END_XFER;
+			}
+		}
+	}
+
+	if (irq & USBD_CEPINTSTS_INTKIF)
+	{
+		if (udc->ep0state == EP0_IN_DATA_PHASE)
+		{
+			if (req)
+				is_last = write_fifo(ep,req);
+
+			if (!is_last)
+			{
+				__raw_writel(USBD_CEPINTEN_SETUPPKIEN|USBD_CEPINTEN_STSDONEIEN|USBD_CEPINTEN_TXPKIEN|USBD_CEPINTEN_INTKIEN, udc->base + REG_USBD_CEPINTEN);
+			}
+			else 
+			{
+				if (udc->setup_ret >= 0)
+					__raw_writel(USB_CEPCTL_NAKCLR, udc->base + REG_USBD_CEPCTL);
+				__raw_writel(USBD_CEPINTEN_STSDONEIEN|USBD_CEPINTEN_TXPKIEN|USBD_CEPINTEN_SETUPPKIEN, udc->base + REG_USBD_CEPINTEN);
+
+				if (udc->setup_ret < 0)
+					udc->ep0state=EP0_IDLE;
+				else if (udc->ep0state != EP0_IDLE)
+					udc->ep0state=EP0_END_XFER;
+			}
+		}
+	}
+
+	if (irq & USBD_CEPINTSTS_STSDONEIF)
+	{
+		__raw_writel(USBD_CEPINTEN_SETUPPKIEN, udc->base + REG_USBD_CEPINTEN);
+		udc_isr_update_dev(udc);
+		udc->ep0state=EP0_IDLE;
+		udc->setup_ret = 0;
+	}
+}
+
+
+void paser_irq_nep(struct nuc980_ep *ep, u32 irq)
+{
+	struct nuc980_udc *udc = ep->dev;
+	struct nuc980_request *req;
+
+	if (list_empty(&ep->queue))
+	{
+		pr_devel("nep->queue is empty\n");
+		req = 0;
+	}
+	else
+	{
+		req = list_entry(ep->queue.next, struct nuc980_request, queue);
+	}
+
+//printk("%s: A[0x%x / 0x%x], B[0x%x / 0x%x / 0x%x]\n", ep->ep.name, __raw_readl(udc->base + REG_USBD_EPA_EPINTEN), __raw_readl(udc->base + REG_USBD_EPA_EPINTSTS), __raw_readl(udc->base + REG_USBD_EPA_EPINTEN + 0x28), __raw_readl(udc->base + REG_USBD_EPA_EPINTSTS + 0x28), __raw_readl(udc->base + REG_USBD_EPA_EPDATCNT + 0x28));
+
+	if (irq & USBD_EPINTSTS_INTKIF)
+	{
+		__raw_writel(USBD_EPINTSTS_INTKIF, udc->base + REG_USBD_EPA_EPINTSTS + 0x28*(ep->index-1));
+		if (ep->ep_type == USB_EP_CFG_TYPE_BULK)
+		{
+			if (__raw_readl(udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1)) & USB_EP_RSPCTL_SHORTTXEN)
+			{
+				pr_devel("send last packet\n");
+				return;
+			}
+		}
+
+		if (req == NULL)
+		{
+			__raw_writel(0, udc->base + REG_USBD_EPA_EPINTEN + 0x28*(ep->index-1));
+			return;
+		}
+
+		while (__raw_readl(udc->base + REG_USBD_DMACTL) & 0x20) //wait DMA complete
+		{
+			if (!(__raw_readl(udc->base + REG_USBD_PHYCTL) & USBD_PHYCTL_VBUSDET))
+			{
+				printk("unplug!\n");
+				return;
+			}
+		}
+		if (!write_fifo(ep, req))
+			__raw_writel(0x40, udc->base + REG_USBD_EPA_EPINTEN + 0x28*(ep->index-1));
+	}
+
+	if (irq & USBD_EPINTSTS_TXPKIF)
+	{
+		__raw_writel(USBD_EPINTSTS_TXPKIF, udc->base + REG_USBD_EPA_EPINTSTS + 0x28*(ep->index-1));
+//		if (req)
+//		{
+//			if (!write_fifo(ep, req))
+//				__raw_writel(0x48, udc->base + REG_USBD_EPA_EPINTEN + 0x28*(ep->index-1));
+//		}
+//		else
+//			__raw_writel(0, udc->base + REG_USBD_EPA_EPINTEN + 0x28*(ep->index-1));
+	}
+
+	if ((irq & USBD_EPINTSTS_RXPKIF) || (irq & USBD_EPINTSTS_SHORTRXIF))
+	{
+		__raw_writel(USBD_EPINTSTS_RXPKIF|USBD_EPINTSTS_SHORTRXIF, udc->base + REG_USBD_EPA_EPINTSTS + 0x28*(ep->index-1));
+		if (req == NULL)
+		{
+			__raw_writel(0, udc->base + REG_USBD_EPA_EPINTEN + 0x28*(ep->index-1));
+			__raw_writel(irq, udc->base + REG_USBD_EPA_EPINTSTS + 0x28*(ep->index-1));
+			return;
+		}
+		read_fifo(ep, req, __raw_readl(udc->base + REG_USBD_EPA_EPDATCNT + 0x28*(ep->index-1)));
+//printk("@@ 0x%x\n", __raw_readl(udc->base + REG_USBD_EPA_EPDATCNT + 0x28*(ep->index-1)));
+	}
+
+	return ;
+}
+
+
+/*
+ *      nuc980_udc_irq - interrupt handler
+ */
+static irqreturn_t nuc980_udc_irq(int irq, void *_dev)
+{
+	struct nuc980_udc *udc;
+	u32 volatile IrqStL, IrqSt;
+	int j;
+
+	udc = (struct nuc980_udc *)(_dev);
+
+	IrqStL = __raw_readl(udc->base + REG_USBD_GINTSTS) & __raw_readl(udc->base + REG_USBD_GINTEN);
+//printk("0x%x/ 0x%x / 0x%x\n", __raw_readl(udc->base + REG_USBD_GINTSTS), __raw_readl(udc->base + REG_USBD_GINTEN), __raw_readl(udc->base + REG_USBD_PHYCTL));
+	if (!IrqStL)
+	{
+		pr_err("Not our interrupt !\n");
+		return IRQ_HANDLED;
+	}
+
+	if (IrqStL & USBD_GINTSTS_USBIF)
+	{
+//printk("1. 0x%x / 0x%x\n", __raw_readl(udc->base + REG_USBD_BUSINTSTS), __raw_readl(udc->base + REG_USBD_BUSINTEN));
+		IrqSt = __raw_readl(udc->base + REG_USBD_BUSINTSTS) & __raw_readl(udc->base + REG_USBD_BUSINTEN);
+		__raw_writel(IrqSt, udc->base + REG_USBD_BUSINTSTS);
+		if (IrqSt && udc->driver)
+			paser_usb_irq(udc, IrqSt);
+	}
+
+	if (IrqStL & USBD_GINTSTS_CEPIF)
+	{
+		IrqSt = __raw_readl(udc->base + REG_USBD_CEPINTSTS) & __raw_readl(udc->base + REG_USBD_CEPINTEN);
+		__raw_writel(IrqSt, udc->base + REG_USBD_CEPINTSTS);
+		if (IrqSt && udc->driver)
+			paser_irq_cep(udc, IrqSt);
+	}
+
+	if (IrqStL & USBD_GINTSTS_EPIF)
+	{
+		IrqStL >>= 2;
+		for (j = 0; j < NUC980_ENDPOINTS-1; j++)
+		{
+			if (IrqStL & (1 << j))
+			{
+				//in-token and out token interrupt can deal with one only
+				IrqSt = __raw_readl(udc->base + REG_USBD_EPA_EPINTSTS+0x28*j) & __raw_readl(udc->base + REG_USBD_EPA_EPINTEN+0x28*j);
+				if (IrqSt && udc->driver)
+					paser_irq_nep(&udc->ep[j+1], IrqSt);
+			}
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+
+static s32 sram_data[13][2] = {{0,0x40}};
+
+//0-3F for Ctrl pipe
+s32 get_sram_base(struct nuc980_udc *udc, u32 max)
+{
+	int i, cnt = 1, j;
+	s32 start, end;
+
+	for (i = 1; i < NUC980_ENDPOINTS; i++)
+	{
+		struct nuc980_ep *ep = &udc->ep[i];
+
+		start = __raw_readl(udc->base + REG_USBD_EPA_EPBUFSTART+0x28*(ep->index-1));
+		end = __raw_readl(udc->base + REG_USBD_EPA_EPBUFEND+0x28*(ep->index-1));
+		if (end - start > 0)
+		{
+				sram_data[cnt][0] = start;
+				sram_data[cnt][1] = end + 1;
+				cnt++;
+		}
+	}
+	if (cnt == 1)
+		return 0x40;
+	//sorting from small to big
+	j= 1;
+	while ((j<cnt))
+	{
+		for (i=0; i<cnt -j; i++)
+		{
+			if (sram_data[i][0]>sram_data[i+1][0])
+			{
+				start = sram_data[i][0];
+				end = sram_data[i][1];
+				sram_data[i][0] = sram_data[i+1][0];
+				sram_data[i][1] = sram_data[i+1][1];
+				sram_data[i+1][0] = start;
+				sram_data[i+1][1] = end;
+			}
+		}
+		j++;
+	}
+
+	for (i = 0; i< cnt-1; i++)
+	{
+		if (sram_data[i+1][0] - sram_data[i][1] >= max)
+			return sram_data[i][1];
+	}
+
+	if (0x1000 - sram_data[cnt-1][1] >= max)
+		return sram_data[cnt-1][1];
+
+	return -ENOBUFS;
+}
+
+/*
+ *  nuc980_ep_enable
+ */
+static int nuc980_ep_enable (struct usb_ep *_ep, const struct usb_endpoint_descriptor *desc)
+{
+	struct nuc980_udc *udc;
+	struct nuc980_ep *ep;
+	u32 max, tmp;
+	unsigned long flags;
+	u32 int_en_reg;
+	s32 sram_addr;
+
+	ep = container_of (_ep, struct nuc980_ep, ep);
+	if (!_ep || !desc || _ep->name == ep0name || desc->bDescriptorType != USB_DT_ENDPOINT)
+		return -EINVAL;
+	udc = ep->dev;
+
+	if (!udc->driver || udc->gadget.speed == USB_SPEED_UNKNOWN)
+		return -ESHUTDOWN;
+
+	max = usb_endpoint_maxp(desc);
+
+	spin_lock_irqsave (&udc->lock, flags);
+	_ep->maxpacket = max & 0x7ff;
+
+	ep->ep.desc = desc;
+	ep->bEndpointAddress = desc->bEndpointAddress;
+
+	/* set max packet */
+	if (ep->index != 0)
+	{
+		__raw_writel(max, udc->base + REG_USBD_EPA_EPMPS + 0x28*(ep->index-1));
+		ep->ep.maxpacket = max;
+
+		sram_addr = get_sram_base(udc, max);
+
+		if (sram_addr < 0)
+			return sram_addr;
+
+		__raw_writel(sram_addr, udc->base + REG_USBD_EPA_EPBUFSTART+0x28*(ep->index-1));
+		sram_addr = sram_addr + max;
+		__raw_writel(sram_addr-1, udc->base + REG_USBD_EPA_EPBUFEND+0x28*(ep->index-1));
+	}
+
+	/* set type, direction, address; reset fifo counters */
+	if (ep->index != 0)
+	{
+		ep->ep_num = desc->bEndpointAddress & ~USB_DIR_IN;
+		ep->ep_dir = desc->bEndpointAddress &0x80 ? 1 : 0;
+		ep->ep_type = ep->ep.desc->bmAttributes & USB_ENDPOINT_XFERTYPE_MASK;
+		if (ep->ep_type == USB_ENDPOINT_XFER_ISOC)
+		{
+			ep->ep_type = USB_EP_CFG_TYPE_ISO;
+			ep->ep_mode = USB_EP_RSPCTL_MODE_AUTO;
+		}
+		else if (ep->ep_type == USB_ENDPOINT_XFER_BULK)
+		{
+			ep->ep_type = USB_EP_CFG_TYPE_BULK;
+			ep->ep_mode = USB_EP_RSPCTL_MODE_AUTO;
+		}
+		else if (ep->ep_type == USB_ENDPOINT_XFER_INT)
+		{
+			ep->ep_type = USB_EP_CFG_TYPE_INT;
+			ep->ep_mode = USB_EP_RSPCTL_MODE_MANUAL;
+		}
+		__raw_writel(USB_EP_RSPCTL_FLUSH|USB_EP_RSPCTL_TOGGLE, udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));
+		__raw_writel(ep->ep_num<<4|ep->ep_dir<<3|ep->ep_type|USB_EP_CFG_VALID,
+					 udc->base + REG_USBD_EPA_EPCFG+0x28*(ep->index-1));
+		__raw_writel(ep->ep_mode, udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));
+
+		/* enable irqs */
+		int_en_reg = __raw_readl(udc->base + REG_USBD_GINTEN);
+		__raw_writel(int_en_reg | (1<<(ep->index+1)), udc->base + REG_USBD_GINTEN);
+		udc->irq_enbl = __raw_readl(udc->base + REG_USBD_GINTEN);
+
+		if (ep->ep_type == USB_EP_CFG_TYPE_BULK)
+		{
+			if (ep->ep_dir)//IN
+				ep->irq_enb = 0x40;
+			else
+			{
+				ep->irq_enb = 0x1010;
+//				__raw_writel((__raw_readl(udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1))&0xF7)|0x80,
+//							 udc->base + REG_USBD_EPA_EPRSPCTL + 0x28*(ep->index-1));//disable buffer when short packet
+//				ep->buffer_disabled = 1;
+			}
+		}
+		else if (ep->ep_type == USB_EP_CFG_TYPE_INT)
+		{
+			if (ep->ep_dir)//IN
+				ep->irq_enb = 0x40;
+			else
+				ep->irq_enb = 0x10;
+		}
+		else if (ep->ep_type == USB_EP_CFG_TYPE_ISO)
+		{
+			if (ep->ep_dir)//IN
+				ep->irq_enb = 0x40;
+			else
+				ep->irq_enb = 0x20;
+		}
+	}
+
+	/* print some debug message */
+	tmp = desc->bEndpointAddress;
+	pr_devel ("enable %s(%d) ep%x%s-blk max %02x\n",
+			_ep->name,ep->ep_num, tmp, desc->bEndpointAddress & USB_DIR_IN ? "in" : "out", max);
+
+	spin_unlock_irqrestore (&udc->lock, flags);
+	return 0;
+}
+
+/*
+ * nuc980_ep_disable
+ */
+static int nuc980_ep_disable (struct usb_ep *_ep)
+{
+	struct nuc980_ep *ep = container_of(_ep, struct nuc980_ep, ep);
+	unsigned long flags;
+
+	if (!_ep || !ep->ep.desc)
+		return -EINVAL;
+
+	spin_lock_irqsave(&ep->dev->lock, flags);
+	ep->ep.desc = 0;
+
+	__raw_writel(0, ep->dev->base + REG_USBD_EPA_EPCFG+0x28*(ep->index-1));
+	__raw_writel(0, ep->dev->base + REG_USBD_EPA_EPINTEN + 0x28*(ep->index-1));
+
+	nuke (ep->dev, ep, -ESHUTDOWN);
+
+	__raw_writel(0, ep->dev->base + REG_USBD_EPA_EPBUFSTART+0x28*(ep->index-1));
+	__raw_writel(0, ep->dev->base + REG_USBD_EPA_EPBUFEND+0x28*(ep->index-1));
+
+	spin_unlock_irqrestore(&ep->dev->lock, flags);
+	pr_devel("%s disabled\n", _ep->name);
+	return 0;
+}
+
+/*
+ * nuc980_alloc_request
+ */
+static struct usb_request *nuc980_alloc_request (struct usb_ep *_ep, gfp_t mem_flags)
+{
+	struct nuc980_ep *ep;
+	struct nuc980_request *req;
+
+	ep = container_of (_ep, struct nuc980_ep, ep);
+	if (!_ep)
+		return 0;
+
+	req = kmalloc (sizeof *req, mem_flags);
+	if (!req)
+		return 0;
+	memset (req, 0, sizeof *req);
+	INIT_LIST_HEAD (&req->queue);
+
+	return &req->req;
+}
+
+/*
+ * nuc980_free_request
+ */
+static void nuc980_free_request (struct usb_ep *_ep, struct usb_request *_req)
+{
+	struct nuc980_ep *ep;
+	struct nuc980_request *req;
+
+	ep = container_of (_ep, struct nuc980_ep, ep);
+	if (!ep || !_req || (!ep->ep.desc && _ep->name != ep0name))
+		return;
+
+	req = container_of (_req, struct nuc980_request, req);
+	list_del_init(&req->queue);
+
+	WARN_ON (!list_empty (&req->queue));
+	kfree (req);
+}
+
+
+/*
+ *  nuc980_queue
+ */
+static int nuc980_queue(struct usb_ep *_ep, struct usb_request *_req, gfp_t gfp_flags)
+{
+	struct nuc980_request *req;
+	struct nuc980_ep *ep;
+	struct nuc980_udc *udc;
+	unsigned long flags;
+
+	ep = container_of(_ep, struct nuc980_ep, ep);
+	if (unlikely (!_ep || (!ep->ep.desc && ep->ep.name != ep0name)))
+	{
+		pr_err("nuc980_queue: invalid args\n");
+		local_irq_restore(flags);
+		return -EINVAL;
+	}
+
+	udc = ep->dev;
+	if (unlikely (!udc->driver || udc->gadget.speed == USB_SPEED_UNKNOWN))
+	{
+		pr_err("nuc980_queue: speed =%d\n",udc->gadget.speed);
+		return -ESHUTDOWN;
+	}
+
+	local_irq_save(flags);
+
+	req = container_of(_req, struct nuc980_request, req);
+
+	if (unlikely (!_req || !_req->complete || !_req->buf || !list_empty(&req->queue)))
+	{
+		local_irq_restore(flags);
+		return -EINVAL;
+	}
+
+	/* iso is always one packet per request, that's the only way
+	 * we can report per-packet status.  that also helps with dma.
+	 */
+	if (ep->ep.desc)
+	{ //clyu
+		if (unlikely (ep->ep.desc->bmAttributes == USB_ENDPOINT_XFER_ISOC
+						&& req->req.length > usb_endpoint_maxp(ep->ep.desc)))
+		{
+			local_irq_restore(flags);
+			return -EMSGSIZE;
+		}
+	}
+
+	_req->status = -EINPROGRESS;
+	_req->actual = 0;
+
+	/* for ep0 IN without premature status, zlp is required and
+	 * writing EOP starts the status stage (OUT).
+	 */
+	if (unlikely(ep->ep_num == 0 && ep->ep_dir))
+		_req->zero = 1;
+
+	/* pio or dma irq handler advances the queue. */
+	if (likely (req != 0))
+		list_add_tail(&req->queue, &ep->queue);
+
+	if (ep->index==0)
+	{ //delayed status
+        if ((req->req.length != 0) && (udc->ep0state == EP0_END_XFER))
+        {
+            udc->ep0state = EP0_IN_DATA_PHASE;
+            __raw_writel(0x0a, udc->base + REG_USBD_CEPINTEN);
+		}
+		if ((udc->setup_ret > 1000) || ((req->req.length==0)&&(udc->ep0state == EP0_OUT_DATA_PHASE)))
+		{
+			__raw_writel(USB_CEPCTL_NAKCLR, udc->base + REG_USBD_CEPCTL);
+			__raw_writel(0x402, udc->base + REG_USBD_CEPINTEN);
+			done(ep, req, 0);
+			__raw_writel(USB_CEPCTL_FLUSH, udc->base + REG_USBD_CEPCTL);
+		}
+	}
+	else if (ep->index > 0)
+	{
+		__raw_writel(ep->irq_enb, udc->base + REG_USBD_EPA_EPINTEN + 0x28*(ep->index-1));
+	}
+
+	local_irq_restore(flags);
+	return 0;
+}
+
+/*
+ *  nuc980_dequeue
+ */
+static int nuc980_dequeue (struct usb_ep *_ep, struct usb_request *_req)
+{
+	struct nuc980_ep *ep;
+	struct nuc980_udc *udc;
+	int retval = -EINVAL;
+	unsigned long flags;
+	struct nuc980_request *req;
+
+	if (!_ep || !_req)
+		return retval;
+	ep = container_of (_ep, struct nuc980_ep, ep);
+	udc = ep->dev;
+
+	if (!udc->driver)
+		return -ESHUTDOWN;
+
+	spin_lock_irqsave (&udc->lock, flags);
+	list_for_each_entry(req, &ep->queue, queue)
+	{
+		if (&req->req == _req)
+		{
+			list_del_init (&req->queue);
+			_req->status = -ECONNRESET;
+			retval = 0;
+			break;
+		}
+	}
+	spin_unlock_irqrestore (&udc->lock, flags);
+	pr_devel("dequeue: %d, req %p\n", retval,  &req->req);
+	if (retval == 0)
+	{
+		pr_devel( "dequeued req %p from %s, len %d buf %p\n", req, _ep->name, _req->length, _req->buf);
+		_req->complete (_ep, _req);
+		done(ep, req, -ECONNRESET);
+	}
+
+	return retval;
+}
+
+
+/*
+ * nuc980_set_halt
+ */
+static int nuc980_set_halt (struct usb_ep *_ep, int value)
+{
+	struct nuc980_ep *ep = container_of(_ep, struct nuc980_ep, ep);
+	struct nuc980_udc *udc = ep->dev;
+	unsigned long flags;
+
+	if (!_ep || (ep->ep_type == USB_EP_CFG_TYPE_ISO))
+		return -EINVAL;
+
+	spin_lock_irqsave(&udc->lock, flags);
+
+	/* Halting an IN endpoint should fail if queue is not empty */
+	if (value && ep->ep_dir && !list_empty(&ep->queue)) {
+		spin_unlock_irqrestore(&udc->lock, flags);
+		return -EAGAIN;
+	}
+
+	if (value == 1)
+	{
+		/* stall */
+		if (ep->ep_num == 0)
+		{
+			__raw_writel(USB_CEPCTL_STALL, udc->base + REG_USBD_CEPCTL);
+			udc->ep0state = EP0_STALL;
+		}
+		else
+		{
+			__raw_writel((__raw_readl(udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1)) & 0xf7) | USB_EP_RSPCTL_HALT,
+						udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));
+		}
+	}
+	else
+	{
+		/* End stall */
+		if (ep->ep_num != 0)
+		{
+			__raw_writel(USB_EP_RSPCTL_TOGGLE, udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));
+		}
+	}
+
+	spin_unlock_irqrestore(&udc->lock, flags);
+
+	return 0;
+}
+
+/*
+ * Return the total number of bytes currently stored in the internal buffers of
+ * the endpoint.
+ */
+static int nuc980_fifo_status(struct usb_ep *_ep)
+{
+	struct nuc980_ep *ep;
+	struct nuc980_udc *udc;
+	u32 bytes = 0;
+
+	if (!_ep)
+		return -ENODEV;
+
+	ep = container_of(_ep, struct nuc980_ep, ep);
+	udc = ep->dev;
+
+	if (ep->ep_num == 0)
+	{
+		bytes = __raw_readl(udc->base + REG_USBD_CEPDATCNT) & 0xffff;
+	}
+	else
+	{
+		bytes = __raw_readl(udc->base + REG_USBD_EPA_EPDATCNT+0x28*(ep->index-1)) & 0xffff;
+	}
+
+	return bytes;
+}
+
+
+/* Empty data from internal buffers of an endpoint. */
+static void nuc980_fifo_flush(struct usb_ep *_ep)
+{
+	struct nuc980_ep *ep;
+	struct nuc980_udc *udc;
+	unsigned long flags;
+
+	if (!_ep)
+		return;
+
+	ep = container_of(_ep, struct nuc980_ep, ep);
+	udc = ep->dev;
+	pr_devel("EP: flush fifo %s\n", ep->ep.name);
+
+	spin_lock_irqsave(&udc->lock, flags);
+
+	if (ep->ep_num == 0)
+	{
+		__raw_writel(USB_CEPCTL_FLUSH, udc->base + REG_USBD_CEPCTL);
+	}
+	else
+	{
+		__raw_writel(USB_EP_RSPCTL_FLUSH, udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));
+	}
+
+	spin_unlock_irqrestore(&udc->lock, flags);
+}
+
+
+
+static const struct usb_ep_ops nuc980_ep_ops =
+{
+	.enable         = nuc980_ep_enable,
+	.disable        = nuc980_ep_disable,
+
+	.alloc_request  = nuc980_alloc_request,
+	.free_request   = nuc980_free_request,
+
+	.queue          = nuc980_queue,
+	.dequeue        = nuc980_dequeue,
+
+	.set_halt       = nuc980_set_halt,
+	.fifo_status	= nuc980_fifo_status,
+	.fifo_flush		= nuc980_fifo_flush,
+};
+
+/*
+ *  nuc980_g_get_frame
+ */
+static int nuc980_g_get_frame (struct usb_gadget *_gadget)
+{
+	struct nuc980_udc *udc = to_nuc980_udc(_gadget);
+	int tmp;
+	tmp = __raw_readl(udc->base + REG_USBD_FRAMECNT);
+	return tmp & 0xffff;
+}
+
+/*
+ *  nuc980_wakeup
+ */
+static int nuc980_wakeup (struct usb_gadget *_gadget)
+{
+	return 0;
+}
+
+/*
+ *  nuc980_set_selfpowered
+ */
+static int nuc980_set_selfpowered (struct usb_gadget *_gadget, int value)
+{
+	return 0;
+}
+
+static int nuc980_pullup (struct usb_gadget *g, int is_on)
+{
+	struct nuc980_udc *udc = to_nuc980_udc(g);
+printk("pullup\n");
+
+	if (is_on)
+		nuc980_udc_enable(udc);
+	else {
+		if (udc->gadget.speed != USB_SPEED_UNKNOWN) {
+			if (udc->driver && udc->driver->disconnect)
+				udc->driver->disconnect(&udc->gadget);
+		}
+		nuc980_udc_disable(udc);
+	}
+	return 0;
+}
+
+static int nuc980_udc_start(struct usb_gadget *g, struct usb_gadget_driver *driver);
+static int nuc980_udc_stop(struct usb_gadget *g, struct usb_gadget_driver *driver);
+
+static const struct usb_gadget_ops nuc980_ops =
+{
+	.get_frame          = nuc980_g_get_frame,
+	.wakeup             = nuc980_wakeup,
+	.set_selfpowered    = nuc980_set_selfpowered,
+	.pullup             = nuc980_pullup,
+	.udc_start          = nuc980_udc_start,
+	.udc_stop           = nuc980_udc_stop,
+};
+
+
+static void nuc980_udc_enable(struct nuc980_udc *udc)
+{
+//    udc->gadget.speed = USB_SPEED_HIGH;
+printk("enable: 0x%x\n", __raw_readl(udc->base + REG_USBD_PHYCTL));
+	__raw_writel(__raw_readl(udc->base + REG_USBD_PHYCTL) | 0x100, udc->base + REG_USBD_PHYCTL);
+}
+
+static void nuc980_udc_disable(struct nuc980_udc *udc)
+{
+	unsigned int i;
+printk("disable: 0x%x\n", __raw_readl(udc->base + REG_USBD_PHYCTL));
+	__raw_writel(0, udc->base + REG_USBD_CEPINTEN);
+	__raw_writel(0xffff, udc->base + REG_USBD_CEPINTSTS);
+	__raw_writel(__raw_readl(udc->base + REG_USBD_CEPCTL)|USB_CEPCTL_FLUSH, udc->base + REG_USBD_CEPCTL);
+	for (i = 1; i < NUC980_ENDPOINTS; i++)
+		__raw_writel(USB_EP_RSPCTL_FLUSH|USB_EP_RSPCTL_TOGGLE, udc->base + REG_USBD_EPA_EPRSPCTL + 0x28*(i-1));
+
+	__raw_writel(__raw_readl(udc->base + REG_USBD_PHYCTL) & ~0x100, udc->base + REG_USBD_PHYCTL);
+	udc->gadget.speed = USB_SPEED_UNKNOWN;
+}
+
+/*
+ *  nuc980_udc_start
+ */
+static int nuc980_udc_start(struct usb_gadget *g, struct usb_gadget_driver *driver)
+{
+	struct nuc980_udc *udc = to_nuc980_udc(g);
+
+	pr_devel("nuc980_udc_start() '%s'\n", driver->driver.name);
+
+	udc->gadget.name = gadget_name;
+	udc->gadget.ops = &nuc980_ops;
+	udc->gadget.max_speed = USB_SPEED_HIGH;
+	udc->driver = driver;
+
+	udc->usb_address = 0;
+	/*
+	 * configure USB controller
+	 */
+	__raw_writel(0x03, udc->base + REG_USBD_GINTEN);    /* enable usb, cep interrupt */
+	__raw_writel((USBD_BUSINTEN_RESUMEIEN | USBD_BUSINTEN_RSTIEN | USBD_BUSINTEN_VBUSDETIEN), udc->base + REG_USBD_BUSINTEN);
+	__raw_writel(0, udc->base + REG_USBD_FADDR);
+	__raw_writel(0x402, udc->base + REG_USBD_CEPINTEN);
+
+
+	nuc980_udc_enable(udc);
+	return 0;
+}
+
+/*
+ *  nuc980_udc_stop
+ */
+static int nuc980_udc_stop(struct usb_gadget *g, struct usb_gadget_driver *driver)
+{
+	struct nuc980_udc *udc = to_nuc980_udc(g);
+	unsigned int volatile i;
+
+	udc->driver = 0;
+
+	pr_devel("device_release_driver\n");
+
+	/* clear/disable all interrupts */
+	__raw_writel(0, udc->base + REG_USBD_BUSINTEN);
+	__raw_writel(0xffff, udc->base + REG_USBD_BUSINTSTS);
+
+	__raw_writel(0, udc->base + REG_USBD_CEPINTEN);
+	__raw_writel(0xffff, udc->base + REG_USBD_CEPINTSTS);
+
+	for (i = 0; i < NUC980_ENDPOINTS-1; i++)
+	{ //6 endpoints
+		__raw_writel(0, udc->base + REG_USBD_EPA_EPINTEN + 0x28 * i);
+		__raw_writel(0xffff, udc->base + REG_USBD_EPA_EPINTSTS + 0x28 * i);
+	}
+
+	nuc980_udc_disable(udc);
+	return 0;
+}
+
+static void udc_isr_reset(struct nuc980_udc *udc)
+{
+	int i;
+
+	udc->usb_address = 0;
+	udc->usb_less_mps = 0;
+
+	//reset DMA
+	__raw_writel(0x80, udc->base + REG_USBD_DMACTL);
+	__raw_writel(0x00, udc->base + REG_USBD_DMACTL);
+
+	pr_devel("speed:%x\n", __raw_readl(udc->base + REG_USBD_OPER));
+	if (__raw_readl(udc->base + REG_USBD_OPER) & 0x04)
+		udc->gadget.speed = USB_SPEED_HIGH;
+	else
+		udc->gadget.speed = USB_SPEED_FULL;
+
+	__raw_writel(__raw_readl(udc->base + REG_USBD_CEPCTL)|USB_CEPCTL_FLUSH, udc->base + REG_USBD_CEPCTL);
+	for (i = 1; i < NUC980_ENDPOINTS; i++)
+		__raw_writel(USB_EP_RSPCTL_FLUSH|USB_EP_RSPCTL_TOGGLE, udc->base + REG_USBD_EPA_EPRSPCTL + 0x28*(i-1));
+
+	__raw_writel(0, udc->base + REG_USBD_FADDR);
+	__raw_writel(USBD_CEPINTEN_SETUPPKIEN, udc->base + REG_USBD_CEPINTEN);
+}
+
+static void udc_isr_dma(struct nuc980_udc *udc)
+{
+	struct nuc980_request *req;
+	struct nuc980_ep *ep;
+	u32 datacnt_reg;
+
+	if (!udc->usb_dma_trigger)
+	{
+		pr_devel("DMA not trigger, intr?\n");
+		return;
+	}
+
+	ep = &udc->ep[udc->usb_dma_owner];
+	datacnt_reg = (u32)(REG_USBD_EPA_EPDATCNT+0x28*(ep->index-1));
+
+	if (udc->usb_dma_dir == Ep_In)
+		__raw_writel(USBD_EPINTSTS_INTKIF, udc->base + REG_USBD_EPA_EPINTSTS + 0x28*(ep->index-1));
+
+	udc->usb_dma_trigger = 0;
+	if (list_empty(&ep->queue)) {
+		pr_devel("DMA ep->queue is empty\n");
+		req = 0;
+		__raw_writel(udc->irq_enbl, udc->base + REG_USBD_GINTEN);
+		return;
+	}
+	else {
+		req = list_entry(ep->queue.next, struct nuc980_request, queue);
+	}
+
+	if (req) {
+		if (ep->ep_type == USB_EP_CFG_TYPE_BULK) {
+			if (udc->usb_less_mps == 1) {
+				__raw_writel((__raw_readl(udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1)) & 0x16)|USB_EP_RSPCTL_SHORTTXEN, udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));
+				udc->usb_less_mps = 0;
+			}
+		}
+		else if (ep->ep_type == USB_EP_CFG_TYPE_INT) {
+			__raw_writel(udc->usb_dma_cnt, udc->base + REG_USBD_EPA_EPTXCNT+0x28*(ep->index-1));
+		}
+		else if (ep->ep_type == USB_EP_CFG_TYPE_ISO) {
+			if (udc->usb_less_mps == 1) {
+				__raw_writel((__raw_readl(udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1)) & 0x16)|USB_EP_RSPCTL_SHORTTXEN, udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));
+				udc->usb_less_mps = 0;
+			}
+		}
+		req->req.actual += udc->usb_dma_cnt;
+		if ((req->req.length == req->req.actual) || udc->usb_dma_cnt < ep->ep.maxpacket) {
+			__raw_writel(udc->irq_enbl, udc->base + REG_USBD_GINTEN);
+			if ((ep->ep_type == USB_EP_CFG_TYPE_BULK) && (ep->ep_dir == 0) && (udc->usb_dma_cnt < ep->ep.maxpacket)) {
+				if (ep->buffer_disabled) {
+					__raw_writel((__raw_readl(udc->base + REG_USBD_EPA_EPRSPCTL + 0x28*(ep->index-1))) & 0x16,
+								 udc->base + REG_USBD_EPA_EPRSPCTL + 0x28*(ep->index-1));//enable buffer
+					__raw_writel((__raw_readl(udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1)) & 0x16) | 0x80,
+								 udc->base + REG_USBD_EPA_EPRSPCTL+0x28*(ep->index-1));//disable buffer when short packet
+				}
+			}
+			done(ep, req, 0);
+
+			return;
+		}
+	}
+
+	if (udc->usb_dma_dir == Ep_Out) {
+		if (udc->usb_dma_trigger_next) {
+			udc->usb_dma_trigger_next = 0;
+			pr_devel("dma out\n");
+			read_fifo(ep, req, 0);
+		}
+	}
+	else if (udc->usb_dma_dir == Ep_In) {
+		if (udc->usb_less_mps == 1)
+			udc->usb_less_mps = 0;
+		if (udc->usb_dma_trigger_next) {
+			udc->usb_dma_trigger_next = 0;
+			pr_devel("dma in\n");
+			write_fifo(ep, req);
+		}
+	}
+}
+
+
+static void udc_isr_ctrl_pkt(struct nuc980_udc *udc)
+{
+	struct nuc980_ep *ep = &udc->ep[0];
+	struct usb_ctrlrequest crq;
+	struct nuc980_request *req;
+	int ret;
+
+	if (list_empty(&ep->queue)) {
+		pr_devel("ctrl ep->queue is empty\n");
+		req = 0;
+	}
+	else {
+		req = list_entry(ep->queue.next, struct nuc980_request, queue);
+	}
+
+	crq.bRequestType = (u8)__raw_readl(udc->base + REG_USBD_SETUP1_0) & 0xff;
+	crq.bRequest = (u8)(__raw_readl(udc->base + REG_USBD_SETUP1_0) >> 8) & 0xff;
+	crq.wValue = (u16)__raw_readl(udc->base + REG_USBD_SETUP3_2);
+	crq.wIndex = (u16)__raw_readl(udc->base + REG_USBD_SETUP5_4);
+	crq.wLength = (u16)__raw_readl(udc->base + REG_USBD_SETUP7_6);
+	udc->crq = crq;
+
+	switch (udc->ep0state) {
+		case EP0_IDLE:
+			if (crq.bRequest == USB_REQ_SET_ADDRESS) {
+				udc->usb_address = crq.wValue;
+			}
+
+			if (crq.bRequestType & USB_DIR_IN) {
+				udc->ep0state = EP0_IN_DATA_PHASE;
+				__raw_writel(USBD_CEPINTEN_SETUPPKIEN|USBD_CEPINTEN_INTKIEN, udc->base + REG_USBD_CEPINTEN);
+			}
+			else {
+				udc->ep0state = EP0_OUT_DATA_PHASE;
+				__raw_writel(USBD_CEPINTEN_SETUPPKIEN|USBD_CEPINTEN_RXPKIEN, udc->base + REG_USBD_CEPINTEN);
+			}
+
+			if (udc->gadget.speed == USB_SPEED_FULL)
+				udelay(5);
+
+            ret = udc->driver->setup(&udc->gadget, &crq);
+            udc->setup_ret = ret;
+            if ((ret < 0) || (crq.bRequest == USB_REQ_SET_ADDRESS)) {
+				__raw_writel(USBD_CEPINTSTS_STSDONEIF, udc->base + REG_USBD_CEPINTSTS);
+				__raw_writel(USB_CEPCTL_NAKCLR, udc->base + REG_USBD_CEPCTL);
+				__raw_writel(USBD_CEPINTEN_SETUPPKIEN|USBD_CEPINTEN_STSDONEIEN, udc->base + REG_USBD_CEPINTEN);
+			}
+			else if (ret > 1000) {
+				pr_devel("DELAYED_STATUS:%p\n", req);
+				udc->ep0state = EP0_END_XFER;
+				__raw_writel(USBD_CEPINTEN_SETUPPKIEN, udc->base + REG_USBD_CEPINTEN);
+			}
+			break;
+
+		case EP0_STALL:
+			break;
+
+		default:
+			;
+	}
+}
+
+void udc_isr_update_dev(struct nuc980_udc *udc)
+{
+	struct usb_ctrlrequest *pcrq = &udc->crq;
+
+	//update this device for set requests
+	switch (pcrq->bRequest)
+	{
+		case USB_REQ_SET_ADDRESS:
+			__raw_writel(udc->usb_address, udc->base + REG_USBD_FADDR);
+			break;
+
+		case USB_REQ_SET_CONFIGURATION:
+			break;
+
+		case USB_REQ_SET_INTERFACE:
+			break;
+
+		case USB_REQ_SET_FEATURE:
+			if ((pcrq->bRequestType & 0x3) == 0x0) 	/* Receipent is Device */
+			{
+				if ((pcrq->wValue & 0x3) == 0x2)
+				{
+					 __raw_writel(pcrq->wIndex >> 8, udc->base + REG_USBD_TEST);
+				}
+			}
+			break;
+
+		case USB_REQ_CLEAR_FEATURE:
+			break;
+
+		default:
+			;
+	}//switch end
+	return;
+}
+
+
+static void USB_Init(struct nuc980_udc *udc)
+{
+	int i, j;
+
+	udc->usb_address = 0;
+	/*
+	 * configure USB controller
+	 */
+	__raw_writel(0x03, udc->base + REG_USBD_GINTEN);    /* enable usb, cep interrupt */
+	__raw_writel((USBD_BUSINTEN_RESUMEIEN | USBD_BUSINTEN_RSTIEN | USBD_BUSINTEN_VBUSDETIEN), udc->base + REG_USBD_BUSINTEN);
+
+	__raw_writel(0, udc->base + REG_USBD_FADDR);
+	__raw_writel((USBD_CEPINTEN_SETUPPKIEN | USBD_CEPINTEN_STSDONEIEN), udc->base + REG_USBD_CEPINTEN);
+
+	for (j = 0; j < NUC980_ENDPOINTS; j++)
+	{
+		udc->ep[j].ep_num = 0xff;
+		udc->ep[j].ep_dir = 0xff;
+		udc->ep[j].ep_type = 0xff;
+	}
+
+	/* setup endpoint information */
+	INIT_LIST_HEAD (&udc->gadget.ep_list);
+	for (i = 0; i < NUC980_ENDPOINTS; i++)
+	{
+		struct nuc980_ep *ep = &udc->ep[i];
+
+		if (!ep_info[i].name)
+			break;
+		ep->index = i;
+		ep->ep.name = ep_info[i].name;
+		ep->ep.caps = ep_info[i].caps;
+		ep->ep.ops = &nuc980_ep_ops;
+		list_add_tail (&ep->ep.ep_list, &udc->gadget.ep_list);
+
+		/* maxpacket differs between ep0 and others ep */
+		if (!i)
+		{
+			ep->ep_num = 0;
+			ep->ep.maxpacket = EP0_FIFO_SIZE;
+			usb_ep_set_maxpacket_limit(&ep->ep, EP0_FIFO_SIZE);
+			__raw_writel(0x00000000, udc->base + REG_USBD_CEPBUFSTART);
+			__raw_writel(0x0000003f, udc->base + REG_USBD_CEPBUFEND);
+		}
+		else
+		{
+			ep->ep.maxpacket = EP_FIFO_SIZE;
+			usb_ep_set_maxpacket_limit(&ep->ep, EP_FIFO_SIZE);
+			__raw_writel(0, udc->base + REG_USBD_EPA_EPBUFSTART + 0x28*(ep->index-1));
+			__raw_writel(0, udc->base + REG_USBD_EPA_EPBUFEND + 0x28*(ep->index-1));
+		}
+		ep->dev = udc;
+		ep->ep.desc = 0;
+		INIT_LIST_HEAD (&ep->queue);
+	}
+	udc->gadget.ep0 = &udc->ep[0].ep;
+	list_del_init (&udc->ep[0].ep.ep_list);
+}
+
+/*
+ *  probe - binds to the platform device
+ */
+static int nuc980_udc_probe(struct platform_device *pdev)
+{
+	struct nuc980_udc *udc;
+	struct device *dev = &pdev->dev;
+	struct pinctrl *p;
+	int error;
+
+	pr_devel("nuc980_udc_probe...\n");
+	dev_dbg(dev, "%s()\n", __func__);
+
+	udc = devm_kzalloc(dev, sizeof(*udc), GFP_KERNEL);
+	if (!udc)
+		return -ENOMEM;
+
+#ifdef CONFIG_OF
+
+        p = devm_pinctrl_get_select_default(&pdev->dev);
+        if (IS_ERR(p)) {
+            return PTR_ERR(p);
+        }
+
+		/*
+		 * Right now device-tree probed devices don't get dma_mask set.
+		 * Since shared usb code relies on it, set it here for now.
+		 * Once we have dma capability bindings this can go away.
+		 */
+		if (!pdev->dev.dma_mask)
+			pdev->dev.dma_mask = &pdev->dev.coherent_dma_mask;
+		if (!pdev->dev.coherent_dma_mask)
+			pdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+
+#else
+	p = devm_pinctrl_get_select(&pdev->dev, "usbd-vbusvld");
+	if (IS_ERR(p))
+	{
+		dev_err(&pdev->dev, "unable to reserve pin\n");
+		error = PTR_ERR(p);
+	}
+#endif
+
+	udc->pdev = pdev;
+
+	udc->clk = clk_get(NULL, "usbd_hclk");
+	if (IS_ERR(udc->clk))
+	{
+		error = -ENODEV;
+		dev_dbg(&pdev->dev, "no udc_clk?\n");
+		goto fail1;
+	}
+
+	clk_prepare(udc->clk);
+	clk_enable(udc->clk);       /* Enable the peripheral clock */
+
+	udc->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (udc->res == NULL)
+	{
+		dev_err(dev, "failed to get I/O memory\n");
+		error = -ENXIO;
+		goto fail1;
+	}
+
+	if (!request_mem_region(udc->res->start, resource_size(udc->res), pdev->name))
+	{
+		dev_err(dev, "failed to request I/O memory\n");
+		error = -EBUSY;
+		goto fail1;
+	}
+
+	udc->base = ioremap(udc->res->start, resource_size(udc->res));
+	if (udc->base == NULL)
+	{
+		dev_err(dev, "failed to remap I/O memory\n");
+		error = -ENXIO;
+		goto fail1;
+	}
+
+	udc->gadget.dev.parent = dev;
+	platform_set_drvdata (pdev, udc);
+
+	spin_lock_init (&udc->lock);
+
+	__raw_writel(__raw_readl(udc->base + REG_USBD_PHYCTL) | 0x200, udc->base + REG_USBD_PHYCTL);
+	// FIXME: is it possible to loop forever?
+	while (1)
+	{
+		__raw_writel(0x20, udc->base + REG_USBD_EPA_EPMPS);
+		if (__raw_readl(udc->base + REG_USBD_EPA_EPMPS) == 0x20)
+			break;
+	}
+
+	/* initial gadget structure */
+	udc->gadget.ops = &nuc980_ops;
+	udc->gadget.speed = USB_SPEED_UNKNOWN;
+	udc->gadget.max_speed = USB_SPEED_HIGH;
+	udc->ep0state = EP0_IDLE;
+	udc->gadget.name = dev_name(dev);
+
+	USB_Init(udc);
+
+	udc->irq = platform_get_irq(pdev, 0);
+	if (udc->irq < 0)
+	{
+		dev_err(dev, "Failed to get irq\n");
+		error = -ENXIO;
+		goto fail2;
+	}
+	error = request_irq(udc->irq, nuc980_udc_irq, 0, gadget_name, udc);
+	if (error != 0)
+	{
+		dev_err(dev, "request_irq() failed\n");
+		goto fail2;
+	}
+
+	usb_vaddr = (u32)dma_alloc_writecombine(NULL, 512, (u32 *)&usb_paddr, GFP_KERNEL);
+	error = usb_add_gadget_udc(dev, &udc->gadget);
+	if (error)
+		goto fail3;
+
+	pr_devel("nuc980_udc_probe done.\n");
+	return 0;
+fail3:
+	free_irq(udc->irq, udc);
+fail2:
+	iounmap(udc->base);
+fail1:
+	return error;
+}
+
+/*
+ *  nuc980_udc_remove
+ */
+static int nuc980_udc_remove(struct platform_device *pdev)
+{
+	struct nuc980_udc *udc = platform_get_drvdata (pdev);
+
+	dev_dbg(&pdev->dev, "%s()\n", __func__);
+
+	usb_del_gadget_udc(&udc->gadget);
+	free_irq(udc->irq, udc);
+	iounmap(udc->base);
+
+	__raw_writel(__raw_readl(udc->base + REG_USBD_PHYCTL) & ~0x200,
+				 udc->base + REG_USBD_PHYCTL);    // phy suspend
+	clk_disable(udc->clk);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980_udc_suspend (struct platform_device *pdev, pm_message_t state)
+{
+	__raw_writel(__raw_readl(udc->base + REG_USBD_PHYCTL) & ~0x200, udc->base + REG_USBD_PHYCTL);    // phy suspend
+	return 0;
+}
+
+static int nuc980_udc_resume (struct platform_device *pdev)
+{
+	unsigned int reg = __raw_readl(udc->base + REG_USBD_EPA_EPMPS);
+
+	__raw_writel(__raw_readl(udc->base + REG_USBD_PHYCTL) | 0x200, udc->base + REG_USBD_PHYCTL);
+	while (1)
+	{
+		__raw_writel(0x20, udc->base + REG_USBD_EPA_EPMPS);
+		if (__raw_readl(udc->base + REG_USBD_EPA_EPMPS) == 0x20)
+		{
+			__raw_writel(reg, udc->base + REG_USBD_EPA_EPMPS);
+			break;
+		}
+	}
+
+	return 0;
+}
+#else
+#define nuc980_udc_suspend     NULL
+#define nuc980_udc_resume      NULL
+#endif
+
+static const struct of_device_id nuc980_usbd_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-usbdev" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_usbd_of_match);
+
+static struct platform_driver nuc980_udc_driver =
+{
+	.probe      = nuc980_udc_probe,
+	.remove     = nuc980_udc_remove,
+	.suspend    = nuc980_udc_suspend,
+	.resume     = nuc980_udc_resume,
+	.driver     = {
+			.owner  = THIS_MODULE,
+			.name   = (char *) "nuc980-usbdev",
+		        .of_match_table = of_match_ptr(nuc980_usbd_of_match),
+	},
+};
+
+//insmod g_mass_storage.ko file=/dev/mmcblk0p1 stall=0 removable=1
+
+module_platform_driver(nuc980_udc_driver);
+
+MODULE_AUTHOR(DRIVER_AUTHOR);
+MODULE_DESCRIPTION(DRIVER_DESC);
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/usb/gadget/udc/nuc980_udc.h NUC980-linux-4.4.194/drivers/usb/gadget/udc/nuc980_udc.h
--- linux-4.4.194/drivers/usb/gadget/udc/nuc980_udc.h	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/usb/gadget/udc/nuc980_udc.h	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,84 @@
+/* linux/include/asm-arm/arch-nuc980/nuc980_reg.h
+ *
+ * Copyright (c) 2018 Nuvoton technology corporation
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * Changelog:
+ *
+ *   2018/03/16     add this file for nuvoton nuc980 MCU ip REG.
+ */
+#ifndef _NUC980_UDC_H
+#define _NUC980_UDC_H
+
+#define NUC980_ENDPOINTS    13
+
+struct nuc980_ep {
+    struct list_head    queue;
+    struct nuc980_udc   *dev;
+    struct usb_ep       ep;
+    u8                  index;
+    u8                  buffer_disabled;
+    u8                  bEndpointAddress;//w/ direction
+
+    u8                  ep_mode;//auto/manual/fly
+    u8                  ep_num;//no direction ep address
+    u8                  ep_dir;//0 OUT, 1 IN
+    u8                  ep_type;//bulk/in/iso
+    u32 irq_enb;
+};
+
+
+struct nuc980_request {
+    struct list_head      queue;      /* ep's requests */
+    struct usb_request    req;
+    u32                   dma_mapped;
+};
+
+enum ep0_state {
+    EP0_IDLE,
+    EP0_IN_DATA_PHASE,
+    EP0_OUT_DATA_PHASE,
+    EP0_END_XFER,
+    EP0_STALL,
+};
+
+
+struct nuc980_udc {
+    spinlock_t                  lock;
+    struct nuc980_ep            ep[NUC980_ENDPOINTS];
+    struct usb_gadget           gadget;
+    struct usb_gadget_driver    *driver;
+    struct platform_device      *pdev;
+
+    struct clk                  *clk;
+    struct resource             *res;
+    void __iomem                *base;
+    int                         irq;
+
+    enum ep0_state              ep0state;
+
+    u8                          usb_devstate;
+    u8                          usb_address;
+
+    u8                          usb_dma_dir;
+    u8                          usb_dma_trigger;//bool. dma triggered
+    u8                          usb_dma_trigger_next;//need trigger again
+    u8                          usb_less_mps;
+    u32                         usb_dma_cnt;//one dma transfer count
+    u32                         usb_dma_loop;//for short packet only;dma loop, each loop 32byte;
+    u32                         usb_dma_owner;
+
+    struct usb_ctrlrequest      crq;
+    s32                         setup_ret;
+
+    u32                         irq_enbl;
+};
+
+#define to_nuc980_udc(g)        (container_of((g), struct nuc980_udc, gadget))
+
+#endif
diff -uprN linux-4.4.194/drivers/usb/host/ehci-hcd.c NUC980-linux-4.4.194/drivers/usb/host/ehci-hcd.c
--- linux-4.4.194/drivers/usb/host/ehci-hcd.c	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/usb/host/ehci-hcd.c	2019-12-29 19:12:21.000000000 -0800
@@ -855,6 +855,15 @@ static int ehci_urb_enqueue (
 ) {
 	struct ehci_hcd		*ehci = hcd_to_ehci (hcd);
 	struct list_head	qtd_list;
+	struct usb_device   *parent_hub = urb->dev->parent;
+
+	if (((ehci_readl(ehci, &ehci->regs->port_status[0]) & 0x1005) != 0x1005) && 
+		(parent_hub->parent == NULL) && (urb->dev->portnum == 1))
+		return -ENODEV;
+
+	if (((ehci_readl(ehci, &ehci->regs->port_status[1]) & 0x1005) != 0x1005) && 
+		(parent_hub->parent == NULL) && (urb->dev->portnum == 2))
+		return -ENODEV;
 
 	INIT_LIST_HEAD (&qtd_list);
 
@@ -1251,6 +1260,11 @@ MODULE_DESCRIPTION(DRIVER_DESC);
 MODULE_AUTHOR (DRIVER_AUTHOR);
 MODULE_LICENSE ("GPL");
 
+#ifdef CONFIG_USB_NUC980_EHCI
+#include "ehci-nuc980.c"
+#define PLATFORM_DRIVER         ehci_hcd_nuc980_driver
+#endif
+
 #ifdef CONFIG_USB_EHCI_SH
 #include "ehci-sh.c"
 #define PLATFORM_DRIVER		ehci_hcd_sh_driver
diff -uprN linux-4.4.194/drivers/usb/host/ehci-nuc980.c NUC980-linux-4.4.194/drivers/usb/host/ehci-nuc980.c
--- linux-4.4.194/drivers/usb/host/ehci-nuc980.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/usb/host/ehci-nuc980.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,422 @@
+/*
+ * linux/driver/usb/host/ehci-nuc980.c
+ *
+ * Copyright (c) 2018 Nuvoton technology corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+
+#include <linux/platform_device.h>
+#include <linux/signal.h>
+#include <linux/gfp.h>
+#include <linux/of.h>
+
+#include <linux/clk.h>
+#include <mach/irqs.h>
+#include <mach/map.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-aic.h>
+#include <mach/regs-timer.h>
+#include <mach/regs-gpio.h>
+
+
+//#define PORT_DEBUG
+
+//#define FORCE_PORT0_HOST
+
+
+#ifdef CONFIG_USE_OF
+static int  of_pm_vbus_off;
+static int  of_mfp_setting;
+#endif
+
+
+#ifdef PORT_DEBUG
+#include <linux/kthread.h>
+static int port_dump_thread(void *__unused)
+{
+	while (1) {
+		printk("EHCI: 0x%x 0x%x\n", __raw_readl(NUC980_VA_EHCI+0x64), __raw_readl(NUC980_VA_EHCI+0x68));
+		printk("OHCI: 0x%x, 0x%x, 0x%x, 0x%x, 0x%x, 0x%x, 0x%x, 0x%x\n", __raw_readl(NUC980_VA_OHCI+0x54), __raw_readl(NUC980_VA_OHCI+0x58), __raw_readl(NUC980_VA_OHCI+0x5C), __raw_readl(NUC980_VA_OHCI+0x60), __raw_readl(NUC980_VA_OHCI+0x64), __raw_readl(NUC980_VA_OHCI+0x68), __raw_readl(NUC980_VA_OHCI+0x6C), __raw_readl(NUC980_VA_OHCI+0x70));
+		msleep(20000);
+	}
+	return 0;
+}
+#endif
+
+
+static int usb_nuc980_probe(const struct hc_driver *driver,
+                            struct platform_device *pdev)
+{
+	struct usb_hcd *hcd;
+	struct ehci_hcd *ehci;
+	u32  physical_map_ehci;
+	struct pinctrl *p;
+	int retval;
+#ifdef FORCE_PORT0_HOST
+	unsigned long flags;
+#endif
+#ifdef CONFIG_USE_OF
+	u32   val32[2];
+#endif
+
+	(void)p;
+
+	if (IS_ERR(clk_get(NULL, "usbh_hclk"))) {
+		printk("clk_get error!!\n");
+		return -1;
+	}
+
+	/* Enable USB Host clock */
+	clk_prepare(clk_get(NULL, "usb_eclk"));
+	clk_enable(clk_get(NULL, "usb_eclk"));
+
+	clk_prepare(clk_get(NULL, "usbh_hclk"));
+	clk_enable(clk_get(NULL, "usbh_hclk"));
+
+#ifdef FORCE_PORT0_HOST
+	local_irq_save(flags);
+	do {
+		__raw_writel(0x59UL, REG_WRPRTR);
+		__raw_writel(0x16UL, REG_WRPRTR);
+		__raw_writel(0x88UL, REG_WRPRTR);
+	} while(__raw_readl(REG_WRPRTR) == 0UL);
+
+	/* set USRHDSEN as 1; USB host/device role selection decided by USBID (SYS_PWRON[16]) */
+	__raw_writel(__raw_readl(REG_MISCFCR) | (1<<11), (volatile void __iomem *)REG_MISCFCR);
+
+	/* set USB port 0 used for Host */
+	__raw_writel(__raw_readl(REG_PWRON) | (1<<16), (volatile void __iomem *)REG_PWRON);
+	__raw_writel(0, REG_WRPRTR);
+	local_irq_restore(flags);
+#endif
+
+
+#ifdef CONFIG_USE_OF
+
+	p = devm_pinctrl_get_select_default(&pdev->dev);
+	if (IS_ERR(p)) {
+		return PTR_ERR(p);
+	}
+
+	if ((__raw_readl(REG_MFP_GPE_H) & 0x000F0000) == 0x00010000)
+		of_mfp_setting = 1;
+	else
+		of_mfp_setting = 0;
+
+	//printk("of_mfp_setting = %d\n", of_mfp_setting);
+
+	if (of_property_read_u32_array(pdev->dev.of_node, "ov_active", val32, 1) != 0) {
+		printk("%s - can not get ov_active setting!\n", __func__);
+		return -EINVAL;
+	}
+	// printk("Over-current active level %s...\n", val32[0] ? "high" : "low");
+	if (val32[0]) {
+		/* set over-current active high */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	} else {
+		/* set over-current active low */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) | 0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	}
+
+	if (of_property_read_u32_array(pdev->dev.of_node, "pm_vbus_off", val32, 1) == 0) {
+		if (val32[0])
+			of_pm_vbus_off = 1;
+		else
+			of_pm_vbus_off = 0;
+	} else {
+		of_pm_vbus_off = 0;
+	}
+
+	/*
+	 * Right now device-tree probed devices don't get dma_mask set.
+	 * Since shared usb code relies on it, set it here for now.
+	 * Once we have dma capability bindings this can go away.
+	 */
+	if (!pdev->dev.dma_mask)
+		pdev->dev.dma_mask = &pdev->dev.coherent_dma_mask;
+	if (!pdev->dev.coherent_dma_mask)
+		pdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+#else
+
+	/* multi-function pin select */
+#if defined(CONFIG_NUC980_USBH_PWREN_OVC_ON)
+
+	p = devm_pinctrl_get_select(&pdev->dev, "usbh_pwren_ovc_on");
+	if (IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve USBH_PWREN and USB_OVC pins\n");
+		retval = PTR_ERR(p);
+		/* set over-current active high */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	} else {
+		/* set over-current active low */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) | 0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	}
+
+#elif defined(CONFIG_NUC980_USBH_PWREN_ON)
+
+	p = devm_pinctrl_get_select(&pdev->dev, "usbh_pwren_on");
+	if (IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve USBH_PWREN pin\n");
+		retval = PTR_ERR(p);
+	}
+	/* set over-current active high */
+	__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+
+#elif defined(CONFIG_NUC980_USBH_OVC_ON)
+	p = devm_pinctrl_get_select(&pdev->dev, "usbh_ovc_on");
+	if (IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve USB_OVC pin\n");
+		retval = PTR_ERR(p);
+		/* set over-current active high */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	} else {
+		/* set over-current active low */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) | 0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	}
+#elif defined(CONFIG_NUC980_USBH_PWREN_OVC_OFF)
+
+	/* set over-current active high */
+	__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+
+#endif
+
+
+#endif  // CONFIG_USE_OF
+
+	if (pdev->resource[1].flags != IORESOURCE_IRQ) {
+		pr_debug("resource[1] is not IORESOURCE_IRQ");
+		retval = -ENOMEM;
+	}
+
+	hcd = usb_create_hcd(driver, &pdev->dev, dev_name(&pdev->dev));
+	if (!hcd) {
+		retval = -ENOMEM;
+		goto err1;
+	}
+
+	hcd->rsrc_start = pdev->resource[0].start;
+	hcd->rsrc_len = pdev->resource[0].end - pdev->resource[0].start + 1;
+
+	if (!request_mem_region(hcd->rsrc_start, hcd->rsrc_len, hcd_name)) {
+		pr_debug("ehci probe request_mem_region failed");
+		retval = -EBUSY;
+		goto err2;
+	}
+
+	hcd->regs = ioremap(hcd->rsrc_start, hcd->rsrc_len);
+	if (hcd->regs == NULL) {
+		pr_debug("ehci error mapping memory\n");
+		retval = -EFAULT;
+		goto err3;
+	}
+
+	ehci = hcd_to_ehci(hcd);
+	ehci->caps = hcd->regs;
+	ehci->regs = hcd->regs + 0x20;
+
+	/* enable PHY 0/1 */
+	physical_map_ehci = (u32)ehci->caps;
+	__raw_writel(0x160, (volatile void __iomem *)physical_map_ehci+0xC4);
+	__raw_writel(0x520, (volatile void __iomem *)physical_map_ehci+0xC8);
+
+	//__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) | 0xfc0000, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+
+	/* cache this readonly data; minimize chip reads */
+	ehci->hcs_params = readl(&ehci->caps->hcs_params);
+	ehci->sbrn = 0x20;
+
+	retval = usb_add_hcd(hcd, pdev->resource[1].start, IRQF_SHARED);
+
+	if (retval != 0)
+		goto err4;
+
+#ifdef PORT_DEBUG
+	kthread_run(port_dump_thread, NULL, "khubd");
+#endif
+
+	return retval;
+
+err4:
+	iounmap(hcd->regs);
+err3:
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+err2:
+	usb_put_hcd(hcd);
+err1:
+
+	return retval;
+}
+
+void usb_nuc980_remove(struct usb_hcd *hcd, struct platform_device *pdev)
+{
+	usb_remove_hcd(hcd);
+	iounmap(hcd->regs);
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+	usb_put_hcd(hcd);
+}
+
+
+static const struct hc_driver ehci_nuc980_hc_driver = {
+	.description = hcd_name,
+	.product_desc = "Nuvoton NUC980 EHCI Host Controller",
+	.hcd_priv_size = sizeof(struct ehci_hcd),
+
+	/*
+	 * generic hardware linkage
+	 */
+	.irq = ehci_irq,
+	.flags = HCD_USB2|HCD_MEMORY,
+
+	/*
+	 * basic lifecycle operations
+	 */
+	.reset = ehci_init,
+	.start = ehci_run,
+
+	.stop = ehci_stop,
+	.shutdown = ehci_shutdown,
+
+	/*
+	 * managing i/o requests and associated device resources
+	 */
+	.urb_enqueue = ehci_urb_enqueue,
+	.urb_dequeue = ehci_urb_dequeue,
+	.endpoint_disable = ehci_endpoint_disable,
+	.endpoint_reset     = ehci_endpoint_reset,
+
+	/*
+	 * scheduling support
+	 */
+	.get_frame_number = ehci_get_frame,
+
+	/*
+	 * root hub support
+	 */
+	.hub_status_data = ehci_hub_status_data,
+	.hub_control = ehci_hub_control,
+#ifdef  CONFIG_PM
+	.bus_suspend = ehci_bus_suspend,
+	.bus_resume = ehci_bus_resume,
+#endif
+	.relinquish_port = ehci_relinquish_port,
+	.port_handed_over = ehci_port_handed_over,
+
+	.clear_tt_buffer_complete = ehci_clear_tt_buffer_complete,
+};
+
+static int ehci_nuc980_probe(struct platform_device *pdev)
+{
+	if (usb_disabled())
+		return -ENODEV;
+
+	return usb_nuc980_probe(&ehci_nuc980_hc_driver, pdev);
+}
+
+static int ehci_nuc980_remove(struct platform_device *pdev)
+{
+	struct usb_hcd *hcd = platform_get_drvdata(pdev);
+
+	usb_nuc980_remove(hcd, pdev);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int ehci_nuc980_pm_suspend(struct device *dev)
+{
+	struct usb_hcd *hcd = dev_get_drvdata(dev);
+	bool do_wakeup = device_may_wakeup(dev);
+	int  ret;
+
+	ret = ehci_suspend(hcd, do_wakeup);
+
+#if !defined(CONFIG_USB_NUC980_OHCI)
+	/* Suspend PHY0 and PHY1; this will turn off PHY power. */
+	/* If NUC980 OHCI enabled, this job will be left to NUC980 OHCI driver. */
+	__raw_writel(0x60, NUC980_VA_EHCI+0xC4);
+	__raw_writel(0x20, NUC980_VA_EHCI+0xC8);
+#endif
+
+#ifdef CONFIG_USE_OF
+	if (of_pm_vbus_off) {
+		if (of_mfp_setting == 1) {
+			__raw_writel(__raw_readl(REG_GPIOE_DOUT) & ~(1<<12), REG_GPIOE_DOUT);     // PE.12 output low
+			__raw_writel(((__raw_readl(REG_GPIOE_MODE) & 0xFCFFFFFF) | (1<<24)), REG_GPIOE_MODE);   // PE.12 output mode
+			__raw_writel(__raw_readl(REG_MFP_GPE_H) & 0xFFF0FFFF, REG_MFP_GPE_H);     // PE.12 GPIO mode
+		}
+	}
+#else   /* !CONFIG_USE_OF */
+
+#if defined(CONFIG_USB_NUC980_PM_VBUS_OFF) && defined(CONFIG_NUC980_USBH_PWREN_ON)
+	/* turn off port power */
+	__raw_writel(__raw_readl(REG_GPIOE_DOUT) & ~(1<<12), REG_GPIOE_DOUT);     // PE.12 output low
+	__raw_writel(((__raw_readl(REG_GPIOE_MODE) & 0xFCFFFFFF) | (1<<24)), REG_GPIOE_MODE);   // PE.12 output mode
+	__raw_writel(__raw_readl(REG_MFP_GPE_H) & 0xFFF0FFFF, REG_MFP_GPE_H);     // PE.12 GPIO mode
+#endif
+
+#endif  /* end of CONFIG_USE_OFF */
+
+	return ret;
+}
+
+static int ehci_nuc980_pm_resume(struct device *dev)
+{
+	struct usb_hcd *hcd = dev_get_drvdata(dev);
+
+#ifdef CONFIG_USE_OF
+	if (of_pm_vbus_off) {
+		if (of_mfp_setting == 1) {
+			__raw_writel(__raw_readl(REG_MFP_GPE_H) | 0x00010000, REG_MFP_GPE_H);       // PE.12 for USBH_PWREN
+		}
+	}
+#else  /* !CONFIG_USE_OF */
+
+#if defined(CONFIG_USB_NUC980_PM_VBUS_OFF) && defined(CONFIG_NUC980_USBH_PWREN_ON)
+	__raw_writel(__raw_readl(REG_MFP_GPE_H) | 0x00010000, REG_MFP_GPE_H);       // PE.12 for USBH_PWREN
+#endif
+
+#endif  /* end of CONFIG_USE_OF */
+
+	/* re-enable PHY0 and PHY1 */
+	__raw_writel(0x160, NUC980_VA_EHCI+0xC4);
+	__raw_writel(0x520, NUC980_VA_EHCI+0xC8);
+
+	ehci_resume(hcd, false);
+
+	return 0;
+}
+#else
+#define ehci_nuc980_pm_suspend  NULL
+#define ehci_nuc980_pm_resume   NULL
+#endif
+
+static const struct dev_pm_ops ehci_nuc980_dev_pm_ops = {
+	.suspend         = ehci_nuc980_pm_suspend,
+	.resume          = ehci_nuc980_pm_resume,
+};
+
+
+static const struct of_device_id nuc980_ehci_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-ehci" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_ehci_of_match);
+
+
+static struct platform_driver ehci_hcd_nuc980_driver = {
+
+	.probe = ehci_nuc980_probe,
+	.remove = ehci_nuc980_remove,
+	.driver = {
+		.name = "nuc980-ehci",
+		.pm = &ehci_nuc980_dev_pm_ops,
+		.owner= THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_ehci_of_match),
+	},
+};
diff -uprN linux-4.4.194/drivers/usb/host/Kconfig NUC980-linux-4.4.194/drivers/usb/host/Kconfig
--- linux-4.4.194/drivers/usb/host/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/usb/host/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -151,6 +151,36 @@ config USB_EHCI_FSL
 	---help---
 	  Variation of ARC USB block used in some Freescale chips.
 
+config USB_NUC980_EHCI
+	tristate "Support for NUC980 EHCI (USB 2.0)"
+	depends on ARCH_NUC980
+	---help---
+	  Enables support for NUC980 USB EHCI controller.
+
+choice
+    prompt "NUC980 USB Host power pin select"
+    default NUC980_USBH_PWREN_OVC_ON
+	depends on !USE_OF
+    depends on USB_NUC980_EHCI
+
+    config NUC980_USBH_PWREN_OVC_ON
+	bool "Use PE.12 for USBH_PWREN and PE.10 for USB_OVC"
+    config NUC980_USBH_PWREN_ON
+	bool "Use PE.12 for USBH_PWREN"
+    config NUC980_USBH_OVC_ON
+	bool "Use PE.10 for USB_OVC"
+    config NUC980_USBH_PWREN_OVC_OFF
+	bool "No USBH_PWREN and USB_OVC"
+endchoice
+
+config USB_NUC980_PM_VBUS_OFF
+	bool "NUC980 turn off USB Host VBUS power while power down"
+	depends on !USE_OF
+	depends on USB_NUC980_EHCI && (NUC980_USBH_PWREN_OVC_ON || NUC980_USBH_PWREN_ON)
+	---help---
+		While kernel in power down mode, turn off USB Host port VBUS power supply.
+		After kernel resumed, all connected USB devices will be re-enumerated.
+
 config USB_EHCI_MXC
 	tristate "Support for Freescale i.MX on-chip EHCI USB controller"
 	depends on ARCH_MXC
@@ -389,6 +419,161 @@ config USB_OHCI_HCD
 
 if USB_OHCI_HCD
 
+config USB_NUC980_OHCI
+	tristate "Support for NUC980 OHCI (USB 1.1)"
+	depends on ARCH_NUC980
+	---help---
+	  Enables support for NUC980 USB OHCI controller.
+
+choice
+    prompt "NUC980 USB Host power pin select"
+    default NUC980_USBH_PWREN_OVC_ON_
+    depends on (!USE_OF && USB_NUC980_OHCI && !USB_NUC980_EHCI)
+
+    config NUC980_USBH_PWREN_OVC_ON_
+	bool "Use PE.12 for USBH_PWREN and PE.10 for USB_OVC"
+    config NUC980_USBH_PWREN_ON_
+	bool "Use PE.12 for USBH_PWREN"
+    config NUC980_USBH_OVC_ON_
+	bool "Use PE.10 for USB_OVC"
+    config NUC980_USBH_PWREN_OVC_OFF_
+	bool "No USBH_PWREN and USB_OVC"
+endchoice
+
+
+if USB_NUC980_OHCI
+
+config USB_NUC980_USBH_LITE0
+	bool "NUC980 USBH Lite0 (OHCI port3) support"
+	depends on USB_OHCI_HCD && ARCH_NUC980 && !USE_OF
+	default n
+	---help---
+		Enables support for NUC980 USBH Lite0
+
+choice
+    prompt "Select USBH Lite0 D+/D- pin"
+    default LITE0_PB4_PB6
+    depends on USB_NUC980_USBH_LITE0
+
+    config LITE0_PB4_PB6
+	bool "D+/D- is PB.4/PB.6"
+    config LITE0_PB5_PB7
+	bool "D+/D- is PB.5/PB.7"
+    config LITE0_PB10_PB9
+	bool "D+/D- is PB.10/PB.9"
+    config LITE0_PD15_PD14
+	bool "D+/D- is PD.15/PD.14"
+endchoice
+
+config USB_NUC980_USBH_LITE1
+	bool "NUC980 USBH Lite1 (OHCI port4) support"
+	depends on USB_OHCI_HCD && ARCH_NUC980 && !USE_OF
+	default n
+	---help---
+		Enables support for NUC980 USBH Lite1
+
+choice
+    prompt "Select USBH Lite1 D+/D- pin"
+    default LITE1_PE1_PE0
+    depends on USB_NUC980_USBH_LITE1
+
+    config LITE1_PE1_PE0
+	bool "D+/D- is PE.1/PE.0"
+    config LITE1_PF1_PF0
+	bool "D+/D- is PF.1/PF.0"
+endchoice
+
+config USB_NUC980_USBH_LITE2
+	bool "NUC980 USBH Lite2 (OHCI port5) support"
+	depends on USB_OHCI_HCD && ARCH_NUC980 && !USE_OF
+	default n
+	---help---
+		Enables support for NUC980 USBH Lite2
+
+choice
+    prompt "Select USBH Lite2 D+/D- pin"
+    default LITE2_PE3_PE2
+    depends on USB_NUC980_USBH_LITE2
+
+    config LITE2_PE3_PE2
+	bool "D+/D- is PE.3/PE.2"
+    config LITE2_PF3_PF2
+	bool "D+/D- is PF.3/PF.2"
+endchoice
+
+config USB_NUC980_USBH_LITE3
+	bool "NUC980 USBH Lite3 (OHCI port6) support"
+	depends on USB_OHCI_HCD && ARCH_NUC980 && !USE_OF
+	default n
+	---help---
+		Enables support for NUC980 USBH Lite3
+
+choice
+    prompt "Select USBH Lite3 D+/D- pin"
+    default LITE3_PE5_PE4
+    depends on USB_NUC980_USBH_LITE3
+
+    config LITE3_PE5_PE4
+	bool "D+/D- is PE.5/PE.4"
+    config LITE3_PF5_PF4
+	bool "D+/D- is PF.5/PF.4"
+endchoice
+
+config USB_NUC980_USBH_LITE4
+	bool "NUC980 USBH Lite4 (OHCI port7) support"
+	depends on USB_OHCI_HCD && ARCH_NUC980 && !USE_OF
+	default n
+	---help---
+		Enables support for NUC980 USBH Lite4
+
+choice
+    prompt "Select USBH Lite4 D+/D- pin"
+    default LITE4_PE7_PE6
+    depends on USB_NUC980_USBH_LITE4
+
+    config LITE4_PE7_PE6
+	bool "D+/D- is PE.7/PE.6"
+    config LITE4_PF7_PF6
+	bool "D+/D- is PF.7/PF.6"
+    config LITE4_PG10_PA15
+	bool "D+/D- is PG.10/PA.15"
+    config LITE4_PB13_PF6
+	bool "D+/D- is PB.13/PF.6"
+endchoice
+
+config USB_NUC980_USBH_LITE5
+	bool "NUC980 USBH Lite5 (OHCI port8) support"
+	depends on USB_OHCI_HCD && ARCH_NUC980 && !USE_OF
+	default n
+	---help---
+		Enables support for NUC980 USBH Lite5
+
+choice
+    prompt "Select USBH Lite5 D+/D- pin"
+    default LITE5_PE9_PE8
+    depends on USB_NUC980_USBH_LITE5
+
+    config LITE5_PE9_PE8
+	bool "D+/D- is PE.9/PE.8"
+    config LITE5_PF9_PF8
+	bool "D+/D- is PF.9/PF.8"
+    config LITE5_PA14_PA13
+	bool "D+/D- is PA.14/PA.13"
+    config LITE5_PB12_PB11
+	bool "D+/D- is PB.12/PB.11"
+endchoice
+
+config USB_NUC980_PM_VBUS_OFF_
+	bool "NUC980 turn off USB Host VBUS power while power down"
+	depends on !USE_OF
+	depends on USB_NUC980_OHCI && !USB_NUC980_EHCI && (NUC980_USBH_PWREN_OVC_ON_ || NUC980_USBH_PWREN_ON_)
+	---help---
+		While kernel in power down mode, turn off USB Host port VBUS power supply.
+		After kernel resumed, all connected USB devices will be re-enumerated.
+
+endif # USB_NUC980_OHCI
+
+
 config USB_OHCI_HCD_OMAP1
 	tristate "OHCI support for OMAP1/2 chips"
 	depends on ARCH_OMAP1
diff -uprN linux-4.4.194/drivers/usb/host/ohci-hcd.c NUC980-linux-4.4.194/drivers/usb/host/ohci-hcd.c
--- linux-4.4.194/drivers/usb/host/ohci-hcd.c	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/usb/host/ohci-hcd.c	2019-12-29 19:12:21.000000000 -0800
@@ -102,7 +102,7 @@ static void io_watchdog_func(unsigned lo
 static bool distrust_firmware = 1;
 module_param (distrust_firmware, bool, 0);
 MODULE_PARM_DESC (distrust_firmware,
-	"true to distrust firmware power/overcurrent setup");
+                  "true to distrust firmware power/overcurrent setup");
 
 /* Some boards leave IR set wrongly, since they fail BIOS/SMM handshakes */
 static bool no_handshake = 0;
@@ -142,10 +142,11 @@ static int number_of_tds(struct urb *urb
  * queue up an urb for anything except the root hub
  */
 static int ohci_urb_enqueue (
-	struct usb_hcd	*hcd,
-	struct urb	*urb,
-	gfp_t		mem_flags
-) {
+    struct usb_hcd	*hcd,
+    struct urb	*urb,
+    gfp_t		mem_flags
+)
+{
 	struct ohci_hcd	*ohci = hcd_to_ohci (hcd);
 	struct ed	*ed;
 	urb_priv_t	*urb_priv;
@@ -153,6 +154,15 @@ static int ohci_urb_enqueue (
 	int		i, size = 0;
 	unsigned long	flags;
 	int		retval = 0;
+	struct usb_device   *parent_hub = urb->dev->parent;
+
+	if (((ohci_readl(ohci, &ohci->regs->roothub.portstatus[0]) & 0x103) != 0x103) &&
+	    (parent_hub->parent == NULL) && (urb->dev->portnum == 1))
+		return -ENODEV;
+
+	if (((ohci_readl(ohci, &ohci->regs->roothub.portstatus[1]) & 0x103) != 0x103) &&
+	    (parent_hub->parent == NULL) && (urb->dev->portnum == 2))
+		return -ENODEV;
 
 	/* every endpoint has a ed, locate and maybe (re)initialize it */
 	ed = ed_get(ohci, urb->ep, urb->dev, pipe, urb->interval);
@@ -161,35 +171,35 @@ static int ohci_urb_enqueue (
 
 	/* for the private part of the URB we need the number of TDs (size) */
 	switch (ed->type) {
-		case PIPE_CONTROL:
-			/* td_submit_urb() doesn't yet handle these */
-			if (urb->transfer_buffer_length > 4096)
-				return -EMSGSIZE;
-
-			/* 1 TD for setup, 1 for ACK, plus ... */
-			size = 2;
-			/* FALLTHROUGH */
-		// case PIPE_INTERRUPT:
-		// case PIPE_BULK:
-		default:
-			size += number_of_tds(urb);
-			/* maybe a zero-length packet to wrap it up */
-			if (size == 0)
-				size++;
-			else if ((urb->transfer_flags & URB_ZERO_PACKET) != 0
-				&& (urb->transfer_buffer_length
-					% usb_maxpacket (urb->dev, pipe,
-						usb_pipeout (pipe))) == 0)
-				size++;
-			break;
-		case PIPE_ISOCHRONOUS: /* number of packets from URB */
-			size = urb->number_of_packets;
-			break;
+	case PIPE_CONTROL:
+		/* td_submit_urb() doesn't yet handle these */
+		if (urb->transfer_buffer_length > 4096)
+			return -EMSGSIZE;
+
+		/* 1 TD for setup, 1 for ACK, plus ... */
+		size = 2;
+	/* FALLTHROUGH */
+	// case PIPE_INTERRUPT:
+	// case PIPE_BULK:
+	default:
+		size += number_of_tds(urb);
+		/* maybe a zero-length packet to wrap it up */
+		if (size == 0)
+			size++;
+		else if ((urb->transfer_flags & URB_ZERO_PACKET) != 0
+		         && (urb->transfer_buffer_length
+		             % usb_maxpacket (urb->dev, pipe,
+		                              usb_pipeout (pipe))) == 0)
+			size++;
+		break;
+	case PIPE_ISOCHRONOUS: /* number of packets from URB */
+		size = urb->number_of_packets;
+		break;
 	}
 
 	/* allocate the private part of the URB */
 	urb_priv = kzalloc (sizeof (urb_priv_t) + size * sizeof (struct td *),
-			mem_flags);
+	                    mem_flags);
 	if (!urb_priv)
 		return -ENOMEM;
 	INIT_LIST_HEAD (&urb_priv->pending);
@@ -231,10 +241,10 @@ static int ohci_urb_enqueue (
 
 		/* Start up the I/O watchdog timer, if it's not running */
 		if (!timer_pending(&ohci->io_watchdog) &&
-				list_empty(&ohci->eds_in_use)) {
+		    list_empty(&ohci->eds_in_use)) {
 			ohci->prev_frame_no = ohci_frame_no(ohci);
 			mod_timer(&ohci->io_watchdog,
-					jiffies + IO_WATCHDOG_DELAY);
+			          jiffies + IO_WATCHDOG_DELAY);
 		}
 		list_add(&ed->in_use_list, &ohci->eds_in_use);
 
@@ -259,12 +269,12 @@ static int ohci_urb_enqueue (
 			/* URB_ISO_ASAP: Round up to the first available slot */
 			if (urb->transfer_flags & URB_ISO_ASAP) {
 				frame += (next - frame + ed->interval - 1) &
-						-ed->interval;
+				         -ed->interval;
 
-			/*
-			 * Not ASAP: Use the next slot in the stream,
-			 * no matter what.
-			 */
+				/*
+				 * Not ASAP: Use the next slot in the stream,
+				 * no matter what.
+				 */
 			} else {
 				/*
 				 * Some OHCI hardware doesn't handle late TDs
@@ -274,13 +284,13 @@ static int ohci_urb_enqueue (
 				 * entirely.
 				 */
 				urb_priv->td_cnt = DIV_ROUND_UP(
-						(u16) (next - frame),
-						ed->interval);
+				                       (u16) (next - frame),
+				                       ed->interval);
 				if (urb_priv->td_cnt >= urb_priv->length) {
 					++urb_priv->td_cnt;	/* Mark it */
 					ohci_dbg(ohci, "iso underrun %p (%u+%u < %u)\n",
-							urb, frame, length,
-							next);
+					         urb, frame, length,
+					         next);
 				}
 			}
 		}
@@ -381,14 +391,14 @@ sanitize:
 			ed_free (ohci, ed);
 			break;
 		}
-		/* else FALL THROUGH */
+	/* else FALL THROUGH */
 	default:
 		/* caller was supposed to have unlinked any requests;
 		 * that's not our job.  can't recover; must leak ed.
 		 */
 		ohci_err (ohci, "leak ed %p (#%02x) state %d%s\n",
-			ed, ep->desc.bEndpointAddress, ed->state,
-			list_empty (&ed->td_list) ? "" : " (has tds)");
+		          ed, ep->desc.bEndpointAddress, ed->state,
+		          list_empty (&ed->td_list) ? "" : " (has tds)");
 		td_free (ohci, ed->dummy);
 		break;
 	}
@@ -469,7 +479,7 @@ static int ohci_init (struct ohci_hcd *o
 #ifndef IR_DISABLE
 	/* SMM owns the HC?  not for long! */
 	if (!no_handshake && ohci_readl (ohci,
-					&ohci->regs->control) & OHCI_CTRL_IR) {
+	                                 &ohci->regs->control) & OHCI_CTRL_IR) {
 		u32 temp;
 
 		ohci_dbg (ohci, "USB HC TakeOver from BIOS/SMM\n");
@@ -486,7 +496,7 @@ static int ohci_init (struct ohci_hcd *o
 			msleep (10);
 			if (--temp == 0) {
 				ohci_err (ohci, "USB HC takeover failed!"
-					"  (BIOS/SMM bug)\n");
+				          "  (BIOS/SMM bug)\n");
 				return -EBUSY;
 			}
 		}
@@ -509,11 +519,11 @@ static int ohci_init (struct ohci_hcd *o
 		return 0;
 
 	setup_timer(&ohci->io_watchdog, io_watchdog_func,
-			(unsigned long) ohci);
+	            (unsigned long) ohci);
 	set_timer_slack(&ohci->io_watchdog, msecs_to_jiffies(20));
 
 	ohci->hcca = dma_alloc_coherent (hcd->self.controller,
-			sizeof(*ohci->hcca), &ohci->hcca_dma, GFP_KERNEL);
+	                                 sizeof(*ohci->hcca), &ohci->hcca_dma, GFP_KERNEL);
 	if (!ohci->hcca)
 		return -ENOMEM;
 
@@ -547,7 +557,7 @@ static int ohci_run (struct ohci_hcd *oh
 		ohci->fminterval = val & 0x3fff;
 		if (ohci->fminterval != FI)
 			ohci_dbg (ohci, "fminterval delta %d\n",
-				ohci->fminterval - FI);
+			          ohci->fminterval - FI);
 		ohci->fminterval |= FSMP (ohci->fminterval) << 16;
 		/* also: power/overcurrent flags in roothub.a */
 	}
@@ -630,7 +640,7 @@ retry:
 	 * bogus values here mean not even enumeration could work.
 	 */
 	if ((ohci_readl (ohci, &ohci->regs->fminterval) & 0x3fff0000) == 0
-			|| !ohci_readl (ohci, &ohci->regs->periodicstart)) {
+	    || !ohci_readl (ohci, &ohci->regs->periodicstart)) {
 		if (!(ohci->flags & OHCI_QUIRK_INITRESET)) {
 			ohci->flags |= OHCI_QUIRK_INITRESET;
 			ohci_dbg (ohci, "enabling initreset quirk\n");
@@ -638,8 +648,8 @@ retry:
 		}
 		spin_unlock_irq (&ohci->lock);
 		ohci_err (ohci, "init err (%08x %04x)\n",
-			ohci_readl (ohci, &ohci->regs->fminterval),
-			ohci_readl (ohci, &ohci->regs->periodicstart));
+		          ohci_readl (ohci, &ohci->regs->fminterval),
+		          ohci_readl (ohci, &ohci->regs->periodicstart));
 		return -EOVERFLOW;
 	}
 
@@ -670,7 +680,7 @@ retry:
 		val &= ~(RH_A_POTPGT | RH_A_NPS);
 		ohci_writel (ohci, val, &ohci->regs->roothub.a);
 	} else if ((ohci->flags & OHCI_QUIRK_AMD756) ||
-			(ohci->flags & OHCI_QUIRK_HUB_POWER)) {
+	           (ohci->flags & OHCI_QUIRK_HUB_POWER)) {
 		/* hub power always on; required for AMD-756 and some
 		 * Mac platforms.  ganged overcurrent reporting, if any.
 		 */
@@ -679,7 +689,7 @@ retry:
 	}
 	ohci_writel (ohci, RH_HS_LPSC, &ohci->regs->roothub.status);
 	ohci_writel (ohci, (val & RH_A_NPS) ? 0 : RH_B_PPCM,
-						&ohci->regs->roothub.b);
+	             &ohci->regs->roothub.b);
 	// flush those writes
 	(void) ohci_readl (ohci, &ohci->regs->control);
 
@@ -701,7 +711,7 @@ int ohci_setup(struct usb_hcd *hcd)
 	struct ohci_hcd		*ohci = hcd_to_ohci(hcd);
 
 	ohci_hcd_init(ohci);
-	
+
 	return ohci_init(ohci);
 }
 EXPORT_SYMBOL_GPL(ohci_setup);
@@ -756,7 +766,7 @@ static void io_watchdog_func(unsigned lo
 	if (!(status & OHCI_INTR_WDH) && ohci->wdh_cnt == ohci->prev_wdh_cnt) {
 		if (ohci->prev_donehead) {
 			ohci_err(ohci, "HcDoneHead not written back; disabled\n");
- died:
+died:
 			usb_hc_died(ohci_to_hcd(ohci));
 			ohci_dump(ohci);
 			_ohci_shutdown(ohci_to_hcd(ohci));
@@ -771,13 +781,13 @@ static void io_watchdog_func(unsigned lo
 	list_for_each_entry(ed, &ohci->eds_in_use, in_use_list) {
 		if (ed->pending_td) {
 			if (takeback_all_pending ||
-					OKAY_TO_TAKEBACK(ohci, ed)) {
+			    OKAY_TO_TAKEBACK(ohci, ed)) {
 				unsigned tmp = hc32_to_cpu(ohci, ed->hwINFO);
 
 				ohci_dbg(ohci, "takeback pending TD for dev %d ep 0x%x\n",
-						0x007f & tmp,
-						(0x000f & (tmp >> 7)) +
-							((tmp & ED_IN) >> 5));
+				         0x007f & tmp,
+				         (0x000f & (tmp >> 7)) +
+				         ((tmp & ED_IN) >> 5));
 				add_to_done_list(ohci, ed->pending_td);
 			}
 		}
@@ -848,13 +858,13 @@ static void io_watchdog_func(unsigned lo
 			ohci->prev_frame_no = frame_no;
 			ohci->prev_wdh_cnt = ohci->wdh_cnt;
 			ohci->prev_donehead = ohci_readl(ohci,
-					&ohci->regs->donehead);
+			                                 &ohci->regs->donehead);
 			mod_timer(&ohci->io_watchdog,
-					jiffies + IO_WATCHDOG_DELAY);
+			          jiffies + IO_WATCHDOG_DELAY);
 		}
 	}
 
- done:
+done:
 	spin_unlock_irqrestore(&ohci->lock, flags);
 }
 
@@ -914,7 +924,7 @@ static irqreturn_t ohci_irq (struct usb_
 		ohci_dbg(ohci, "rhsc\n");
 		ohci->next_statechange = jiffies + STATECHANGE_DELAY;
 		ohci_writel(ohci, OHCI_INTR_RD | OHCI_INTR_RHSC,
-				&regs->intrstatus);
+		            &regs->intrstatus);
 
 		/* NOTE: Vendors didn't always make the same implementation
 		 * choices for RHSC.  Many followed the spec; RHSC triggers
@@ -955,7 +965,7 @@ static irqreturn_t ohci_irq (struct usb_
 	 */
 	ohci_work(ohci);
 	if ((ints & OHCI_INTR_SF) != 0 && !ohci->ed_rm_list
-			&& ohci->rh_state == OHCI_RH_RUNNING)
+	    && ohci->rh_state == OHCI_RH_RUNNING)
 		ohci_writel (ohci, OHCI_INTR_SF, &regs->intrdisable);
 
 	if (ohci->rh_state == OHCI_RH_RUNNING) {
@@ -996,8 +1006,8 @@ static void ohci_stop (struct usb_hcd *h
 	ohci_mem_cleanup (ohci);
 	if (ohci->hcca) {
 		dma_free_coherent (hcd->self.controller,
-				sizeof *ohci->hcca,
-				ohci->hcca, ohci->hcca_dma);
+		                   sizeof *ohci->hcca,
+		                   ohci->hcca, ohci->hcca_dma);
 		ohci->hcca = NULL;
 		ohci->hcca_dma = 0;
 	}
@@ -1034,12 +1044,12 @@ int ohci_restart(struct ohci_hcd *ohci)
 			ed->ed_next = ohci->ed_rm_list;
 			ed->ed_prev = NULL;
 			ohci->ed_rm_list = ed;
-			/* FALLTHROUGH */
+		/* FALLTHROUGH */
 		case ED_UNLINK:
 			break;
 		default:
 			ohci_dbg(ohci, "bogus ed %p state %d\n",
-					ed, ed->state);
+			         ed, ed->state);
 		}
 
 		if (!urb->unlinked)
@@ -1139,7 +1149,7 @@ int ohci_resume(struct usb_hcd *hcd, boo
 		ohci_dbg(ohci, "powerup ports\n");
 		for (port = 0; port < ohci->num_ports; port++)
 			ohci_writel(ohci, RH_PS_PPS,
-					&ohci->regs->roothub.portstatus[port]);
+			            &ohci->regs->roothub.portstatus[port]);
 
 		ohci_writel(ohci, OHCI_INTR_MIE, &ohci->regs->intrenable);
 		ohci_readl(ohci, &ohci->regs->intrenable);
@@ -1205,7 +1215,7 @@ static const struct hc_driver ohci_hc_dr
 };
 
 void ohci_init_driver(struct hc_driver *drv,
-		const struct ohci_driver_overrides *over)
+                      const struct ohci_driver_overrides *over)
 {
 	/* Copy the generic table to drv and then apply the overrides */
 	*drv = ohci_hc_driver;
@@ -1225,6 +1235,11 @@ MODULE_AUTHOR (DRIVER_AUTHOR);
 MODULE_DESCRIPTION(DRIVER_DESC);
 MODULE_LICENSE ("GPL");
 
+#ifdef CONFIG_USB_NUC980_OHCI
+#include "ohci-nuc980.c"
+#define PLATFORM_DRIVER		ohci_hcd_nuc980_driver
+#endif
+
 #if defined(CONFIG_ARCH_SA1100) && defined(CONFIG_SA1111)
 #include "ohci-sa1111.c"
 #define SA1111_DRIVER		ohci_hcd_sa1111_driver
@@ -1274,7 +1289,7 @@ static int __init ohci_hcd_mod_init(void
 
 	printk(KERN_INFO "%s: " DRIVER_DESC "\n", hcd_name);
 	pr_debug ("%s: block sizes: ed %Zd td %Zd\n", hcd_name,
-		sizeof (struct ed), sizeof (struct td));
+	          sizeof (struct ed), sizeof (struct td));
 	set_bit(USB_OHCI_LOADED, &usb_hcds_loaded);
 
 	ohci_debug_root = debugfs_create_dir("ohci", usb_debug_root);
@@ -1330,35 +1345,35 @@ static int __init ohci_hcd_mod_init(void
 	/* Error path */
 #ifdef DAVINCI_PLATFORM_DRIVER
 	platform_driver_unregister(&DAVINCI_PLATFORM_DRIVER);
- error_davinci:
+error_davinci:
 #endif
 #ifdef TMIO_OHCI_DRIVER
 	platform_driver_unregister(&TMIO_OHCI_DRIVER);
- error_tmio:
+error_tmio:
 #endif
 #ifdef SM501_OHCI_DRIVER
 	platform_driver_unregister(&SM501_OHCI_DRIVER);
- error_sm501:
+error_sm501:
 #endif
 #ifdef SA1111_DRIVER
 	sa1111_driver_unregister(&SA1111_DRIVER);
- error_sa1111:
+error_sa1111:
 #endif
 #ifdef OF_PLATFORM_DRIVER
 	platform_driver_unregister(&OF_PLATFORM_DRIVER);
- error_of_platform:
+error_of_platform:
 #endif
 #ifdef PLATFORM_DRIVER
 	platform_driver_unregister(&PLATFORM_DRIVER);
- error_platform:
+error_platform:
 #endif
 #ifdef PS3_SYSTEM_BUS_DRIVER
 	ps3_ohci_driver_unregister(&PS3_SYSTEM_BUS_DRIVER);
- error_ps3:
+error_ps3:
 #endif
 	debugfs_remove(ohci_debug_root);
 	ohci_debug_root = NULL;
- error_debug:
+error_debug:
 
 	clear_bit(USB_OHCI_LOADED, &usb_hcds_loaded);
 	return retval;
diff -uprN linux-4.4.194/drivers/usb/host/ohci-nuc980.c NUC980-linux-4.4.194/drivers/usb/host/ohci-nuc980.c
--- linux-4.4.194/drivers/usb/host/ohci-nuc980.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/usb/host/ohci-nuc980.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,528 @@
+/*
+ * linux/driver/usb/host/ohci-nuc980.c
+ *
+ * Copyright (c) 2017 Nuvoton technology corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/platform_device.h>
+#include <linux/signal.h>
+#include <linux/of.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-gpio.h>
+#include <mach/regs-clock.h>
+#include <linux/clk.h>
+
+#include <mach/map.h>
+
+
+#ifdef CONFIG_USE_OF
+static int  of_pm_vbus_off;
+static int  of_mfp_setting;
+#endif
+
+
+/**
+ * usb_hcd_ppc_soc_probe - initialize On-Chip HCDs
+ * Context: !in_interrupt()
+ *
+ * Allocates basic resources for this USB host controller.
+ *
+ * Store this function in the HCD's struct pci_driver as probe().
+ */
+static int usb_hcd_nuc980_probe(const struct hc_driver *driver,
+                                struct platform_device *pdev)
+{
+	int retval;
+	struct usb_hcd *hcd;
+	struct ohci_hcd *ohci ;
+#ifdef CONFIG_USE_OF
+	u32   val32[2];
+#endif
+	struct pinctrl *p=NULL;
+
+	printk("usb_hcd_nuc980_probe, id = %d, name: %s, %d\n", pdev->id, dev_name(&pdev->dev), (int)p);
+
+	/*------------------------------------------------------------*/
+	/*  USBH Lite initialization                                  */
+	/*------------------------------------------------------------*/
+#ifdef CONFIG_USB_NUC980_USBH_LITE0
+	if (pdev->id == 1) {
+#if defined(CONFIG_LITE0_PB4_PB6)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite0_pb4_pb6");
+#elif defined(CONFIG_LITE0_PB5_PB7)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite0_pb5_pb7");
+#elif defined(CONFIG_LITE0_PB10_PB9)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite0_pb10_pb9");
+#elif defined(CONFIG_LITE0_PD15_PD14)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite0_pd15_pd15");
+#endif
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve usbh_lite0 pin\n");
+			retval = PTR_ERR(p);
+		}
+	}
+#endif   // CONFIG_USB_NUC980_USBH_LITE0
+
+#ifdef CONFIG_USB_NUC980_USBH_LITE1
+	if (pdev->id == 2) {
+#if defined(CONFIG_LITE1_PE1_PE0)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite1_pe1_pe0");
+#elif defined(CONFIG_LITE1_PF1_PF0)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite1_pf1_pf0");
+#endif
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve usbh_lite1 pin\n");
+			retval = PTR_ERR(p);
+		}
+	}
+#endif  // CONFIG_USB_NUC980_USBH_LITE1
+
+#ifdef CONFIG_USB_NUC980_USBH_LITE2
+	if (pdev->id == 3) {
+#if defined(CONFIG_LITE2_PE3_PE2)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite2_pe3_pe2");
+#elif defined(CONFIG_LITE2_PF3_PF2)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite2_pf3_pf2");
+#endif
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve usbh_lite2 pin\n");
+			retval = PTR_ERR(p);
+		}
+	}
+#endif  // CONFIG_USB_NUC980_USBH_LITE2
+
+#ifdef CONFIG_USB_NUC980_USBH_LITE3
+	if (pdev->id == 4) {
+#if defined(CONFIG_LITE3_PE5_PE4)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite3_pe5_pe4");
+#elif defined(CONFIG_LITE3_PF3_PF2)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite3_pf5_pf4");
+#endif
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve usbh_lite3 pin\n");
+			retval = PTR_ERR(p);
+		}
+	}
+#endif  // CONFIG_USB_NUC980_USBH_LITE3
+
+#ifdef CONFIG_USB_NUC980_USBH_LITE4
+	if (pdev->id == 5) {
+#if defined(CONFIG_LITE4_PE7_PE6)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite4_pe7_pe6");
+#elif defined(CONFIG_LITE4_PF7_PF6)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite4_pf7_pf6");
+#elif defined(CONFIG_LITE4_PG10_PA15)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite4_pg10_pa15");
+#elif defined(CONFIG_LITE4_PB13_PF6)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite4_pb13_pf6");
+#endif
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve usbh_lite4 pin\n");
+			retval = PTR_ERR(p);
+		}
+	}
+#endif  // CONFIG_USB_NUC980_USBH_LITE4
+
+#ifdef CONFIG_USB_NUC980_USBH_LITE5
+	if (pdev->id == 6) {
+#if defined(CONFIG_LITE5_PE9_PE8)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite5_pe9_pe8");
+#elif defined(CONFIG_LITE5_PF9_PF8)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite5_pf9_pf8");
+#elif defined(CONFIG_LITE5_PA14_PA13)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite5_pa14_pa13");
+#elif defined(CONFIG_LITE5_PB12_PB11)
+		p = devm_pinctrl_get_select(&pdev->dev, "usbh_lite5_pb12_pb11");
+#endif
+		if (IS_ERR(p)) {
+			dev_err(&pdev->dev, "unable to reserve usbh_lite5 pin\n");
+			retval = PTR_ERR(p);
+		}
+	}
+#endif  // CONFIG_USB_NUC980_USBH_LITE5
+
+
+#ifdef CONFIG_USE_OF
+
+	devm_pinctrl_get_select_default(&pdev->dev);
+
+	if ((__raw_readl(REG_MFP_GPE_H) & 0x000F0000) == 0x00010000)
+		of_mfp_setting = 1;
+	else
+		of_mfp_setting = 0;
+
+	//printk("of_mfp_setting = %d\n", of_mfp_setting);
+
+	if (of_property_read_u32_array(pdev->dev.of_node, "ov_active", val32, 1) == 0) {
+		// printk("Over-current active level %s...\n", val32[0] ? "high" : "low");
+		if (val32[0]) {
+			/* set over-current active high */
+			__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+		} else {
+			/* set over-current active low */
+			__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) | 0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+		}
+	}
+
+	if (of_property_read_u32_array(pdev->dev.of_node, "pm_vbus_off", val32, 1) == 0) {
+		if (val32[0])
+			of_pm_vbus_off = 1;
+		else
+			of_pm_vbus_off = 0;
+	} else {
+		of_pm_vbus_off = 0;
+	}
+
+	/*
+	 * Right now device-tree probed devices don't get dma_mask set.
+	 * Since shared usb code relies on it, set it here for now.
+	 * Once we have dma capability bindings this can go away.
+	 */
+	if (!pdev->dev.dma_mask)
+		pdev->dev.dma_mask = &pdev->dev.coherent_dma_mask;
+	if (!pdev->dev.coherent_dma_mask)
+		pdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+
+#else
+
+#if !defined(CONFIG_USB_NUC980_EHCI)
+
+	/* multi-function pin select */
+#if defined(CONFIG_NUC980_USBH_PWREN_OVC_ON_)
+	p = devm_pinctrl_get_select(&pdev->dev, "usbh_pwren_ovc_on");
+	if (IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve USBH_PWREN and USB_OVC pins\n");
+		retval = PTR_ERR(p);
+		/* set over-current active high */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	} else {
+		/* set over-current active low */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) | 0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	}
+
+#elif defined(CONFIG_NUC980_USBH_PWREN_ON_)
+
+	p = devm_pinctrl_get_select(&pdev->dev, "usbh_pwren_on");
+	if (IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve USBH_PWREN pin\n");
+		retval = PTR_ERR(p);
+	}
+	/* set over-current active high */
+	__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+
+#elif defined(CONFIG_NUC980_USBH_OVC_ON_)
+	p = devm_pinctrl_get_select(&pdev->dev, "usbh_ovc_on");
+	if (IS_ERR(p)) {
+		dev_err(&pdev->dev, "unable to reserve USB_OVC pin\n");
+		retval = PTR_ERR(p);
+		/* set over-current active high */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	} else {
+		/* set over-current active low */
+		__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) | 0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+	}
+#elif defined(CONFIG_NUC980_USBH_PWREN_OVC_OFF_)
+
+	/* set over-current active high */
+	__raw_writel(__raw_readl(NUC980_VA_OHCI+0x204) &~0x8, (volatile void __iomem *)(NUC980_VA_OHCI+0x204));
+
+#endif
+
+#endif   // !CONFIG_USB_NUC980_EHCI
+
+#endif   // CONFIG_USE_OF
+
+#ifdef CONFIG_USE_OF
+	if (strcmp(pdev->name, "b0017000.usbh_ohci") != 0)
+		return 0;         /* return here if is USBH Lite device */
+#else
+	if (pdev->id != 0)
+		return 0;         /* return here if is USBH Lite device */
+#endif
+
+	clk_prepare(clk_get(NULL, "usb_eclk"));
+	clk_enable(clk_get(NULL, "usb_eclk"));
+
+	/* enable USB Host clock */
+	clk_prepare(clk_get(NULL, "usbh_hclk"));
+	clk_enable(clk_get(NULL, "usbh_hclk"));
+
+	/* enable PHY 0/1 */
+	__raw_writel(0x160, (volatile void __iomem *)(NUC980_VA_EHCI+0xC4));
+	__raw_writel(0x520, (volatile void __iomem *)(NUC980_VA_EHCI+0xC8));
+
+	hcd = usb_create_hcd(driver, &pdev->dev, "nuc980-ohci");
+	if (!hcd)
+		return -ENOMEM;
+
+	hcd->rsrc_start = pdev->resource[0].start;
+	hcd->rsrc_len = pdev->resource[0].end - pdev->resource[0].start + 1;
+
+	if (!request_mem_region(hcd->rsrc_start, hcd->rsrc_len, hcd_name)) {
+		pr_debug("ohci probe request_mem_region failed");
+		retval = -EBUSY;
+		goto err1;
+	}
+
+	hcd->regs = ioremap(hcd->rsrc_start, hcd->rsrc_len);
+	if (!hcd->regs) {
+		pr_debug("ohci error mapping memory\n");
+		retval = -ENOMEM;
+		goto err2;
+	}
+
+	ohci = hcd_to_ohci(hcd);
+	ohci_hcd_init(ohci);
+
+	retval = usb_add_hcd(hcd, pdev->resource[1].start, IRQF_SHARED);
+
+	//printk("Port status: 0x%x, 0x%x\n", __raw_readl((volatile void __iomem *)(NUC980_VA_EHCI+0x64)), __raw_readl((volatile void __iomem *)(NUC980_VA_EHCI+0x68)));
+	//printk("Port status: 0x%x, 0x%x\n", __raw_readl((volatile void __iomem *)(NUC980_VA_OHCI+0x54)), __raw_readl((volatile void __iomem *)(NUC980_VA_OHCI+0x58)));
+
+	if (retval == 0)
+		return retval;
+
+	pr_debug("Removing nuc980 OHCI USB Controller\n");
+
+	iounmap(hcd->regs);
+err2:
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+err1:
+
+	usb_put_hcd(hcd);
+	return retval;
+}
+
+
+/* may be called without controller electrically present */
+/* may be called with controller, bus, and devices active */
+
+/**
+ * usb_hcd_ppc_soc_remove - shutdown processing for On-Chip HCDs
+ * @pdev: USB Host Controller being removed
+ * Context: !in_interrupt()
+ *
+ * Reverses the effect of usb_hcd_ppc_soc_probe().
+ * It is always called from a thread
+ * context, normally "rmmod", "apmd", or something similar.
+ *
+ */
+static void usb_hcd_nuc980_remove(struct usb_hcd *hcd,
+                                  struct platform_device *dev)
+{
+	usb_remove_hcd(hcd);
+
+	//pr_debug("stopping PPC-SOC USB Controller\n");
+
+	iounmap(hcd->regs);
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+	usb_put_hcd(hcd);
+}
+
+
+static int ohci_nuc980_start (struct usb_hcd *hcd)
+{
+	struct ohci_hcd *ohci = hcd_to_ohci (hcd);
+	int ret;
+
+	if ((ret = ohci_init(ohci)) < 0)
+		return ret;
+
+	if ((ret = ohci_run (ohci)) < 0) {
+		printk("can't start %s", hcd->self.bus_name);
+		ohci_stop (hcd);
+		return ret;
+	}
+
+	return 0;
+}
+
+
+static const struct hc_driver ohci_nuc980_hc_driver = {
+	.description =      hcd_name,
+	.product_desc =     "Nuvoton NUC980 OHCI Host Controller",
+	.hcd_priv_size =    sizeof(struct ohci_hcd),
+
+	/*
+	 * generic hardware linkage
+	 */
+	.irq =          ohci_irq,
+	.flags =        HCD_USB11 | HCD_MEMORY,
+
+	/*
+	 * basic lifecycle operations
+	 */
+	.start =        ohci_nuc980_start,
+	.stop =         ohci_stop,
+	.shutdown =      ohci_shutdown,
+
+	/*
+	 * managing i/o requests and associated device resources
+	 */
+	.urb_enqueue =      ohci_urb_enqueue,
+	.urb_dequeue =      ohci_urb_dequeue,
+	.endpoint_disable = ohci_endpoint_disable,
+
+	/*
+	 * scheduling support
+	 */
+	.get_frame_number = ohci_get_frame,
+
+	/*
+	 * root hub support
+	 */
+	.hub_status_data =  ohci_hub_status_data,
+	.hub_control =      ohci_hub_control,
+#ifdef  CONFIG_PM
+	.bus_suspend =      ohci_bus_suspend,
+	.bus_resume =       ohci_bus_resume,
+#endif
+	.start_port_reset = ohci_start_port_reset,
+};
+
+
+static int ohci_hcd_nuc980_drv_probe(struct platform_device *pdev)
+{
+	int ret;
+
+	if (usb_disabled())
+		return -ENODEV;
+
+	ret = usb_hcd_nuc980_probe(&ohci_nuc980_hc_driver, pdev);
+	return ret;
+}
+
+static int ohci_hcd_nuc980_drv_remove(struct platform_device *pdev)
+{
+	struct usb_hcd *hcd = platform_get_drvdata(pdev);
+
+	usb_hcd_nuc980_remove(hcd, pdev);
+	return 0;
+}
+
+
+#if defined(CONFIG_PM)
+
+static int ohci_nuc980_pm_suspend(struct device *dev)
+{
+	struct usb_hcd *hcd = dev_get_drvdata(dev);
+	bool do_wakeup = device_may_wakeup(dev);
+	struct platform_device  *pdev = to_platform_device(dev);
+	int  ret;
+
+#ifdef CONFIG_USE_OF
+	if (strcmp(pdev->name, "b0017000.usbh_ohci") != 0)
+		return 0;         /* return here if is USBH Lite device */
+#else
+	if (pdev->id != 0)
+		return 0;         /* return here if is USBH Lite device */
+#endif
+
+	ret = ohci_suspend(hcd, do_wakeup);
+
+	/* Suspend PHY0 and PHY1; this will turn off PHY power. */
+	__raw_writel(0x60, NUC980_VA_EHCI+0xC4);
+	__raw_writel(0x20, NUC980_VA_EHCI+0xC8);
+
+#if !defined(CONFIG_USB_NUC980_EHCI)
+#ifdef CONFIG_USE_OF
+	if (of_pm_vbus_off) {
+		if (of_mfp_setting == 1) {
+			__raw_writel(__raw_readl(REG_GPIOE_DOUT) & ~(1<<12), REG_GPIOE_DOUT);     // PE.12 output low
+			__raw_writel(((__raw_readl(REG_GPIOE_MODE) & 0xFCFFFFFF) | (1<<24)), REG_GPIOE_MODE);   // PE.12 output mode
+			__raw_writel(__raw_readl(REG_MFP_GPE_H) & 0xFFF0FFFF, REG_MFP_GPE_H);     // PE.12 GPIO mode
+		}
+	}
+#else   /* !CONFIG_USE_OF */
+
+#if defined(CONFIG_USB_NUC980_PM_VBUS_OFF) && defined(CONFIG_NUC980_USBH_PWREN_ON_)
+	/* turn off port power */
+	__raw_writel(__raw_readl(REG_GPIOE_DOUT) & ~(1<<12), REG_GPIOE_DOUT);     // PE.12 output low
+	__raw_writel(((__raw_readl(REG_GPIOE_MODE) & 0xFCFFFFFF) | (1<<24)), REG_GPIOE_MODE);   // PE.12 output mode
+	__raw_writel(__raw_readl(REG_MFP_GPE_H) & 0xFFF0FFFF, REG_MFP_GPE_H);     // PE.12 GPIO mode
+#endif
+
+#endif  /* end of CONFIG_USE_OFF */
+#endif  /* end of !CONFIG_USB_NUC980_EHCI */
+
+	return ret;
+}
+
+static int ohci_nuc980_pm_resume(struct device *dev)
+{
+	struct usb_hcd *hcd = dev_get_drvdata(dev);
+	struct platform_device  *pdev = to_platform_device(dev);
+
+#ifdef CONFIG_USE_OF
+	if (strcmp(pdev->name, "b0017000.usbh_ohci") != 0)
+		return 0;         /* return here if is USBH Lite device */
+#else
+	if (pdev->id != 0)
+		return 0;         /* return here if is USBH Lite device */
+#endif
+
+#if !defined(CONFIG_USB_NUC980_EHCI)
+#ifdef CONFIG_USE_OF
+	if (of_pm_vbus_off) {
+		if (of_mfp_setting == 1) {
+			__raw_writel(__raw_readl(REG_MFP_GPE_H) | 0x00010000, REG_MFP_GPE_H);       // PE.12 for USBH_PWREN
+		}
+	}
+#else  /* !CONFIG_USE_OF */
+
+#if defined(CONFIG_USB_NUC980_PM_VBUS_OFF) && defined(CONFIG_NUC980_USBH_PWREN_ON_)
+	__raw_writel(__raw_readl(REG_MFP_GPE_H) | 0x00010000, REG_MFP_GPE_H);       // PE.12 for USBH_PWREN
+#endif
+
+#endif  /* end of CONFIG_USE_OF */
+#endif  /* !CONFIG_USB_NUC980_EHCI */
+
+	/* re-enable PHY0 and PHY1 */
+	__raw_writel(0x160, NUC980_VA_EHCI+0xC4);
+	__raw_writel(0x520, NUC980_VA_EHCI+0xC8);
+
+	ohci_resume(hcd, false);
+
+	return 0;
+}
+#else
+#define ohci_nuc980_pm_suspend  NULL
+#define ohci_nuc980_pm_resume   NULL
+#endif
+
+static const struct dev_pm_ops ohci_nuc980_dev_pm_ops = {
+	.suspend         = ohci_nuc980_pm_suspend,
+	.resume          = ohci_nuc980_pm_resume,
+};
+
+
+static const struct of_device_id nuc980_ohci_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-ohci" },
+	{ .compatible = "nuvoton,nuc980-usbh-lite0" },
+	{ .compatible = "nuvoton,nuc980-usbh-lite1" },
+	{ .compatible = "nuvoton,nuc980-usbh-lite2" },
+	{ .compatible = "nuvoton,nuc980-usbh-lite3" },
+	{ .compatible = "nuvoton,nuc980-usbh-lite4" },
+	{ .compatible = "nuvoton,nuc980-usbh-lite5" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_ohci_of_match);
+
+
+static struct platform_driver ohci_hcd_nuc980_driver = {
+	.probe      = ohci_hcd_nuc980_drv_probe,
+	.remove     = ohci_hcd_nuc980_drv_remove,
+
+	.driver     = {
+		.name   = "nuc980-ohci",
+		.pm     = &ohci_nuc980_dev_pm_ops,
+		.owner  = THIS_MODULE,
+		.of_match_table = of_match_ptr(nuc980_ohci_of_match),
+	},
+};
diff -uprN linux-4.4.194/drivers/usb/host/ohci-q.c NUC980-linux-4.4.194/drivers/usb/host/ohci-q.c
--- linux-4.4.194/drivers/usb/host/ohci-q.c	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/usb/host/ohci-q.c	2019-12-29 19:12:21.000000000 -0800
@@ -804,8 +804,13 @@ static int td_done(struct ohci_hcd *ohci
 		if (cc == TD_DATAUNDERRUN
 				&& !(urb->transfer_flags & URB_SHORT_NOT_OK))
 			cc = TD_CC_NOERROR;
+
 		if (cc != TD_CC_NOERROR && cc < 0x0E)
+		{
+            if (cc != 9)	// 9: DATAUNDERRUN: The endpoint returned less than MaximumPacketSize and that amount was not sufficient to fill the specified buffer */
+                printk("ERROR ohci-q.c  0x%x! %x 0x%x\n", cc, td->hwCBP, tdBE);
 			status = cc_to_error[cc];
+	    }
 
 		/* count all non-empty packets except control SETUP packet */
 		if ((type != PIPE_CONTROL || td->index != 0) && tdBE != 0) {
diff -uprN linux-4.4.194/drivers/usb/serial/option.c NUC980-linux-4.4.194/drivers/usb/serial/option.c
--- linux-4.4.194/drivers/usb/serial/option.c	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/usb/serial/option.c	2019-12-29 19:12:21.000000000 -0800
@@ -1757,6 +1757,7 @@ static const struct usb_device_id option
 	 .driver_info = RSVD(3) | RSVD(4) | RSVD(5) },
 	{ USB_DEVICE(ZTE_VENDOR_ID, ZTE_PRODUCT_ZM8620_X),
 	 .driver_info = RSVD(3) | RSVD(4) | RSVD(5) },
+	{ USB_DEVICE(ZTE_VENDOR_ID, 0x1476)},/*for ME3630-W*/
 	{ USB_VENDOR_AND_INTERFACE_INFO(ZTE_VENDOR_ID, 0xff, 0x02, 0x01) },
 	{ USB_VENDOR_AND_INTERFACE_INFO(ZTE_VENDOR_ID, 0xff, 0x02, 0x05) },
 	{ USB_VENDOR_AND_INTERFACE_INFO(ZTE_VENDOR_ID, 0xff, 0x86, 0x10) },
@@ -2016,6 +2017,9 @@ static struct usb_serial_driver option_1
 #ifdef CONFIG_PM
 	.suspend           = usb_wwan_suspend,
 	.resume            = usb_wwan_resume,
+#if 1 //Added by Quectel
+	.reset_resume      = usb_wwan_resume,
+#endif
 #endif
 };
 
@@ -2053,6 +2057,39 @@ static int option_probe(struct usb_seria
 	    iface_desc->bInterfaceClass != USB_CLASS_CDC_DATA)
 		return -ENODEV;
 
+#if 1 //Added by Quectel
+	//Quectel UC20's interface 4 can be used as USB network device
+	if (serial->dev->descriptor.idVendor == cpu_to_le16(0x05C6) &&
+	    serial->dev->descriptor.idProduct == cpu_to_le16(0x9003)
+	    && serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4)
+		return -ENODEV;
+	//Quectel EC20's interface 4 can be used as USB network device
+	if (serial->dev->descriptor.idVendor == cpu_to_le16(0x05C6) &&
+	    serial->dev->descriptor.idProduct == cpu_to_le16(0x9215)
+	    && serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4)
+		return -ENODEV;
+	//Quectel EC25&EC21&EG91&EG95&EG06&EP06&EM06&BG96/AG35's interface 4 can be used as USB network device
+	if (serial->dev->descriptor.idVendor == cpu_to_le16(0x2C7C)
+	    && serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4)
+		return -ENODEV;
+#endif
+
+#if 1  /////////////////////for ME3630-W///////////////////////
+	if (serial->dev->descriptor.idVendor == 0x19d2 &&
+	    serial->dev->descriptor.idProduct == 0x1476 &&
+	    serial->interface->cur_altsetting->desc. bInterfaceNumber == 3)
+		return -ENODEV;
+
+	if (serial->dev->descriptor.idVendor == 0x19d2 &&
+	    serial->dev->descriptor.idProduct == 0x1476 &&
+	    serial->interface->cur_altsetting->desc. bInterfaceNumber == 4)
+		return -ENODEV;
+
+	if (serial->dev->descriptor.idVendor == 0x19d2 &&
+	    serial->dev->descriptor.idProduct == 0x1476 &&
+	    serial->interface->cur_altsetting->desc. bInterfaceNumber == 5)
+		return -ENODEV;
+#endif
 	/* Store the device flags so we can use them during attach. */
 	usb_set_serial_data(serial, (void *)device_flags);
 
diff -uprN linux-4.4.194/drivers/usb/serial/usb_wwan.c NUC980-linux-4.4.194/drivers/usb/serial/usb_wwan.c
--- linux-4.4.194/drivers/usb/serial/usb_wwan.c	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/usb/serial/usb_wwan.c	2019-12-29 19:12:21.000000000 -0800
@@ -504,7 +504,19 @@ static struct urb *usb_wwan_setup_urb(st
 	usb_fill_bulk_urb(urb, serial->dev,
 			  usb_sndbulkpipe(serial->dev, endpoint) | dir,
 			  buf, len, callback, ctx);
-
+#if 1 //Added by Quectel for zero packet
+	if (dir == USB_DIR_OUT) {
+		struct usb_device_descriptor *desc = &serial->dev->descriptor;
+		if (desc->idVendor == cpu_to_le16(0x05C6) && desc->idProduct == cpu_to_le16(0x9090))
+			urb->transfer_flags |= URB_ZERO_PACKET;
+		if (desc->idVendor == cpu_to_le16(0x05C6) && desc->idProduct == cpu_to_le16(0x9003))
+			urb->transfer_flags |= URB_ZERO_PACKET;
+		if (desc->idVendor == cpu_to_le16(0x05C6) && desc->idProduct == cpu_to_le16(0x9215))
+			urb->transfer_flags |= URB_ZERO_PACKET;
+		if (desc->idVendor == cpu_to_le16(0x2C7C))
+			urb->transfer_flags |= URB_ZERO_PACKET;
+	}
+#endif
 	return urb;
 }
 
diff -uprN linux-4.4.194/drivers/watchdog/Kconfig NUC980-linux-4.4.194/drivers/watchdog/Kconfig
--- linux-4.4.194/drivers/watchdog/Kconfig	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/watchdog/Kconfig	2019-12-29 19:12:21.000000000 -0800
@@ -426,6 +426,30 @@ config NUC900_WATCHDOG
 	  To compile this driver as a module, choose M here: the
 	  module will be called nuc900_wdt.
 
+config NUC980_WDT
+	tristate "Nuvoton NUC980 Watchdog Timer"
+	depends on ARCH_NUC980
+	select WATCHDOG_CORE
+	help
+	  Say Y here if to include support for the watchdog timer
+	  for the Nuvoton NUC980 series microprosser.
+	  To compile this driver as a module, choose M here: the
+	  module will be called nuc980_wdt.
+
+config NUC980_WDT_WKUP
+        tristate "NUC980 WDT wake-up support"
+        depends on NUC980_WDT
+
+config NUC980_WWDT
+	tristate "Nuvoton NUC980 Window Watchdog Timer"
+	depends on ARCH_NUC980
+	select WATCHDOG_CORE
+	help
+	  Say Y here if to include support for the window watchdog timer
+	  for the Nuvoton NUC980 series MCU.
+	  To compile this driver as a module, choose M here: the
+	  module will be called nuc980_wwdt.
+
 config TS72XX_WATCHDOG
 	tristate "TS-72XX SBC Watchdog"
 	depends on MACH_TS72XX
diff -uprN linux-4.4.194/drivers/watchdog/Makefile NUC980-linux-4.4.194/drivers/watchdog/Makefile
--- linux-4.4.194/drivers/watchdog/Makefile	2019-09-20 22:12:54.000000000 -0700
+++ NUC980-linux-4.4.194/drivers/watchdog/Makefile	2019-12-29 19:12:21.000000000 -0800
@@ -69,6 +69,8 @@ obj-$(CONFIG_MEDIATEK_WATCHDOG) += mtk_w
 obj-$(CONFIG_DIGICOLOR_WATCHDOG) += digicolor_wdt.o
 obj-$(CONFIG_LPC18XX_WATCHDOG) += lpc18xx_wdt.o
 obj-$(CONFIG_BCM7038_WDT) += bcm7038_wdt.o
+obj-$(CONFIG_NUC980_WDT) += nuc980_wdt.o
+obj-$(CONFIG_NUC980_WWDT) += nuc980_wwdt.o
 
 # AVR32 Architecture
 obj-$(CONFIG_AT32AP700X_WDT) += at32ap700x_wdt.o
diff -uprN linux-4.4.194/drivers/watchdog/nuc980_wdt.c NUC980-linux-4.4.194/drivers/watchdog/nuc980_wdt.c
--- linux-4.4.194/drivers/watchdog/nuc980_wdt.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/watchdog/nuc980_wdt.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,377 @@
+/*
+ * Copyright (c) 2018 Nuvoton Technology corporation.
+ *
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/bitops.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/types.h>
+#include <linux/watchdog.h>
+#include <linux/of.h>
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-gcr.h>
+#include <mach/regs-wdt.h>
+
+#define TOUTSEL			(0x07 << 8)     /* wdt interval selection */
+#define WDTEN			(0x01 << 7)	/* wdt enable*/
+#define INTEN			(0x01 << 6)
+#define WKF			(0x01 << 5)
+#define WKEN			(0x01 << 4)
+#define IF			(0x01 << 3)
+#define RSTF			(0x01 << 2)	/* wdt reset flag */
+#define RSTEN			(0x01 << 1)	/* wdt reset enable */
+/*
+ * Assumming 32k crystal is configured as the watchdog clock source,
+ * the time out interval can be calculated via following formula:
+ * TOUTSEL		real time interval (formula)
+ * 0x05		((2^ 14 + 1024) * (32k crystal freq))seconds = 0.53 sec
+ * 0x06		((2^ 16 + 1024) * (32k crystal freq))seconds = 2.03 sec
+ * 0x07		((2^ 18 + 1024) * (32k crystal freq))seconds = 8.03 sec
+ */
+#define WDT_HW_TIMEOUT		0x05
+
+#define RESET_COUNTER		0x00005AA5
+
+static int heartbeat = 2;	// default 2 second
+module_param(heartbeat, int, 0);
+MODULE_PARM_DESC(heartbeat, "Watchdog heartbeats in seconds. "
+	"(default = " __MODULE_STRING(WDT_HEARTBEAT) ")");
+
+static bool nowayout = WATCHDOG_NOWAYOUT;
+module_param(nowayout, bool, 0);
+MODULE_PARM_DESC(nowayout, "Watchdog cannot be stopped once started "
+	"(default=" __MODULE_STRING(WATCHDOG_NOWAYOUT) ")");
+
+struct nuc980_wdt {
+	struct resource		*res;
+	struct clk		*clk;
+	struct clk		*eclk;
+	struct platform_device	*pdev;
+};
+
+static struct nuc980_wdt *nuc980_wdt;
+
+// UnLock register write protect
+static void Unlock_RegWriteProtect(void)
+{
+    do {
+        __raw_writel(0x59, REG_WRPRTR);
+        __raw_writel(0x16, REG_WRPRTR);
+        __raw_writel(0x88, REG_WRPRTR);
+    //wait for write-protection disabled indicator raised
+    } while(!(__raw_readl(REG_WRPRTR) & 1));
+}
+
+// Lock register write protect
+static void Lock_RegWriteProtect(void)
+{
+    __raw_writel(0x0, REG_WRPRTR);
+}
+
+static int nuc980wdt_ping(struct watchdog_device *wdd)
+{
+	__raw_writel(RESET_COUNTER, REG_WDT_RSTCNT);
+	return 0;
+}
+
+
+static int nuc980wdt_start(struct watchdog_device *wdd)
+{
+	unsigned int val = RSTEN | WDTEN;
+	unsigned long flags;
+
+
+#ifdef CONFIG_NUC980_WDT_WKUP
+	val |= INTEN;
+	val |= WKEN;
+#endif
+
+	if(wdd->timeout < 2) {
+		val |= 0x5 << 8;
+	} else if (wdd->timeout < 8) {
+		val |= 0x6 << 8;
+	} else {
+		val |= 0x7 << 8;
+	}
+
+	local_irq_save(flags);
+	Unlock_RegWriteProtect();
+	__raw_writel(val, REG_WDT_CTL);
+	Lock_RegWriteProtect();
+	local_irq_restore(flags);
+	__raw_writel(RESET_COUNTER, REG_WDT_RSTCNT);
+
+	return 0;
+}
+
+static int nuc980wdt_stop(struct watchdog_device *wdd)
+{
+	unsigned long flags;
+
+	pr_warn("Stopping WDT is probably not a good idea\n");
+
+	local_irq_save(flags);
+	Unlock_RegWriteProtect();
+	__raw_writel(0, REG_WDT_CTL);
+	Lock_RegWriteProtect();
+	local_irq_restore(flags);
+	return 0;
+}
+
+
+static int nuc980wdt_set_timeout(struct watchdog_device *wdd, unsigned int timeout)
+{
+	unsigned int val;
+	unsigned long flags;
+
+
+	val = __raw_readl(REG_WDT_CTL);
+	val &= ~TOUTSEL;
+	if(timeout < 2) {
+		val |= 0x5 << 8;
+#ifdef CONFIG_NUC980_WDT_WKUP
+	} else if (timeout < 8) {
+#else
+	} else if (timeout < 11) {
+#endif
+		val |= 0x6 << 8;
+	} else {
+		val |= 0x7 << 8;
+	}
+
+	local_irq_save(flags);
+	Unlock_RegWriteProtect();
+	__raw_writel(val, REG_WDT_CTL);
+	Lock_RegWriteProtect();
+	local_irq_restore(flags);
+
+	return 0;
+}
+
+static const struct watchdog_info nuc980wdt_info = {
+	.identity	= "nuc980 watchdog",
+	.options	= WDIOF_SETTIMEOUT | WDIOF_KEEPALIVEPING | WDIOF_MAGICCLOSE,
+};
+
+static struct watchdog_ops nuc980wdt_ops = {
+	.owner = THIS_MODULE,
+	.start = nuc980wdt_start,
+	.stop = nuc980wdt_stop,
+	.ping = nuc980wdt_ping,
+	.set_timeout = nuc980wdt_set_timeout,
+};
+
+static struct watchdog_device nuc980_wdd = {
+	.status = WATCHDOG_NOWAYOUT_INIT_STATUS,
+	.info = &nuc980wdt_info,
+	.ops = &nuc980wdt_ops,
+};
+
+#ifdef CONFIG_NUC980_WDT_WKUP
+static irqreturn_t nuc980_wdt_interrupt(int irq, void *dev_id)
+{
+	__raw_writel(RESET_COUNTER, REG_WDT_RSTCNT);
+
+	Unlock_RegWriteProtect();
+	if (__raw_readl(REG_WDT_CTL) & IF) {
+		__raw_writel(__raw_readl(REG_WDT_CTL) | IF, REG_WDT_CTL);
+	}
+	Lock_RegWriteProtect();
+
+	return IRQ_HANDLED;
+};
+#endif
+
+static int nuc980wdt_probe(struct platform_device *pdev)
+{
+	int ret = 0;
+	struct clk *clkmux, *clksrc;
+
+	nuc980_wdt = devm_kzalloc(&pdev->dev, sizeof(struct nuc980_wdt), GFP_KERNEL);
+	if (!nuc980_wdt)
+		return -ENOMEM;
+
+	nuc980_wdt->pdev = pdev;
+
+	nuc980_wdt->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (nuc980_wdt->res == NULL) {
+		dev_err(&pdev->dev, "no memory resource specified\n");
+		return -ENOENT;
+	}
+
+	if (!devm_request_mem_region(&pdev->dev, nuc980_wdt->res->start,
+				resource_size(nuc980_wdt->res), pdev->name)) {
+		dev_err(&pdev->dev, "failed to get memory region\n");
+		return -ENOENT;
+	}
+
+	clkmux = clk_get(NULL, "wdt_eclk_mux");
+	if (IS_ERR(clkmux)) {
+		dev_err(&pdev->dev, "failed to get watchdog clock mux\n");
+		ret = PTR_ERR(clkmux);
+		return ret;
+	}
+#ifdef CONFIG_NUC980_WDT_WKUP
+	/* Need to select xin32k to support WDT wake up */
+	clksrc = clk_get(NULL, "xin32k");
+#else
+	clksrc = clk_get(NULL, "xin512_div");
+#endif
+	if (IS_ERR(clksrc)) {
+#ifdef CONFIG_NUC980_WDT_WKUP
+		dev_err(&pdev->dev, "failed to get xin32k clk\n");
+#else
+		dev_err(&pdev->dev, "failed to get xin/512 clk\n");
+#endif
+		ret = PTR_ERR(clksrc);
+		return ret;
+	}
+
+
+	clk_set_parent(clkmux, clksrc);
+
+	nuc980_wdt->clk = clk_get(NULL, "wdt");
+	if (IS_ERR(nuc980_wdt->clk)) {
+		dev_err(&pdev->dev, "failed to get watchdog clock\n");
+		ret = PTR_ERR(nuc980_wdt->clk);
+		return ret;
+	}
+
+	clk_prepare(nuc980_wdt->clk);
+	clk_enable(nuc980_wdt->clk);
+
+	nuc980_wdt->eclk = clk_get(NULL, "wdt_eclk");
+	if (IS_ERR(nuc980_wdt->eclk)) {
+		dev_err(&pdev->dev, "failed to get watchdog eclock\n");
+		ret = PTR_ERR(nuc980_wdt->eclk);
+		return ret;
+	}
+
+	clk_prepare(nuc980_wdt->eclk);
+	clk_enable(nuc980_wdt->eclk);
+#ifdef CONFIG_NUC980_WDT_WKUP
+	nuc980_wdd.timeout = 2;		// default time out = 2 sec
+	nuc980_wdd.min_timeout = 1;	// min time out = 1 sec
+	nuc980_wdd.max_timeout = 8;	// max time out = 8 sec
+#else
+	nuc980_wdd.timeout = 2;		// default time out = 2.8 sec
+	nuc980_wdd.min_timeout = 1;	// min time out = 1.4 sec
+	nuc980_wdd.max_timeout = 11;	// max time out = 11.2 sec
+#endif
+	watchdog_init_timeout(&nuc980_wdd, heartbeat, &pdev->dev);
+	watchdog_set_nowayout(&nuc980_wdd, nowayout);
+
+	nuc980_wdd.bootstatus = __raw_readl(REG_RSTSTS) & (1 << 5) ? WDIOF_CARDRESET : 0;
+
+	ret = watchdog_register_device(&nuc980_wdd);
+	if (ret) {
+		dev_err(&pdev->dev, "err register watchdog device\n");
+		clk_disable(nuc980_wdt->clk);
+		clk_put(nuc980_wdt->clk);
+		return ret;
+	}
+
+
+	return 0;
+}
+
+static int nuc980wdt_remove(struct platform_device *pdev)
+{
+	watchdog_unregister_device(&nuc980_wdd);
+
+	clk_disable(nuc980_wdt->eclk);
+	clk_put(nuc980_wdt->eclk);
+	clk_disable(nuc980_wdt->clk);
+	clk_put(nuc980_wdt->clk);
+
+	return 0;
+}
+
+static void nuc980wdt_shutdown(struct platform_device *pdev)
+{
+	nuc980wdt_stop(&nuc980_wdd);
+}
+
+#ifdef CONFIG_NUC980_WDT_WKUP
+static u32 reg_save;
+static int nuc980wdt_suspend(struct platform_device *dev, pm_message_t state)
+{
+	unsigned long flags;
+
+	reg_save = __raw_readl(REG_WDT_CTL);
+
+	local_irq_save(flags);
+	Unlock_RegWriteProtect();
+	__raw_writel(__raw_readl(REG_WDT_CTL) & ~RSTEN, REG_WDT_CTL); //Disable WDT reset
+	Lock_RegWriteProtect();
+	local_irq_restore(flags);
+
+	__raw_writel( (1 << 0) | __raw_readl(REG_WKUPSER0), REG_WKUPSER0); //Enable System WDT wakeup
+	if (request_irq(IRQ_WDT, nuc980_wdt_interrupt, IRQF_NO_SUSPEND, "nuc980wdt", NULL)) {
+		return -EBUSY;
+	}
+	enable_irq_wake(IRQ_WDT);
+
+	return 0;
+}
+
+static int nuc980wdt_resume(struct platform_device *dev)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	Unlock_RegWriteProtect();
+	__raw_writel(reg_save, REG_WDT_CTL);
+	Lock_RegWriteProtect();
+	local_irq_restore(flags);
+
+	__raw_writel(RESET_COUNTER, REG_WDT_RSTCNT);
+	disable_irq_wake(IRQ_WDT);
+	free_irq(IRQ_WDT, NULL);
+
+	return 0;
+}
+
+#else
+#define nuc980wdt_suspend NULL
+#define nuc980wdt_resume  NULL
+#endif /* CONFIG_NUC980_WDT_WKUP */
+
+static const struct of_device_id nuc980_wdt_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-wdt" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_wdt_of_match);
+
+static struct platform_driver nuc980wdt_driver = {
+	.probe		= nuc980wdt_probe,
+	.remove		= nuc980wdt_remove,
+	.shutdown	= nuc980wdt_shutdown,
+	.suspend	= nuc980wdt_suspend,
+	.resume		= nuc980wdt_resume,
+	.driver		= {
+		.name	= "nuc980-wdt",
+		.of_match_table = of_match_ptr(nuc980_wdt_of_match),
+		.owner	= THIS_MODULE,
+	},
+};
+
+module_platform_driver(nuc980wdt_driver);
+
+MODULE_DESCRIPTION("Watchdog driver for NUC980");
+MODULE_LICENSE("GPL");
diff -uprN linux-4.4.194/drivers/watchdog/nuc980_wwdt.c NUC980-linux-4.4.194/drivers/watchdog/nuc980_wwdt.c
--- linux-4.4.194/drivers/watchdog/nuc980_wwdt.c	1969-12-31 16:00:00.000000000 -0800
+++ NUC980-linux-4.4.194/drivers/watchdog/nuc980_wwdt.c	2019-12-29 19:12:21.000000000 -0800
@@ -0,0 +1,219 @@
+/*
+ * Copyright (c) 2018 Nuvoton technology corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation;version 2 of the License.
+ *
+ */
+
+#include <linux/bitops.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/types.h>
+#include <linux/watchdog.h>
+#include <linux/of.h>
+#include <mach/map.h>
+#include <mach/regs-clock.h>
+#include <mach/regs-wwdt.h>
+
+#define RELOAD_WORD	0x00005AA5
+
+/*
+ *  Select WWDT clock source from 12M/512.
+ *  Here we set compare window to 32, and prescale to 1024 after init.
+ *
+ *  So WWDT time out every 2048 * 32 * (512/12000000) = 2.79 second,
+ *  And software has another 2.79 second window period to reload
+ *  WWDT counter by writing RELOAD_WORD to REG_WWDT_RLD register.
+ */
+#define WWDT_CONFIG	0x00200F01
+
+struct nuc980_wwdt {
+	struct resource		*res;
+	struct platform_device	*pdev;
+};
+
+static struct nuc980_wwdt *nuc980_wwdt;
+
+static int nuc980wwdt_ping(struct watchdog_device *wdd)
+{
+	__raw_writel(RELOAD_WORD, REG_WWDT_RLD);
+	return 0;
+}
+
+static int nuc980wwdt_start(struct watchdog_device *wdd)
+{
+	__raw_writel(WWDT_CONFIG, REG_WWDT_CR);
+	return 0;
+}
+
+/*
+ *  This function always return error, we define it here simply because stop() is mandatory operation.
+ *  Due to the fact that WWDT register can only be programmed once, so there is NO WAY OUT!!!
+ */
+static int nuc980wwdt_stop(struct watchdog_device *wdd)
+{
+
+	return -EBUSY;
+}
+
+static unsigned int nuc980wwdt_get_timeleft(struct watchdog_device *wdd)
+{
+	unsigned int time_left;
+
+	time_left = __raw_readl(REG_WWDT_CVR) / 32;
+
+	return time_left;
+}
+
+static const struct watchdog_info nuc980wwdt_info = {
+	.identity	= "nuc980 window watchdog",
+	.options	= WDIOF_KEEPALIVEPING,
+};
+
+static struct watchdog_ops nuc980wwdt_ops = {
+	.owner 	= THIS_MODULE,
+	.start 	= nuc980wwdt_start,
+	.stop 	= nuc980wwdt_stop,
+	.ping 	= nuc980wwdt_ping,
+	.get_timeleft = nuc980wwdt_get_timeleft,
+};
+
+static struct watchdog_device nuc980_wdd = {
+	.status	= WATCHDOG_NOWAYOUT_INIT_STATUS,
+	.info 	= &nuc980wwdt_info,
+	.ops 	= &nuc980wwdt_ops,
+	.timeout = 2,
+};
+
+
+static int nuc980wwdt_probe(struct platform_device *pdev)
+{
+	int ret = 0;
+	struct clk *clk, *eclk, *clkmux, *clksrc;
+
+	nuc980_wwdt = devm_kzalloc(&pdev->dev, sizeof(struct nuc980_wwdt), GFP_KERNEL);
+	if (!nuc980_wwdt)
+		return -ENOMEM;
+
+	nuc980_wwdt->pdev = pdev;
+
+	nuc980_wwdt->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (nuc980_wwdt->res == NULL) {
+		dev_err(&pdev->dev, "no memory resource specified\n");
+		return -ENOENT;
+	}
+
+	if (!devm_request_mem_region(&pdev->dev, nuc980_wwdt->res->start,
+				resource_size(nuc980_wwdt->res), pdev->name)) {
+		dev_err(&pdev->dev, "failed to get memory region\n");
+		return -ENOENT;
+	}
+
+
+	clkmux = clk_get(NULL, "wwdt_eclk_mux");
+	if (IS_ERR(clkmux)) {
+		dev_err(&pdev->dev, "failed to get wwdt clock mux\n");
+		ret = PTR_ERR(clkmux);
+		return ret;
+	}
+
+	clksrc = clk_get(NULL, "xin512_div");
+	if (IS_ERR(clksrc)) {
+		dev_err(&pdev->dev, "failed to get xin/512 clk\n");
+		ret = PTR_ERR(clksrc);
+		return ret;
+	}
+
+
+	clk_set_parent(clkmux, clksrc);
+
+	clk = clk_get(NULL, "wwdt");
+	if (IS_ERR(clk)) {
+		dev_err(&pdev->dev, "failed to get wwdt clock\n");
+		ret = PTR_ERR(clk);
+		return ret;
+	}
+
+	clk_prepare(clk);
+	clk_enable(clk);
+
+	eclk = clk_get(NULL, "wwdt_eclk");
+	if (IS_ERR(eclk)) {
+		dev_err(&pdev->dev, "failed to get wwdt clock\n");
+		ret = PTR_ERR(eclk);
+		return ret;
+	}
+
+	clk_prepare(eclk);
+	clk_enable(eclk);
+
+	ret = watchdog_register_device(&nuc980_wdd);
+	if (ret) {
+		dev_err(&pdev->dev, "err register window watchdog device\n");
+		return ret;
+	}
+
+	return 0;
+
+}
+
+static int nuc980wwdt_remove(struct platform_device *pdev)
+{
+
+	watchdog_unregister_device(&nuc980_wdd);
+	// There's no way out~~~~
+	/* You can check-out any time you like
+	   But you can never leave! */
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int nuc980wwdt_suspend(struct platform_device *dev, pm_message_t state)
+{
+        return 0;
+}
+
+static int nuc980wwdt_resume(struct platform_device *dev)
+{
+        return 0;
+}
+
+#else
+#define nuc980wwdt_suspend NULL
+#define nuc980wwdt_resume  NULL
+#endif /* CONFIG_PM */
+
+static const struct of_device_id nuc980_wwdt_of_match[] = {
+	{ .compatible = "nuvoton,nuc980-wwdt" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nuc980_wwdt_of_match);
+
+
+static struct platform_driver nuc980wwdt_driver = {
+	.probe		= nuc980wwdt_probe,
+	.remove		= nuc980wwdt_remove,
+	.suspend        = nuc980wwdt_suspend,
+        .resume         = nuc980wwdt_resume,
+	.driver		= {
+		.name	= "nuc980-wwdt",
+		.of_match_table = of_match_ptr(nuc980_wwdt_of_match),
+		.owner	= THIS_MODULE,
+	},
+};
+
+module_platform_driver(nuc980wwdt_driver);
+
+MODULE_DESCRIPTION("NUC980 Window Watchdog Timer Driver");
+MODULE_LICENSE("GPL");
